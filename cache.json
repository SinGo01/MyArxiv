{"2024-10-07T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2410.05269v1","updated":"2024-10-07T17:59:58Z","published":"2024-10-07T17:59:58Z","title":"Data Advisor: Dynamic Data Curation for Safety Alignment of Large\n  Language Models","summary":"  Data is a crucial element in large language model (LLM) alignment. Recent\nstudies have explored using LLMs for efficient data collection. However,\nLLM-generated data often suffers from quality issues, with underrepresented or\nabsent aspects and low-quality datapoints. To address these problems, we\npropose Data Advisor, an enhanced LLM-based method for generating data that\ntakes into account the characteristics of the desired dataset. Starting from a\nset of pre-defined principles in hand, Data Advisor monitors the status of the\ngenerated data, identifies weaknesses in the current dataset, and advises the\nnext iteration of data generation accordingly. Data Advisor can be easily\nintegrated into existing data generation methods to enhance data quality and\ncoverage. Experiments on safety alignment of three representative LLMs (i.e.,\nMistral, Llama2, and Falcon) demonstrate the effectiveness of Data Advisor in\nenhancing model safety against various fine-grained safety issues without\nsacrificing model utility.\n","authors":["Fei Wang","Ninareh Mehrabi","Palash Goyal","Rahul Gupta","Kai-Wei Chang","Aram Galstyan"],"pdf_url":"https://arxiv.org/pdf/2410.05269v1.pdf","comment":"Accepted to EMNLP 2024 Main Conference. Project website:\n  https://feiwang96.github.io/DataAdvisor/"},{"id":"http://arxiv.org/abs/2410.05267v1","updated":"2024-10-07T17:59:48Z","published":"2024-10-07T17:59:48Z","title":"Grounding Partially-Defined Events in Multimodal Data","summary":"  How are we able to learn about complex current events just from short\nsnippets of video? While natural language enables straightforward ways to\nrepresent under-specified, partially observable events, visual data does not\nfacilitate analogous methods and, consequently, introduces unique challenges in\nevent understanding. With the growing prevalence of vision-capable AI agents,\nthese systems must be able to model events from collections of unstructured\nvideo data. To tackle robust event modeling in multimodal settings, we\nintroduce a multimodal formulation for partially-defined events and cast the\nextraction of these events as a three-stage span retrieval task. We propose a\ncorresponding benchmark for this task, MultiVENT-G, that consists of 14.5 hours\nof densely annotated current event videos and 1,168 text documents, containing\n22.8K labeled event-centric entities. We propose a collection of LLM-driven\napproaches to the task of multimodal event analysis, and evaluate them on\nMultiVENT-G. Results illustrate the challenges that abstract event\nunderstanding poses and demonstrates promise in event-centric video-language\nsystems.\n","authors":["Kate Sanders","Reno Kriz","David Etter","Hannah Recknor","Alexander Martin","Cameron Carpenter","Jingyang Lin","Benjamin Van Durme"],"pdf_url":"https://arxiv.org/pdf/2410.05267v1.pdf","comment":"Preprint; 9 pages; 2024 EMNLP Findings"},{"id":"http://arxiv.org/abs/2406.11839v2","updated":"2024-10-07T17:59:42Z","published":"2024-06-17T17:59:58Z","title":"mDPO: Conditional Preference Optimization for Multimodal Large Language\n  Models","summary":"  Direct preference optimization (DPO) has shown to be an effective method for\nlarge language model (LLM) alignment. Recent works have attempted to apply DPO\nto multimodal scenarios but have found it challenging to achieve consistent\nimprovement. Through a comparative experiment, we identify the unconditional\npreference problem in multimodal preference optimization, where the model\noverlooks the image condition. To address this problem, we propose mDPO, a\nmultimodal DPO objective that prevents the over-prioritization of language-only\npreferences by also optimizing image preference. Moreover, we introduce a\nreward anchor that forces the reward to be positive for chosen responses,\nthereby avoiding the decrease in their likelihood -- an intrinsic problem of\nrelative preference optimization. Experiments on two multimodal LLMs of\ndifferent sizes and three widely used benchmarks demonstrate that mDPO\neffectively addresses the unconditional preference problem in multimodal\npreference optimization and significantly improves model performance,\nparticularly in reducing hallucination.\n","authors":["Fei Wang","Wenxuan Zhou","James Y. Huang","Nan Xu","Sheng Zhang","Hoifung Poon","Muhao Chen"],"pdf_url":"https://arxiv.org/pdf/2406.11839v2.pdf","comment":"Accepted to EMNLP 2024 Main Conference. Project website:\n  https://feiwang96.github.io/mDPO"},{"id":"http://arxiv.org/abs/2410.05265v1","updated":"2024-10-07T17:59:35Z","published":"2024-10-07T17:59:35Z","title":"PrefixQuant: Static Quantization Beats Dynamic through Prefixed Outliers\n  in LLMs","summary":"  Quantization is essential for deploying Large Language Models (LLMs) by\nenhancing memory efficiency and inference speed. Existing methods for\nactivation quantization mainly address channel-wise outliers, often neglecting\ntoken-wise outliers, leading to reliance on costly per-token dynamic\nquantization. To address this, we introduce PrefixQuant, a novel technique that\nisolates outlier tokens offline without re-training. Specifically, PrefixQuant\nidentifies high-frequency outlier tokens and prefixes them in the KV cache,\npreventing the generation of outlier tokens during inference and simplifying\nquantization. To our knowledge, PrefixQuant is the first to enable efficient\nper-tensor static quantization to outperform expensive per-token dynamic\nquantization. For instance, in W4A4KV4 (4- bit weight, 4-bit activation, and\n4-bit KV cache) Llama-3-8B, PrefixQuant with per-tensor static quantization\nachieves a 7.43 WikiText2 perplexity and 71.08% average accuracy on 5\ncommon-sense reasoning tasks, outperforming previous per-token dynamic\nquantization methods like QuaRot with 0.98 perplexity improvement and +5.98\npoints accuracy. Additionally, the inference speed of W4A4 quantized models\nusing PrefixQuant is 1.60x to 2.81x faster than FP16 models and exceeds QuaRot\nmodels by 1.2x to 1.3x. Our code is available at\n\\url{https://github.com/ChenMnZ/PrefixQuant}.\n","authors":["Mengzhao Chen","Yi Liu","Jiahao Wang","Yi Bin","Wenqi Shao","Ping Luo"],"pdf_url":"https://arxiv.org/pdf/2410.05265v1.pdf","comment":"A PTQ method to significantly boost the performance of static\n  activation quantization"},{"id":"http://arxiv.org/abs/2410.05262v1","updated":"2024-10-07T17:58:47Z","published":"2024-10-07T17:58:47Z","title":"TurtleBench: Evaluating Top Language Models via Real-World Yes/No\n  Puzzles","summary":"  As the application of Large Language Models (LLMs) expands, the demand for\nreliable evaluations increases. Existing LLM evaluation benchmarks primarily\nrely on static datasets, making it challenging to assess model performance in\ndynamic interactions with users. Moreover, these benchmarks often depend on\nspecific background knowledge, complicating the measurement of a model's\nlogical reasoning capabilities. Other dynamic evaluation methods based on\nstrong models or manual efforts may introduce biases and incur high costs and\ntime demands, hindering large-scale application. To address these issues, we\npropose TurtleBench. TurtleBench collects real user guesses from our online\nTurtle Soup Puzzle platform that we developed. This approach allows for the\nrelatively dynamic generation of evaluation datasets, mitigating the risk of\nmodel cheating while aligning assessments more closely with genuine user needs\nfor reasoning capabilities, thus enhancing the reliability of evaluations.\nTurtleBench includes 1,532 user guesses along with the correctness of guesses\nafter annotation. Using this dataset, we thoroughly evaluated nine of the most\nadvanced LLMs available today. Notably, the OpenAI o1 series models did not\nachieve leading results in these evaluations. We propose several hypotheses for\nfurther research, such as \"the latent reasoning of o1 utilizes trivial\nChain-of-Thought (CoT) techniques\" and \"increasing CoT length not only provides\nreasoning benefits but also incurs noise costs.\"\n","authors":["Qingchen Yu","Shichao Song","Ke Fang","Yunfeng Shi","Zifan Zheng","Hanyu Wang","Simin Niu","Zhiyu Li"],"pdf_url":"https://arxiv.org/pdf/2410.05262v1.pdf","comment":"22 pages"},{"id":"http://arxiv.org/abs/2410.05258v1","updated":"2024-10-07T17:57:38Z","published":"2024-10-07T17:57:38Z","title":"Differential Transformer","summary":"  Transformer tends to overallocate attention to irrelevant context. In this\nwork, we introduce Diff Transformer, which amplifies attention to the relevant\ncontext while canceling noise. Specifically, the differential attention\nmechanism calculates attention scores as the difference between two separate\nsoftmax attention maps. The subtraction cancels noise, promoting the emergence\nof sparse attention patterns. Experimental results on language modeling show\nthat Diff Transformer outperforms Transformer in various settings of scaling up\nmodel size and training tokens. More intriguingly, it offers notable advantages\nin practical applications, such as long-context modeling, key information\nretrieval, hallucination mitigation, in-context learning, and reduction of\nactivation outliers. By being less distracted by irrelevant context, Diff\nTransformer can mitigate hallucination in question answering and text\nsummarization. For in-context learning, Diff Transformer not only enhances\naccuracy but is also more robust to order permutation, which was considered as\na chronic robustness issue. The results position Diff Transformer as a highly\neffective and promising architecture to advance large language models.\n","authors":["Tianzhu Ye","Li Dong","Yuqing Xia","Yutao Sun","Yi Zhu","Gao Huang","Furu Wei"],"pdf_url":"https://arxiv.org/pdf/2410.05258v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.05254v1","updated":"2024-10-07T17:55:35Z","published":"2024-10-07T17:55:35Z","title":"GLEE: A Unified Framework and Benchmark for Language-based Economic\n  Environments","summary":"  Large Language Models (LLMs) show significant potential in economic and\nstrategic interactions, where communication via natural language is often\nprevalent. This raises key questions: Do LLMs behave rationally? Can they mimic\nhuman behavior? Do they tend to reach an efficient and fair outcome? What is\nthe role of natural language in the strategic interaction? How do\ncharacteristics of the economic environment influence these dynamics? These\nquestions become crucial concerning the economic and societal implications of\nintegrating LLM-based agents into real-world data-driven systems, such as\nonline retail platforms and recommender systems. While the ML community has\nbeen exploring the potential of LLMs in such multi-agent setups, varying\nassumptions, design choices and evaluation criteria across studies make it\ndifficult to draw robust and meaningful conclusions. To address this, we\nintroduce a benchmark for standardizing research on two-player, sequential,\nlanguage-based games. Inspired by the economic literature, we define three base\nfamilies of games with consistent parameterization, degrees of freedom and\neconomic measures to evaluate agents' performance (self-gain), as well as the\ngame outcome (efficiency and fairness). We develop an open-source framework for\ninteraction simulation and analysis, and utilize it to collect a dataset of LLM\nvs. LLM interactions across numerous game configurations and an additional\ndataset of human vs. LLM interactions. Through extensive experimentation, we\ndemonstrate how our framework and dataset can be used to: (i) compare the\nbehavior of LLM-based agents to human players in various economic contexts;\n(ii) evaluate agents in both individual and collective performance measures;\nand (iii) quantify the effect of the economic characteristics of the\nenvironments on the behavior of agents.\n","authors":["Eilam Shapira","Omer Madmon","Itamar Reinman","Samuel Joseph Amouyal","Roi Reichart","Moshe Tennenholtz"],"pdf_url":"https://arxiv.org/pdf/2410.05254v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.05252v1","updated":"2024-10-07T17:55:10Z","published":"2024-10-07T17:55:10Z","title":"Causal Micro-Narratives","summary":"  We present a novel approach to classify causal micro-narratives from text.\nThese narratives are sentence-level explanations of the cause(s) and/or\neffect(s) of a target subject. The approach requires only a subject-specific\nontology of causes and effects, and we demonstrate it with an application to\ninflation narratives. Using a human-annotated dataset spanning historical and\ncontemporary US news articles for training, we evaluate several large language\nmodels (LLMs) on this multi-label classification task. The best-performing\nmodel--a fine-tuned Llama 3.1 8B--achieves F1 scores of 0.87 on narrative\ndetection and 0.71 on narrative classification. Comprehensive error analysis\nreveals challenges arising from linguistic ambiguity and highlights how model\nerrors often mirror human annotator disagreements. This research establishes a\nframework for extracting causal micro-narratives from real-world data, with\nwide-ranging applications to social science research.\n","authors":["Mourad Heddaya","Qingcheng Zeng","Chenhao Tan","Rob Voigt","Alexander Zentefis"],"pdf_url":"https://arxiv.org/pdf/2410.05252v1.pdf","comment":"Accepted to EMNLP 2024 Workshop on Narrative Understanding"},{"id":"http://arxiv.org/abs/2410.05248v1","updated":"2024-10-07T17:52:21Z","published":"2024-10-07T17:52:21Z","title":"SFTMix: Elevating Language Model Instruction Tuning with Mixup Recipe","summary":"  To induce desired behaviors in large language models (LLMs) for\ninteraction-driven tasks, the instruction-tuning stage typically trains LLMs on\ninstruction-response pairs using the next-token prediction (NTP) loss. Previous\nwork aiming to improve instruction-tuning performance often emphasizes the need\nfor higher-quality supervised fine-tuning (SFT) datasets, which typically\ninvolves expensive data filtering with proprietary LLMs or labor-intensive data\ngeneration by human annotators. However, these approaches do not fully leverage\nthe datasets' intrinsic properties, resulting in high computational and labor\ncosts, thereby limiting scalability and performance gains. In this paper, we\npropose SFTMix, a novel recipe that elevates instruction-tuning performance\nbeyond the conventional NTP paradigm, without the need for well-curated\ndatasets. Observing that LLMs exhibit uneven confidence across the semantic\nrepresentation space, we argue that examples with different confidence levels\nshould play distinct roles during the instruction-tuning process. Based on this\ninsight, SFTMix leverages training dynamics to identify examples with varying\nconfidence levels, then applies a Mixup-based regularization to mitigate\noverfitting on confident examples while propagating supervision signals to\nimprove learning on relatively unconfident ones. This approach enables SFTMix\nto significantly outperform NTP across a wide range of instruction-following\nand healthcare domain-specific SFT tasks, demonstrating its adaptability to\ndiverse LLM families and scalability to datasets of any size. Comprehensive\nablation studies further verify the robustness of SFTMix's design choices,\nunderscoring its versatility in consistently enhancing performance across\ndifferent LLMs and datasets in broader natural language processing\napplications.\n","authors":["Yuxin Xiao","Shujian Zhang","Wenxuan Zhou","Marzyeh Ghassemi","Sanqiang Zhao"],"pdf_url":"https://arxiv.org/pdf/2410.05248v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17975v2","updated":"2024-10-07T17:49:13Z","published":"2024-06-25T23:12:07Z","title":"SoK: Membership Inference Attacks on LLMs are Rushing Nowhere (and How\n  to Fix It)","summary":"  Whether LLMs memorize their training data and what this means, from privacy\nleakage to detecting copyright violations -- has become a rapidly growing area\nof research over the last two years. In recent months, more than 10 new methods\nhave been proposed to perform Membership Inference Attacks (MIAs) against LLMs.\nContrary to traditional MIAs which rely on fixed -- but randomized -- records\nor models, these methods are mostly evaluated on datasets collected post-hoc.\nSets of members and non-members, used to evaluate the MIA, are constructed\nusing informed guesses after the release of a model. This lack of randomization\nraises concerns of a distribution shift between members and non-members. In the\nfirst part, we review the literature on MIAs against LLMs. While most work\nfocuses on sequence-level MIAs evaluated in post-hoc setups, we show that a\nrange of target models, motivations and units of interest have been considered\nin the literature. We then quantify distribution shifts present in the 6\ndatasets used in the literature, ranging from books to papers, using a bag of\nword classifier. Our analysis reveals that all of them suffer from severe\ndistribution shifts. This challenges the validity of using such setups to\nmeasure LLM memorization and may undermine the benchmarking of recently\nproposed methods. Yet, all hope might not be lost. In the second part, we\nintroduce important considerations to properly evaluate MIAs against LLMs and\ndiscuss potential ways forward: randomized test splits, injections of\nrandomized (unique) sequences, randomized finetuning, and post-hoc control\nmethods. While each option comes with its advantages and limitations, we\nbelieve they collectively provide solid grounds to guide the development of MIA\nmethods and study LLM memorization. We conclude by proposing comprehensive,\neasy-to-use benchmarks for sequence- and document-level MIAs against LLMs.\n","authors":["Matthieu Meeus","Igor Shilov","Shubham Jain","Manuel Faysse","Marek Rei","Yves-Alexandre de Montjoye"],"pdf_url":"https://arxiv.org/pdf/2406.17975v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.05243v1","updated":"2024-10-07T17:47:50Z","published":"2024-10-07T17:47:50Z","title":"Navigating the Digital World as Humans Do: Universal Visual Grounding\n  for GUI Agents","summary":"  Multimodal large language models (MLLMs) are transforming the capabilities of\ngraphical user interface (GUI) agents, facilitating their transition from\ncontrolled simulations to complex, real-world applications across various\nplatforms. However, the effectiveness of these agents hinges on the robustness\nof their grounding capability. Current GUI agents predominantly utilize\ntext-based representations such as HTML or accessibility trees, which, despite\ntheir utility, often introduce noise, incompleteness, and increased\ncomputational overhead. In this paper, we advocate a human-like embodiment for\nGUI agents that perceive the environment entirely visually and directly take\npixel-level operations on the GUI. The key is visual grounding models that can\naccurately map diverse referring expressions of GUI elements to their\ncoordinates on the GUI across different platforms. We show that a simple\nrecipe, which includes web-based synthetic data and slight adaptation of the\nLLaVA architecture, is surprisingly effective for training such visual\ngrounding models. We collect the largest dataset for GUI visual grounding so\nfar, containing 10M GUI elements and their referring expressions over 1.3M\nscreenshots, and use it to train UGround, a strong universal visual grounding\nmodel for GUI agents. Empirical results on six benchmarks spanning three\ncategories (grounding, offline agent, and online agent) show that 1) UGround\nsubstantially outperforms existing visual grounding models for GUI agents, by\nup to 20% absolute, and 2) agents with UGround outperform state-of-the-art\nagents, despite the fact that existing agents use additional text-based input\nwhile ours only uses visual perception. These results provide strong support\nfor the feasibility and promises of GUI agents that navigate the digital world\nas humans do.\n","authors":["Boyu Gou","Ruohan Wang","Boyuan Zheng","Yanan Xie","Cheng Chang","Yiheng Shu","Huan Sun","Yu Su"],"pdf_url":"https://arxiv.org/pdf/2410.05243v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.01574v5","updated":"2024-10-07T17:46:08Z","published":"2024-06-03T17:53:00Z","title":"MMLU-Pro: A More Robust and Challenging Multi-Task Language\n  Understanding Benchmark (Published at NeurIPS 2024 Track Datasets and\n  Benchmarks)","summary":"  In the age of large-scale language models, benchmarks like the Massive\nMultitask Language Understanding (MMLU) have been pivotal in pushing the\nboundaries of what AI can achieve in language comprehension and reasoning\nacross diverse domains. However, as models continue to improve, their\nperformance on these benchmarks has begun to plateau, making it increasingly\ndifficult to discern differences in model capabilities. This paper introduces\nMMLU-Pro, an enhanced dataset designed to extend the mostly knowledge-driven\nMMLU benchmark by integrating more challenging, reasoning-focused questions and\nexpanding the choice set from four to ten options. Additionally, MMLU-Pro\neliminates the trivial and noisy questions in MMLU. Our experimental results\nshow that MMLU-Pro not only raises the challenge, causing a significant drop in\naccuracy by 16% to 33% compared to MMLU but also demonstrates greater stability\nunder varying prompts. With 24 different prompt styles tested, the sensitivity\nof model scores to prompt variations decreased from 4-5% in MMLU to just 2% in\nMMLU-Pro. Additionally, we found that models utilizing Chain of Thought (CoT)\nreasoning achieved better performance on MMLU-Pro compared to direct answering,\nwhich is in stark contrast to the findings on the original MMLU, indicating\nthat MMLU-Pro includes more complex reasoning questions. Our assessments\nconfirm that MMLU-Pro is a more discriminative benchmark to better track\nprogress in the field.\n","authors":["Yubo Wang","Xueguang Ma","Ge Zhang","Yuansheng Ni","Abhranil Chandra","Shiguang Guo","Weiming Ren","Aaran Arulraj","Xuan He","Ziyan Jiang","Tianle Li","Max Ku","Kai Wang","Alex Zhuang","Rongqi Fan","Xiang Yue","Wenhu Chen"],"pdf_url":"https://arxiv.org/pdf/2406.01574v5.pdf","comment":"This version has been accepted and published at NeurIPS 2024 Track\n  Datasets and Benchmarks (Spotlight)"},{"id":"http://arxiv.org/abs/2410.05239v1","updated":"2024-10-07T17:42:53Z","published":"2024-10-07T17:42:53Z","title":"TuneVLSeg: Prompt Tuning Benchmark for Vision-Language Segmentation\n  Models","summary":"  Vision-Language Models (VLMs) have shown impressive performance in vision\ntasks, but adapting them to new domains often requires expensive fine-tuning.\nPrompt tuning techniques, including textual, visual, and multimodal prompting,\noffer efficient alternatives by leveraging learnable prompts. However, their\napplication to Vision-Language Segmentation Models (VLSMs) and evaluation under\nsignificant domain shifts remain unexplored. This work presents an open-source\nbenchmarking framework, TuneVLSeg, to integrate various unimodal and multimodal\nprompt tuning techniques into VLSMs, making prompt tuning usable for downstream\nsegmentation datasets with any number of classes. TuneVLSeg includes $6$ prompt\ntuning strategies on various prompt depths used in $2$ VLSMs totaling of $8$\ndifferent combinations. We test various prompt tuning on $8$ diverse medical\ndatasets, including $3$ radiology datasets (breast tumor, echocardiograph,\nchest X-ray pathologies) and $5$ non-radiology datasets (polyp, ulcer, skin\ncancer), and two natural domain segmentation datasets. Our study found that\ntextual prompt tuning struggles under significant domain shifts, from\nnatural-domain images to medical data. Furthermore, visual prompt tuning, with\nfewer hyperparameters than multimodal prompt tuning, often achieves performance\ncompetitive to multimodal approaches, making it a valuable first attempt. Our\nwork advances the understanding and applicability of different prompt-tuning\ntechniques for robust domain-specific segmentation. The source code is\navailable at https://github.com/naamiinepal/tunevlseg.\n","authors":["Rabin Adhikari","Safal Thapaliya","Manish Dhakal","Bishesh Khanal"],"pdf_url":"https://arxiv.org/pdf/2410.05239v1.pdf","comment":"Accepted at ACCV 2024 (oral presentation)"},{"id":"http://arxiv.org/abs/2410.05235v1","updated":"2024-10-07T17:41:45Z","published":"2024-10-07T17:41:45Z","title":"CasiMedicos-Arg: A Medical Question Answering Dataset Annotated with\n  Explanatory Argumentative Structures","summary":"  Explaining Artificial Intelligence (AI) decisions is a major challenge\nnowadays in AI, in particular when applied to sensitive scenarios like medicine\nand law. However, the need to explain the rationale behind decisions is a main\nissue also for human-based deliberation as it is important to justify\n\\textit{why} a certain decision has been taken. Resident medical doctors for\ninstance are required not only to provide a (possibly correct) diagnosis, but\nalso to explain how they reached a certain conclusion. Developing new tools to\naid residents to train their explanation skills is therefore a central\nobjective of AI in education. In this paper, we follow this direction, and we\npresent, to the best of our knowledge, the first multilingual dataset for\nMedical Question Answering where correct and incorrect diagnoses for a clinical\ncase are enriched with a natural language explanation written by doctors. These\nexplanations have been manually annotated with argument components (i.e.,\npremise, claim) and argument relations (i.e., attack, support), resulting in\nthe Multilingual CasiMedicos-Arg dataset which consists of 558 clinical cases\nin four languages (English, Spanish, French, Italian) with explanations, where\nwe annotated 5021 claims, 2313 premises, 2431 support relations, and 1106\nattack relations. We conclude by showing how competitive baselines perform over\nthis challenging dataset for the argument mining task.\n","authors":["katerina Sviridova","Anar Yeginbergen","Ainara Estarrona","Elena Cabrio","Serena Villata","Rodrigo Agerri"],"pdf_url":"https://arxiv.org/pdf/2410.05235v1.pdf","comment":"9 pages"},{"id":"http://arxiv.org/abs/2410.05224v1","updated":"2024-10-07T17:29:40Z","published":"2024-10-07T17:29:40Z","title":"Cookbook: A framework for improving LLM generative abilities via\n  programmatic data generating templates","summary":"  Fine-tuning large language models (LLMs) on instruction datasets is a common\nway to improve their generative capabilities. However, instruction datasets can\nbe expensive and time-consuming to manually curate, and while LLM-generated\ndata is less labor-intensive, it may violate user privacy agreements or terms\nof service of LLM providers. Therefore, we seek a way of constructing\ninstruction datasets with samples that are not generated by humans or LLMs but\nstill improve LLM generative capabilities. In this work, we introduce Cookbook,\na framework that programmatically generates training data consisting of simple\npatterns over random tokens, resulting in a scalable, cost-effective approach\nthat avoids legal and privacy issues. First, Cookbook uses a template -- a data\ngenerating Python function -- to produce training data that encourages the\nmodel to learn an explicit pattern-based rule that corresponds to a desired\ntask. We find that fine-tuning on Cookbook-generated data is able to improve\nperformance on its corresponding task by up to 52.7 accuracy points. Second,\nsince instruction datasets improve performance on multiple downstream tasks\nsimultaneously, Cookbook algorithmically learns how to mix data from various\ntemplates to optimize performance on multiple tasks. On the standard multi-task\nGPT4ALL evaluation suite, Mistral-7B fine-tuned using a Cookbook-generated\ndataset attains the best accuracy on average compared to other 7B parameter\ninstruction-tuned models and is the best performing model on 3 out of 8 tasks.\nFinally, we analyze when and why Cookbook improves performance and present a\nmetric that allows us to verify that the improvement is largely explained by\nthe model's generations adhering better to template rules.\n","authors":["Avanika Narayan","Mayee F. Chen","Kush Bhatia","Christopher Ré"],"pdf_url":"https://arxiv.org/pdf/2410.05224v1.pdf","comment":"COLM 2024"},{"id":"http://arxiv.org/abs/2410.05222v1","updated":"2024-10-07T17:26:31Z","published":"2024-10-07T17:26:31Z","title":"Precise Model Benchmarking with Only a Few Observations","summary":"  How can we precisely estimate a large language model's (LLM) accuracy on\nquestions belonging to a specific topic within a larger question-answering\ndataset? The standard direct estimator, which averages the model's accuracy on\nthe questions in each subgroup, may exhibit high variance for subgroups\n(topics) with small sample sizes. Synthetic regression modeling, which\nleverages the model's accuracy on questions about other topics, may yield\nbiased estimates that are too unreliable for large subgroups. We prescribe a\nsimple yet effective solution: an empirical Bayes (EB) estimator that balances\ndirect and regression estimates for each subgroup separately, improving the\nprecision of subgroup-level estimates of model performance. Our experiments on\nmultiple datasets show that this approach consistently provides more precise\nestimates of the LLM performance compared to the direct and regression\napproaches, achieving substantial reductions in the mean squared error.\nConfidence intervals for EB estimates also have near-nominal coverage and are\nnarrower compared to those for the direct estimator. Additional experiments on\ntabular and vision data validate the benefits of this EB approach.\n","authors":["Riccardo Fogliato","Pratik Patil","Nil-Jana Akpinar","Mathew Monfort"],"pdf_url":"https://arxiv.org/pdf/2410.05222v1.pdf","comment":"To appear at EMNLP 2024"},{"id":"http://arxiv.org/abs/2406.15877v3","updated":"2024-10-07T17:23:30Z","published":"2024-06-22T15:52:04Z","title":"BigCodeBench: Benchmarking Code Generation with Diverse Function Calls\n  and Complex Instructions","summary":"  Task automation has been greatly empowered by the recent advances in Large\nLanguage Models (LLMs) via Python code, where the tasks ranging from software\nengineering development to general-purpose reasoning. While current benchmarks\nhave shown that LLMs can solve tasks using programs like human developers, the\nmajority of their evaluations are limited to short and self-contained\nalgorithmic tasks or standalone function calls. Solving challenging and\npractical requires the capability of utilizing diverse function calls as tools\nto efficiently implement functionalities like data analysis and web\ndevelopment. In addition, using multiple tools to solve a task needs\ncompositional reasoning by accurately understanding complex instructions.\nFulfilling both of these characteristics can pose a great challenge for LLMs.To\nassess how well LLMs can solve challenging and practical tasks via programs, we\nintroduce BigCodeBench, a benchmark that challenges LLMs to invoke multiple\nfunction calls as tools from 139 libraries and 7 domains for 1,140 fine-grained\ntasks. To evaluate LLMs rigorously, each task encompasses 5.6 test cases with\nan average branch coverage of 99%. In addition, we propose a\nnatural-language-oriented variant of BigCodeBench, BigCodeBench-Instruct, that\nautomatically transforms the original docstrings into short instructions only\nwith essential information. Our extensive evaluation of 60 LLMs shows that LLMs\nare not yet capable of following complex instructions to use function calls\nprecisely, with scores up to 60%, significantly lower than the human\nperformance of 97%. The results underscore the need for further advancements in\nthis area.\n","authors":["Terry Yue Zhuo","Minh Chien Vu","Jenny Chim","Han Hu","Wenhao Yu","Ratnadira Widyasari","Imam Nur Bani Yusuf","Haolan Zhan","Junda He","Indraneil Paul","Simon Brunner","Chen Gong","Thong Hoang","Armel Randy Zebaze","Xiaoheng Hong","Wen-Ding Li","Jean Kaddour","Ming Xu","Zhihan Zhang","Prateek Yadav","Naman Jain","Alex Gu","Zhoujun Cheng","Jiawei Liu","Qian Liu","Zijian Wang","David Lo","Binyuan Hui","Niklas Muennighoff","Daniel Fried","Xiaoning Du","Harm de Vries","Leandro Von Werra"],"pdf_url":"https://arxiv.org/pdf/2406.15877v3.pdf","comment":"44 pages, 14 figures, 7 tables, built with love by the BigCode\n  community :)"},{"id":"http://arxiv.org/abs/2410.05218v1","updated":"2024-10-07T17:22:56Z","published":"2024-10-07T17:22:56Z","title":"Density estimation with LLMs: a geometric investigation of in-context\n  learning trajectories","summary":"  Large language models (LLMs) demonstrate remarkable emergent abilities to\nperform in-context learning across various tasks, including time series\nforecasting. This work investigates LLMs' ability to estimate probability\ndensity functions (PDFs) from data observed in-context; such density estimation\n(DE) is a fundamental task underlying many probabilistic modeling problems. We\nleverage the Intensive Principal Component Analysis (InPCA) to visualize and\nanalyze the in-context learning dynamics of LLaMA-2 models. Our main finding is\nthat these LLMs all follow similar learning trajectories in a low-dimensional\nInPCA space, which are distinct from those of traditional density estimation\nmethods like histograms and Gaussian kernel density estimation (KDE). We\ninterpret the LLaMA in-context DE process as a KDE with an adaptive kernel\nwidth and shape. This custom kernel model captures a significant portion of\nLLaMA's behavior despite having only two parameters. We further speculate on\nwhy LLaMA's kernel width and shape differs from classical algorithms, providing\ninsights into the mechanism of in-context probabilistic reasoning in LLMs.\n","authors":["Toni J. B. Liu","Nicolas Boullé","Raphaël Sarfati","Christopher J. Earls"],"pdf_url":"https://arxiv.org/pdf/2410.05218v1.pdf","comment":"Under review as a conference paper at ICLR 2025"},{"id":"http://arxiv.org/abs/2309.02233v3","updated":"2024-10-07T17:21:45Z","published":"2023-09-05T13:39:38Z","title":"Augmenting Black-box LLMs with Medical Textbooks for Biomedical Question\n  Answering (Published in Findings of EMNLP 2024)","summary":"  Large-scale language models (LLMs) like ChatGPT have demonstrated impressive\nabilities in generating responses based on human instructions. However, their\nuse in the medical field can be challenging due to their lack of specific,\nin-depth knowledge. In this study, we present a system called LLMs Augmented\nwith Medical Textbooks (LLM-AMT) designed to enhance the proficiency of LLMs in\nspecialized domains. LLM-AMT integrates authoritative medical textbooks into\nthe LLMs' framework using plug-and-play modules. These modules include a Query\nAugmenter, a Hybrid Textbook Retriever, and a Knowledge Self-Refiner. Together,\nthey incorporate authoritative medical knowledge. Additionally, an LLM Reader\naids in contextual understanding. Our experimental results on three medical QA\ntasks demonstrate that LLMAMT significantly improves response quality, with\naccuracy gains ranging from 11.6% to 16.6%. Notably, with GPT-4-Turbo as the\nbase model, LLM-AMT outperforms the specialized Med-PaLM 2 model pre-trained on\na massive amount of medical corpus by 2-3%. We found that despite being 100x\nsmaller in size, medical textbooks as a retrieval corpus is proven to be a more\neffective knowledge database than Wikipedia in the medical domain, boosting\nperformance by 7.8%-13.7%.\n","authors":["Yubo Wang","Xueguang Ma","Wenhu Chen"],"pdf_url":"https://arxiv.org/pdf/2309.02233v3.pdf","comment":"This version has been accepted and published at EMNLP Findings 2024"},{"id":"http://arxiv.org/abs/2410.05210v1","updated":"2024-10-07T17:16:20Z","published":"2024-10-07T17:16:20Z","title":"Preserving Multi-Modal Capabilities of Pre-trained VLMs for Improving\n  Vision-Linguistic Compositionality","summary":"  In this paper, we propose a new method to enhance compositional understanding\nin pre-trained vision and language models (VLMs) without sacrificing\nperformance in zero-shot multi-modal tasks. Traditional fine-tuning approaches\noften improve compositional reasoning at the cost of degrading multi-modal\ncapabilities, primarily due to the use of global hard negative (HN) loss, which\ncontrasts global representations of images and texts. This global HN loss\npushes HN texts that are highly similar to the original ones, damaging the\nmodel's multi-modal representations. To overcome this limitation, we propose\nFine-grained Selective Calibrated CLIP (FSC-CLIP), which integrates local hard\nnegative loss and selective calibrated regularization. These innovations\nprovide fine-grained negative supervision while preserving the model's\nrepresentational integrity. Our extensive evaluations across diverse benchmarks\nfor both compositionality and multi-modal tasks show that FSC-CLIP not only\nachieves compositionality on par with state-of-the-art models but also retains\nstrong multi-modal capabilities. Code is available at:\nhttps://github.com/ytaek-oh/fsc-clip.\n","authors":["Youngtaek Oh","Jae Won Cho","Dong-Jin Kim","In So Kweon","Junmo Kim"],"pdf_url":"https://arxiv.org/pdf/2410.05210v1.pdf","comment":"EMNLP 2024 (Long, Main). Project page:\n  https://ytaek-oh.github.io/fsc-clip"},{"id":"http://arxiv.org/abs/2406.06369v4","updated":"2024-10-07T17:13:45Z","published":"2024-06-10T15:30:13Z","title":"Annotation alignment: Comparing LLM and human annotations of\n  conversational safety","summary":"  Do LLMs align with human perceptions of safety? We study this question via\nannotation alignment, the extent to which LLMs and humans agree when annotating\nthe safety of user-chatbot conversations. We leverage the recent DICES dataset\n(Aroyo et al., 2023), in which 350 conversations are each rated for safety by\n112 annotators spanning 10 race-gender groups. GPT-4 achieves a Pearson\ncorrelation of $r = 0.59$ with the average annotator rating, \\textit{higher}\nthan the median annotator's correlation with the average ($r=0.51$). We show\nthat larger datasets are needed to resolve whether LLMs exhibit disparities in\nhow well they correlate with different demographic groups. Also, there is\nsubstantial idiosyncratic variation in correlation within groups, suggesting\nthat race & gender do not fully capture differences in alignment. Finally, we\nfind that GPT-4 cannot predict when one demographic group finds a conversation\nmore unsafe than another.\n","authors":["Rajiv Movva","Pang Wei Koh","Emma Pierson"],"pdf_url":"https://arxiv.org/pdf/2406.06369v4.pdf","comment":"EMNLP 2024 (Main). Main text contains 6 pages, 2 figures"},{"id":"http://arxiv.org/abs/2410.05206v1","updated":"2024-10-07T17:09:03Z","published":"2024-10-07T17:09:03Z","title":"Studying and Mitigating Biases in Sign Language Understanding Models","summary":"  Ensuring that the benefits of sign language technologies are distributed\nequitably among all community members is crucial. Thus, it is important to\naddress potential biases and inequities that may arise from the design or use\nof these resources. Crowd-sourced sign language datasets, such as the ASL\nCitizen dataset, are great resources for improving accessibility and preserving\nlinguistic diversity, but they must be used thoughtfully to avoid reinforcing\nexisting biases.\n  In this work, we utilize the rich information about participant demographics\nand lexical features present in the ASL Citizen dataset to study and document\nthe biases that may result from models trained on crowd-sourced sign datasets.\nFurther, we apply several bias mitigation techniques during model training, and\nfind that these techniques reduce performance disparities without decreasing\naccuracy. With the publication of this work, we release the demographic\ninformation about the participants in the ASL Citizen dataset to encourage\nfuture bias mitigation work in this space.\n","authors":["Katherine Atwell","Danielle Bragg","Malihe Alikhani"],"pdf_url":"https://arxiv.org/pdf/2410.05206v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.05193v1","updated":"2024-10-07T16:50:47Z","published":"2024-10-07T16:50:47Z","title":"RevisEval: Improving LLM-as-a-Judge via Response-Adapted References","summary":"  With significant efforts in recent studies, LLM-as-a-Judge has become a\ncost-effective alternative to human evaluation for assessing the text\ngeneration quality in a wide range of tasks. However, there still remains a\nreliability gap between LLM-as-a-Judge and human evaluation. One important\nreason is the lack of guided oracles in the evaluation process. Motivated by\nthe role of reference pervasively used in classic text evaluation, we introduce\nRevisEval, a novel text generation evaluation paradigm via the response-adapted\nreferences. RevisEval is driven by the key observation that an ideal reference\nshould maintain the necessary relevance to the response to be evaluated.\nSpecifically, RevisEval leverages the text revision capabilities of large\nlanguage models (LLMs) to adaptively revise the response, then treat the\nrevised text as the reference (response-adapted reference) for the subsequent\nevaluation. Extensive experiments demonstrate that RevisEval outperforms\ntraditional reference-free and reference-based evaluation paradigms that use\nLLM-as-a-Judge across NLG tasks and open-ended instruction-following tasks.\nMore importantly, our response-adapted references can further boost the\nclassical text metrics, e.g., BLEU and BERTScore, compared to traditional\nreferences and even rival the LLM-as-a-Judge. A detailed analysis is also\nconducted to confirm RevisEval's effectiveness in bias reduction, the impact of\ninference cost, and reference relevance.\n","authors":["Qiyuan Zhang","Yufei Wang","Tiezheng YU","Yuxin Jiang","Chuhan Wu","Liangyou Li","Yasheng Wang","Xin Jiang","Lifeng Shang","Ruiming Tang","Fuyuan Lyu","Chen Ma"],"pdf_url":"https://arxiv.org/pdf/2410.05193v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.05192v1","updated":"2024-10-07T16:49:39Z","published":"2024-10-07T16:49:39Z","title":"Understanding Warmup-Stable-Decay Learning Rates: A River Valley Loss\n  Landscape Perspective","summary":"  Training language models currently requires pre-determining a fixed compute\nbudget because the typical cosine learning rate schedule depends on the total\nnumber of steps. In contrast, the Warmup-Stable-Decay (WSD) schedule uses a\nconstant learning rate to produce a main branch of iterates that can in\nprinciple continue indefinitely without a pre-specified compute budget. Then,\ngiven any compute budget, one can branch out from the main branch at a proper\nat any time with a rapidly decaying learning rate to produce a strong model.\nEmpirically, WSD generates a non-traditional loss curve: the loss remains\nelevated during the stable phase but sharply declines during the decay phase.\nTowards explaining this phenomenon, we conjecture that pretraining loss\nexhibits a river valley landscape, which resembles a deep valley with a river\nat its bottom. Under this assumption, we show that during the stable phase, the\niterate undergoes large oscillations due to the high learning rate, yet it\nprogresses swiftly along the river. During the decay phase, the rapidly\ndropping learning rate minimizes the iterate's oscillations, moving it closer\nto the river and revealing true optimization progress. Therefore, the sustained\nhigh learning rate phase and fast decaying phase are responsible for progress\nin the river and the mountain directions respectively, and are both critical.\nOur analysis predicts phenomenons consistent with empirical observations and\nshows that this landscape can emerge from pretraining on a simple bi-gram\ndataset. Inspired by the theory, we introduce WSD-S, a variant of WSD that\nreuses previous checkpoints' decay phases and keeps only one main branch, where\nwe resume from a decayed checkpoint. WSD-S empirically outperforms WSD and\nCyclic-Cosine in obtaining multiple language model checkpoints across various\ncompute budgets in a single run for parameters scaling from 0.1B to 1.2B.\n","authors":["Kaiyue Wen","Zhiyuan Li","Jason Wang","David Hall","Percy Liang","Tengyu Ma"],"pdf_url":"https://arxiv.org/pdf/2410.05192v1.pdf","comment":"45 pages,13 figures"},{"id":"http://arxiv.org/abs/2410.02525v2","updated":"2024-10-07T16:46:05Z","published":"2024-10-03T14:33:34Z","title":"Contextual Document Embeddings","summary":"  Dense document embeddings are central to neural retrieval. The dominant\nparadigm is to train and construct embeddings by running encoders directly on\nindividual documents. In this work, we argue that these embeddings, while\neffective, are implicitly out-of-context for targeted use cases of retrieval,\nand that a contextualized document embedding should take into account both the\ndocument and neighboring documents in context - analogous to contextualized\nword embeddings. We propose two complementary methods for contextualized\ndocument embeddings: first, an alternative contrastive learning objective that\nexplicitly incorporates the document neighbors into the intra-batch contextual\nloss; second, a new contextual architecture that explicitly encodes neighbor\ndocument information into the encoded representation. Results show that both\nmethods achieve better performance than biencoders in several settings, with\ndifferences especially pronounced out-of-domain. We achieve state-of-the-art\nresults on the MTEB benchmark with no hard negative mining, score distillation,\ndataset-specific instructions, intra-GPU example-sharing, or extremely large\nbatch sizes. Our method can be applied to improve performance on any\ncontrastive learning dataset and any biencoder.\n","authors":["John X. Morris","Alexander M. Rush"],"pdf_url":"https://arxiv.org/pdf/2410.02525v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.00099v4","updated":"2024-10-07T16:45:42Z","published":"2024-04-30T18:00:02Z","title":"Creative Beam Search: LLM-as-a-Judge For Improving Response Generation","summary":"  Large language models are revolutionizing several areas, including artificial\ncreativity. However, the process of generation in machines profoundly diverges\nfrom that observed in humans. In particular, machine generation is\ncharacterized by a lack of intentionality and an underlying creative process.\nWe propose a method called Creative Beam Search that uses Diverse Beam Search\nand LLM-as-a-Judge to perform response generation and response validation. The\nresults of a qualitative experiment show how our approach can provide better\noutput than standard sampling techniques. We also show that the response\nvalidation step is a necessary complement to the response generation step.\n","authors":["Giorgio Franceschelli","Mirco Musolesi"],"pdf_url":"https://arxiv.org/pdf/2405.00099v4.pdf","comment":"Presented as a short paper at the 15th International Conference on\n  Computational Creativity (ICCC'24)"},{"id":"http://arxiv.org/abs/2410.05183v1","updated":"2024-10-07T16:42:10Z","published":"2024-10-07T16:42:10Z","title":"Beyond Correlation: Interpretable Evaluation of Machine Translation\n  Metrics","summary":"  Machine Translation (MT) evaluation metrics assess translation quality\nautomatically. Recently, researchers have employed MT metrics for various new\nuse cases, such as data filtering and translation re-ranking. However, most MT\nmetrics return assessments as scalar scores that are difficult to interpret,\nposing a challenge to making informed design choices. Moreover, MT metrics'\ncapabilities have historically been evaluated using correlation with human\njudgment, which, despite its efficacy, falls short of providing intuitive\ninsights into metric performance, especially in terms of new metric use cases.\nTo address these issues, we introduce an interpretable evaluation framework for\nMT metrics. Within this framework, we evaluate metrics in two scenarios that\nserve as proxies for the data filtering and translation re-ranking use cases.\nFurthermore, by measuring the performance of MT metrics using Precision,\nRecall, and F-score, we offer clearer insights into their capabilities than\ncorrelation with human judgments. Finally, we raise concerns regarding the\nreliability of manually curated data following the Direct Assessments+Scalar\nQuality Metrics (DA+SQM) guidelines, reporting a notably low agreement with\nMultidimensional Quality Metrics (MQM) annotations.\n","authors":["Stefano Perrella","Lorenzo Proietti","Pere-Lluís Huguet Cabot","Edoardo Barba","Roberto Navigli"],"pdf_url":"https://arxiv.org/pdf/2410.05183v1.pdf","comment":"Accepted at EMNLP 2024 Main Conference. 26 pages"},{"id":"http://arxiv.org/abs/2410.05180v1","updated":"2024-10-07T16:40:21Z","published":"2024-10-07T16:40:21Z","title":"Enhancing Equity in Large Language Models for Medical Applications","summary":"  Recent advancements have highlighted the potential of large language models\n(LLMs) in medical applications, notably in automating Clinical Trial Matching\nfor translational research and providing medical question-answering for\nclinical decision support. However, our study reveals significant inequities in\nthe use of LLMs, particularly for individuals from specific racial, gender, and\nunderrepresented groups influenced by social determinants of health. These\ndisparities could worsen existing health inequities if LLMs are broadly adopted\nin healthcare. To address this, we propose and evaluate a novel framework,\nEquityGuard, designed to detect and mitigate biases in LLM-based medical\napplications. EquityGuard incorporates a Bias Detection Mechanism capable of\nidentifying and correcting unfair predictions, thus enhancing outcomes and\npromoting equity across diverse population groups.\n","authors":["Yuelyu Ji","Wenhe Ma","Sonish Sivarajkumar","Hang Zhang","Eugene Mathew Sadhu","Zhuochun Li","Xizhi Wu","Shyam Visweswaran","Yanshan Wang"],"pdf_url":"https://arxiv.org/pdf/2410.05180v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.02381v2","updated":"2024-10-07T16:39:24Z","published":"2024-10-03T11:01:25Z","title":"MetaMetrics: Calibrating Metrics For Generation Tasks Using Human\n  Preferences","summary":"  Understanding the quality of a performance evaluation metric is crucial for\nensuring that model outputs align with human preferences. However, it remains\nunclear how well each metric captures the diverse aspects of these preferences,\nas metrics often excel in one particular area but not across all dimensions. To\naddress this, it is essential to systematically calibrate metrics to specific\naspects of human preference, catering to the unique characteristics of each\naspect. We introduce MetaMetrics, a calibrated meta-metric designed to evaluate\ngeneration tasks across different modalities in a supervised manner.\nMetaMetrics optimizes the combination of existing metrics to enhance their\nalignment with human preferences. Our metric demonstrates flexibility and\neffectiveness in both language and vision downstream tasks, showing significant\nbenefits across various multilingual and multi-domain scenarios. MetaMetrics\naligns closely with human preferences and is highly extendable and easily\nintegrable into any application. This makes MetaMetrics a powerful tool for\nimproving the evaluation of generation tasks, ensuring that metrics are more\nrepresentative of human judgment across diverse contexts.\n","authors":["Genta Indra Winata","David Anugraha","Lucky Susanto","Garry Kuwanto","Derry Tanti Wijaya"],"pdf_url":"https://arxiv.org/pdf/2410.02381v2.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2402.14901v2","updated":"2024-10-07T16:38:35Z","published":"2024-02-22T18:09:33Z","title":"A Usage-centric Take on Intent Understanding in E-Commerce","summary":"  Identifying and understanding user intents is a pivotal task for E-Commerce.\nDespite its essential role in product recommendation and business user\nprofiling analysis, intent understanding has not been consistently defined or\naccurately benchmarked. In this paper, we focus on predicative user intents as\n\"how a customer uses a product\", and pose intent understanding as a natural\nlanguage reasoning task, independent of product ontologies. We identify two\nweaknesses of FolkScope, the SOTA E-Commerce Intent Knowledge Graph:\ncategory-rigidity and property-ambiguity. They limit its ability to strongly\nalign user intents with products having the most desirable property, and to\nrecommend useful products across diverse categories. Following these\nobservations, we introduce a Product Recovery Benchmark featuring a novel\nevaluation framework and an example dataset. We further validate the above\nFolkScope weaknesses on this benchmark. Our code and dataset are available at\nhttps://github.com/stayones/Usgae-Centric-Intent-Understanding.\n","authors":["Wendi Zhou","Tianyi Li","Pavlos Vougiouklis","Mark Steedman","Jeff Z. Pan"],"pdf_url":"https://arxiv.org/pdf/2402.14901v2.pdf","comment":"Acepted by EMNLP 2024 main"},{"id":"http://arxiv.org/abs/2310.09675v2","updated":"2024-10-07T16:28:52Z","published":"2023-10-14T22:24:26Z","title":"Efficient Model-Agnostic Multi-Group Equivariant Networks","summary":"  Constructing model-agnostic group equivariant networks, such as equitune\n(Basu et al., 2023b) and its generalizations (Kim et al., 2023), can be\ncomputationally expensive for large product groups. We address this problem by\nproviding efficient model-agnostic equivariant designs for two related\nproblems: one where the network has multiple inputs each with potentially\ndifferent groups acting on them, and another where there is a single input but\nthe group acting on it is a large product group. For the first design, we\ninitially consider a linear model and characterize the entire equivariant space\nthat satisfies this constraint. This characterization gives rise to a novel\nfusion layer between different channels that satisfies an invariance-symmetry\n(IS) constraint, which we call an IS layer. We then extend this design beyond\nlinear models, similar to equitune, consisting of equivariant and IS layers. We\nalso show that the IS layer is a universal approximator of invariant-symmetric\nfunctions. Inspired by the first design, we use the notion of the IS property\nto design a second efficient model-agnostic equivariant design for large\nproduct groups acting on a single input. For the first design, we provide\nexperiments on multi-image classification where each view is transformed\nindependently with transformations such as rotations. We find equivariant\nmodels are robust to such transformations and perform competitively otherwise.\nFor the second design, we consider three applications: language\ncompositionality on the SCAN dataset to product groups; fairness in natural\nlanguage generation from GPT-2 to address intersectionality; and robust\nzero-shot image classification with CLIP. Overall, our methods are simple and\ngeneral, competitive with equitune and its variants, while also being\ncomputationally more efficient.\n","authors":["Razan Baltaji","Sourya Basu","Lav R. Varshney"],"pdf_url":"https://arxiv.org/pdf/2310.09675v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10054v2","updated":"2024-10-07T16:26:00Z","published":"2023-11-16T17:48:55Z","title":"When \"A Helpful Assistant\" Is Not Really Helpful: Personas in System\n  Prompts Do Not Improve Performances of Large Language Models","summary":"  Prompting serves as the major way humans interact with Large Language Models\n(LLM). Commercial AI systems commonly define the role of the LLM in system\nprompts. For example, ChatGPT uses \"You are a helpful assistant\" as part of its\ndefault system prompt. Despite current practices of adding personas to system\nprompts, it remains unclear how different personas affect a model's performance\non objective tasks. In this study, we present a systematic evaluation of\npersonas in system prompts. We curate a list of 162 roles covering 6 types of\ninterpersonal relationships and 8 domains of expertise. Through extensive\nanalysis of 4 popular families of LLMs and 2,410 factual questions, we\ndemonstrate that adding personas in system prompts does not improve model\nperformance across a range of questions compared to the control setting where\nno persona is added. Nevertheless, further analysis suggests that the gender,\ntype, and domain of the persona can all influence the resulting prediction\naccuracies. We further experimented with a list of persona search strategies\nand found that, while aggregating results from the best persona for each\nquestion significantly improves prediction accuracy, automatically identifying\nthe best persona is challenging, with predictions often performing no better\nthan random selection. Overall, our findings suggest that while adding a\npersona may lead to performance gains in certain settings, the effect of each\npersona can be largely random. Code and data are available at\nhttps://github.com/Jiaxin-Pei/Prompting-with-Social-Roles.\n","authors":["Mingqian Zheng","Jiaxin Pei","Lajanugen Logeswaran","Moontae Lee","David Jurgens"],"pdf_url":"https://arxiv.org/pdf/2311.10054v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.05168v1","updated":"2024-10-07T16:25:39Z","published":"2024-10-07T16:25:39Z","title":"ReasoningRank: Teaching Student Models to Rank through Reasoning-Based\n  Knowledge Distillation","summary":"  Reranking documents based on their relevance to a given query is critical in\ninformation retrieval. Traditional reranking methods often focus on improving\nthe initial rankings but lack transparency, failing to explain why one document\nis ranked higher. In this paper, we introduce ReasoningRank, a novel reranking\napproach that enhances clarity by generating two types of reasoning: explicit\nreasoning, which explains how a document addresses the query, and comparison\nreasoning, which justifies the relevance of one document over another. We\nleverage large language models (LLMs) as teacher models to generate these\nexplanations and distill this knowledge into smaller, more resource-efficient\nstudent models. While the student models may not outperform LLMs in speed, they\nsignificantly reduce the computational burden by requiring fewer resources,\nmaking them more suitable for large-scale or resource-constrained settings.\nThese student models are trained to both generate meaningful reasoning and\nrerank documents, achieving competitive performance across multiple datasets,\nincluding MSMARCO and BRIGHT. Experiments demonstrate that ReasoningRank\nimproves reranking accuracy and provides valuable insights into the\ndecision-making process, offering a structured and interpretable solution for\nreranking tasks.\n","authors":["Yuelyu Ji","Zhuochun Li","Rui Meng","Daqing He"],"pdf_url":"https://arxiv.org/pdf/2410.05168v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.02902v2","updated":"2024-10-07T16:25:04Z","published":"2024-10-03T18:48:38Z","title":"Better Instruction-Following Through Minimum Bayes Risk","summary":"  General-purpose LLM judges capable of human-level evaluation provide not only\na scalable and accurate way of evaluating instruction-following LLMs but also\nnew avenues for supervising and improving their performance. One promising way\nof leveraging LLM judges for supervision is through Minimum Bayes Risk (MBR)\ndecoding, which uses a reference-based evaluator to select a high-quality\noutput from amongst a set of candidate outputs. In the first part of this work,\nwe explore using MBR decoding as a method for improving the test-time\nperformance of instruction-following LLMs. We find that MBR decoding with\nreference-based LLM judges substantially improves over greedy decoding,\nbest-of-N decoding with reference-free judges and MBR decoding with lexical and\nembedding-based metrics on AlpacaEval and MT-Bench. These gains are consistent\nacross LLMs with up to 70B parameters, demonstrating that smaller LLM judges\ncan be used to supervise much larger LLMs. Then, seeking to retain the\nimprovements from MBR decoding while mitigating additional test-time costs, we\nexplore iterative self-training on MBR-decoded outputs. We find that\nself-training using Direct Preference Optimisation leads to significant\nperformance gains, such that the self-trained models with greedy decoding\ngenerally match and sometimes exceed the performance of their base models with\nMBR decoding.\n","authors":["Ian Wu","Patrick Fernandes","Amanda Bertsch","Seungone Kim","Sina Pakazad","Graham Neubig"],"pdf_url":"https://arxiv.org/pdf/2410.02902v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.05165v1","updated":"2024-10-07T16:23:36Z","published":"2024-10-07T16:23:36Z","title":"Efficient Inference for Large Language Model-based Generative\n  Recommendation","summary":"  Large Language Model (LLM)-based generative recommendation has achieved\nnotable success, yet its practical deployment is costly particularly due to\nexcessive inference latency caused by autoregressive decoding. For lossless LLM\ndecoding acceleration, Speculative Decoding (SD) has emerged as a promising\nsolution. However, applying SD to generative recommendation presents unique\nchallenges due to the requirement of generating top-K items (i.e., K distinct\ntoken sequences) as a recommendation list by beam search. This leads to more\nstringent verification in SD, where all the top-K sequences from the target LLM\nmust be successfully drafted by the draft model at each decoding step. To\nalleviate this, we consider 1) boosting top-K sequence alignment between the\ndraft model and the target LLM, and 2) relaxing the verification strategy to\nreduce trivial LLM calls. To this end, we propose an alignment framework named\nAtSpeed, which presents the AtSpeed-S optimization objective for top-K\nalignment under the strict top-K verification. Moreover, we introduce a relaxed\nsampling verification strategy that allows high-probability non-top-K drafted\nsequences to be accepted, significantly reducing LLM calls. Correspondingly, we\npropose AtSpeed-R for top-K alignment under this relaxed sampling verification.\nEmpirical results on two real-world datasets demonstrate that AtSpeed\nsignificantly accelerates LLM-based generative recommendation, e.g., near 2x\nspeedup under strict top-K verification and up to 2.5 speedup under relaxed\nsampling verification. The codes and datasets will be released in the near\nfuture.\n","authors":["Xinyu Lin","Chaoqun Yang","Wenjie Wang","Yongqi Li","Cunxiao Du","Fuli Feng","See-Kiong Ng","Tat-Seng Chua"],"pdf_url":"https://arxiv.org/pdf/2410.05165v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.05162v1","updated":"2024-10-07T16:14:47Z","published":"2024-10-07T16:14:47Z","title":"Deciphering the Interplay of Parametric and Non-parametric Memory in\n  Retrieval-augmented Language Models","summary":"  Generative language models often struggle with specialized or less-discussed\nknowledge. A potential solution is found in Retrieval-Augmented Generation\n(RAG) models which act like retrieving information before generating responses.\nIn this study, we explore how the \\textsc{Atlas} approach, a RAG model, decides\nbetween what it already knows (parametric) and what it retrieves\n(non-parametric). We use causal mediation analysis and controlled experiments\nto examine how internal representations influence information processing. Our\nfindings disentangle the effects of parametric knowledge and the retrieved\ncontext. They indicate that in cases where the model can choose between both\ntypes of information (parametric and non-parametric), it relies more on the\ncontext than the parametric knowledge. Furthermore, the analysis investigates\nthe computations involved in \\emph{how} the model uses the information from the\ncontext. We find that multiple mechanisms are active within the model and can\nbe detected with mediation analysis: first, the decision of \\emph{whether the\ncontext is relevant}, and second, how the encoder computes output\nrepresentations to support copying when relevant.\n","authors":["Mehrdad Farahani","Richard Johansson"],"pdf_url":"https://arxiv.org/pdf/2410.05162v1.pdf","comment":"Accepted at EMNLP 2024"},{"id":"http://arxiv.org/abs/2410.05160v1","updated":"2024-10-07T16:14:05Z","published":"2024-10-07T16:14:05Z","title":"VLM2Vec: Training Vision-Language Models for Massive Multimodal\n  Embedding Tasks","summary":"  Embedding models have been crucial in enabling various downstream tasks such\nas semantic similarity, information retrieval, and clustering. Recently, there\nhas been a surge of interest in developing universal text embedding models that\ncan generalize across tasks (e.g., MTEB). However, progress in learning\nuniversal multimodal embedding models has been relatively slow despite their\nimportance. In this work, we aim to explore the potential for building\nuniversal embeddings capable of handling a wide range of downstream tasks. Our\ncontributions are twofold: (1) MMEB (Massive Multimodal Embedding Benchmark),\nwhich covers 4 meta-tasks (i.e. classification, visual question answering,\nmultimodal retrieval, and visual grounding) and 36 datasets, including 20\ntraining and 16 evaluation datasets, and (2) VLM2Vec (Vision-Language Model ->\nVector), a contrastive training framework that converts any state-of-the-art\nvision-language model into an embedding model via training on MMEB. Unlike\nprevious models such as CLIP and BLIP, VLM2Vec can process any combination of\nimages and text to generate a fixed-dimensional vector based on task\ninstructions. We build a series of VLM2Vec models on Phi-3.5-V and evaluate\nthem on MMEB's evaluation split. Our results show that \\model achieves an\nabsolute average improvement of 10% to 20% over existing multimodal embedding\nmodels on both in-distribution and out-of-distribution datasets in MMEB.\n","authors":["Ziyan Jiang","Rui Meng","Xinyi Yang","Semih Yavuz","Yingbo Zhou","Wenhu Chen"],"pdf_url":"https://arxiv.org/pdf/2410.05160v1.pdf","comment":"Technical Report"},{"id":"http://arxiv.org/abs/2405.14577v2","updated":"2024-10-07T16:01:49Z","published":"2024-05-23T13:51:55Z","title":"Representation noising effectively prevents harmful fine-tuning on LLMs","summary":"  Releasing open-source large language models (LLMs) presents a dual-use risk\nsince bad actors can easily fine-tune these models for harmful purposes. Even\nwithout the open release of weights, weight stealing and fine-tuning APIs make\nclosed models vulnerable to harmful fine-tuning attacks (HFAs). While safety\nmeasures like preventing jailbreaks and improving safety guardrails are\nimportant, such measures can easily be reversed through fine-tuning. In this\nwork, we propose Representation Noising (RepNoise), a defence mechanism that is\neffective even when attackers have access to the weights. RepNoise works by\nremoving information about harmful representations such that it is difficult to\nrecover them during fine-tuning. Importantly, our defence is also able to\ngeneralize across different subsets of harm that have not been seen during the\ndefence process as long as they are drawn from the same distribution of the\nattack set. Our method does not degrade the general capability of LLMs and\nretains the ability to train the model on harmless tasks. We provide empirical\nevidence that the effectiveness of our defence lies in its \"depth\": the degree\nto which information about harmful representations is removed across all layers\nof the LLM.\n","authors":["Domenic Rosati","Jan Wehner","Kai Williams","Łukasz Bartoszcze","David Atanasov","Robie Gonzales","Subhabrata Majumdar","Carsten Maple","Hassan Sajjad","Frank Rudzicz"],"pdf_url":"https://arxiv.org/pdf/2405.14577v2.pdf","comment":"Published in NeurIPs 2024"},{"id":"http://arxiv.org/abs/2311.09090v4","updated":"2024-10-07T16:01:06Z","published":"2023-11-15T16:35:59Z","title":"Social Bias Probing: Fairness Benchmarking for Language Models","summary":"  While the impact of social biases in language models has been recognized,\nprior methods for bias evaluation have been limited to binary association tests\non small datasets, limiting our understanding of bias complexities. This paper\nproposes a novel framework for probing language models for social biases by\nassessing disparate treatment, which involves treating individuals differently\naccording to their affiliation with a sensitive demographic group. We curate\nSoFa, a large-scale benchmark designed to address the limitations of existing\nfairness collections. SoFa expands the analysis beyond the binary comparison of\nstereotypical versus anti-stereotypical identities to include a diverse range\nof identities and stereotypes. Comparing our methodology with existing\nbenchmarks, we reveal that biases within language models are more nuanced than\nacknowledged, indicating a broader scope of encoded biases than previously\nrecognized. Benchmarking LMs on SoFa, we expose how identities expressing\ndifferent religions lead to the most pronounced disparate treatments across all\nmodels. Finally, our findings indicate that real-life adversities faced by\nvarious groups such as women and people with disabilities are mirrored in the\nbehavior of these models.\n","authors":["Marta Marchiori Manerba","Karolina Stańczak","Riccardo Guidotti","Isabelle Augenstein"],"pdf_url":"https://arxiv.org/pdf/2311.09090v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.05146v1","updated":"2024-10-07T15:58:03Z","published":"2024-10-07T15:58:03Z","title":"CTC-GMM: CTC guided modality matching for fast and accurate streaming\n  speech translation","summary":"  Models for streaming speech translation (ST) can achieve high accuracy and\nlow latency if they're developed with vast amounts of paired audio in the\nsource language and written text in the target language. Yet, these text labels\nfor the target language are often pseudo labels due to the prohibitive cost of\nmanual ST data labeling. In this paper, we introduce a methodology named\nConnectionist Temporal Classification guided modality matching (CTC-GMM) that\nenhances the streaming ST model by leveraging extensive machine translation\n(MT) text data. This technique employs CTC to compress the speech sequence into\na compact embedding sequence that matches the corresponding text sequence,\nallowing us to utilize matched {source-target} language text pairs from the MT\ncorpora to refine the streaming ST model further. Our evaluations with FLEURS\nand CoVoST2 show that the CTC-GMM approach can increase translation accuracy\nrelatively by 13.9% and 6.4% respectively, while also boosting decoding speed\nby 59.7% on GPU.\n","authors":["Rui Zhao","Jinyu Li","Ruchao Fan","Matt Post"],"pdf_url":"https://arxiv.org/pdf/2410.05146v1.pdf","comment":"Accepted by IEEE Spoken Language Technology Workshop (SLT 2024)"},{"id":"http://arxiv.org/abs/2407.10930v2","updated":"2024-10-07T15:52:48Z","published":"2024-07-15T17:30:31Z","title":"Fine-Tuning and Prompt Optimization: Two Great Steps that Work Better\n  Together","summary":"  Natural Language Processing (NLP) systems are increasingly taking the form of\nsophisticated modular pipelines, e.g., Retrieval Augmented Generation (RAG),\nwhere each module may involve a distinct Language Model (LM) and an associated\nprompt template. These compound systems often lack intermediate labels or\ngradient flow to optimize each module, making their end-to-end optimization\nchallenging. Here we seek strategies to optimize both the module-level LM\nweights and the associated prompt templates of such systems to maximize a\ndownstream task metric. We propose for the first time combining the weight and\nprompt optimization strategies to optimize a modular LM pipeline by alternating\nbetween the two to get the same LM to teach itself. In experiments with\nmulti-hop QA, mathematical reasoning, and feature-based classification using\nmistral-7b, llama-2-7b, and llama-3-8b, these BetterTogether strategies\noptimizing the weights and prompts of a pipeline together outperform directly\noptimizing weights alone and prompts alone by up to 60% and 6%, respectively,\non average across LMs and tasks. BetterTogether optimizer is released in DSPy\nat http://dspy.ai\n","authors":["Dilara Soylu","Christopher Potts","Omar Khattab"],"pdf_url":"https://arxiv.org/pdf/2407.10930v2.pdf","comment":"EMNLP 2024"},{"id":"http://arxiv.org/abs/2403.00126v2","updated":"2024-10-07T15:44:45Z","published":"2024-02-29T21:05:37Z","title":"FAC$^2$E: Better Understanding Large Language Model Capabilities by\n  Dissociating Language and Cognition","summary":"  Large language models (LLMs) are primarily evaluated by overall performance\non various text understanding and generation tasks. However, such a paradigm\nfails to comprehensively differentiate the fine-grained language and cognitive\nskills, rendering the lack of sufficient interpretation to LLMs' capabilities.\nIn this paper, we present FAC$^2$E, a framework for Fine-grAined and\nCognition-grounded LLMs' Capability Evaluation. Specifically, we formulate\nLLMs' evaluation in a multi-dimensional and explainable manner by dissociating\nthe language-related capabilities and the cognition-related ones. Besides,\nthrough extracting the intermediate reasoning from LLMs, we further break down\nthe process of applying a specific capability into three sub-steps: recalling\nrelevant knowledge, utilizing knowledge, and solving problems. Finally,\nFAC$^2$E evaluates each sub-step of each fine-grained capability, providing a\ntwo-faceted diagnosis for LLMs. Utilizing FAC$^2$E, we identify a common\nshortfall in knowledge utilization among models and propose a straightforward,\nknowledge-enhanced method to mitigate this issue. Our results not only showcase\npromising performance enhancements but also highlight a direction for future\nLLM advancements.\n","authors":["Xiaoqiang Wang","Lingfei Wu","Tengfei Ma","Bang Liu"],"pdf_url":"https://arxiv.org/pdf/2403.00126v2.pdf","comment":"Accepted at EMNLP 2024 main conference"},{"id":"http://arxiv.org/abs/2404.12132v2","updated":"2024-10-07T15:28:18Z","published":"2024-04-18T12:33:57Z","title":"Non-Invasive Suicide Risk Prediction Through Speech Analysis","summary":"  The delayed access to specialized psychiatric assessments and care for\npatients at risk of suicidal tendencies in emergency departments creates a\nnotable gap in timely intervention, hindering the provision of adequate mental\nhealth support during critical situations. To address this, we present a\nnon-invasive, speech-based approach for automatic suicide risk assessment. For\nour study, we collected a novel speech recording dataset from $20$ patients. We\nextract three sets of features, including wav2vec, interpretable speech and\nacoustic features, and deep learning-based spectral representations. We proceed\nby conducting a binary classification to assess suicide risk in a\nleave-one-subject-out fashion. Our most effective speech model achieves a\nbalanced accuracy of $66.2\\,\\%$. Moreover, we show that integrating our speech\nmodel with a series of patients' metadata, such as the history of suicide\nattempts or access to firearms, improves the overall result. The metadata\nintegration yields a balanced accuracy of $94.4\\,\\%$, marking an absolute\nimprovement of $28.2\\,\\%$, demonstrating the efficacy of our proposed\napproaches for automatic suicide risk assessment in emergency medicine.\n","authors":["Shahin Amiriparian","Maurice Gerczuk","Justina Lutz","Wolfgang Strube","Irina Papazova","Alkomiet Hasan","Alexander Kathan","Björn W. Schuller"],"pdf_url":"https://arxiv.org/pdf/2404.12132v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17385v2","updated":"2024-10-07T15:15:18Z","published":"2024-06-25T09:04:21Z","title":"Native Design Bias: Studying the Impact of English Nativeness on\n  Language Model Performance","summary":"  Large Language Models (LLMs) excel at providing information acquired during\npretraining on large-scale corpora and following instructions through user\nprompts. This study investigates whether the quality of LLM responses varies\ndepending on the demographic profile of users. Considering English as the\nglobal lingua franca, along with the diversity of its dialects among speakers\nof different native languages, we explore whether non-native English speakers\nreceive lower-quality or even factually incorrect responses from LLMs more\nfrequently. Our results show that performance discrepancies occur when LLMs are\nprompted by native versus non-native English speakers and persist when\ncomparing native speakers from Western countries with others. Additionally, we\nfind a strong anchoring effect when the model recognizes or is made aware of\nthe user's nativeness, which further degrades the response quality when\ninteracting with non-native speakers. Our analysis is based on a newly\ncollected dataset with over 12,000 unique annotations from 124 annotators,\nincluding information on their native language and English proficiency.\n","authors":["Manon Reusens","Philipp Borchert","Jochen De Weerdt","Bart Baesens"],"pdf_url":"https://arxiv.org/pdf/2406.17385v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.05257v2","updated":"2024-10-07T15:14:26Z","published":"2024-09-09T00:40:47Z","title":"UPCS: Unbiased Persona Construction for Dialogue Generation","summary":"  Narrative systems, such as dialogue and storytelling systems, often utilize\npersona profiles to enhance personalized interactions. Existing persona\nprofiles frequently exhibit biases, posing risks to system integrity and\nfairness. To address this, we introduce the UPCS framework, which categorizes\ncharacter descriptions into eight dimensions, including bias mitigation\nstrategies. Experimental results demonstrate UPCS's superiority in accuracy,\ndiversity, bias elimination, and user satisfaction, marking a significant\nadvancement in persona construction for reliable narrative systems.\n","authors":["Kuiyun Chen","Yanbin Wei"],"pdf_url":"https://arxiv.org/pdf/2409.05257v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2205.11472v3","updated":"2024-10-07T15:11:12Z","published":"2022-05-23T17:14:32Z","title":"Diversity Over Size: On the Effect of Sample and Topic Sizes for\n  Topic-Dependent Argument Mining Datasets","summary":"  The task of Argument Mining, that is extracting and classifying argument\ncomponents for a specific topic from large document sources, is an inherently\ndifficult task for machine learning models and humans alike, as large Argument\nMining datasets are rare and recognition of argument components requires expert\nknowledge. The task becomes even more difficult if it also involves stance\ndetection of retrieved arguments. In this work, we investigate the effect of\nArgument Mining dataset composition in few- and zero-shot settings. Our\nfindings show that, while fine-tuning is mandatory to achieve acceptable model\nperformance, using carefully composed training samples and reducing the\ntraining sample size by up to almost 90% can still yield 95% of the maximum\nperformance. This gain is consistent across three Argument Mining tasks on\nthree different datasets. We also publish a new dataset for future\nbenchmarking.\n","authors":["Benjamin Schiller","Johannes Daxenberger","Andreas Waldis","Iryna Gurevych"],"pdf_url":"https://arxiv.org/pdf/2205.11472v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.00161v2","updated":"2024-10-07T15:07:09Z","published":"2024-09-30T19:09:13Z","title":"KV-Compress: Paged KV-Cache Compression with Variable Compression Rates\n  per Attention Head","summary":"  Context lengths of Large Language Models (LLMs) have exploded in recent\nyears, with 128k-token context becoming a standard and million-token context\nbecoming a reality. Efficiently supporting long-context inference remains\nchallenging as the memory that must be allocated in key-value (KV) cache for a\ngeneration scales with its context length, limiting the number of long-context\nrequests that can be served concurrently under a given memory budget. KV cache\ncompression can mitigate this issue by removing under-utilized KVs from each\nattention head's cache and reducing its memory footprint. Higher theoretical\ncompression rates can be achieved when the number of removed KVs varies across\nattention heads, but application of such a strategy within existing inference\nframeworks adds fragmentation and cannot realize the theoretical compression\nrates in physical memory. We introduce KV-Compress, a novel compression method\nthat evicts contiguous KV blocks within a PagedAttention framework, reducing\nthe memory footprint of the KV cache proportionally to this theoretical\ncompression rate. Our method achieves state-of-the-art performance on LongBench\nfor both Mistral-7B-Instruct-v0.2 and Llama-3.1-8B-Instruct while lowering the\ntotal number of compressed KVs by 4x compared with prior methods. Evaluations\non Llama-3.1-8B-Instruct and Llama-3.1-70B-Instruct-FP8 achieve compression\nrates up to 8x with negligible impact on performance, and up to 64x while\nretaining over 90% of full-cache performance for all but three of the suite's\nsubsets. We benchmark an integration of our method with vLLM that increases\ntotal throughput by up to 5.18x by enabling larger decoding batches.\n","authors":["Isaac Rehg"],"pdf_url":"https://arxiv.org/pdf/2410.00161v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.15929v2","updated":"2024-10-07T15:01:48Z","published":"2024-02-24T23:16:57Z","title":"Decoding Intelligence: A Framework for Certifying Knowledge\n  Comprehension in LLMs","summary":"  Knowledge comprehension capability is an important aspect of human\nintelligence. As Large Language Models (LLMs) are being envisioned as\nsuperhuman agents, it is crucial for them to be proficient at knowledge\ncomprehension. However, existing benchmarking studies do not provide\nconsistent, generalizable, and formal guarantees on the knowledge comprehension\ncapabilities of LLMs. In this work, we propose the first framework to certify\nknowledge comprehension in LLMs with formal probabilistic guarantees. Our\ncertificates are quantitative -- they consist of high-confidence, tight bounds\non the probability that a target LLM gives the correct answer on any knowledge\ncomprehension prompt sampled from a distribution. We design and certify novel\nspecifications that precisely represent distributions of knowledge\ncomprehension prompts leveraging knowledge graphs. We certify SOTA LLMs for\nspecifications over the Wikidata5m knowledge graph. We find that the knowledge\ncomprehension capability improves significantly with scaling the size of the\nmodels.\n","authors":["Isha Chaudhary","Vedaant V. Jain","Gagandeep Singh"],"pdf_url":"https://arxiv.org/pdf/2402.15929v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.05102v1","updated":"2024-10-07T15:01:29Z","published":"2024-10-07T15:01:29Z","title":"SparsePO: Controlling Preference Alignment of LLMs via Sparse Token\n  Masks","summary":"  Preference Optimization (PO) has proven an effective step for aligning\nlanguage models to human-desired behaviors. Current variants, following the\noffline Direct Preference Optimization objective, have focused on a strict\nsetting where all tokens are contributing signals of KL divergence and rewards\nto the loss function. However, human preference is not affected by each word in\na sequence equally but is often dependent on specific words or phrases, e.g.\nexistence of toxic terms leads to non-preferred responses. Based on this\nobservation, we argue that not all tokens should be weighted equally during PO\nand propose a flexible objective termed SparsePO, that aims to automatically\nlearn to weight the KL divergence and reward corresponding to each token during\nPO training. We propose two different variants of weight-masks that can either\nbe derived from the reference model itself or learned on the fly. Notably, our\nmethod induces sparsity in the learned masks, allowing the model to learn how\nto best weight reward and KL divergence contributions at the token level,\nlearning an optimal level of mask sparsity. Extensive experiments on multiple\ndomains, including sentiment control, dialogue, text summarization and\ntext-to-code generation, illustrate that our approach assigns meaningful\nweights to tokens according to the target task, generates more responses with\nthe desired preference and improves reasoning tasks by up to 2 percentage\npoints compared to other token- and response-level PO methods.\n","authors":["Fenia Christopoulou","Ronald Cardenas","Gerasimos Lampouras","Haitham Bou-Ammar","Jun Wang"],"pdf_url":"https://arxiv.org/pdf/2410.05102v1.pdf","comment":"20 papges, 9 figures, 5 tables. Under Review"},{"id":"http://arxiv.org/abs/2406.16078v2","updated":"2024-10-07T15:01:26Z","published":"2024-06-23T11:11:46Z","title":"First Heuristic Then Rational: Dynamic Use of Heuristics in Language\n  Model Reasoning","summary":"  Multi-step reasoning instruction, such as chain-of-thought prompting, is\nwidely adopted to explore better language models (LMs) performance. We report\non the systematic strategy that LMs employ in such a multi-step reasoning\nprocess. Our controlled experiments reveal that LMs rely more heavily on\nheuristics, such as lexical overlap, in the earlier stages of reasoning, where\nmore reasoning steps remain to reach a goal. Conversely, their reliance on\nheuristics decreases as LMs progress closer to the final answer through\nmultiple reasoning steps. This suggests that LMs can backtrack only a limited\nnumber of future steps and dynamically combine heuristic strategies with\nrationale ones in tasks involving multi-step reasoning.\n","authors":["Yoichi Aoki","Keito Kudo","Tatsuki Kuribayashi","Shusaku Sone","Masaya Taniguchi","Keisuke Sakaguchi","Kentaro Inui"],"pdf_url":"https://arxiv.org/pdf/2406.16078v2.pdf","comment":"This paper is accepted at EMNLP 2024"},{"id":"http://arxiv.org/abs/2410.05099v1","updated":"2024-10-07T14:55:20Z","published":"2024-10-07T14:55:20Z","title":"Investigating large language models for their competence in extracting\n  grammatically sound sentences from transcribed noisy utterances","summary":"  Selectively processing noisy utterances while effectively disregarding\nspeech-specific elements poses no considerable challenge for humans, as they\nexhibit remarkable cognitive abilities to separate semantically significant\ncontent from speech-specific noise (i.e. filled pauses, disfluencies, and\nrestarts). These abilities may be driven by mechanisms based on acquired\ngrammatical rules that compose abstract syntactic-semantic structures within\nutterances. Segments without syntactic and semantic significance are\nconsistently disregarded in these structures. The structures, in tandem with\nlexis, likely underpin language comprehension and thus facilitate effective\ncommunication. In our study, grounded in linguistically motivated experiments,\nwe investigate whether large language models (LLMs) can effectively perform\nanalogical speech comprehension tasks. In particular, we examine the ability of\nLLMs to extract well-structured utterances from transcriptions of noisy\ndialogues. We conduct two evaluation experiments in the Polish language\nscenario, using a~dataset presumably unfamiliar to LLMs to mitigate the risk of\ndata contamination. Our results show that not all extracted utterances are\ncorrectly structured, indicating that either LLMs do not fully acquire\nsyntactic-semantic rules or they acquire them but cannot apply them\neffectively. We conclude that the ability of LLMs to comprehend noisy\nutterances is still relatively superficial compared to human proficiency in\nprocessing them.\n","authors":["Alina Wróblewska"],"pdf_url":"https://arxiv.org/pdf/2410.05099v1.pdf","comment":"Accepted at CoNLL 2024"},{"id":"http://arxiv.org/abs/2410.02707v2","updated":"2024-10-07T14:46:11Z","published":"2024-10-03T17:31:31Z","title":"LLMs Know More Than They Show: On the Intrinsic Representation of LLM\n  Hallucinations","summary":"  Large language models (LLMs) often produce errors, including factual\ninaccuracies, biases, and reasoning failures, collectively referred to as\n\"hallucinations\". Recent studies have demonstrated that LLMs' internal states\nencode information regarding the truthfulness of their outputs, and that this\ninformation can be utilized to detect errors. In this work, we show that the\ninternal representations of LLMs encode much more information about\ntruthfulness than previously recognized. We first discover that the\ntruthfulness information is concentrated in specific tokens, and leveraging\nthis property significantly enhances error detection performance. Yet, we show\nthat such error detectors fail to generalize across datasets, implying that --\ncontrary to prior claims -- truthfulness encoding is not universal but rather\nmultifaceted. Next, we show that internal representations can also be used for\npredicting the types of errors the model is likely to make, facilitating the\ndevelopment of tailored mitigation strategies. Lastly, we reveal a discrepancy\nbetween LLMs' internal encoding and external behavior: they may encode the\ncorrect answer, yet consistently generate an incorrect one. Taken together,\nthese insights deepen our understanding of LLM errors from the model's internal\nperspective, which can guide future research on enhancing error analysis and\nmitigation.\n","authors":["Hadas Orgad","Michael Toker","Zorik Gekhman","Roi Reichart","Idan Szpektor","Hadas Kotek","Yonatan Belinkov"],"pdf_url":"https://arxiv.org/pdf/2410.02707v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.16671v7","updated":"2024-10-07T14:44:44Z","published":"2024-02-26T15:47:01Z","title":"StructLM: Towards Building Generalist Models for Structured Knowledge\n  Grounding","summary":"  Structured data sources, such as tables, graphs, and databases, are\nubiquitous knowledge sources. Despite the demonstrated capabilities of large\nlanguage models (LLMs) on plain text, their proficiency in interpreting and\nutilizing structured data remains limited. Our investigation reveals a notable\ndeficiency in LLMs' ability to process structured data, e.g., ChatGPT lags\nbehind state-of-the-art (SoTA) model by an average of 35%. To augment the\nStructured Knowledge Grounding (SKG) capabilities in LLMs, we have developed a\ncomprehensive instruction tuning dataset comprising 1.1 million examples.\nUtilizing this dataset, we train a series of models, referred to as StructLM,\nbased on the Mistral and the CodeLlama model family, ranging from 7B to 34B\nparameters. Our StructLM series surpasses task-specific models on 16 out of 18\nevaluated datasets and establishes new SoTA performance on 8 SKG tasks.\nFurthermore, StructLM demonstrates strong generalization across 6 novel\nheld-out SKG tasks, outperforming TableLlama by an average of 35\\% and Flan-UL2\n20B by an average of 10\\%. Contrary to expectations, we observe that scaling\nmodel size offers marginal benefits, with StructLM-34B showing only slight\nimprovements over StructLM-7B. This suggests that structured knowledge\ngrounding is still a challenging task and requires more innovative design to\npush to a new level.\n","authors":["Alex Zhuang","Ge Zhang","Tianyu Zheng","Xinrun Du","Junjie Wang","Weiming Ren","Stephen W. Huang","Jie Fu","Xiang Yue","Wenhu Chen"],"pdf_url":"https://arxiv.org/pdf/2402.16671v7.pdf","comment":"Technical Report"},{"id":"http://arxiv.org/abs/2410.05085v1","updated":"2024-10-07T14:39:45Z","published":"2024-10-07T14:39:45Z","title":"Explanation sensitivity to the randomness of large language models: the\n  case of journalistic text classification","summary":"  Large language models (LLMs) perform very well in several natural language\nprocessing tasks but raise explainability challenges. In this paper, we examine\nthe effect of random elements in the training of LLMs on the explainability of\ntheir predictions. We do so on a task of opinionated journalistic text\nclassification in French. Using a fine-tuned CamemBERT model and an explanation\nmethod based on relevance propagation, we find that training with different\nrandom seeds produces models with similar accuracy but variable explanations.\nWe therefore claim that characterizing the explanations' statistical\ndistribution is needed for the explainability of LLMs. We then explore a\nsimpler model based on textual features which offers stable explanations but is\nless accurate. Hence, this simpler model corresponds to a different tradeoff\nbetween accuracy and explainability. We show that it can be improved by\ninserting features derived from CamemBERT's explanations. We finally discuss\nnew research directions suggested by our results, in particular regarding the\norigin of the sensitivity observed in the training randomness.\n","authors":["Jeremie Bogaert","Marie-Catherine de Marneffe","Antonin Descampe","Louis Escouflaire","Cedrick Fairon","Francois-Xavier Standaert"],"pdf_url":"https://arxiv.org/pdf/2410.05085v1.pdf","comment":"This paper is a faithful translation of a paper which was\n  peer-reviewed and published in the French journal Traitement Automatique des\n  Langues, n. 64"},{"id":"http://arxiv.org/abs/2405.14768v2","updated":"2024-10-07T14:35:14Z","published":"2024-05-23T16:35:52Z","title":"WISE: Rethinking the Knowledge Memory for Lifelong Model Editing of\n  Large Language Models","summary":"  Large language models (LLMs) need knowledge updates to meet the ever-growing\nworld facts and correct the hallucinated responses, facilitating the methods of\nlifelong model editing. Where the updated knowledge resides in memories is a\nfundamental question for model editing. In this paper, we find that editing\neither long-term memory (direct model parameters) or working memory\n(non-parametric knowledge of neural network activations/representations by\nretrieval) will result in an impossible triangle -- reliability,\ngeneralization, and locality can not be realized together in the lifelong\nediting settings. For long-term memory, directly editing the parameters will\ncause conflicts with irrelevant pretrained knowledge or previous edits (poor\nreliability and locality). For working memory, retrieval-based activations can\nhardly make the model understand the edits and generalize (poor\ngeneralization). Therefore, we propose WISE to bridge the gap between memories.\nIn WISE, we design a dual parametric memory scheme, which consists of the main\nmemory for the pretrained knowledge and a side memory for the edited knowledge.\nWe only edit the knowledge in the side memory and train a router to decide\nwhich memory to go through when given a query. For continual editing, we devise\na knowledge-sharding mechanism where different sets of edits reside in distinct\nsubspaces of parameters, and are subsequently merged into a shared memory\nwithout conflicts. Extensive experiments show that WISE can outperform previous\nmodel editing methods and overcome the impossible triangle under lifelong model\nediting of question answering, hallucination, and out-of-distribution settings\nacross trending LLM architectures, e.g., GPT, LLaMA, and Mistral. Code is\navailable at https://github.com/zjunlp/EasyEdit.\n","authors":["Peng Wang","Zexi Li","Ningyu Zhang","Ziwen Xu","Yunzhi Yao","Yong Jiang","Pengjun Xie","Fei Huang","Huajun Chen"],"pdf_url":"https://arxiv.org/pdf/2405.14768v2.pdf","comment":"NeurIPS 2024"},{"id":"http://arxiv.org/abs/2410.05080v1","updated":"2024-10-07T14:33:50Z","published":"2024-10-07T14:33:50Z","title":"ScienceAgentBench: Toward Rigorous Assessment of Language Agents for\n  Data-Driven Scientific Discovery","summary":"  The advancements of language language models (LLMs) have piqued growing\ninterest in developing LLM-based language agents to automate scientific\ndiscovery end-to-end, which has sparked both excitement and skepticism about\nthe true capabilities of such agents. In this work, we argue that for an agent\nto fully automate scientific discovery, it must be able to complete all\nessential tasks in the workflow. Thus, we call for rigorous assessment of\nagents on individual tasks in a scientific workflow before making bold claims\non end-to-end automation. To this end, we present ScienceAgentBench, a new\nbenchmark for evaluating language agents for data-driven scientific discovery.\nTo ensure the scientific authenticity and real-world relevance of our\nbenchmark, we extract 102 tasks from 44 peer-reviewed publications in four\ndisciplines and engage nine subject matter experts to validate them. We unify\nthe target output for every task to a self-contained Python program file and\nemploy an array of evaluation metrics to examine the generated programs,\nexecution results, and costs. Each task goes through multiple rounds of manual\nvalidation by annotators and subject matter experts to ensure its annotation\nquality and scientific plausibility. We also propose two effective strategies\nto mitigate data contamination concerns. Using our benchmark, we evaluate five\nopen-weight and proprietary LLMs, each with three frameworks: direct prompting,\nOpenHands, and self-debug. Given three attempts for each task, the\nbest-performing agent can only solve 32.4% of the tasks independently and 34.3%\nwith expert-provided knowledge. These results underscore the limited capacities\nof current language agents in generating code for data-driven discovery, let\nalone end-to-end automation for scientific research.\n","authors":["Ziru Chen","Shijie Chen","Yuting Ning","Qianheng Zhang","Boshi Wang","Botao Yu","Yifei Li","Zeyi Liao","Chen Wei","Zitong Lu","Vishal Dey","Mingyi Xue","Frazier N. Baker","Benjamin Burns","Daniel Adu-Ampratwum","Xuhui Huang","Xia Ning","Song Gao","Yu Su","Huan Sun"],"pdf_url":"https://arxiv.org/pdf/2410.05080v1.pdf","comment":"55 pages"},{"id":"http://arxiv.org/abs/2410.05077v1","updated":"2024-10-07T14:31:43Z","published":"2024-10-07T14:31:43Z","title":"ZEBRA: Zero-Shot Example-Based Retrieval Augmentation for Commonsense\n  Question Answering","summary":"  Current Large Language Models (LLMs) have shown strong reasoning capabilities\nin commonsense question answering benchmarks, but the process underlying their\nsuccess remains largely opaque. As a consequence, recent approaches have\nequipped LLMs with mechanisms for knowledge retrieval, reasoning and\nintrospection, not only to improve their capabilities but also to enhance the\ninterpretability of their outputs. However, these methods require additional\ntraining, hand-crafted templates or human-written explanations. To address\nthese issues, we introduce ZEBRA, a zero-shot question answering framework that\ncombines retrieval, case-based reasoning and introspection and dispenses with\nthe need for additional training of the LLM. Given an input question, ZEBRA\nretrieves relevant question-knowledge pairs from a knowledge base and generates\nnew knowledge by reasoning over the relationships in these pairs. This\ngenerated knowledge is then used to answer the input question, improving the\nmodel's performance and interpretability. We evaluate our approach across 8\nwell-established commonsense reasoning benchmarks, demonstrating that ZEBRA\nconsistently outperforms strong LLMs and previous knowledge integration\napproaches, achieving an average accuracy improvement of up to 4.5 points.\n","authors":["Francesco Maria Molfese","Simone Conia","Riccardo Orlando","Roberto Navigli"],"pdf_url":"https://arxiv.org/pdf/2410.05077v1.pdf","comment":"Accepted at EMNLP 2024 Main Conference"},{"id":"http://arxiv.org/abs/2410.05076v1","updated":"2024-10-07T14:30:27Z","published":"2024-10-07T14:30:27Z","title":"TidalDecode: Fast and Accurate LLM Decoding with Position Persistent\n  Sparse Attention","summary":"  Large language models (LLMs) have driven significant advancements across\ndiverse NLP tasks, with long-context models gaining prominence for handling\nextended inputs. However, the expanding key-value (KV) cache size required by\nTransformer architectures intensifies the memory constraints, particularly\nduring the decoding phase, creating a significant bottleneck. Existing sparse\nattention mechanisms designed to address this bottleneck have two limitations:\n(1) they often fail to reliably identify the most relevant tokens for\nattention, and (2) they overlook the spatial coherence of token selection\nacross consecutive Transformer layers, which can lead to performance\ndegradation and substantial overhead in token selection. This paper introduces\nTidalDecode, a simple yet effective algorithm and system for fast and accurate\nLLM decoding through position persistent sparse attention. TidalDecode\nleverages the spatial coherence of tokens selected by existing sparse attention\nmethods and introduces a few token selection layers that perform full attention\nto identify the tokens with the highest attention scores, while all other\nlayers perform sparse attention with the pre-selected tokens. This design\nenables TidalDecode to substantially reduce the overhead of token selection for\nsparse attention without sacrificing the quality of the generated results.\nEvaluation on a diverse set of LLMs and tasks shows that TidalDecode closely\nmatches the generative performance of full attention methods while reducing the\nLLM decoding latency by up to 2.1x.\n","authors":["Lijie Yang","Zhihao Zhang","Zhuofu Chen","Zikun Li","Zhihao Jia"],"pdf_url":"https://arxiv.org/pdf/2410.05076v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.12034v2","updated":"2024-10-07T14:27:56Z","published":"2024-06-17T19:06:54Z","title":"Self-MoE: Towards Compositional Large Language Models with\n  Self-Specialized Experts","summary":"  We present Self-MoE, an approach that transforms a monolithic LLM into a\ncompositional, modular system of self-specialized experts, named MiXSE (MiXture\nof Self-specialized Experts). Our approach leverages self-specialization, which\nconstructs expert modules using self-generated synthetic data, each equipping a\nshared base LLM with distinct domain-specific capabilities, activated via\nself-optimized routing. This allows for dynamic and capability-specific\nhandling of various target tasks, enhancing overall capabilities, without\nextensive human-labeled data and added parameters. Our empirical results reveal\nthat specializing LLMs may exhibit potential trade-offs in performances on\nnon-specialized tasks. On the other hand, our Self-MoE demonstrates substantial\nimprovements (6.5%p on average) over the base LLM across diverse benchmarks\nsuch as knowledge, reasoning, math, and coding. It also consistently\noutperforms other methods, including instance merging and weight merging, while\noffering better flexibility and interpretability by design with semantic\nexperts and routing. Our findings highlight the critical role of modularity,\nthe applicability of Self-MoE to multiple base LLMs, and the potential of\nself-improvement in achieving efficient, scalable, and adaptable systems.\n","authors":["Junmo Kang","Leonid Karlinsky","Hongyin Luo","Zhen Wang","Jacob Hansen","James Glass","David Cox","Rameswar Panda","Rogerio Feris","Alan Ritter"],"pdf_url":"https://arxiv.org/pdf/2406.12034v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2112.02325v2","updated":"2024-10-07T14:26:18Z","published":"2021-12-04T13:18:12Z","title":"A Russian Jeopardy! Data Set for Question-Answering Systems","summary":"  Question answering (QA) is one of the most common NLP tasks that relates to\nnamed entity recognition, fact extraction, semantic search and some other\nfields. In industry, it is much appreciated in chatbots and corporate\ninformation systems. It is also a challenging task that attracted the attention\nof a very general audience at the quiz show Jeopardy! In this article we\ndescribe a Jeopardy!-like Russian QA data set collected from the official\nRussian quiz database Chgk (che ge ka). The data set includes 379,284 quiz-like\nquestions with 29,375 from the Russian analogue of Jeopardy! - \"Own Game\". We\nobserve its linguistic features and the related QA-task. We conclude about\nperspectives of a QA competition based on the data set collected from this\ndatabase.\n","authors":["Elena Mikhalkova"],"pdf_url":"https://arxiv.org/pdf/2112.02325v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.19745v2","updated":"2024-10-07T14:17:44Z","published":"2024-09-29T15:40:54Z","title":"PEAR: Position-Embedding-Agnostic Attention Re-weighting Enhances\n  Retrieval-Augmented Generation with Zero Inference Overhead","summary":"  Large language models (LLMs) enhanced with retrieval-augmented generation\n(RAG) have introduced a new paradigm for web search. However, the limited\ncontext awareness of LLMs degrades their performance on RAG tasks. Existing\nmethods to enhance context awareness are often inefficient, incurring time or\nmemory overhead during inference, and many are tailored to specific position\nembeddings. In this paper, we propose Position-Embedding-Agnostic attention\nRe-weighting (PEAR), which enhances the context awareness of LLMs with zero\ninference overhead. Specifically, on a proxy task focused on context copying,\nwe first detect heads which suppress the models' context awareness thereby\ndiminishing RAG performance. To weaken the impact of these heads, we re-weight\ntheir outputs with learnable coefficients. The LLM (with frozen parameters) is\noptimized by adjusting these coefficients to minimize loss on the proxy task.\nAs a result, the coefficients are optimized to values less than one, thereby\nreducing their tendency to suppress RAG performance. During inference, the\noptimized coefficients are fixed to re-weight these heads, regardless of the\nspecific task at hand. Our proposed PEAR offers two major advantages over\nprevious approaches: (1) It introduces zero additional inference overhead in\nterms of memory usage or inference time, while outperforming competitive\nbaselines in accuracy and efficiency across various RAG tasks. (2) It is\nindependent of position embedding algorithms, ensuring broader applicability.\n","authors":["Tao Tan","Yining Qian","Ang Lv","Hongzhan Lin","Songhao Wu","Yongbo Wang","Feng Wang","Jingtong Wu","Xin Lu","Rui Yan"],"pdf_url":"https://arxiv.org/pdf/2409.19745v2.pdf","comment":"preprint"},{"id":"http://arxiv.org/abs/2410.05052v1","updated":"2024-10-07T14:09:58Z","published":"2024-10-07T14:09:58Z","title":"Initialization of Large Language Models via Reparameterization to\n  Mitigate Loss Spikes","summary":"  Loss spikes, a phenomenon in which the loss value diverges suddenly, is a\nfundamental issue in the pre-training of large language models. This paper\nsupposes that the non-uniformity of the norm of the parameters is one of the\ncauses of loss spikes. Here, in training of neural networks, the scale of the\ngradients is required to be kept constant throughout the layers to avoid the\nvanishing and exploding gradients problem. However, to meet these requirements\nin the Transformer model, the norm of the model parameters must be non-uniform,\nand thus, parameters whose norm is smaller are more sensitive to the parameter\nupdate. To address this issue, we propose a novel technique, weight scaling as\nreparameterization (WeSaR). WeSaR introduces a gate parameter per parameter\nmatrix and adjusts it to the value satisfying the requirements. Because of the\ngate parameter, WeSaR sets the norm of the original parameters uniformly, which\nresults in stable training. Experimental results with the Transformer decoders\nconsisting of 130 million, 1.3 billion, and 13 billion parameters showed that\nWeSaR stabilizes and accelerates training and that it outperformed compared\nmethods including popular initialization methods.\n","authors":["Kosuke Nishida","Kyosuke Nishida","Kuniko Saito"],"pdf_url":"https://arxiv.org/pdf/2410.05052v1.pdf","comment":"EMNLP2024 accepted"},{"id":"http://arxiv.org/abs/2406.12058v4","updated":"2024-10-07T14:08:13Z","published":"2024-06-17T19:50:40Z","title":"WellDunn: On the Robustness and Explainability of Language Models and\n  Large Language Models in Identifying Wellness Dimensions","summary":"  Language Models (LMs) are being proposed for mental health applications where\nthe heightened risk of adverse outcomes means predictive performance may not be\na sufficient litmus test of a model's utility in clinical practice. A model\nthat can be trusted for practice should have a correspondence between\nexplanation and clinical determination, yet no prior research has examined the\nattention fidelity of these models and their effect on ground truth\nexplanations. We introduce an evaluation design that focuses on the robustness\nand explainability of LMs in identifying Wellness Dimensions (WDs). We focus on\ntwo existing mental health and well-being datasets: (a) Multi-label\nClassification-based MultiWD, and (b) WellXplain for evaluating attention\nmechanism veracity against expert-labeled explanations. The labels are based on\nHalbert Dunn's theory of wellness, which gives grounding to our evaluation. We\nreveal four surprising results about LMs/LLMs: (1) Despite their human-like\ncapabilities, GPT-3.5/4 lag behind RoBERTa, and MedAlpaca, a fine-tuned LLM on\nWellXplain fails to deliver any remarkable improvements in performance or\nexplanations. (2) Re-examining LMs' predictions based on a confidence-oriented\nloss function reveals a significant performance drop. (3) Across all LMs/LLMs,\nthe alignment between attention and explanations remains low, with LLMs scoring\na dismal 0.0. (4) Most mental health-specific LMs/LLMs overlook domain-specific\nknowledge and undervalue explanations, causing these discrepancies. This study\nhighlights the need for further research into their consistency and\nexplanations in mental health and well-being.\n","authors":["Seyedali Mohammadi","Edward Raff","Jinendra Malekar","Vedant Palit","Francis Ferraro","Manas Gaur"],"pdf_url":"https://arxiv.org/pdf/2406.12058v4.pdf","comment":"Accepted in BlackboxNLP @ EMNLP 2024"},{"id":"http://arxiv.org/abs/2410.05047v1","updated":"2024-10-07T14:01:20Z","published":"2024-10-07T14:01:20Z","title":"A test suite of prompt injection attacks for LLM-based machine\n  translation","summary":"  LLM-based NLP systems typically work by embedding their input data into\nprompt templates which contain instructions and/or in-context examples,\ncreating queries which are submitted to a LLM, and then parsing the LLM\nresponse in order to generate the system outputs. Prompt Injection Attacks\n(PIAs) are a type of subversion of these systems where a malicious user crafts\nspecial inputs which interfere with the prompt templates, causing the LLM to\nrespond in ways unintended by the system designer.\n  Recently, Sun and Miceli-Barone proposed a class of PIAs against LLM-based\nmachine translation. Specifically, the task is to translate questions from the\nTruthfulQA test suite, where an adversarial prompt is prepended to the\nquestions, instructing the system to ignore the translation instruction and\nanswer the questions instead.\n  In this test suite, we extend this approach to all the language pairs of the\nWMT 2024 General Machine Translation task. Moreover, we include additional\nattack formats in addition to the one originally studied.\n","authors":["Antonio Valerio Miceli-Barone","Zhifan Sun"],"pdf_url":"https://arxiv.org/pdf/2410.05047v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.05046v1","updated":"2024-10-07T14:00:18Z","published":"2024-10-07T14:00:18Z","title":"Named Clinical Entity Recognition Benchmark","summary":"  This technical report introduces a Named Clinical Entity Recognition\nBenchmark for evaluating language models in healthcare, addressing the crucial\nnatural language processing (NLP) task of extracting structured information\nfrom clinical narratives to support applications like automated coding,\nclinical trial cohort identification, and clinical decision support.\n  The leaderboard provides a standardized platform for assessing diverse\nlanguage models, including encoder and decoder architectures, on their ability\nto identify and classify clinical entities across multiple medical domains. A\ncurated collection of openly available clinical datasets is utilized,\nencompassing entities such as diseases, symptoms, medications, procedures, and\nlaboratory measurements. Importantly, these entities are standardized according\nto the Observational Medical Outcomes Partnership (OMOP) Common Data Model,\nensuring consistency and interoperability across different healthcare systems\nand datasets, and a comprehensive evaluation of model performance. Performance\nof models is primarily assessed using the F1-score, and it is complemented by\nvarious assessment modes to provide comprehensive insights into model\nperformance. The report also includes a brief analysis of models evaluated to\ndate, highlighting observed trends and limitations.\n  By establishing this benchmarking framework, the leaderboard aims to promote\ntransparency, facilitate comparative analyses, and drive innovation in clinical\nentity recognition tasks, addressing the need for robust evaluation methods in\nhealthcare NLP.\n","authors":["Wadood M Abdul","Marco AF Pimentel","Muhammad Umar Salman","Tathagata Raha","Clément Christophe","Praveen K Kanithi","Nasir Hayat","Ronnie Rajan","Shadab Khan"],"pdf_url":"https://arxiv.org/pdf/2410.05046v1.pdf","comment":"Technical Report"},{"id":"http://arxiv.org/abs/2410.05045v1","updated":"2024-10-07T14:00:08Z","published":"2024-10-07T14:00:08Z","title":"Can LLMs plan paths with extra hints from solvers?","summary":"  Large Language Models (LLMs) have shown remarkable capabilities in natural\nlanguage processing, mathematical problem solving, and tasks related to program\nsynthesis. However, their effectiveness in long-term planning and higher-order\nreasoning has been noted to be limited and fragile. This paper explores an\napproach for enhancing LLM performance in solving a classical robotic planning\ntask by integrating solver-generated feedback. We explore four different\nstrategies for providing feedback, including visual feedback, we utilize\nfine-tuning, and we evaluate the performance of three different LLMs across a\n10 standard and 100 more randomly generated planning problems. Our results\nsuggest that the solver-generated feedback improves the LLM's ability to solve\nthe moderately difficult problems, but the harder problems still remain out of\nreach. The study provides detailed analysis of the effects of the different\nhinting strategies and the different planning tendencies of the evaluated LLMs.\n","authors":["Erik Wu","Sayan Mitra"],"pdf_url":"https://arxiv.org/pdf/2410.05045v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.05021v1","updated":"2024-10-07T13:24:24Z","published":"2024-10-07T13:24:24Z","title":"DEPT: Decoupled Embeddings for Pre-training Language Models","summary":"  Language Model pre-training benefits from a broader data mixture to enhance\nperformance across domains and languages. However, training on such\nheterogeneous text corpora is complex, requiring extensive and cost-intensive\nefforts. Since these data sources vary in lexical, syntactic, and semantic\naspects, they cause negative interference or the \"curse of multilinguality\". We\npropose a novel pre-training framework to alleviate this curse. Our method,\nDEPT, decouples the embedding layers from the transformer body while\nsimultaneously training the latter in multiple contexts. DEPT enables the model\nto train without being bound to a shared global vocabulary. DEPT: (1) can train\nrobustly and effectively under significant data heterogeneity, (2) reduces the\nparameter count of the token embeddings by up to 80% and the communication\ncosts by 675x for billion-scale models (3) enhances model generalization and\nplasticity in adapting to new languages and domains, and (4) allows training\nwith custom optimized vocabulary per data source. We prove DEPT's potential by\nperforming the first vocabulary-agnostic federated multilingual pre-training of\na 1.3 billion-parameter model across high and low-resource languages, reducing\nits parameter count by 409 million.\n","authors":["Alex Iacob","Lorenzo Sani","Meghdad Kurmanji","William F. Shen","Xinchi Qiu","Dongqi Cai","Yan Gao","Nicholas D. Lane"],"pdf_url":"https://arxiv.org/pdf/2410.05021v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.15160v2","updated":"2024-10-07T13:19:53Z","published":"2024-07-21T13:31:02Z","title":"When Can Transformers Count to n?","summary":"  Large language models based on the transformer architectures can solve highly\ncomplex tasks. But are there simple tasks that such models cannot solve? Here\nwe focus on very simple counting tasks, that involve counting how many times a\ntoken in the vocabulary have appeared in a string. We show that if the\ndimension of the transformer state is linear in the context length, this task\ncan be solved. However, the solution we propose does not scale beyond this\nlimit, and we provide theoretical arguments for why it is likely impossible for\na size limited transformer to implement this task. Our empirical results\ndemonstrate the same phase-transition in performance, as anticipated by the\ntheoretical argument. Our results demonstrate the importance of understanding\nhow transformers can solve simple tasks.\n","authors":["Gilad Yehudai","Haim Kaplan","Asma Ghandeharioun","Mor Geva","Amir Globerson"],"pdf_url":"https://arxiv.org/pdf/2407.15160v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.05018v1","updated":"2024-10-07T13:19:08Z","published":"2024-10-07T13:19:08Z","title":"On the Biased Assessment of Expert Finding Systems","summary":"  In large organisations, identifying experts on a given topic is crucial in\nleveraging the internal knowledge spread across teams and departments.\nSo-called enterprise expert retrieval systems automatically discover and\nstructure employees' expertise based on the vast amount of heterogeneous data\navailable about them and the work they perform. Evaluating these systems\nrequires comprehensive ground truth expert annotations, which are hard to\nobtain. Therefore, the annotation process typically relies on automated\nrecommendations of knowledge areas to validate. This case study provides an\nanalysis of how these recommendations can impact the evaluation of expert\nfinding systems. We demonstrate on a popular benchmark that system-validated\nannotations lead to overestimated performance of traditional term-based\nretrieval models and even invalidate comparisons with more recent neural\nmethods. We also augment knowledge areas with synonyms to uncover a strong bias\ntowards literal mentions of their constituent words. Finally, we propose\nconstraints to the annotation process to prevent these biased evaluations, and\nshow that this still allows annotation suggestions of high utility. These\nfindings should inform benchmark creation or selection for expert finding, to\nguarantee meaningful comparison of methods.\n","authors":["Jens-Joris Decorte","Jeroen Van Hautte","Chris Develder","Thomas Demeester"],"pdf_url":"https://arxiv.org/pdf/2410.05018v1.pdf","comment":"Accepted to the 4th Workshop on Recommender Systems for Human\n  Resources (RecSys in HR 2024) as part of RecSys 2024"},{"id":"http://arxiv.org/abs/2402.18376v2","updated":"2024-10-07T13:17:03Z","published":"2024-02-28T14:52:15Z","title":"Tokenization Is More Than Compression","summary":"  Tokenization is a foundational step in natural language processing (NLP)\ntasks, bridging raw text and language models. Existing tokenization approaches\nlike Byte-Pair Encoding (BPE) originate from the field of data compression, and\nit has been suggested that the effectiveness of BPE stems from its ability to\ncondense text into a relatively small number of tokens. We test the hypothesis\nthat fewer tokens lead to better downstream performance by introducing\nPathPiece, a new tokenizer that segments a document's text into the minimum\nnumber of tokens for a given vocabulary. Through extensive experimentation we\nfind this hypothesis not to be the case, casting doubt on the understanding of\nthe reasons for effective tokenization. To examine which other factors play a\nrole, we evaluate design decisions across all three phases of tokenization:\npre-tokenization, vocabulary construction, and segmentation, offering new\ninsights into the design of effective tokenizers. Specifically, we illustrate\nthe importance of pre-tokenization and the benefits of using BPE to initialize\nvocabulary construction. We train 64 language models with varying tokenization,\nranging in size from 350M to 2.4B parameters, all of which are made publicly\navailable.\n","authors":["Craig W. Schmidt","Varshini Reddy","Haoran Zhang","Alec Alameddine","Omri Uzan","Yuval Pinter","Chris Tanner"],"pdf_url":"https://arxiv.org/pdf/2402.18376v2.pdf","comment":"EMNLP 2024"},{"id":"http://arxiv.org/abs/2410.05006v1","updated":"2024-10-07T13:05:26Z","published":"2024-10-07T13:05:26Z","title":"SkillMatch: Evaluating Self-supervised Learning of Skill Relatedness","summary":"  Accurately modeling the relationships between skills is a crucial part of\nhuman resources processes such as recruitment and employee development. Yet, no\nbenchmarks exist to evaluate such methods directly. We construct and release\nSkillMatch, a benchmark for the task of skill relatedness, based on expert\nknowledge mining from millions of job ads. Additionally, we propose a scalable\nself-supervised learning technique to adapt a Sentence-BERT model based on\nskill co-occurrence in job ads. This new method greatly surpasses traditional\nmodels for skill relatedness as measured on SkillMatch. By releasing SkillMatch\npublicly, we aim to contribute a foundation for research towards increased\naccuracy and transparency of skill-based recommendation systems.\n","authors":["Jens-Joris Decorte","Jeroen Van Hautte","Thomas Demeester","Chris Develder"],"pdf_url":"https://arxiv.org/pdf/2410.05006v1.pdf","comment":"Accepted to the International workshop on AI for Human Resources and\n  Public Employment Services (AI4HR&PES) as part of ECML-PKDD 2024"},{"id":"http://arxiv.org/abs/2406.04866v2","updated":"2024-10-07T12:32:24Z","published":"2024-06-07T12:01:59Z","title":"ComplexTempQA: A Large-Scale Dataset for Complex Temporal Question\n  Answering","summary":"  We introduce ComplexTempQA, a large-scale dataset consisting of over 100\nmillion question-answer pairs designed to tackle the challenges in temporal\nquestion answering. ComplexTempQA significantly surpasses existing benchmarks\nlike HOTPOTQA, TORQUE, and TEQUILA in scale and scope. Utilizing data from\nWikipedia and Wikidata, the dataset covers questions spanning over two decades\nand offers an unmatched breadth of topics. We introduce a unique taxonomy that\ncategorizes questions as attributes, comparisons, and counting questions, each\nrevolving around events, entities, and time periods. One standout feature of\nComplexTempQA is the high complexity of its questions, which demand effective\ncapabilities for answering such as across-time comparison, temporal\naggregation, and multi-hop reasoning involving temporal event ordering and\nentity recognition. Additionally, each question is accompanied by detailed\nmetadata, including specific time scopes, allowing for comprehensive evaluation\nand enhancement of the temporal reasoning abilities of large language models.\nComplexTempQA serves both as a testing ground for developing sophisticated AI\nmodels and as a foundation for advancing research in question answering,\ninformation retrieval, and language understanding.\n","authors":["Raphael Gruber","Abdelrahman Abdallah","Michael Färber","Adam Jatowt"],"pdf_url":"https://arxiv.org/pdf/2406.04866v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04981v1","updated":"2024-10-07T12:22:06Z","published":"2024-10-07T12:22:06Z","title":"On the Rigour of Scientific Writing: Criteria, Analysis, and Insights","summary":"  Rigour is crucial for scientific research as it ensures the reproducibility\nand validity of results and findings. Despite its importance, little work\nexists on modelling rigour computationally, and there is a lack of analysis on\nwhether these criteria can effectively signal or measure the rigour of\nscientific papers in practice. In this paper, we introduce a bottom-up,\ndata-driven framework to automatically identify and define rigour criteria and\nassess their relevance in scientific writing. Our framework includes rigour\nkeyword extraction, detailed rigour definition generation, and salient criteria\nidentification. Furthermore, our framework is domain-agnostic and can be\ntailored to the evaluation of scientific rigour for different areas,\naccommodating the distinct salient criteria across fields. We conducted\ncomprehensive experiments based on datasets collected from two high impact\nvenues for Machine Learning and NLP (i.e., ICLR and ACL) to demonstrate the\neffectiveness of our framework in modelling rigour. In addition, we analyse\nlinguistic patterns of rigour, revealing that framing certainty is crucial for\nenhancing the perception of scientific rigour, while suggestion certainty and\nprobability uncertainty diminish it.\n","authors":["Joseph James","Chenghao Xiao","Yucheng Li","Chenghua Lin"],"pdf_url":"https://arxiv.org/pdf/2410.04981v1.pdf","comment":"Accepted Findings at EMNLP 2024"},{"id":"http://arxiv.org/abs/2402.02987v2","updated":"2024-10-07T12:11:58Z","published":"2024-02-05T13:18:42Z","title":"Reconstruct Your Previous Conversations! Comprehensively Investigating\n  Privacy Leakage Risks in Conversations with GPT Models","summary":"  Significant advancements have recently been made in large language models\nrepresented by GPT models. Users frequently have multi-round private\nconversations with cloud-hosted GPT models for task optimization. Yet, this\noperational paradigm introduces additional attack surfaces, particularly in\ncustom GPTs and hijacked chat sessions. In this paper, we introduce a\nstraightforward yet potent Conversation Reconstruction Attack. This attack\ntargets the contents of previous conversations between GPT models and benign\nusers, i.e., the benign users' input contents during their interaction with GPT\nmodels. The adversary could induce GPT models to leak such contents by querying\nthem with designed malicious prompts. Our comprehensive examination of privacy\nrisks during the interactions with GPT models under this attack reveals GPT-4's\nconsiderable resilience. We present two advanced attacks targeting improved\nreconstruction of past conversations, demonstrating significant privacy leakage\nacross all models under these advanced techniques. Evaluating various defense\nmechanisms, we find them ineffective against these attacks. Our findings\nhighlight the ease with which privacy can be compromised in interactions with\nGPT models, urging the community to safeguard against potential abuses of these\nmodels' capabilities.\n","authors":["Junjie Chu","Zeyang Sha","Michael Backes","Yang Zhang"],"pdf_url":"https://arxiv.org/pdf/2402.02987v2.pdf","comment":"Accepted in EMNLP 2024. 14 pages, 10 figures"},{"id":"http://arxiv.org/abs/2409.19339v2","updated":"2024-10-07T12:05:55Z","published":"2024-09-28T12:49:16Z","title":"Visual Question Decomposition on Multimodal Large Language Models","summary":"  Question decomposition has emerged as an effective strategy for prompting\nLarge Language Models (LLMs) to answer complex questions. However, while\nexisting methods primarily focus on unimodal language models, the question\ndecomposition capability of Multimodal Large Language Models (MLLMs) has yet to\nbe explored. To this end, this paper explores visual question decomposition on\nMLLMs. Specifically, we introduce a systematic evaluation framework including a\ndataset and several evaluation criteria to assess the quality of the decomposed\nsub-questions, revealing that existing MLLMs struggle to produce high-quality\nsub-questions. To address this limitation, we propose a specific finetuning\ndataset, DecoVQA+, for enhancing the model's question decomposition capability.\nAiming at enabling models to perform appropriate selective decomposition, we\npropose an efficient finetuning pipeline. The finetuning pipeline consists of\nour proposed dataset and a training objective for selective decomposition.\nFinetuned MLLMs demonstrate significant improvements in the quality of\nsub-questions and the policy of selective question decomposition. Additionally,\nthe models also achieve higher accuracy with selective decomposition on VQA\nbenchmark datasets.\n","authors":["Haowei Zhang","Jianzhe Liu","Zhen Han","Shuo Chen","Bailan He","Volker Tresp","Zhiqiang Xu","Jindong Gu"],"pdf_url":"https://arxiv.org/pdf/2409.19339v2.pdf","comment":"Accepted to EMNLP2024 Findings"},{"id":"http://arxiv.org/abs/2410.04962v1","updated":"2024-10-07T12:01:32Z","published":"2024-10-07T12:01:32Z","title":"Activation Scaling for Steering and Interpreting Language Models","summary":"  Given the prompt \"Rome is in\", can we steer a language model to flip its\nprediction of an incorrect token \"France\" to a correct token \"Italy\" by only\nmultiplying a few relevant activation vectors with scalars? We argue that\nsuccessfully intervening on a model is a prerequisite for interpreting its\ninternal workings. Concretely, we establish a three-term objective: a\nsuccessful intervention should flip the correct with the wrong token and vice\nversa (effectiveness), and leave other tokens unaffected (faithfulness), all\nwhile being sparse (minimality). Using gradient-based optimization, this\nobjective lets us learn (and later evaluate) a specific kind of efficient and\ninterpretable intervention: activation scaling only modifies the signed\nmagnitude of activation vectors to strengthen, weaken, or reverse the steering\ndirections already encoded in the model. On synthetic tasks, this intervention\nperforms comparably with steering vectors in terms of effectiveness and\nfaithfulness, but is much more minimal allowing us to pinpoint interpretable\nmodel components. We evaluate activation scaling from different angles, compare\nperformance on different datasets, and make activation scalars a learnable\nfunction of the activation vectors themselves to generalize to varying-length\nprompts.\n","authors":["Niklas Stoehr","Kevin Du","Vésteinn Snæbjarnarson","Robert West","Ryan Cotterell","Aaron Schein"],"pdf_url":"https://arxiv.org/pdf/2410.04962v1.pdf","comment":"Findings of the Association for Computational Linguistics: EMNLP 2024"},{"id":"http://arxiv.org/abs/2407.17023v2","updated":"2024-10-07T11:59:37Z","published":"2024-07-24T06:06:07Z","title":"DYNAMICQA: Tracing Internal Knowledge Conflicts in Language Models","summary":"  Knowledge-intensive language understanding tasks require Language Models\n(LMs) to integrate relevant context, mitigating their inherent weaknesses, such\nas incomplete or outdated knowledge. However, conflicting knowledge can be\npresent in the LM's parameters, termed intra-memory conflict, which can affect\na model's propensity to accept contextual knowledge. To study the effect of\nintra-memory conflict on an LM's ability to accept relevant context, we utilize\ntwo knowledge conflict measures and a novel dataset containing inherently\nconflicting data, DynamicQA. This dataset includes facts with a temporal\ndynamic nature where facts can change over time and disputable dynamic facts,\nwhich can change depending on the viewpoint. DynamicQA is the first to include\nreal-world knowledge conflicts and provide context to study the link between\nthe different types of knowledge conflicts. We also evaluate several measures\non their ability to reflect the presence of intra-memory conflict: semantic\nentropy and a novel coherent persuasion score. With our extensive experiments,\nwe verify that LMs exhibit a greater degree of intra-memory conflict with\ndynamic facts compared to facts that have a single truth value. Furthermore, we\nreveal that facts with intra-memory conflict are harder to update with context,\nsuggesting that retrieval-augmented generation will struggle with the most\ncommonly adapted facts.\n","authors":["Sara Vera Marjanović","Haeun Yu","Pepa Atanasova","Maria Maistro","Christina Lioma","Isabelle Augenstein"],"pdf_url":"https://arxiv.org/pdf/2407.17023v2.pdf","comment":"15 pages, 6 figures, Accepted to Findings of EMNLP 2024"},{"id":"http://arxiv.org/abs/2409.04185v2","updated":"2024-10-07T11:54:11Z","published":"2024-09-06T11:01:55Z","title":"Residual Stream Analysis with Multi-Layer SAEs","summary":"  Sparse autoencoders (SAEs) are a promising approach to interpreting the\ninternal representations of transformer language models. However, SAEs are\nusually trained separately on each transformer layer, making it difficult to\nuse them to study how information flows across layers. To solve this problem,\nwe introduce the multi-layer SAE (MLSAE): a single SAE trained on the residual\nstream activation vectors from every transformer layer. Given that the residual\nstream is understood to preserve information across layers, we expected MLSAE\nlatents to `switch on' at a token position and remain active at later layers.\nInterestingly, we find that individual latents are often active at a single\nlayer for a given token or prompt, but this layer may differ for different\ntokens or prompts. We quantify these phenomena by defining a distribution over\nlayers and considering its variance. We find that the variance of the\ndistributions of latent activations over layers is about two orders of\nmagnitude greater when aggregating over tokens compared with a single token.\nFor larger underlying models, the degree to which latents are active at\nmultiple layers increases, which is consistent with the fact that the residual\nstream activation vectors at adjacent layers become more similar. Finally, we\nrelax the assumption that the residual stream basis is the same at every layer\nby applying pre-trained tuned-lens transformations, but our findings remain\nqualitatively similar. Our results represent a new approach to understanding\nhow representations change as they flow through transformers. We release our\ncode to train and analyze MLSAEs at https://github.com/tim-lawson/mlsae.\n","authors":["Tim Lawson","Lucy Farnik","Conor Houghton","Laurence Aitchison"],"pdf_url":"https://arxiv.org/pdf/2409.04185v2.pdf","comment":"34 pages, 26 figures"},{"id":"http://arxiv.org/abs/2407.10805v4","updated":"2024-10-07T11:52:50Z","published":"2024-07-15T15:20:40Z","title":"Think-on-Graph 2.0: Deep and Faithful Large Language Model Reasoning\n  with Knowledge-guided Retrieval Augmented Generation","summary":"  Retrieval-augmented generation (RAG) has enhanced large language models\n(LLMs) by using knowledge retrieval to address knowledge gaps. However,\nexisting RAG approaches often fail to ensure the depth and completeness of the\ninformation retrieved, which is essential for complex reasoning tasks. In this\nwork, we present Think-on-Graph 2.0 (ToG-2), a hybrid RAG framework that\niteratively retrieves information from both unstructured and structured\nknowledge sources in a tightly integrated manner. Specifically, ToG-2 leverages\nknowledge graphs (KGs) to connect documents via entities, facilitating deep and\nknowledge-guided context retrieval. Simultaneously, it uses documents as entity\ncontexts to enable precise and efficient graph retrieval.\n  ToG-2 alternates between graph retrieval and context retrieval to search for\nin-depth clues relevant to the question, enabling LLMs to generate accurate\nanswers. We conduct a series of experiments to demonstrate the following\nadvantages of ToG-2: (1) ToG-2 tightly integrates context retrieval and graph\nretrieval, enhancing context retrieval through the KG while enabling reliable\ngraph retrieval based on contexts; (2) it achieves deep and faithful reasoning\nin LLMs through an iterative knowledge retrieval process that integrates\ncontexts and the KG; and (3) ToG-2 is training-free and compatible with various\nLLMs as a plug-and-play solution. Extensive experiments show that ToG-2\nachieves state-of-the-art (SOTA) performance on 6 out of 7 knowledge-intensive\ndatasets with GPT-3.5, and can elevate the performance of smaller models (e.g.,\nLLAMA-2-13B) to the level of GPT-3.5's direct reasoning.\n","authors":["Shengjie Ma","Chengjin Xu","Xuhui Jiang","Muzhi Li","Huaren Qu","Cehao Yang","Jiaxin Mao","Jian Guo"],"pdf_url":"https://arxiv.org/pdf/2407.10805v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.14883v2","updated":"2024-10-07T11:37:44Z","published":"2024-04-23T10:09:46Z","title":"Language in Vivo vs. in Silico: Size Matters but Larger Language Models\n  Still Do Not Comprehend Language on a Par with Humans","summary":"  Understanding the limits of language is a prerequisite for Large Language\nModels (LLMs) to act as theories of natural language. LLM performance in some\nlanguage tasks presents both quantitative and qualitative differences from that\nof humans, however it remains to be determined whether such differences are\namenable to model size. This work investigates the critical role of model\nscaling, determining whether increases in size make up for such differences\nbetween humans and models. We test three LLMs from different families (Bard,\n137 billion parameters; ChatGPT-3.5, 175 billion; ChatGPT-4, 1.5 trillion) on a\ngrammaticality judgment task featuring anaphora, center embedding,\ncomparatives, and negative polarity. N=1,200 judgments are collected and scored\nfor accuracy, stability, and improvements in accuracy upon repeated\npresentation of a prompt. Results of the best performing LLM, ChatGPT-4, are\ncompared to results of n=80 humans on the same stimuli. We find that humans are\noverall less accurate than ChatGPT-4 (76% vs. 80% accuracy, respectively), but\nthat this is due to ChatGPT-4 outperforming humans only in one task condition,\nnamely on grammatical sentences. Additionally, ChatGPT-4 wavers more than\nhumans in its answers (12.5% vs. 9.6% likelihood of an oscillating answer,\nrespectively). Thus, while increased model size may lead to better performance,\nLLMs are still not sensitive to (un)grammaticality the same way as humans are.\nIt seems possible but unlikely that scaling alone can fix this issue. We\ninterpret these results by comparing language learning in vivo and in silico,\nidentifying three critical differences concerning (i) the type of evidence,\n(ii) the poverty of the stimulus, and (iii) the occurrence of semantic\nhallucinations due to impenetrable linguistic reference.\n","authors":["Vittoria Dentella","Fritz Guenther","Evelina Leivada"],"pdf_url":"https://arxiv.org/pdf/2404.14883v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04925v1","updated":"2024-10-07T11:17:05Z","published":"2024-10-07T11:17:05Z","title":"Intent Classification for Bank Chatbots through LLM Fine-Tuning","summary":"  This study evaluates the application of large language models (LLMs) for\nintent classification within a chatbot with predetermined responses designed\nfor banking industry websites. Specifically, the research examines the\neffectiveness of fine-tuning SlovakBERT compared to employing multilingual\ngenerative models, such as Llama 8b instruct and Gemma 7b instruct, in both\ntheir pre-trained and fine-tuned versions. The findings indicate that\nSlovakBERT outperforms the other models in terms of in-scope accuracy and\nout-of-scope false positive rate, establishing it as the benchmark for this\napplication.\n","authors":["Bibiána Lajčinová","Patrik Valábek","Michal Spišiak"],"pdf_url":"https://arxiv.org/pdf/2410.04925v1.pdf","comment":"7 pages, no figures"},{"id":"http://arxiv.org/abs/2401.05930v4","updated":"2024-10-07T09:58:48Z","published":"2024-01-11T14:09:09Z","title":"SH2: Self-Highlighted Hesitation Helps You Decode More Truthfully","summary":"  Large language models (LLMs) demonstrate great performance in text\ngeneration. However, LLMs are still suffering from hallucinations. In this\nwork, we propose an inference-time method, Self-Highlighted Hesitation (SH2),\nto help LLMs decode more truthfully. SH2 is based on a simple fact rooted in\ninformation theory that for an LLM, the tokens predicted with lower\nprobabilities are prone to be more informative than others. Our analysis shows\nthat the tokens assigned with lower probabilities by an LLM are more likely to\nbe closely related to factual information, such as nouns, proper nouns, and\nadjectives. Therefore, we propose to ''highlight'' the factual information by\nselecting the tokens with the lowest probabilities and concatenating them to\nthe original context, thus forcing the model to repeatedly read and hesitate on\nthese tokens before generation. During decoding, we also adopt contrastive\ndecoding to emphasize the difference in the output probabilities brought by the\nhesitation. Experimental results demonstrate that our SH2, requiring no\nadditional data or models, can effectively help LLMs elicit factual knowledge\nand distinguish hallucinated contexts. Significant and consistent improvements\nare achieved by SH2 for LLaMA-7b, LLaMA2-7b and Mistral-7b on multiple\nhallucination tasks.\n","authors":["Jushi Kai","Tianhang Zhang","Hai Hu","Zhouhan Lin"],"pdf_url":"https://arxiv.org/pdf/2401.05930v4.pdf","comment":"EMNLP 2024 Findings"},{"id":"http://arxiv.org/abs/2410.04878v1","updated":"2024-10-07T09:57:59Z","published":"2024-10-07T09:57:59Z","title":"Leveraging Grammar Induction for Language Understanding and Generation","summary":"  Grammar induction has made significant progress in recent years. However, it\nis not clear how the application of induced grammar could enhance practical\nperformance in downstream tasks. In this work, we introduce an unsupervised\ngrammar induction method for language understanding and generation. We\nconstruct a grammar parser to induce constituency structures and dependency\nrelations, which is simultaneously trained on downstream tasks without\nadditional syntax annotations. The induced grammar features are subsequently\nincorporated into Transformer as a syntactic mask to guide self-attention. We\nevaluate and apply our method to multiple machine translation tasks and natural\nlanguage understanding tasks. Our method demonstrates superior performance\ncompared to the original Transformer and other models enhanced with external\nparsers. Experimental results indicate that our method is effective in both\nfrom-scratch and pre-trained scenarios. Additionally, our research highlights\nthe contribution of explicitly modeling the grammatical structure of texts to\nneural network models.\n","authors":["Jushi Kai","Shengyuan Hou","Yusheng Huang","Zhouhan Lin"],"pdf_url":"https://arxiv.org/pdf/2410.04878v1.pdf","comment":"EMNLP 2024 Findings"},{"id":"http://arxiv.org/abs/2408.15625v2","updated":"2024-10-07T09:49:08Z","published":"2024-08-28T08:25:22Z","title":"CBF-LLM: Safe Control for LLM Alignment","summary":"  This paper proposes a control-based framework for aligning large language\nmodels (LLMs) by leveraging a control barrier function (CBF) to ensure\nuser-desirable text generation. The presented framework applies the safety\nfilter, designed based on the CBF, to the output generation of the baseline\nLLM, i.e., the sequence of the token, with the aim of intervening in the\ngenerated text. The overall text-generation system is implemented with Llama 3\nand a RoBERTa model, and the source code is available at\nhttps://github.com/Mya-Mya/CBF-LLM. The experiment demonstrates its control\nability and effectiveness in reducing the number of interventions needed for\nuser-specified alignment tasks.\n","authors":["Yuya Miyaoka","Masaki Inoue"],"pdf_url":"https://arxiv.org/pdf/2408.15625v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.15489v2","updated":"2024-10-07T08:55:15Z","published":"2024-07-22T09:16:30Z","title":"A Comparison of Language Modeling and Translation as Multilingual\n  Pretraining Objectives","summary":"  Pretrained language models (PLMs) display impressive performances and have\ncaptured the attention of the NLP community. Establishing best practices in\npretraining has, therefore, become a major focus of NLP research, especially\nsince insights gained from monolingual English models may not necessarily apply\nto more complex multilingual models. One significant caveat of the current\nstate of the art is that different works are rarely comparable: they often\ndiscuss different parameter counts, training data, and evaluation methodology.\n  This paper proposes a comparison of multilingual pretraining objectives in a\ncontrolled methodological environment. We ensure that training data and model\narchitectures are comparable, and discuss the downstream performances across 6\nlanguages that we observe in probing and fine-tuning scenarios. We make two key\nobservations: (1) the architecture dictates which pretraining objective is\noptimal; (2) multilingual translation is a very effective pretraining objective\nunder the right conditions. We make our code, data, and model weights available\nat \\texttt{\\url{https://github.com/Helsinki-NLP/lm-vs-mt}}.\n","authors":["Zihao Li","Shaoxiong Ji","Timothee Mickus","Vincent Segonne","Jörg Tiedemann"],"pdf_url":"https://arxiv.org/pdf/2407.15489v2.pdf","comment":"Proceedings of EMNLP 2024"},{"id":"http://arxiv.org/abs/2410.04838v1","updated":"2024-10-07T08:53:00Z","published":"2024-10-07T08:53:00Z","title":"Rationale-Aware Answer Verification by Pairwise Self-Evaluation","summary":"  Answer verification identifies correct solutions among candidates generated\nby large language models (LLMs). Current approaches typically train verifier\nmodels by labeling solutions as correct or incorrect based solely on whether\nthe final answer matches the gold answer. However, this approach neglects any\nflawed rationale in the solution yielding the correct answer, undermining the\nverifier's ability to distinguish between sound and flawed rationales. We\nempirically show that in StrategyQA, only 19% of LLM-generated solutions with\ncorrect answers have valid rationales, thus leading to an unreliable verifier.\nFurthermore, we demonstrate that training a verifier on valid rationales\nsignificantly improves its ability to distinguish valid and flawed rationale.\nTo make a better verifier without extra human supervision, we introduce REPS\n(Rationale Enhancement through Pairwise Selection), a method for selecting\nvalid rationales from candidates by iteratively applying pairwise\nself-evaluation using the same LLM that generates the solutions. Verifiers\ntrained on solutions selected by REPS outperform those trained using\nconventional training methods on three reasoning benchmarks (ARC-Challenge,\nDROP, and StrategyQA). Our results suggest that training reliable verifiers\nrequires ensuring the validity of rationales in addition to the correctness of\nthe final answers, which would be critical for models assisting humans in\nsolving complex reasoning tasks.\n","authors":["Akira Kawabata","Saku Sugawara"],"pdf_url":"https://arxiv.org/pdf/2410.04838v1.pdf","comment":"EMNLP 2024"},{"id":"http://arxiv.org/abs/2410.00545v2","updated":"2024-10-07T08:52:39Z","published":"2024-10-01T09:38:34Z","title":"What the Harm? Quantifying the Tangible Impact of Gender Bias in Machine\n  Translation with a Human-centered Study","summary":"  Gender bias in machine translation (MT) is recognized as an issue that can\nharm people and society. And yet, advancements in the field rarely involve\npeople, the final MT users, or inform how they might be impacted by biased\ntechnologies. Current evaluations are often restricted to automatic methods,\nwhich offer an opaque estimate of what the downstream impact of gender\ndisparities might be. We conduct an extensive human-centered study to examine\nif and to what extent bias in MT brings harms with tangible costs, such as\nquality of service gaps across women and men. To this aim, we collect\nbehavioral data from 90 participants, who post-edited MT outputs to ensure\ncorrect gender translation. Across multiple datasets, languages, and types of\nusers, our study shows that feminine post-editing demands significantly more\ntechnical and temporal effort, also corresponding to higher financial costs.\nExisting bias measurements, however, fail to reflect the found disparities. Our\nfindings advocate for human-centered approaches that can inform the societal\nimpact of bias.\n","authors":["Beatrice Savoldi","Sara Papi","Matteo Negri","Ana Guerberof","Luisa Bentivogli"],"pdf_url":"https://arxiv.org/pdf/2410.00545v2.pdf","comment":"Accepted ad EMNLP 2024"},{"id":"http://arxiv.org/abs/2407.06551v2","updated":"2024-10-07T08:49:49Z","published":"2024-07-09T05:16:22Z","title":"OffsetBias: Leveraging Debiased Data for Tuning Evaluators","summary":"  Employing Large Language Models (LLMs) to assess the quality of generated\nresponses, such as prompting instruct-tuned models or fine-tuning judge models,\nhas become a widely adopted evaluation method. It is also known that such\nevaluators are vulnerable to biases, such as favoring longer responses. While\nit is important to overcome this problem, the specifics of these biases remain\nunder-explored. In this work, we qualitatively identify six types of biases\ninherent in various judge models. We propose EvalBiasBench as a meta-evaluation\ncollection of hand-crafted test cases for each bias type. Additionally, we\npresent de-biasing dataset construction methods and the associated preference\ndataset OffsetBias. Experimental results demonstrate that fine-tuning on our\ndataset significantly enhances the robustness of judge models against biases\nand improves performance across most evaluation scenarios. We release our\ndatasets and the fine-tuned judge model to public.\n","authors":["Junsoo Park","Seungyeon Jwa","Meiying Ren","Daeyoung Kim","Sanghyuk Choi"],"pdf_url":"https://arxiv.org/pdf/2407.06551v2.pdf","comment":"EMNLP2024 Findings"},{"id":"http://arxiv.org/abs/2408.08313v2","updated":"2024-10-07T08:44:35Z","published":"2024-08-15T17:59:57Z","title":"Can Large Language Models Understand Symbolic Graphics Programs?","summary":"  Against the backdrop of enthusiasm for large language models (LLMs), there is\nan urgent need to scientifically assess their capabilities and shortcomings.\nThis is nontrivial in part because it is difficult to find tasks which the\nmodels have not encountered during training. Utilizing symbolic graphics\nprograms, we propose a domain well-suited to test multiple spatial-semantic\nreasoning skills of LLMs. Popular in computer graphics, these programs\nprocedurally generate visual data. While LLMs exhibit impressive skills in\ngeneral program synthesis and analysis, symbolic graphics programs offer a new\nlayer of evaluation: they allow us to test an LLM's ability to answer\ndifferent-grained semantic-level questions of the images or 3D geometries\nwithout a vision encoder. To semantically understand the symbolic programs,\nLLMs would need to possess the ability to \"imagine\" and reason how the\ncorresponding graphics content would look with only the symbolic description.\nWe use this task to evaluate LLMs by creating a large benchmark for the\nsemantic visual understanding of symbolic graphics programs, built procedurally\nwith minimal human effort. Particular emphasis is placed on transformations of\nimages that leave the image level semantics invariant while introducing\nsignificant changes to the underlying program. We evaluate commercial and\nopen-source LLMs on our benchmark to assess their ability to reason about\nvisual output of programs, finding that LLMs considered stronger at reasoning\ngenerally perform better. Lastly, we introduce a novel method to improve this\nability -- Symbolic Instruction Tuning (SIT), in which the LLM is finetuned\nwith pre-collected instruction data on symbolic graphics programs.\nInterestingly, we find that SIT not only improves LLM's understanding on\nsymbolic programs, but it also improves general reasoning ability on various\nother benchmarks.\n","authors":["Zeju Qiu","Weiyang Liu","Haiwen Feng","Zhen Liu","Tim Z. Xiao","Katherine M. Collins","Joshua B. Tenenbaum","Adrian Weller","Michael J. Black","Bernhard Schölkopf"],"pdf_url":"https://arxiv.org/pdf/2408.08313v2.pdf","comment":"Technical Report v2 (46 pages, 24 figures, project page:\n  https://sgp-bench.github.io/, substantial update from v1)"},{"id":"http://arxiv.org/abs/2410.04834v1","updated":"2024-10-07T08:44:04Z","published":"2024-10-07T08:44:04Z","title":"As Simple as Fine-tuning: LLM Alignment via Bidirectional Negative\n  Feedback Loss","summary":"  Direct Preference Optimization (DPO) has emerged as a more computationally\nefficient alternative to Reinforcement Learning from Human Feedback (RLHF) with\nProximal Policy Optimization (PPO), eliminating the need for reward models and\nonline sampling. Despite these benefits, DPO and its variants remain sensitive\nto hyper-parameters and prone to instability, particularly on mathematical\ndatasets. We argue that these issues arise from the unidirectional\nlikelihood-derivative negative feedback inherent in the log-likelihood loss\nfunction. To address this, we propose a novel LLM alignment loss that\nestablishes a stable Bidirectional Negative Feedback (BNF) during optimization.\nOur proposed BNF loss eliminates the need for pairwise contrastive losses and\ndoes not require any extra tunable hyper-parameters or pairwise preference\ndata, streamlining the alignment pipeline to be as simple as supervised\nfine-tuning. We conduct extensive experiments across two challenging QA\nbenchmarks and four reasoning benchmarks. The experimental results show that\nBNF achieves comparable performance to the best methods on QA benchmarks, while\nits performance decrease on the four reasoning benchmarks is significantly\nlower compared to the best methods, thus striking a better balance between\nvalue alignment and reasoning ability. In addition, we further validate the\nperformance of BNF on non-pairwise datasets, and conduct in-depth analysis of\nlog-likelihood and logit shifts across different preference optimization\nmethods.\n","authors":["Xin Mao","Feng-Lin Li","Huimin Xu","Wei Zhang","Wang Chen","Anh Tuan Luu"],"pdf_url":"https://arxiv.org/pdf/2410.04834v1.pdf","comment":"20 pages, 9 figures"},{"id":"http://arxiv.org/abs/2410.02298v2","updated":"2024-10-07T08:40:35Z","published":"2024-10-03T08:34:17Z","title":"Jailbreak Antidote: Runtime Safety-Utility Balance via Sparse\n  Representation Adjustment in Large Language Models","summary":"  As large language models (LLMs) become integral to various applications,\nensuring both their safety and utility is paramount. Jailbreak attacks, which\nmanipulate LLMs into generating harmful content, pose significant challenges to\nthis balance. Existing defenses, such as prompt engineering and safety\nfine-tuning, often introduce computational overhead, increase inference\nlatency, and lack runtime flexibility. Moreover, overly restrictive safety\nmeasures can degrade model utility by causing refusals of benign queries. In\nthis paper, we introduce Jailbreak Antidote, a method that enables real-time\nadjustment of LLM safety preferences by manipulating a sparse subset of the\nmodel's internal states during inference. By shifting the model's hidden\nrepresentations along a safety direction with varying strengths, we achieve\nflexible control over the safety-utility balance without additional token\noverhead or inference delays. Our analysis reveals that safety-related\ninformation in LLMs is sparsely distributed; adjusting approximately 5% of the\ninternal state is as effective as modifying the entire state. Extensive\nexperiments on nine LLMs (ranging from 2 billion to 72 billion parameters),\nevaluated against ten jailbreak attack methods and compared with six defense\nstrategies, validate the effectiveness and efficiency of our approach. By\ndirectly manipulating internal states during reasoning, Jailbreak Antidote\noffers a lightweight, scalable solution that enhances LLM safety while\npreserving utility, opening new possibilities for real-time safety mechanisms\nin widely-deployed AI systems.\n","authors":["Guobin Shen","Dongcheng Zhao","Yiting Dong","Xiang He","Yi Zeng"],"pdf_url":"https://arxiv.org/pdf/2410.02298v2.pdf","comment":"10 pages, 5 figures"},{"id":"http://arxiv.org/abs/2410.04819v1","updated":"2024-10-07T08:13:16Z","published":"2024-10-07T08:13:16Z","title":"MINER: Mining the Underlying Pattern of Modality-Specific Neurons in\n  Multimodal Large Language Models","summary":"  In recent years, multimodal large language models (MLLMs) have significantly\nadvanced, integrating more modalities into diverse applications. However, the\nlack of explainability remains a major barrier to their use in scenarios\nrequiring decision transparency. Current neuron-level explanation paradigms\nmainly focus on knowledge localization or language- and domain-specific\nanalyses, leaving the exploration of multimodality largely unaddressed. To\ntackle these challenges, we propose MINER, a transferable framework for mining\nmodality-specific neurons (MSNs) in MLLMs, which comprises four stages: (1)\nmodality separation, (2) importance score calculation, (3) importance score\naggregation, (4) modality-specific neuron selection. Extensive experiments\nacross six benchmarks and two representative MLLMs show that (I) deactivating\nONLY 2% of MSNs significantly reduces MLLMs performance (0.56 to 0.24 for\nQwen2-VL, 0.69 to 0.31 for Qwen2-Audio), (II) different modalities mainly\nconverge in the lower layers, (III) MSNs influence how key information from\nvarious modalities converges to the last token, (IV) two intriguing phenomena\nworth further investigation, i.e., semantic probing and semantic telomeres. The\nsource code is available at this URL.\n","authors":["Kaichen Huang","Jiahao Huo","Yibo Yan","Kun Wang","Yutao Yue","Xuming Hu"],"pdf_url":"https://arxiv.org/pdf/2410.04819v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.00016v3","updated":"2024-10-07T07:54:37Z","published":"2024-07-28T15:45:08Z","title":"Towards a Universal Method for Meaningful Signal Detection","summary":"  It is known that human speech and certain animal vocalizations can convey\nmeaningful content because we can decipher the content that a given utterance\ndoes convey. This paper explores an alternative approach to determining whether\na signal is meaningful, one that analyzes only the signal itself and is\nindependent of what the conveyed meaning might be. We devise a method that\ntakes a waveform as input and outputs a score indicating its degree of\n`meaningfulness`. We cluster contiguous portions of the input to minimize the\ntotal description length, and then take the length of the code of the assigned\ncluster labels as meaningfulness score. We evaluate our method empirically,\nagainst several baselines, and show that it is the only one to give a high\nscore to human speech in various languages and with various speakers, a\nmoderate score to animal vocalizations from birds and orcas, and a low score to\nambient noise from various sources.\n","authors":["Louis Mahon"],"pdf_url":"https://arxiv.org/pdf/2408.00016v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.14399v2","updated":"2024-10-07T07:49:27Z","published":"2024-09-22T11:35:59Z","title":"Beyond Persuasion: Towards Conversational Recommender System with\n  Credible Explanations","summary":"  With the aid of large language models, current conversational recommender\nsystem (CRS) has gaining strong abilities to persuade users to accept\nrecommended items. While these CRSs are highly persuasive, they can mislead\nusers by incorporating incredible information in their explanations, ultimately\ndamaging the long-term trust between users and the CRS. To address this, we\npropose a simple yet effective method, called PC-CRS, to enhance the\ncredibility of CRS's explanations during persuasion. It guides the explanation\ngeneration through our proposed credibility-aware persuasive strategies and\nthen gradually refines explanations via post-hoc self-reflection. Experimental\nresults demonstrate the efficacy of PC-CRS in promoting persuasive and credible\nexplanations. Further analysis reveals the reason behind current methods\nproducing incredible explanations and the potential of credible explanations to\nimprove recommendation accuracy.\n","authors":["Peixin Qin","Chen Huang","Yang Deng","Wenqiang Lei","Tat-Seng Chua"],"pdf_url":"https://arxiv.org/pdf/2409.14399v2.pdf","comment":"Findings of EMNLP 2024. Our code is available at\n  https://github.com/mumen798/PC-CRS"},{"id":"http://arxiv.org/abs/2407.01449v3","updated":"2024-10-07T07:46:00Z","published":"2024-06-27T15:45:29Z","title":"ColPali: Efficient Document Retrieval with Vision Language Models","summary":"  Documents are visually rich structures that convey information through text,\nas well as tables, figures, page layouts, or fonts. While modern document\nretrieval systems exhibit strong performance on query-to-text matching, they\nstruggle to exploit visual cues efficiently, hindering their performance on\npractical document retrieval applications such as Retrieval Augmented\nGeneration. To benchmark current systems on visually rich document retrieval,\nwe introduce the Visual Document Retrieval Benchmark ViDoRe, composed of\nvarious page-level retrieving tasks spanning multiple domains, languages, and\nsettings. The inherent shortcomings of modern systems motivate the introduction\nof a new retrieval model architecture, ColPali, which leverages the document\nunderstanding capabilities of recent Vision Language Models to produce\nhigh-quality contextualized embeddings solely from images of document pages.\nCombined with a late interaction matching mechanism, ColPali largely\noutperforms modern document retrieval pipelines while being drastically faster\nand end-to-end trainable.\n","authors":["Manuel Faysse","Hugues Sibille","Tony Wu","Bilel Omrani","Gautier Viaud","Céline Hudelot","Pierre Colombo"],"pdf_url":"https://arxiv.org/pdf/2407.01449v3.pdf","comment":"Under Review"},{"id":"http://arxiv.org/abs/2410.04808v1","updated":"2024-10-07T07:41:48Z","published":"2024-10-07T07:41:48Z","title":"LPZero: Language Model Zero-cost Proxy Search from Zero","summary":"  In spite of the outstanding performance, Neural Architecture Search (NAS) is\ncriticized for massive computation. Recently, Zero-shot NAS has emerged as a\npromising approach by exploiting Zero-cost (ZC) proxies, which markedly reduce\ncomputational demands. Despite this, existing ZC proxies heavily rely on expert\nknowledge and incur significant trial-and-error costs. Particularly in NLP\ntasks, most existing ZC proxies fail to surpass the performance of the naive\nbaseline. To address these challenges, we introduce a novel framework,\n\\textbf{LPZero}, which is the first to automatically design ZC proxies for\nvarious tasks, achieving higher ranking consistency than human-designed\nproxies. Specifically, we model the ZC proxy as a symbolic equation and\nincorporate a unified proxy search space that encompasses existing ZC proxies,\nwhich are composed of a predefined set of mathematical symbols. To\nheuristically search for the best ZC proxy, LPZero incorporates genetic\nprogramming to find the optimal symbolic composition. We propose a\n\\textit{Rule-based Pruning Strategy (RPS),} which preemptively eliminates\nunpromising proxies, thereby mitigating the risk of proxy degradation.\nExtensive experiments on FlexiBERT, GPT-2, and LLaMA-7B demonstrate LPZero's\nsuperior ranking ability and performance on downstream tasks compared to\ncurrent approaches.\n","authors":["Peijie Dong","Lujun Li","Xiang Liu","Zhenheng Tang","Xuebo Liu","Qiang Wang","Xiaowen Chu"],"pdf_url":"https://arxiv.org/pdf/2410.04808v1.pdf","comment":"8 pages, 7 figures, 10 appendix"},{"id":"http://arxiv.org/abs/2410.04798v1","updated":"2024-10-07T07:21:49Z","published":"2024-10-07T07:21:49Z","title":"DAPE V2: Process Attention Score as Feature Map for Length Extrapolation","summary":"  The attention mechanism is a fundamental component of the Transformer model,\ncontributing to interactions among distinct tokens, in contrast to earlier\nfeed-forward neural networks. In general, the attention scores are determined\nsimply by the key-query products. However, this work's occasional trial\n(combining DAPE and NoPE) of including additional MLPs on attention scores\nwithout position encoding indicates that the classical key-query multiplication\nmay limit the performance of Transformers. In this work, we conceptualize\nattention as a feature map and apply the convolution operator (for neighboring\nattention scores across different heads) to mimic the processing methods in\ncomputer vision. Specifically, the main contribution of this paper is\nidentifying and interpreting the Transformer length extrapolation problem as a\nresult of the limited expressiveness of the naive query and key dot product,\nand we successfully translate the length extrapolation issue into a\nwell-understood feature map processing problem. The novel insight, which can be\nadapted to various attention-related models, reveals that the current\nTransformer architecture has the potential for further evolution. Extensive\nexperiments demonstrate that treating attention as a feature map and applying\nconvolution as a processing method significantly enhances Transformer\nperformance.\n","authors":["Chuanyang Zheng","Yihang Gao","Han Shi","Jing Xiong","Jiankai Sun","Jingyao Li","Minbin Huang","Xiaozhe Ren","Michael Ng","Xin Jiang","Zhenguo Li","Yu Li"],"pdf_url":"https://arxiv.org/pdf/2410.04798v1.pdf","comment":"Tech Report. arXiv admin note: text overlap with arXiv:2405.14722"},{"id":"http://arxiv.org/abs/2410.04795v1","updated":"2024-10-07T07:14:37Z","published":"2024-10-07T07:14:37Z","title":"Representing the Under-Represented: Cultural and Core Capability\n  Benchmarks for Developing Thai Large Language Models","summary":"  The rapid advancement of large language models (LLMs) has highlighted the\nneed for robust evaluation frameworks that assess their core capabilities, such\nas reasoning, knowledge, and commonsense, leading to the inception of certain\nwidely-used benchmark suites such as the H6 benchmark. However, these benchmark\nsuites are primarily built for the English language, and there exists a lack\nthereof for under-represented languages, in terms of LLM development, such as\nThai. On the other hand, developing LLMs for Thai should also include enhancing\nthe cultural understanding as well as core capabilities. To address these dual\nchallenge in Thai LLM research, we propose two key benchmarks: Thai-H6 and Thai\nCultural and Linguistic Intelligence Benchmark (ThaiCLI). Through a thorough\nevaluation of various LLMs with multi-lingual capabilities, we provide a\ncomprehensive analysis of the proposed benchmarks and how they contribute to\nThai LLM development. Furthermore, we will make both the datasets and\nevaluation code publicly available to encourage further research and\ndevelopment for Thai LLMs.\n","authors":["Dahyun Kim","Sukyung Lee","Yungi Kim","Attapol Rutherford","Chanjun Park"],"pdf_url":"https://arxiv.org/pdf/2410.04795v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02901v3","updated":"2024-10-07T07:13:24Z","published":"2024-08-06T02:15:12Z","title":"Lighthouse: A User-Friendly Library for Reproducible Video Moment\n  Retrieval and Highlight Detection","summary":"  We propose Lighthouse, a user-friendly library for reproducible video moment\nretrieval and highlight detection (MR-HD). Although researchers proposed\nvarious MR-HD approaches, the research community holds two main issues. The\nfirst is a lack of comprehensive and reproducible experiments across various\nmethods, datasets, and video-text features. This is because no unified training\nand evaluation codebase covers multiple settings. The second is user-unfriendly\ndesign. Because previous works use different libraries, researchers set up\nindividual environments. In addition, most works release only the training\ncodes, requiring users to implement the whole inference process of MR-HD.\nLighthouse addresses these issues by implementing a unified reproducible\ncodebase that includes six models, three features, and five datasets. In\naddition, it provides an inference API and web demo to make these methods\neasily accessible for researchers and developers. Our experiments demonstrate\nthat Lighthouse generally reproduces the reported scores in the reference\npapers. The code is available at https://github.com/line/lighthouse.\n","authors":["Taichi Nishimura","Shota Nakada","Hokuto Munakata","Tatsuya Komatsu"],"pdf_url":"https://arxiv.org/pdf/2408.02901v3.pdf","comment":"accepted at EMNLP2024 - system demonstration track"},{"id":"http://arxiv.org/abs/2410.04790v1","updated":"2024-10-07T07:02:09Z","published":"2024-10-07T07:02:09Z","title":"GARLIC: LLM-Guided Dynamic Progress Control with Hierarchical Weighted\n  Graph for Long Document QA","summary":"  In the past, Retrieval-Augmented Generation (RAG) methods split text into\nchunks to enable language models to handle long documents. Recent tree-based\nRAG methods are able to retrieve detailed information while preserving global\ncontext. However, with the advent of more powerful LLMs, such as Llama 3.1,\nwhich offer better comprehension and support for longer inputs, we found that\neven recent tree-based RAG methods perform worse than directly feeding the\nentire document into Llama 3.1, although RAG methods still hold an advantage in\nreducing computational costs. In this paper, we propose a new retrieval method,\ncalled LLM-Guided Dynamic Progress Control with Hierarchical Weighted Graph\n(GARLIC), which outperforms previous state-of-the-art baselines, including\nLlama 3.1, while retaining the computational efficiency of RAG methods. Our\nmethod introduces several improvements: (1) Rather than using a tree structure,\nwe construct a Hierarchical Weighted Directed Acyclic Graph with many-to-many\nsummarization, where the graph edges are derived from attention mechanisms, and\neach node focuses on a single event or very few events. (2) We introduce a\nnovel retrieval method that leverages the attention weights of LLMs rather than\ndense embedding similarity. Our method allows for searching the graph along\nmultiple paths and can terminate at any depth. (3) We use the LLM to control\nthe retrieval process, enabling it to dynamically adjust the amount and depth\nof information retrieved for different queries. Experimental results show that\nour method outperforms previous state-of-the-art baselines, including Llama\n3.1, on two single-document and two multi-document QA datasets, while\nmaintaining similar computational complexity to traditional RAG methods.\n","authors":["Xinyu Wang","Yanzheng Xiang","Lin Gui","Yulan He"],"pdf_url":"https://arxiv.org/pdf/2410.04790v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.07284v4","updated":"2024-10-07T06:54:30Z","published":"2023-10-11T08:17:54Z","title":"Typing to Listen at the Cocktail Party: Text-Guided Target Speaker\n  Extraction","summary":"  Humans can easily isolate a single speaker from a complex acoustic\nenvironment, a capability referred to as the \"Cocktail Party Effect.\" However,\nreplicating this ability has been a significant challenge in the field of\ntarget speaker extraction (TSE). Traditional TSE approaches predominantly rely\non voiceprints, which raise privacy concerns and face issues related to the\nquality and availability of enrollment samples, as well as intra-speaker\nvariability. To address these issues, this work introduces a novel text-guided\nTSE paradigm named LLM-TSE. In this paradigm, a state-of-the-art large language\nmodel, LLaMA 2, processes typed text input from users to extract semantic cues.\nWe demonstrate that textual descriptions alone can effectively serve as cues\nfor extraction, thus addressing privacy concerns and reducing dependency on\nvoiceprints. Furthermore, our approach offers flexibility by allowing the user\nto specify the extraction or suppression of a speaker and enhances robustness\nagainst intra-speaker variability by incorporating context-dependent textual\ninformation. Experimental results show competitive performance with text-based\ncues alone and demonstrate the effectiveness of using text as a task selector.\nAdditionally, they achieve a new state-of-the-art when combining text-based\ncues with pre-registered cues. This work represents the first integration of\nLLMs with TSE, potentially establishing a new benchmark in solving the cocktail\nparty problem and expanding the scope of TSE applications by providing a\nversatile, privacy-conscious solution.\n","authors":["Xiang Hao","Jibin Wu","Jianwei Yu","Chenglin Xu","Kay Chen Tan"],"pdf_url":"https://arxiv.org/pdf/2310.07284v4.pdf","comment":"Under review, https://github.com/haoxiangsnr/llm-tse"},{"id":"http://arxiv.org/abs/2410.04784v1","updated":"2024-10-07T06:49:41Z","published":"2024-10-07T06:49:41Z","title":"Formality is Favored: Unraveling the Learning Preferences of Large\n  Language Models on Data with Conflicting Knowledge","summary":"  Having been trained on massive pretraining data, large language models have\nshown excellent performance on many knowledge-intensive tasks. However,\npretraining data tends to contain misleading and even conflicting information,\nand it is intriguing to understand how LLMs handle these noisy data during\ntraining. In this study, we systematically analyze LLMs' learning preferences\nfor data with conflicting knowledge. We find that pretrained LLMs establish\nlearning preferences similar to humans, i.e., preferences towards formal texts\nand texts with fewer spelling errors, resulting in faster learning and more\nfavorable treatment of knowledge in data with such features when facing\nconflicts. This finding is generalizable across models and languages and is\nmore evident in larger models. An in-depth analysis reveals that LLMs tend to\ntrust data with features that signify consistency with the majority of data,\nand it is possible to instill new preferences and erase old ones by\nmanipulating the degree of consistency with the majority data.\n","authors":["Jiahuan Li","Yiqing Cao","Shujian Huang","Jiajun Chen"],"pdf_url":"https://arxiv.org/pdf/2410.04784v1.pdf","comment":"accepted by EMNLP 2024, main conference"},{"id":"http://arxiv.org/abs/2408.01084v2","updated":"2024-10-07T06:11:46Z","published":"2024-08-02T08:03:38Z","title":"Adaptive Contrastive Decoding in Retrieval-Augmented Generation for\n  Handling Noisy Contexts","summary":"  When using large language models (LLMs) in knowledge-intensive tasks, such as\nopen-domain question answering, external context can bridge the gap between\nexternal knowledge and the LLMs' parametric knowledge. Recent research has been\ndeveloped to amplify contextual knowledge over the parametric knowledge of LLMs\nwith contrastive decoding approaches. While these approaches could yield\ntruthful responses when relevant context is provided, they are prone to\nvulnerabilities when faced with noisy contexts. We extend the scope of previous\nstudies to encompass noisy contexts and propose adaptive contrastive decoding\n(ACD) to leverage contextual influence effectively. ACD demonstrates\nimprovements in open-domain question answering tasks compared to baselines,\nespecially in robustness by remaining undistracted by noisy contexts in\nretrieval-augmented generation.\n","authors":["Youna Kim","Hyuhng Joon Kim","Cheonbok Park","Choonghyun Park","Hyunsoo Cho","Junyeob Kim","Kang Min Yoo","Sang-goo Lee","Taeuk Kim"],"pdf_url":"https://arxiv.org/pdf/2408.01084v2.pdf","comment":"EMNLP 2024 Findings"},{"id":"http://arxiv.org/abs/2409.05356v2","updated":"2024-10-07T05:29:01Z","published":"2024-09-09T06:28:47Z","title":"IndicVoices-R: Unlocking a Massive Multilingual Multi-speaker Speech\n  Corpus for Scaling Indian TTS","summary":"  Recent advancements in text-to-speech (TTS) synthesis show that large-scale\nmodels trained with extensive web data produce highly natural-sounding output.\nHowever, such data is scarce for Indian languages due to the lack of\nhigh-quality, manually subtitled data on platforms like LibriVox or YouTube. To\naddress this gap, we enhance existing large-scale ASR datasets containing\nnatural conversations collected in low-quality environments to generate\nhigh-quality TTS training data. Our pipeline leverages the cross-lingual\ngeneralization of denoising and speech enhancement models trained on English\nand applied to Indian languages. This results in IndicVoices-R (IV-R), the\nlargest multilingual Indian TTS dataset derived from an ASR dataset, with 1,704\nhours of high-quality speech from 10,496 speakers across 22 Indian languages.\nIV-R matches the quality of gold-standard TTS datasets like LJSpeech, LibriTTS,\nand IndicTTS. We also introduce the IV-R Benchmark, the first to assess\nzero-shot, few-shot, and many-shot speaker generalization capabilities of TTS\nmodels on Indian voices, ensuring diversity in age, gender, and style. We\ndemonstrate that fine-tuning an English pre-trained model on a combined dataset\nof high-quality IndicTTS and our IV-R dataset results in better zero-shot\nspeaker generalization compared to fine-tuning on the IndicTTS dataset alone.\nFurther, our evaluation reveals limited zero-shot generalization for Indian\nvoices in TTS models trained on prior datasets, which we improve by fine-tuning\nthe model on our data containing diverse set of speakers across language\nfamilies. We open-source all data and code, releasing the first TTS model for\nall 22 official Indian languages.\n","authors":["Ashwin Sankar","Srija Anand","Praveen Srinivasa Varadhan","Sherry Thomas","Mehak Singal","Shridhar Kumar","Deovrat Mehendale","Aditi Krishana","Giri Raju","Mitesh Khapra"],"pdf_url":"https://arxiv.org/pdf/2409.05356v2.pdf","comment":"Accepted to NeurIPS 2024 Datasets and Benchmarks track"},{"id":"http://arxiv.org/abs/2407.17467v2","updated":"2024-10-07T05:16:25Z","published":"2024-07-24T17:59:02Z","title":"CMR Scaling Law: Predicting Critical Mixture Ratios for Continual\n  Pre-training of Language Models","summary":"  Large Language Models (LLMs) excel in diverse tasks but often underperform in\nspecialized fields due to limited domain-specific or proprietary corpus.\nContinual pre-training (CPT) enhances LLM capabilities by imbuing new\ndomain-specific or proprietary knowledge while replaying general corpus to\nprevent catastrophic forgetting. The data mixture ratio of general corpus and\ndomain-specific corpus, however, has been chosen heuristically, leading to\nsub-optimal training efficiency in practice. In this context, we attempt to\nre-visit the scaling behavior of LLMs under the hood of CPT, and discover a\npower-law relationship between loss, mixture ratio, and training tokens scale.\nWe formalize the trade-off between general and domain-specific capabilities,\nleading to a well-defined Critical Mixture Ratio (CMR) of general and domain\ndata. By striking the balance, CMR maintains the model's general ability and\nachieves the desired domain transfer, ensuring the highest utilization of\navailable resources. Considering the balance between efficiency and\neffectiveness, CMR can be regarded as the optimal mixture ratio. Through\nextensive experiments, we ascertain the predictability of CMR, propose CMR\nscaling law and have substantiated its generalization. These findings offer\npractical guidelines for optimizing LLM training in specialized domains,\nensuring both general and domain-specific performance while efficiently\nmanaging training resources.\n","authors":["Jiawei Gu","Zacc Yang","Chuanghao Ding","Rui Zhao","Fei Tan"],"pdf_url":"https://arxiv.org/pdf/2407.17467v2.pdf","comment":"EMNLP 2024 main conference"},{"id":"http://arxiv.org/abs/2410.04753v1","updated":"2024-10-07T05:14:18Z","published":"2024-10-07T05:14:18Z","title":"ImProver: Agent-Based Automated Proof Optimization","summary":"  Large language models (LLMs) have been used to generate formal proofs of\nmathematical theorems in proofs assistants such as Lean. However, we often want\nto optimize a formal proof with respect to various criteria, depending on its\ndownstream use. For example, we may want a proof to adhere to a certain style,\nor to be readable, concise, or modularly structured. Having suitably optimized\nproofs is also important for learning tasks, especially since human-written\nproofs may not optimal for that purpose. To this end, we study a new problem of\nautomated proof optimization: rewriting a proof so that it is correct and\noptimizes for an arbitrary criterion, such as length or readability. As a first\nmethod for automated proof optimization, we present ImProver, a\nlarge-language-model agent that rewrites proofs to optimize arbitrary\nuser-defined metrics in Lean. We find that naively applying LLMs to proof\noptimization falls short, and we incorporate various improvements into\nImProver, such as the use of symbolic Lean context in a novel Chain-of-States\ntechnique, as well as error-correction and retrieval. We test ImProver on\nrewriting real-world undergraduate, competition, and research-level mathematics\ntheorems, finding that ImProver is capable of rewriting proofs so that they are\nsubstantially shorter, more modular, and more readable.\n","authors":["Riyaz Ahuja","Jeremy Avigad","Prasad Tetali","Sean Welleck"],"pdf_url":"https://arxiv.org/pdf/2410.04753v1.pdf","comment":"19 pages, 21 figures"},{"id":"http://arxiv.org/abs/2410.04752v1","updated":"2024-10-07T05:07:48Z","published":"2024-10-07T05:07:48Z","title":"Document-level Causal Relation Extraction with Knowledge-guided Binary\n  Question Answering","summary":"  As an essential task in information extraction (IE), Event-Event Causal\nRelation Extraction (ECRE) aims to identify and classify the causal\nrelationships between event mentions in natural language texts. However,\nexisting research on ECRE has highlighted two critical challenges, including\nthe lack of document-level modeling and causal hallucinations. In this paper,\nwe propose a Knowledge-guided binary Question Answering (KnowQA) method with\nevent structures for ECRE, consisting of two stages: Event Structure\nConstruction and Binary Question Answering. We conduct extensive experiments\nunder both zero-shot and fine-tuning settings with large language models (LLMs)\non the MECI and MAVEN-ERE datasets. Experimental results demonstrate the\nusefulness of event structures on document-level ECRE and the effectiveness of\nKnowQA by achieving state-of-the-art on the MECI dataset. We observe not only\nthe effectiveness but also the high generalizability and low inconsistency of\nour method, particularly when with complete event structures after fine-tuning\nthe models.\n","authors":["Zimu Wang","Lei Xia","Wei Wang","Xinya Du"],"pdf_url":"https://arxiv.org/pdf/2410.04752v1.pdf","comment":"Accepted at Findings of EMNLP 2024. Camera-ready version"},{"id":"http://arxiv.org/abs/2410.04751v1","updated":"2024-10-07T05:07:01Z","published":"2024-10-07T05:07:01Z","title":"Intriguing Properties of Large Language and Vision Models","summary":"  Recently, large language and vision models (LLVMs) have received significant\nattention and development efforts due to their remarkable generalization\nperformance across a wide range of tasks requiring perception and cognitive\nabilities. A key factor behind their success is their simple architecture,\nwhich consists of a vision encoder, a projector, and a large language model\n(LLM). Despite their achievements in advanced reasoning tasks, their\nperformance on fundamental perception-related tasks (e.g., MMVP) remains\nsurprisingly low. This discrepancy raises the question of how LLVMs truly\nperceive images and exploit the advantages of the vision encoder. To address\nthis, we systematically investigate this question regarding several aspects:\npermutation invariance, robustness, math reasoning, alignment preserving and\nimportance, by evaluating the most common LLVM's families (i.e., LLaVA) across\n10 evaluation benchmarks. Our extensive experiments reveal several intriguing\nproperties of current LLVMs: (1) they internally process the image in a global\nmanner, even when the order of visual patch sequences is randomly permuted; (2)\nthey are sometimes able to solve math problems without fully perceiving\ndetailed numerical information; (3) the cross-modal alignment is overfitted to\ncomplex reasoning tasks, thereby, causing them to lose some of the original\nperceptual capabilities of their vision encoder; (4) the representation space\nin the lower layers (<25%) plays a crucial role in determining performance and\nenhancing visual understanding. Lastly, based on the above observations, we\nsuggest potential future directions for building better LLVMs and constructing\nmore challenging evaluation benchmarks.\n","authors":["Young-Jun Lee","Byungsoo Ko","Han-Gyu Kim","Yechan Hwang","Ho-Jin Choi"],"pdf_url":"https://arxiv.org/pdf/2410.04751v1.pdf","comment":"Code is available in https://github.com/passing2961/IP-LLVM"},{"id":"http://arxiv.org/abs/2405.14722v3","updated":"2024-10-07T04:35:58Z","published":"2024-05-23T15:51:24Z","title":"DAPE: Data-Adaptive Positional Encoding for Length Extrapolation","summary":"  Positional encoding plays a crucial role in transformers, significantly\nimpacting model performance and length generalization. Prior research has\nintroduced absolute positional encoding (APE) and relative positional encoding\n(RPE) to distinguish token positions in given sequences. However, both APE and\nRPE remain fixed after model training regardless of input data, limiting their\nadaptability and flexibility. Hence, we expect that the desired positional\nencoding should be data-adaptive and can be dynamically adjusted with the given\nattention. In this paper, we propose a Data-Adaptive Positional Encoding (DAPE)\nmethod, which dynamically and semantically adjusts based on input context and\nlearned fixed priors. Experimental validation on real-world datasets (Arxiv,\nBooks3, and CHE) demonstrates that DAPE enhances model performances in terms of\ntrained length and length generalization, where the improvements are\nstatistically significant. The model visualization suggests that our model can\nkeep both local and anti-local information. Finally, we successfully train the\nmodel on sequence length 128 and achieve better performance at evaluation\nsequence length 8192, compared with other static positional encoding methods,\nrevealing the benefit of the adaptive positional encoding method.\n","authors":["Chuanyang Zheng","Yihang Gao","Han Shi","Minbin Huang","Jingyao Li","Jing Xiong","Xiaozhe Ren","Michael Ng","Xin Jiang","Zhenguo Li","Yu Li"],"pdf_url":"https://arxiv.org/pdf/2405.14722v3.pdf","comment":"Accepted to NeurIPS 2024"},{"id":"http://arxiv.org/abs/2304.09797v6","updated":"2024-10-07T04:28:04Z","published":"2023-04-19T16:29:48Z","title":"Progressive-Hint Prompting Improves Reasoning in Large Language Models","summary":"  The performance of Large Language Models (LLMs) in reasoning tasks depends\nheavily on prompt design, with Chain-of-Thought (CoT) and self-consistency\nbeing critical methods that enhance this ability. However, these methods do not\nfully exploit the answers generated by the LLM to guide subsequent responses.\nThis paper proposes a new prompting method, named Progressive-Hint Prompting\n(PHP), that enables automatic multiple interactions between users and LLMs by\nusing previously generated answers as hints to progressively guide toward the\ncorrect answers. PHP is orthogonal to CoT and self-consistency, making it easy\nto combine with state-of-the-art techniques to further improve performance. We\nconducted extensive and comprehensive experiments on seven benchmarks. The\nresults show that PHP significantly improves accuracy while remaining highly\nefficient. For instance, with text-davinci-003, we observed a 4.2% improvement\non GSM8K with greedy decoding compared to Complex CoT, and a 46.17% reduction\nin sample paths with self-consistency. With GPT-4 and PHP, we achieve\nstate-of-the-art performances on SVAMP (89.1% -> 91.9%), GSM8K (92% -> 95.5%),\nAQuA (76.4% -> 79.9%) and MATH (50.3% -> 53.9%).\n","authors":["Chuanyang Zheng","Zhengying Liu","Enze Xie","Zhenguo Li","Yu Li"],"pdf_url":"https://arxiv.org/pdf/2304.09797v6.pdf","comment":"Accepted to ICML AI4MATH 2024"},{"id":"http://arxiv.org/abs/2403.19270v2","updated":"2024-10-07T04:21:15Z","published":"2024-03-28T09:56:04Z","title":"sDPO: Don't Use Your Data All at Once","summary":"  As development of large language models (LLM) progresses, aligning them with\nhuman preferences has become increasingly important. We propose stepwise DPO\n(sDPO), an extension of the recently popularized direct preference optimization\n(DPO) for alignment tuning. This approach involves dividing the available\npreference datasets and utilizing them in a stepwise manner, rather than\nemploying it all at once. We demonstrate that this method facilitates the use\nof more precisely aligned reference models within the DPO training framework.\nFurthermore, sDPO trains the final model to be more performant, even\noutperforming other popular LLMs with more parameters.\n","authors":["Dahyun Kim","Yungi Kim","Wonho Song","Hyeonwoo Kim","Yunsu Kim","Sanghoon Kim","Chanjun Park"],"pdf_url":"https://arxiv.org/pdf/2403.19270v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.13803v3","updated":"2024-10-07T04:18:40Z","published":"2024-05-22T16:30:24Z","title":"\"I Like Sunnie More Than I Expected!\": Exploring User Expectation and\n  Perception of an Anthropomorphic LLM-based Conversational Agent for\n  Well-Being Support","summary":"  The human-computer interaction (HCI) research community has a longstanding\ninterest in exploring the mismatch between users' actual experiences and\nexpectation toward new technologies, for instance, large language models\n(LLMs). In this study, we compared users' (N = 38) initial expectations against\ntheir post-interaction perceptions of two LLM-powered mental well-being\nintervention activity recommendation systems. Both systems have a built-in LLM\nto recommend a personalized well-being intervention activity, but one system\n(Sunnie) has an anthropomorphic conversational interaction design via elements\nsuch as appearance, persona, and natural conversation. Results showed that user\nengagement was high with both systems, and both systems exceeded users'\nexpectations along the utility dimension, highlighting AI's potential to offer\nuseful intervention activity recommendations. In addition, Sunnie further\noutperformed the non-anthropomorphic baseline system in relational warmth.\nThese findings suggest that anthropomorphic conversational interaction design\nmay be particularly effective in fostering warmth in mental health support\ncontexts.\n","authors":["Siyi Wu","Julie Y. A. Cachia","Feixue Han","Bingsheng Yao","Tianyi Xie","Xuan Zhao","Dakuo Wang"],"pdf_url":"https://arxiv.org/pdf/2405.13803v3.pdf","comment":"In Submission"},{"id":"http://arxiv.org/abs/2408.07930v3","updated":"2024-10-07T04:17:18Z","published":"2024-08-15T04:57:55Z","title":"MAG-SQL: Multi-Agent Generative Approach with Soft Schema Linking and\n  Iterative Sub-SQL Refinement for Text-to-SQL","summary":"  Recent In-Context Learning based methods have achieved remarkable success in\nText-to-SQL task. However, there is still a large gap between the performance\nof these models and human performance on datasets with complex database schema\nand difficult questions, such as BIRD. Besides, existing work has neglected to\nsupervise intermediate steps when solving questions iteratively with question\ndecomposition methods, and the schema linking methods used in these works are\nvery rudimentary. To address these issues, we propose MAG-SQL, a multi-agent\ngenerative approach with soft schema linking and iterative Sub-SQL refinement.\nIn our framework, an entity-based method with tables' summary is used to select\nthe columns in database, and a novel targets-conditions decomposition method is\nintroduced to decompose those complex questions. Additionally, we build a\niterative generating module which includes a Sub-SQL Generator and Sub-SQL\nRefiner, introducing external oversight for each step of generation. Through a\nseries of ablation studies, the effectiveness of each agent in our framework\nhas been demonstrated. When evaluated on the BIRD benchmark with GPT-4, MAG-SQL\nachieves an execution accuracy of 61.08%, compared to the baseline accuracy of\n46.35% for vanilla GPT-4 and the baseline accuracy of 57.56% for MAC-SQL.\nBesides, our approach makes similar progress on Spider.\n","authors":["Wenxuan Xie","Gaochen Wu","Bowen Zhou"],"pdf_url":"https://arxiv.org/pdf/2408.07930v3.pdf","comment":"22 pages, 14 figures"},{"id":"http://arxiv.org/abs/2410.04739v1","updated":"2024-10-07T04:15:02Z","published":"2024-10-07T04:15:02Z","title":"TableRAG: Million-Token Table Understanding with Language Models","summary":"  Recent advancements in language models (LMs) have notably enhanced their\nability to reason with tabular data, primarily through program-aided mechanisms\nthat manipulate and analyze tables. However, these methods often require the\nentire table as input, leading to scalability challenges due to the positional\nbias or context length constraints. In response to these challenges, we\nintroduce TableRAG, a Retrieval-Augmented Generation (RAG) framework\nspecifically designed for LM-based table understanding. TableRAG leverages\nquery expansion combined with schema and cell retrieval to pinpoint crucial\ninformation before providing it to the LMs. This enables more efficient data\nencoding and precise retrieval, significantly reducing prompt lengths and\nmitigating information loss. We have developed two new million-token benchmarks\nfrom the Arcade and BIRD-SQL datasets to thoroughly evaluate TableRAG's\neffectiveness at scale. Our results demonstrate that TableRAG's retrieval\ndesign achieves the highest retrieval quality, leading to the new\nstate-of-the-art performance on large-scale table understanding.\n","authors":["Si-An Chen","Lesly Miculicich","Julian Martin Eisenschlos","Zifeng Wang","Zilong Wang","Yanfei Chen","Yasuhisa Fujii","Hsuan-Tien Lin","Chen-Yu Lee","Tomas Pfister"],"pdf_url":"https://arxiv.org/pdf/2410.04739v1.pdf","comment":"Accepted to NeurIPS 2024"},{"id":"http://arxiv.org/abs/2410.04734v1","updated":"2024-10-07T04:00:22Z","published":"2024-10-07T04:00:22Z","title":"TLDR: Token-Level Detective Reward Model for Large Vision Language\n  Models","summary":"  Although reward models have been successful in improving multimodal large\nlanguage models, the reward models themselves remain brutal and contain minimal\ninformation. Notably, existing reward models only mimic human annotations by\nassigning only one binary feedback to any text, no matter how long the text is.\nIn the realm of multimodal language models, where models are required to\nprocess both images and texts, a naive reward model may learn implicit biases\ntoward texts and become less grounded in images. In this paper, we propose a\n$\\textbf{T}$oken-$\\textbf{L}$evel $\\textbf{D}$etective $\\textbf{R}$eward Model\n($\\textbf{TLDR}$) to provide fine-grained annotations to each text token. We\nfirst introduce a perturbation-based method to generate synthetic hard\nnegatives and their token-level labels to train TLDR models. Then we show the\nrich usefulness of TLDR models both in assisting off-the-shelf models to\nself-correct their generations, and in serving as a hallucination evaluation\ntool. Finally, we show that TLDR models can significantly speed up human\nannotation by 3 times to acquire a broader range of high-quality vision\nlanguage data.\n","authors":["Deqing Fu","Tong Xiao","Rui Wang","Wang Zhu","Pengchuan Zhang","Guan Pang","Robin Jia","Lawrence Chen"],"pdf_url":"https://arxiv.org/pdf/2410.04734v1.pdf","comment":"Work done at Meta"},{"id":"http://arxiv.org/abs/2409.06927v2","updated":"2024-10-07T03:56:35Z","published":"2024-09-11T00:56:02Z","title":"Representation Tuning","summary":"  Activation engineering is becoming increasingly popular as a means of online\ncontrol of large language models (LLMs). In this work, I extend the idea of\nactive steering with vectors that represent a behavioral direction of interest\nto tuning those vectors directly into the model, obviating the need for online\ncontrol. First, I identify activation vectors related to honesty in an\nopen-source LLM (Llama- 2-13b-chat). Next, I demonstrate that model output can\nbe made more or less honest by adding positive or negative multiples of these\nvectors to residual stream activations during generation. Then, I show that a\nsimilar effect can be achieved by fine-tuning the vectors directly into the\nmodel, by use of a dual loss function based on the cosine similarity of\nresidual stream activations to the vectors combined with a standard token-based\nloss (\"representation tuning\"). Finally, I compare the generations in response\nto honesty-probing prompts from the resulting models to those from models\nfine-tuned with a token-based loss alone, and to those from the untuned model\nsubjected to online steering. Overall, fine-tuning the vectors into the models\nusing the cosine similarity plus token loss showed a stronger effect than\nonline steering, and generalized better than using the standard loss,\nsuggesting the potential utility of this approach as a safety measure. Code and\ndata are available at https://github.com/cma1114/representation_tuning; tuned\nmodels are available at https://huggingface.co/collections/cackerman/\nrepresentation-tuning-66da1e5ab41cd1b824687d9f.\n","authors":["Christopher M. Ackerman"],"pdf_url":"https://arxiv.org/pdf/2409.06927v2.pdf","comment":"9 pages, 6 figures, 6 tables"},{"id":"http://arxiv.org/abs/2406.17169v3","updated":"2024-10-07T03:48:18Z","published":"2024-06-24T23:02:56Z","title":"Multi-LogiEval: Towards Evaluating Multi-Step Logical Reasoning Ability\n  of Large Language Models","summary":"  As Large Language Models (LLMs) continue to exhibit remarkable performance in\nnatural language understanding tasks, there is a crucial need to measure their\nability for human-like multi-step logical reasoning. Existing logical reasoning\nevaluation benchmarks often focus primarily on simplistic single-step or\nmulti-step reasoning with a limited set of inference rules. Furthermore, the\nlack of datasets for evaluating non-monotonic reasoning represents a crucial\ngap since it aligns more closely with human-like reasoning. To address these\nlimitations, we propose Multi-LogiEval, a comprehensive evaluation dataset\nencompassing multi-step logical reasoning with various inference rules and\ndepths. Multi-LogiEval covers three logic types--propositional, first-order,\nand non-monotonic--consisting of more than 30 inference rules and more than 60\nof their combinations with various depths. Leveraging this dataset, we conduct\nevaluations on a range of LLMs including GPT-4, ChatGPT, Gemini-Pro, Yi, Orca,\nand Mistral, employing a zero-shot chain-of-thought. Experimental results show\nthat there is a significant drop in the performance of LLMs as the reasoning\nsteps/depth increases (average accuracy of ~68% at depth-1 to ~43% at depth-5).\nWe further conduct a thorough investigation of reasoning chains generated by\nLLMs which reveals several important findings. We believe that Multi-LogiEval\nfacilitates future research for evaluating and enhancing the logical reasoning\nability of LLMs. Data is available at\nhttps://github.com/Mihir3009/Multi-LogiEval.\n","authors":["Nisarg Patel","Mohith Kulkarni","Mihir Parmar","Aashna Budhiraja","Mutsumi Nakamura","Neeraj Varshney","Chitta Baral"],"pdf_url":"https://arxiv.org/pdf/2406.17169v3.pdf","comment":"Accepted at EMNLP 2024 Main"},{"id":"http://arxiv.org/abs/2410.04731v1","updated":"2024-10-07T03:47:34Z","published":"2024-10-07T03:47:34Z","title":"Efficient transformer with reinforced position embedding for language\n  models","summary":"  In this paper, we propose an efficient transformer architecture that uses\nreinforced positional embedding to obtain superior performance with half the\nnumber of encoder decoder layers. We demonstrate that concatenating positional\nencoding with trainable token embeddings, normalizing columns in the token\nembedding matrix, and using the normalized token embedding matrix as the value\nof the attention layer improve the training and validation loss and the\ntraining time in an encoder-decoder Transformer model for a Portuguese-English\ntranslation task with 10 epochs or 12 hours of training across 10 trials. Our\nmethod, with roughly a threefold parameter reduction compared to the baseline\nmodel, yields a mean training loss of 1.21, a mean validation loss of 1.51, and\nan average training time of 1352.27 seconds per epoch, surpassing the baseline\nmodel with the same embedding dimension that employs addition of positional\nencoding and token embeddings, which achieves a mean training loss of 1.96, a\nvalidation loss of 2.18, and an average training time of 4297.79 seconds per\nepoch. Additionally, we evaluated our proposed architecture and the baseline\nacross 14 diverse translation datasets from TensorFlow. The results indicate\nthat our method consistently achieves lower or comparable training and\nvalidation losses, suggesting enhanced learning efficiency.\n","authors":["Yen-Che Hsiao","Abhishek Dutta"],"pdf_url":"https://arxiv.org/pdf/2410.04731v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.16997v2","updated":"2024-10-07T03:41:57Z","published":"2024-07-24T04:39:24Z","title":"Revisiting Who's Harry Potter: Towards Targeted Unlearning from a Causal\n  Intervention Perspective","summary":"  This paper investigates Who's Harry Potter (WHP), a pioneering yet\ninsufficiently understood method for LLM unlearning. We explore it in two\nsteps. First, we introduce a new task of LLM targeted unlearning, where given\nan unlearning target (e.g., a person) and some unlearning documents, we aim to\nunlearn only the information about the target, rather than everything in the\nunlearning documents. We further argue that a successful unlearning should\nsatisfy criteria such as not outputting gibberish, not fabricating facts about\nthe unlearning target, and not releasing factual information under jailbreak\nattacks. Second, we construct a causal intervention framework for targeted\nunlearning, where the knowledge of the unlearning target is modeled as a\nconfounder between LLM input and output, and the unlearning process as a\ndeconfounding process. This framework justifies and extends WHP, deriving a\nsimple unlearning algorithm that includes WHP as a special case. Experiments on\nexisting and new datasets show that our approach, without explicitly optimizing\nfor the aforementioned criteria, achieves competitive performance in all of\nthem. Our code is available at\nhttps://github.com/UCSB-NLP-Chang/causal_unlearn.git.\n","authors":["Yujian Liu","Yang Zhang","Tommi Jaakkola","Shiyu Chang"],"pdf_url":"https://arxiv.org/pdf/2407.16997v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.05621v2","updated":"2024-10-07T03:41:27Z","published":"2023-12-09T17:38:39Z","title":"PILLOW: Enhancing Efficient Instruction Fine-tuning via Prompt Matching","summary":"  Instruction fine-tuning has conventionally been employed to adapt Large\nLanguage Models (LLMs) to a variety of tasks. Nonetheless, this technique often\nnecessitates substantial computational resources, making it impractical for\ndeployment by individuals or small-scale entities. Recently, Low-Rank\nAdaptation (LoRA) has become a promising alternative, offering high\ncapabilities on par with full tuning with reduced resource overhead. However,\nattaining satisfactory performance through the fine-tuning of LoRA is a\nnon-trivial challenge. In this paper, we propose PILLOW, which aims to improve\nLoRA's performance by a discrimination-based prompting method, leveraging LLMs'\nIn-Context Learning ability. PILLOW incorporates a matching network that\nselects prompts from a user-defined prompt pool, concatenates the selected\nprompts with the user instruction as input, and performs inference using the\nLoRA-fine-tuned LLMs. Trained with Reinforcement Learning, PILLOW exhibits\ncommensurate performance on various evaluation metrics compared with typical\ninstruction fine-tuning methods, utilizing only consumer-grade GPU resources\nand exhibiting a large reduction in computational costs.\n","authors":["Zhenting Qi","Xiaoyu Tan","Shaojie Shi","Chao Qu","Yinghui Xu","Yuan Qi"],"pdf_url":"https://arxiv.org/pdf/2312.05621v2.pdf","comment":"Accepted by EMNLP 2023 (Industry Track), Oral Presentation"},{"id":"http://arxiv.org/abs/2410.04727v1","updated":"2024-10-07T03:38:27Z","published":"2024-10-07T03:38:27Z","title":"Forgetting Curve: A Reliable Method for Evaluating Memorization\n  Capability for Long-context Models","summary":"  Numerous recent works target to extend effective context length for language\nmodels and various methods, tasks and benchmarks exist to measure model's\neffective memorization length. However, through thorough investigations, we\nfind limitations for currently existing evaluations on model's memorization\ncapability. We provide an extensive survey for limitations in this work and\npropose a new method called forgetting curve to measure the memorization\ncapability of long-context models. We show that forgetting curve has the\nadvantage of being robust to the tested corpus and the experimental settings,\nof not relying on prompts and can be applied to any model size.\n  We apply our forgetting curve to a large variety of models involving both\ntransformer and RNN/SSM based architectures. Our measurement provides empirical\nevidence for the effectiveness of transformer extension techniques while raises\nquestions for the effective length of RNN/SSM based models. We also examine the\ndifference between our measurement and existing benchmarks as well as popular\nmetrics for various models. Our code and results can be found at\nhttps://github.com/1azybug/ForgettingCurve.\n","authors":["Xinyu Liu","Runsong Zhao","Pengcheng Huang","Chunyang Xiao","Bei Li","Jingang Wang","Tong Xiao","Jingbo Zhu"],"pdf_url":"https://arxiv.org/pdf/2410.04727v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17141v3","updated":"2024-10-07T03:19:16Z","published":"2024-03-25T19:28:10Z","title":"MetaAligner: Towards Generalizable Multi-Objective Alignment of Language\n  Models","summary":"  Recent advancements in large language models (LLMs) focus on aligning to\nheterogeneous human expectations and values via multi-objective preference\nalignment. However, existing methods are dependent on the policy model\nparameters, which require high-cost repetition of their alignment algorithms\nfor each new policy model, and they cannot expand to unseen objectives due to\ntheir static alignment objectives. In this work, we propose Meta-Objective\nAligner (MetaAligner), the first policy-agnostic and generalizable method for\nmulti-objective preference alignment. MetaAligner models multi-objective\nalignment into three stages: (1) dynamic objectives reformulation algorithm\nreorganizes traditional alignment datasets to supervise the model on performing\nflexible alignment across different objectives; (2) conditional weak-to-strong\ncorrection paradigm aligns the weak outputs of fixed policy models to approach\nstrong outputs with higher preferences in the corresponding alignment\nobjectives, enabling plug-and-play inferences on any policy models, which\nsignificantly reduces training costs and facilitates alignment on close-source\npolicy models; (3) generalizable inference method flexibly adjusts target\nobjectives by updating their text descriptions in the prompts, facilitating\ngeneralizable alignment to unseen objectives. Experimental results show that\nMetaAligner achieves significant and balanced improvements in multi-objective\nalignments on 10 state-of-the-art policy models, and saves up to 93.63% of GPU\ntraining hours compared to previous alignment methods. The model also\neffectively aligns unseen objectives, marking the first step towards\ngeneralizable multi-objective preference alignment.\n","authors":["Kailai Yang","Zhiwei Liu","Qianqian Xie","Jimin Huang","Tianlin Zhang","Sophia Ananiadou"],"pdf_url":"https://arxiv.org/pdf/2403.17141v3.pdf","comment":"Accepted by NeurIPS 2024 main track"},{"id":"http://arxiv.org/abs/2410.04717v1","updated":"2024-10-07T03:15:11Z","published":"2024-10-07T03:15:11Z","title":"$\\textbf{Only-IF}$:Revealing the Decisive Effect of Instruction\n  Diversity on Generalization","summary":"  Understanding and accurately following instructions is critical for large\nlanguage models (LLMs) to be effective across diverse tasks. In this work, we\nrigorously examine the key factors that enable models to generalize to unseen\ninstructions, providing insights to guide the collection of data for\ninstruction-tuning. Through controlled experiments, inspired by the\nTuring-complete Markov algorithm, we demonstrate that such generalization\n$\\textbf{only emerges}$ when training data is diversified enough across\nsemantic domains. Our findings also reveal that merely diversifying within\nlimited domains fails to ensure robust generalization. In contrast,\ncross-domain data diversification, even under constrained data budgets,\nsignificantly enhances a model's adaptability. We further extend our analysis\nto real-world scenarios, including fine-tuning of\n$\\textit{$\\textbf{specialist}$}$ and $\\textit{$\\textbf{generalist}$}$ models.\nIn both cases, we demonstrate that 1) better performance can be achieved by\nincreasing the diversity of an established dataset while keeping the data size\nconstant, and 2) when scaling up the data, diversifying the semantics of\ninstructions is more effective than simply increasing the quantity of similar\ndata. Our research provides important insights for dataset collation,\nparticularly when optimizing model performance by expanding training data for\nboth specialist and generalist scenarios. We show that careful consideration of\ndata diversification is key: training specialist models with data extending\nbeyond their core domain leads to significant performance improvements, while\ngeneralist models benefit from diverse data mixtures that enhance their overall\ninstruction-following capabilities across a wide range of applications. Our\nresults highlight the critical role of strategic diversification and offer\nclear guidelines for improving data quality.\n","authors":["Dylan Zhang","Justin Wang","Francois Charton"],"pdf_url":"https://arxiv.org/pdf/2410.04717v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04715v1","updated":"2024-10-07T03:13:06Z","published":"2024-10-07T03:13:06Z","title":"Rule-based Data Selection for Large Language Models","summary":"  The quality of training data significantly impacts the performance of large\nlanguage models (LLMs). There are increasing studies using LLMs to rate and\nselect data based on several human-crafted metrics (rules). However, these\nconventional rule-based approaches often depend too heavily on human\nheuristics, lack effective metrics for assessing rules, and exhibit limited\nadaptability to new tasks. In our study, we introduce an innovative rule-based\nframework that utilizes the orthogonality of score vectors associated with\nrules as a novel metric for rule evaluations. Our approach includes an\nautomated pipeline that first uses LLMs to generate a diverse set of rules,\nencompassing various rating dimensions to evaluate data quality. Then it rates\na batch of data based on these rules and uses the determinantal point process\n(DPP) from random matrix theory to select the most orthogonal score vectors,\nthereby identifying a set of independent rules. These rules are subsequently\nused to evaluate all data, selecting samples with the highest average scores\nfor downstream tasks such as LLM training. We verify the effectiveness of our\nmethod through two experimental setups: 1) comparisons with ground truth\nratings and 2) benchmarking LLMs trained with the chosen data. Our\ncomprehensive experiments cover a range of scenarios, including general\npre-training and domain-specific fine-tuning in areas such as IMDB, Medical,\nMath, and Code. The outcomes demonstrate that our DPP-based rule rating method\nconsistently outperforms other approaches, including rule-free rating, uniform\nsampling, importance resampling, and QuRating, in terms of both rating\nprecision and model performance.\n","authors":["Xiaomin Li","Mingye Gao","Zhiwei Zhang","Chang Yue","Hong Hu"],"pdf_url":"https://arxiv.org/pdf/2410.04715v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.12327v3","updated":"2024-10-07T03:08:12Z","published":"2024-07-17T05:53:20Z","title":"Spectra: A Comprehensive Study of Ternary, Quantized, and FP16 Language\n  Models","summary":"  Rapid advancements in GPU computational power has outpaced memory capacity\nand bandwidth growth, creating bottlenecks in Large Language Model (LLM)\ninference. Post-training quantization is the leading method for addressing\nmemory-related bottlenecks in LLM inference, but it suffers from significant\nperformance degradation below 4-bit precision. This paper addresses these\nchallenges by investigating the pretraining of low-bitwidth models specifically\nTernary Language Models (TriLMs) as an alternative to traditional\nfloating-point models (FloatLMs) and their post-training quantized versions\n(QuantLMs). We present Spectra LLM suite, the first open suite of LLMs spanning\nmultiple bit-widths, including FloatLMs, QuantLMs, and TriLMs, ranging from 99M\nto 3.9B parameters trained on 300B tokens. Our comprehensive evaluation\ndemonstrates that TriLMs offer superior scaling behavior in terms of model size\n(in bits). Surprisingly, at scales exceeding one billion parameters, TriLMs\nconsistently outperform their QuantLM and FloatLM counterparts for a given bit\nsize across various benchmarks. Notably, the 3.9B parameter TriLM matches the\nperformance of the FloatLM 3.9B across all benchmarks, despite having fewer\nbits than FloatLM 830M. Overall, this research provides valuable insights into\nthe feasibility and scalability of low-bitwidth language models, paving the way\nfor the development of more efficient LLMs.\n  To enhance understanding of low-bitwidth models, we are releasing 500+\nintermediate checkpoints of the Spectra suite at\n\\href{https://github.com/NolanoOrg/SpectraSuite}{https://github.com/NolanoOrg/SpectraSuite}.\n","authors":["Ayush Kaushal","Tejas Vaidhya","Arnab Kumar Mondal","Tejas Pandey","Aaryan Bhagat","Irina Rish"],"pdf_url":"https://arxiv.org/pdf/2407.12327v3.pdf","comment":"42 pages, 21 figures, and 13 tables"},{"id":"http://arxiv.org/abs/2405.15984v3","updated":"2024-10-07T03:07:58Z","published":"2024-05-24T23:56:36Z","title":"Evaluating and Safeguarding the Adversarial Robustness of\n  Retrieval-Based In-Context Learning","summary":"  With the emergence of large language models, such as LLaMA and OpenAI GPT-3,\nIn-Context Learning (ICL) gained significant attention due to its effectiveness\nand efficiency. However, ICL is very sensitive to the choice, order, and\nverbaliser used to encode the demonstrations in the prompt. Retrieval-Augmented\nICL methods try to address this problem by leveraging retrievers to extract\nsemantically related examples as demonstrations. While this approach yields\nmore accurate results, its robustness against various types of adversarial\nattacks, including perturbations on test samples, demonstrations, and retrieved\ndata, remains under-explored. Our study reveals that retrieval-augmented models\ncan enhance robustness against test sample attacks, outperforming vanilla ICL\nwith a 4.87% reduction in Attack Success Rate (ASR); however, they exhibit\noverconfidence in the demonstrations, leading to a 2% increase in ASR for\ndemonstration attacks. Adversarial training can help improve the robustness of\nICL methods to adversarial attacks; however, such a training scheme can be too\ncostly in the context of LLMs. As an alternative, we introduce an effective\ntraining-free adversarial defence method, DARD, which enriches the example pool\nwith those attacked samples. We show that DARD yields improvements in\nperformance and robustness, achieving a 15% reduction in ASR over the\nbaselines. Code and data are released to encourage further research:\nhttps://github.com/simonucl/adv-retreival-icl\n","authors":["Simon Yu","Jie He","Pasquale Minervini","Jeff Z. Pan"],"pdf_url":"https://arxiv.org/pdf/2405.15984v3.pdf","comment":"COLM 2024, 30 pages, 6 figures"},{"id":"http://arxiv.org/abs/2406.05328v2","updated":"2024-10-07T03:06:34Z","published":"2024-06-08T02:59:52Z","title":"FacLens: Transferable Probe for Foreseeing Non-Factuality in Large\n  Language Models","summary":"  Despite advancements in large language models (LLMs), non-factual responses\nremain prevalent. Unlike extensive studies on post-hoc detection of such\nresponses, this work studies non-factuality prediction (NFP), aiming to predict\nwhether an LLM will generate a non-factual response to a question before the\ngeneration process. Previous efforts on NFP have demonstrated LLMs' awareness\nof their internal knowledge, but they still face challenges in efficiency and\ntransferability. In this work, we propose a lightweight NFP model named\nFactuality Lens (FacLens), which effectively probes hidden representations of\nquestions for the NFP task. Besides, we discover that hidden question\nrepresentations sourced from different LLMs exhibit similar NFP patterns, which\nenables the transferability of FacLens across LLMs to reduce development costs.\nExtensive experiments highlight FacLens's superiority in both effectiveness and\nefficiency.\n","authors":["Yanling Wang","Haoyang Li","Hao Zou","Jing Zhang","Xinlei He","Qi Li","Ke Xu"],"pdf_url":"https://arxiv.org/pdf/2406.05328v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.03226v2","updated":"2024-10-07T03:01:01Z","published":"2024-10-04T08:26:06Z","title":"Frame-Voyager: Learning to Query Frames for Video Large Language Models","summary":"  Video Large Language Models (Video-LLMs) have made remarkable progress in\nvideo understanding tasks. However, they are constrained by the maximum length\nof input tokens, making it impractical to input entire videos. Existing frame\nselection approaches, such as uniform frame sampling and text-frame retrieval,\nfail to account for the information density variations in the videos or the\ncomplex instructions in the tasks, leading to sub-optimal performance. In this\npaper, we propose Frame-Voyager that learns to query informative frame\ncombinations, based on the given textual queries in the task. To train\nFrame-Voyager, we introduce a new data collection and labeling pipeline, by\nranking frame combinations using a pre-trained Video-LLM. Given a video of M\nframes, we traverse its T-frame combinations, feed them into a Video-LLM, and\nrank them based on Video-LLM's prediction losses. Using this ranking as\nsupervision, we train Frame-Voyager to query the frame combinations with lower\nlosses. In experiments, we evaluate Frame-Voyager on four Video Question\nAnswering benchmarks by plugging it into two different Video-LLMs. The\nexperimental results demonstrate that Frame-Voyager achieves impressive results\nin all settings, highlighting its potential as a plug-and-play solution for\nVideo-LLMs.\n","authors":["Sicheng Yu","Chengkai Jin","Huanyu Wang","Zhenghao Chen","Sheng Jin","Zhongrong Zuo","Xiaolei Xu","Zhenbang Sun","Bingni Zhang","Jiawei Wu","Hao Zhang","Qianru Sun"],"pdf_url":"https://arxiv.org/pdf/2410.03226v2.pdf","comment":"19 pages, 10 figures"},{"id":"http://arxiv.org/abs/2405.20267v4","updated":"2024-10-07T02:53:44Z","published":"2024-05-30T17:19:19Z","title":"Auto-Arena: Automating LLM Evaluations with Agent Peer Battles and\n  Committee Discussions","summary":"  As LLMs continuously evolve, there is an urgent need for a reliable\nevaluation method that delivers trustworthy results promptly. Currently, static\nbenchmarks suffer from inflexibility and unreliability, leading users to prefer\nhuman voting platforms like Chatbot Arena. However, human evaluations require\nsignificant manual effort. To address this, we propose the Auto-Arena, an\ninnovative framework that automates the entire evaluation process using\nLLM-powered agents. Firstly, an LLM examiner generates questions. Then, two LLM\ncandidates engage in a multi-round peer battle based on individual questions,\naiming at revealing their true performance differences. Finally, a committee of\nLLM judges collaboratively discusses and decides the winner, reducing bias and\nenhancing fairness. During the peer battles, we observe intriguing scenarios\nwhere the LLM candidates display competitive behaviors and even learn from the\nopponents. In our extensive experiments involving 15 recent LLMs, Auto-Arena\nshows a 92.14% correlation with human preferences, surpassing all previous\nexpert-annotated benchmarks without any manual efforts. As a result, Auto-Arena\noffers a promising alternative to current human evaluation platforms for\nevaluating LLMs automatically.\n","authors":["Ruochen Zhao","Wenxuan Zhang","Yew Ken Chia","Weiwen Xu","Deli Zhao","Lidong Bing"],"pdf_url":"https://arxiv.org/pdf/2405.20267v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04707v1","updated":"2024-10-07T02:52:30Z","published":"2024-10-07T02:52:30Z","title":"Learning How Hard to Think: Input-Adaptive Allocation of LM Computation","summary":"  Computationally intensive decoding procedures--including search, reranking,\nand self-critique--can improve the quality of language model (LM) outputs in\nproblems spanning code generation, numerical reasoning, and dialog. Existing\nwork typically applies the same decoding procedure for every input to an LM.\nBut not all inputs require the same amount of computation to process. Can we\nallocate decoding computation adaptively, using more resources to answer\nquestions whose answers will be harder to compute? We present an approach that\npredicts the distribution of rewards given an input and computation budget,\nthen allocates additional computation to inputs for which it is predicted to be\nmost useful. We apply this approach in two decoding procedures: first, an\nadaptive best-of-k procedure that dynamically selects the number of samples to\ngenerate as input to a reranker; second, a routing procedure that dynamically\nresponds to a query using a decoding procedure that is expensive but accurate,\nor one that is cheaper but less capable. Across a suite of programming,\nmathematics, and dialog tasks, we show that accurate computation-allocation\nprocedures can be learned, and reduce computation by up to 50% at no cost to\nresponse quality, or improve quality by up to 10% at a fixed computational\nbudget.\n","authors":["Mehul Damani","Idan Shenfeld","Andi Peng","Andreea Bobu","Jacob Andreas"],"pdf_url":"https://arxiv.org/pdf/2410.04707v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04704v1","updated":"2024-10-07T02:48:18Z","published":"2024-10-07T02:48:18Z","title":"Modeling and Estimation of Vocal Tract and Glottal Source Parameters\n  Using ARMAX-LF Model","summary":"  Modeling and estimation of the vocal tract and glottal source parameters of\nvowels from raw speech can be typically done by using the Auto-Regressive with\neXogenous input (ARX) model and Liljencrants-Fant (LF) model with an\niteration-based estimation approach. However, the all-pole autoregressive model\nin the modeling of vocal tract filters cannot provide the locations of\nanti-formants (zeros), which increases the estimation errors in certain classes\nof speech sounds, such as nasal, fricative, and stop consonants. In this paper,\nwe propose the Auto-Regressive Moving Average eXogenous with LF (ARMAX-LF)\nmodel to extend the ARX-LF model to a wider variety of speech sounds, including\nvowels and nasalized consonants. The LF model represents the glottal source\nderivative as a parametrized time-domain model, and the ARMAX model represents\nthe vocal tract as a pole-zero filter with an additional exogenous LF\nexcitation as input. To estimate multiple parameters with fewer errors, we\nfirst utilize the powerful nonlinear fitting ability of deep neural networks\n(DNNs) to build a mapping from extracted glottal source derivatives or speech\nwaveforms to corresponding LF parameters. Then, glottal source and vocal tract\nparameters can be estimated with fewer estimation errors and without any\niterations as in the analysis-by-synthesis strategy. Experimental results with\nsynthesized speech using the linear source-filter model, synthesized speech\nusing the physical model, and real speech signals showed that the proposed\nARMAX-LF model with a DNN-based estimation method can estimate the parameters\nof both vowels and nasalized sounds with fewer errors and estimation time.\n","authors":["Kai Lia","Masato Akagia","Yongwei Lib","Masashi Unokia"],"pdf_url":"https://arxiv.org/pdf/2410.04704v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.00943v2","updated":"2024-10-07T02:47:36Z","published":"2024-04-01T06:03:39Z","title":"Evalverse: Unified and Accessible Library for Large Language Model\n  Evaluation","summary":"  This paper introduces Evalverse, a novel library that streamlines the\nevaluation of Large Language Models (LLMs) by unifying disparate evaluation\ntools into a single, user-friendly framework. Evalverse enables individuals\nwith limited knowledge of artificial intelligence to easily request LLM\nevaluations and receive detailed reports, facilitated by an integration with\ncommunication platforms like Slack. Thus, Evalverse serves as a powerful tool\nfor the comprehensive assessment of LLMs, offering both researchers and\npractitioners a centralized and easily accessible evaluation framework.\nFinally, we also provide a demo video for Evalverse, showcasing its\ncapabilities and implementation in a two-minute format.\n","authors":["Jihoo Kim","Wonho Song","Dahyun Kim","Yunsu Kim","Yungi Kim","Chanjun Park"],"pdf_url":"https://arxiv.org/pdf/2404.00943v2.pdf","comment":"Accepted to EMNLP 2024 Demo Track"},{"id":"http://arxiv.org/abs/2410.04699v1","updated":"2024-10-07T02:30:18Z","published":"2024-10-07T02:30:18Z","title":"The LLM Effect: Are Humans Truly Using LLMs, or Are They Being\n  Influenced By Them Instead?","summary":"  Large Language Models (LLMs) have shown capabilities close to human\nperformance in various analytical tasks, leading researchers to use them for\ntime and labor-intensive analyses. However, their capability to handle highly\nspecialized and open-ended tasks in domains like policy studies remains in\nquestion. This paper investigates the efficiency and accuracy of LLMs in\nspecialized tasks through a structured user study focusing on Human-LLM\npartnership. The study, conducted in two stages-Topic Discovery and Topic\nAssignment-integrates LLMs with expert annotators to observe the impact of LLM\nsuggestions on what is usually human-only analysis. Results indicate that\nLLM-generated topic lists have significant overlap with human generated topic\nlists, with minor hiccups in missing document-specific topics. However, LLM\nsuggestions may significantly improve task completion speed, but at the same\ntime introduce anchoring bias, potentially affecting the depth and nuance of\nthe analysis, raising a critical question about the trade-off between increased\nefficiency and the risk of biased analysis.\n","authors":["Alexander S. Choi","Syeda Sabrina Akter","JP Singh","Antonios Anastasopoulos"],"pdf_url":"https://arxiv.org/pdf/2410.04699v1.pdf","comment":"Accepted to EMNLP Main 2024. First two authors contributed equally"},{"id":"http://arxiv.org/abs/2410.04698v1","updated":"2024-10-07T02:30:07Z","published":"2024-10-07T02:30:07Z","title":"MathHay: An Automated Benchmark for Long-Context Mathematical Reasoning\n  in LLMs","summary":"  Recent large language models (LLMs) have demonstrated versatile capabilities\nin long-context scenarios. Although some recent benchmarks have been developed\nto evaluate the long-context capabilities of LLMs, there is a lack of\nbenchmarks evaluating the mathematical reasoning abilities of LLMs over long\ncontexts, which is crucial for LLMs' application in real-world scenarios. In\nthis paper, we introduce MathHay, an automated benchmark designed to assess the\nlong-context mathematical reasoning capabilities of LLMs. Unlike previous\nbenchmarks like Needle in a Haystack, which focus primarily on information\nretrieval within long texts, MathHay demands models with both\ninformation-seeking and complex mathematical reasoning abilities. We conduct\nextensive experiments on MathHay to assess the long-context mathematical\nreasoning abilities of eight top-performing LLMs. Even the best-performing\nmodel, Gemini-1.5-Pro-002, still struggles with mathematical reasoning over\nlong contexts, achieving only 51.26% accuracy at 128K tokens. This highlights\nthe significant room for improvement on the MathHay benchmark.\n","authors":["Lei Wang","Shan Dong","Yuhui Xu","Hanze Dong","Yalu Wang","Amrita Saha","Ee-Peng Lim","Caiming Xiong","Doyen Sahoo"],"pdf_url":"https://arxiv.org/pdf/2410.04698v1.pdf","comment":"Work-in-Progress"},{"id":"http://arxiv.org/abs/2401.15884v3","updated":"2024-10-07T02:19:21Z","published":"2024-01-29T04:36:39Z","title":"Corrective Retrieval Augmented Generation","summary":"  Large language models (LLMs) inevitably exhibit hallucinations since the\naccuracy of generated texts cannot be secured solely by the parametric\nknowledge they encapsulate. Although retrieval-augmented generation (RAG) is a\npracticable complement to LLMs, it relies heavily on the relevance of retrieved\ndocuments, raising concerns about how the model behaves if retrieval goes\nwrong. To this end, we propose the Corrective Retrieval Augmented Generation\n(CRAG) to improve the robustness of generation. Specifically, a lightweight\nretrieval evaluator is designed to assess the overall quality of retrieved\ndocuments for a query, returning a confidence degree based on which different\nknowledge retrieval actions can be triggered. Since retrieval from static and\nlimited corpora can only return sub-optimal documents, large-scale web searches\nare utilized as an extension for augmenting the retrieval results. Besides, a\ndecompose-then-recompose algorithm is designed for retrieved documents to\nselectively focus on key information and filter out irrelevant information in\nthem. CRAG is plug-and-play and can be seamlessly coupled with various\nRAG-based approaches. Experiments on four datasets covering short- and\nlong-form generation tasks show that CRAG can significantly improve the\nperformance of RAG-based approaches.\n","authors":["Shi-Qi Yan","Jia-Chen Gu","Yun Zhu","Zhen-Hua Ling"],"pdf_url":"https://arxiv.org/pdf/2401.15884v3.pdf","comment":"Update results, add more analysis, and fix typos"},{"id":"http://arxiv.org/abs/2410.04691v1","updated":"2024-10-07T02:12:22Z","published":"2024-10-07T02:12:22Z","title":"Deeper Insights Without Updates: The Power of In-Context Learning Over\n  Fine-Tuning","summary":"  Fine-tuning and in-context learning (ICL) are two prevalent methods in\nimbuing large language models with task-specific knowledge. It is commonly\nbelieved that fine-tuning can surpass ICL given sufficient training samples as\nit allows the model to adjust its internal parameters based on the data.\nHowever, this paper presents a counterintuitive finding: For tasks with\nimplicit patterns, ICL captures these patterns significantly better than\nfine-tuning. We developed several datasets featuring implicit patterns, such as\nsequences determining answers through parity or identifying reducible terms in\ncalculations. We then evaluated the models' understanding of these patterns\nunder both fine-tuning and ICL across models ranging from 0.5B to 7B\nparameters. The results indicate that models employing ICL can quickly grasp\ndeep patterns and significantly improve accuracy. In contrast, fine-tuning,\ndespite utilizing thousands of times more training samples than ICL, achieved\nonly limited improvements. We also proposed circuit shift theory from a\nmechanistic interpretability's view to explain why ICL wins.\n","authors":["Qingyu Yin","Xuzheng He","Luoao Deng","Chak Tou Leong","Fan Wang","Yanzhao Yan","Xiaoyu Shen","Qiang Zhang"],"pdf_url":"https://arxiv.org/pdf/2410.04691v1.pdf","comment":"EMNLP'24 Findings"},{"id":"http://arxiv.org/abs/2406.08464v2","updated":"2024-10-07T01:45:38Z","published":"2024-06-12T17:52:30Z","title":"Magpie: Alignment Data Synthesis from Scratch by Prompting Aligned LLMs\n  with Nothing","summary":"  High-quality instruction data is critical for aligning large language models\n(LLMs). Although some models, such as Llama-3-Instruct, have open weights,\ntheir alignment data remain private, which hinders the democratization of AI.\nHigh human labor costs and a limited, predefined scope for prompting prevent\nexisting open-source data creation methods from scaling effectively,\npotentially limiting the diversity and quality of public alignment datasets. Is\nit possible to synthesize high-quality instruction data at scale by extracting\nit directly from an aligned LLM? We present a self-synthesis method for\ngenerating large-scale alignment data named Magpie. Our key observation is that\naligned LLMs like Llama-3-Instruct can generate a user query when we input only\nthe left-side templates up to the position reserved for user messages, thanks\nto their auto-regressive nature. We use this method to prompt Llama-3-Instruct\nand generate 4 million instructions along with their corresponding responses.\nWe perform a comprehensive analysis of the extracted data and select 300K\nhigh-quality instances. To compare Magpie data with other public instruction\ndatasets, we fine-tune Llama-3-8B-Base with each dataset and evaluate the\nperformance of the fine-tuned models. Our results indicate that in some tasks,\nmodels fine-tuned with Magpie perform comparably to the official\nLlama-3-8B-Instruct, despite the latter being enhanced with 10 million data\npoints through supervised fine-tuning (SFT) and subsequent feedback learning.\nWe also show that using Magpie solely for SFT can surpass the performance of\nprevious public datasets utilized for both SFT and preference optimization,\nsuch as direct preference optimization with UltraFeedback. This advantage is\nevident on alignment benchmarks such as AlpacaEval, ArenaHard, and WildBench.\n","authors":["Zhangchen Xu","Fengqing Jiang","Luyao Niu","Yuntian Deng","Radha Poovendran","Yejin Choi","Bill Yuchen Lin"],"pdf_url":"https://arxiv.org/pdf/2406.08464v2.pdf","comment":"Link: https://magpie-align.github.io/"},{"id":"http://arxiv.org/abs/2405.16406v3","updated":"2024-10-07T01:27:59Z","published":"2024-05-26T02:15:49Z","title":"SpinQuant: LLM quantization with learned rotations","summary":"  Post-training quantization (PTQ) techniques applied to weights, activations,\nand the KV cache greatly reduce memory usage, latency, and power consumption of\nLarge Language Models (LLMs), but may lead to large quantization errors when\noutliers are present. Rotating activation or weight matrices helps remove\noutliers and benefits quantization. In this work, we identify a collection of\napplicable rotation parameterizations that lead to identical outputs in\nfull-precision Transformer architectures while enhancing quantization accuracy.\nIn addition, we find that some random rotations lead to much better\nquantization than others, with an up to 13 points difference in downstream\nzero-shot reasoning performance. As a result, we propose SpinQuant, a novel\napproach that incorporates learned rotation matrices for optimal quantized\nnetwork accuracy. With 4-bit quantization of weight, activation, and KV-cache,\nSpinQuant narrows the accuracy gap on zero-shot reasoning tasks with full\nprecision to merely 2.9 points on the LLaMA-2 7B model, surpassing LLM-QAT by\n19.1 points and SmoothQuant by 25.0 points. Furthermore, SpinQuant also\noutperforms concurrent work QuaRot, which applies random rotations to remove\noutliers. In particular, for LLaMA-3 8B models that are hard to quantize,\nSpinQuant reduces the gap to full precision by up to 45.1% relative to QuaRot.\n","authors":["Zechun Liu","Changsheng Zhao","Igor Fedorov","Bilge Soran","Dhruv Choudhary","Raghuraman Krishnamoorthi","Vikas Chandra","Yuandong Tian","Tijmen Blankevoort"],"pdf_url":"https://arxiv.org/pdf/2405.16406v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.12832v3","updated":"2024-10-07T01:26:23Z","published":"2024-09-19T15:07:35Z","title":"FoodPuzzle: Developing Large Language Model Agents as Flavor Scientists","summary":"  Flavor development in the food industry is increasingly challenged by the\nneed for rapid innovation and precise flavor profile creation. Traditional\nflavor research methods typically rely on iterative, subjective testing, which\nlacks the efficiency and scalability required for modern demands. This paper\npresents three contributions to address the challenges. Firstly, we define a\nnew problem domain for scientific agents in flavor science, conceptualized as\nthe generation of hypotheses for flavor profile sourcing and understanding. To\nfacilitate research in this area, we introduce the FoodPuzzle, a challenging\nbenchmark consisting of 978 food items and 1,766 flavor molecules profiles. We\npropose a novel Scientific Agent approach, integrating in-context learning and\nretrieval augmented techniques to generate grounded hypotheses in the domain of\nfood science. Experimental results indicate that our model significantly\nsurpasses traditional methods in flavor profile prediction tasks, demonstrating\nits potential to transform flavor development practices.\n","authors":["Tenghao Huang","Donghee Lee","John Sweeney","Jiatong Shi","Emily Steliotes","Matthew Lange","Jonathan May","Muhao Chen"],"pdf_url":"https://arxiv.org/pdf/2409.12832v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04663v1","updated":"2024-10-07T00:22:07Z","published":"2024-10-07T00:22:07Z","title":"Adversarial Multi-Agent Evaluation of Large Language Models through\n  Iterative Debates","summary":"  This paper explores optimal architectures for evaluating the outputs of large\nlanguage models (LLMs) using LLMs themselves. We propose a novel framework that\ninterprets LLMs as advocates within an ensemble of interacting agents, allowing\nthem to defend their answers and reach conclusions through a judge and jury\nsystem. This approach offers a more dynamic and comprehensive evaluation\nprocess compared to traditional human-based assessments or automated metrics.\nWe discuss the motivation behind this framework, its key components, and\ncomparative advantages. We also present a probabilistic model to evaluate the\nerror reduction achieved by iterative advocate systems. Finally, we outline\nexperiments to validate the effectiveness of multi-advocate architectures and\ndiscuss future research directions.\n","authors":["Chaithanya Bandi","Hari Bandi","Abir Harrasse"],"pdf_url":"https://arxiv.org/pdf/2410.04663v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.08760v3","updated":"2024-10-07T00:16:54Z","published":"2024-04-12T18:36:20Z","title":"The Generation Gap: Exploring Age Bias in the Value Systems of Large\n  Language Models","summary":"  We explore the alignment of values in Large Language Models (LLMs) with\nspecific age groups, leveraging data from the World Value Survey across\nthirteen categories. Through a diverse set of prompts tailored to ensure\nresponse robustness, we find a general inclination of LLM values towards\nyounger demographics, especially when compared to the US population. Although a\ngeneral inclination can be observed, we also found that this inclination toward\nyounger groups can be different across different value categories.\nAdditionally, we explore the impact of incorporating age identity information\nin prompts and observe challenges in mitigating value discrepancies with\ndifferent age cohorts. Our findings highlight the age bias in LLMs and provide\ninsights for future work. Materials for our analysis are available at \\url{\nhttps://github.com/MichiganNLP/Age-Bias-In-LLMs}\n","authors":["Siyang Liu","Trish Maturi","Bowen Yi","Siqi Shen","Rada Mihalcea"],"pdf_url":"https://arxiv.org/pdf/2404.08760v3.pdf","comment":"4 pages"},{"id":"http://arxiv.org/abs/2410.04657v1","updated":"2024-10-07T00:09:50Z","published":"2024-10-07T00:09:50Z","title":"Contrastive Learning to Improve Retrieval for Real-world Fact Checking","summary":"  Recent work on fact-checking addresses a realistic setting where models\nincorporate evidence retrieved from the web to decide the veracity of claims. A\nbottleneck in this pipeline is in retrieving relevant evidence: traditional\nmethods may surface documents directly related to a claim, but fact-checking\ncomplex claims requires more inferences. For instance, a document about how a\nvaccine was developed is relevant to addressing claims about what it might\ncontain, even if it does not address them directly. We present Contrastive\nFact-Checking Reranker (CFR), an improved retriever for this setting. By\nleveraging the AVeriTeC dataset, which annotates subquestions for claims with\nhuman written answers from evidence documents, we fine-tune Contriever with a\ncontrastive objective based on multiple training signals, including\ndistillation from GPT-4, evaluating subquestion answers, and gold labels in the\ndataset. We evaluate our model on both retrieval and end-to-end veracity\njudgments about claims. On the AVeriTeC dataset, we find a 6\\% improvement in\nveracity classification accuracy. We also show our gains can be transferred to\nFEVER, ClaimDecomp, HotpotQA, and a synthetic dataset requiring retrievers to\nmake inferences.\n","authors":["Aniruddh Sriram","Fangyuan Xu","Eunsol Choi","Greg Durrett"],"pdf_url":"https://arxiv.org/pdf/2410.04657v1.pdf","comment":"EMNLP 2024 FEVER Workshop"}],"Artificial Intelligence":[{"id":"http://arxiv.org/abs/2410.05269v1","updated":"2024-10-07T17:59:58Z","published":"2024-10-07T17:59:58Z","title":"Data Advisor: Dynamic Data Curation for Safety Alignment of Large\n  Language Models","summary":"  Data is a crucial element in large language model (LLM) alignment. Recent\nstudies have explored using LLMs for efficient data collection. However,\nLLM-generated data often suffers from quality issues, with underrepresented or\nabsent aspects and low-quality datapoints. To address these problems, we\npropose Data Advisor, an enhanced LLM-based method for generating data that\ntakes into account the characteristics of the desired dataset. Starting from a\nset of pre-defined principles in hand, Data Advisor monitors the status of the\ngenerated data, identifies weaknesses in the current dataset, and advises the\nnext iteration of data generation accordingly. Data Advisor can be easily\nintegrated into existing data generation methods to enhance data quality and\ncoverage. Experiments on safety alignment of three representative LLMs (i.e.,\nMistral, Llama2, and Falcon) demonstrate the effectiveness of Data Advisor in\nenhancing model safety against various fine-grained safety issues without\nsacrificing model utility.\n","authors":["Fei Wang","Ninareh Mehrabi","Palash Goyal","Rahul Gupta","Kai-Wei Chang","Aram Galstyan"],"pdf_url":"https://arxiv.org/pdf/2410.05269v1.pdf","comment":"Accepted to EMNLP 2024 Main Conference. Project website:\n  https://feiwang96.github.io/DataAdvisor/"},{"id":"http://arxiv.org/abs/2406.11839v2","updated":"2024-10-07T17:59:42Z","published":"2024-06-17T17:59:58Z","title":"mDPO: Conditional Preference Optimization for Multimodal Large Language\n  Models","summary":"  Direct preference optimization (DPO) has shown to be an effective method for\nlarge language model (LLM) alignment. Recent works have attempted to apply DPO\nto multimodal scenarios but have found it challenging to achieve consistent\nimprovement. Through a comparative experiment, we identify the unconditional\npreference problem in multimodal preference optimization, where the model\noverlooks the image condition. To address this problem, we propose mDPO, a\nmultimodal DPO objective that prevents the over-prioritization of language-only\npreferences by also optimizing image preference. Moreover, we introduce a\nreward anchor that forces the reward to be positive for chosen responses,\nthereby avoiding the decrease in their likelihood -- an intrinsic problem of\nrelative preference optimization. Experiments on two multimodal LLMs of\ndifferent sizes and three widely used benchmarks demonstrate that mDPO\neffectively addresses the unconditional preference problem in multimodal\npreference optimization and significantly improves model performance,\nparticularly in reducing hallucination.\n","authors":["Fei Wang","Wenxuan Zhou","James Y. Huang","Nan Xu","Sheng Zhang","Hoifung Poon","Muhao Chen"],"pdf_url":"https://arxiv.org/pdf/2406.11839v2.pdf","comment":"Accepted to EMNLP 2024 Main Conference. Project website:\n  https://feiwang96.github.io/mDPO"},{"id":"http://arxiv.org/abs/2410.05263v1","updated":"2024-10-07T17:59:09Z","published":"2024-10-07T17:59:09Z","title":"Regression Conformal Prediction under Bias","summary":"  Uncertainty quantification is crucial to account for the imperfect\npredictions of machine learning algorithms for high-impact applications.\nConformal prediction (CP) is a powerful framework for uncertainty\nquantification that generates calibrated prediction intervals with valid\ncoverage. In this work, we study how CP intervals are affected by bias - the\nsystematic deviation of a prediction from ground truth values - a phenomenon\nprevalent in many real-world applications. We investigate the influence of bias\non interval lengths of two different types of adjustments -- symmetric\nadjustments, the conventional method where both sides of the interval are\nadjusted equally, and asymmetric adjustments, a more flexible method where the\ninterval can be adjusted unequally in positive or negative directions. We\npresent theoretical and empirical analyses characterizing how symmetric and\nasymmetric adjustments impact the \"tightness\" of CP intervals for regression\ntasks. Specifically for absolute residual and quantile-based non-conformity\nscores, we prove: 1) the upper bound of symmetrically adjusted interval lengths\nincreases by $2|b|$ where $b$ is a globally applied scalar value representing\nbias, 2) asymmetrically adjusted interval lengths are not affected by bias, and\n3) conditions when asymmetrically adjusted interval lengths are guaranteed to\nbe smaller than symmetric ones. Our analyses suggest that even if predictions\nexhibit significant drift from ground truth values, asymmetrically adjusted\nintervals are still able to maintain the same tightness and validity of\nintervals as if the drift had never happened, while symmetric ones\nsignificantly inflate the lengths. We demonstrate our theoretical results with\ntwo real-world prediction tasks: sparse-view computed tomography (CT)\nreconstruction and time-series weather forecasting. Our work paves the way for\nmore bias-robust machine learning systems.\n","authors":["Matt Y. Cheung","Tucker J. Netherton","Laurence E. Court","Ashok Veeraraghavan","Guha Balakrishnan"],"pdf_url":"https://arxiv.org/pdf/2410.05263v1.pdf","comment":"17 pages, 6 figures, code available at:\n  https://github.com/matthewyccheung/conformal-metric"},{"id":"http://arxiv.org/abs/2410.05261v1","updated":"2024-10-07T17:58:35Z","published":"2024-10-07T17:58:35Z","title":"TextHawk2: A Large Vision-Language Model Excels in Bilingual OCR and\n  Grounding with 16x Fewer Tokens","summary":"  Reading dense text and locating objects within images are fundamental\nabilities for Large Vision-Language Models (LVLMs) tasked with advanced jobs.\nPrevious LVLMs, including superior proprietary models like GPT-4o, have\nstruggled to excel in both tasks simultaneously. Moreover, previous LVLMs with\nfine-grained perception cost thousands of tokens per image, making them\nresource-intensive. We present TextHawk2, a bilingual LVLM featuring efficient\nfine-grained perception and demonstrating cutting-edge performance across\ngeneral-purpose, OCR, and grounding tasks with 16 times fewer image tokens.\nCritical improvements include: (1) Token Compression: Building on the efficient\narchitecture of its predecessor, TextHawk2 significantly reduces the number of\ntokens per image by 16 times, facilitating training and deployment of the\nTextHawk series with minimal resources. (2) Visual Encoder Reinforcement: We\nenhance the visual encoder through LVLM co-training, unlocking its potential\nfor previously unseen tasks like Chinese OCR and grounding. (3) Data Diversity:\nWe maintain a comparable scale of 100 million samples while diversifying the\nsources of pre-training data. We assess TextHawk2 across multiple benchmarks,\nwhere it consistently delivers superior performance and outperforms\nclosed-source models of similar scale, such as achieving 78.4% accuracy on\nOCRBench, 81.4% accuracy on ChartQA, 89.6% ANLS on DocVQA, and 88.1%\naccuracy@0.5 on RefCOCOg-test.\n","authors":["Ya-Qi Yu","Minghui Liao","Jiwen Zhang","Jihao Wu"],"pdf_url":"https://arxiv.org/pdf/2410.05261v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.05254v1","updated":"2024-10-07T17:55:35Z","published":"2024-10-07T17:55:35Z","title":"GLEE: A Unified Framework and Benchmark for Language-based Economic\n  Environments","summary":"  Large Language Models (LLMs) show significant potential in economic and\nstrategic interactions, where communication via natural language is often\nprevalent. This raises key questions: Do LLMs behave rationally? Can they mimic\nhuman behavior? Do they tend to reach an efficient and fair outcome? What is\nthe role of natural language in the strategic interaction? How do\ncharacteristics of the economic environment influence these dynamics? These\nquestions become crucial concerning the economic and societal implications of\nintegrating LLM-based agents into real-world data-driven systems, such as\nonline retail platforms and recommender systems. While the ML community has\nbeen exploring the potential of LLMs in such multi-agent setups, varying\nassumptions, design choices and evaluation criteria across studies make it\ndifficult to draw robust and meaningful conclusions. To address this, we\nintroduce a benchmark for standardizing research on two-player, sequential,\nlanguage-based games. Inspired by the economic literature, we define three base\nfamilies of games with consistent parameterization, degrees of freedom and\neconomic measures to evaluate agents' performance (self-gain), as well as the\ngame outcome (efficiency and fairness). We develop an open-source framework for\ninteraction simulation and analysis, and utilize it to collect a dataset of LLM\nvs. LLM interactions across numerous game configurations and an additional\ndataset of human vs. LLM interactions. Through extensive experimentation, we\ndemonstrate how our framework and dataset can be used to: (i) compare the\nbehavior of LLM-based agents to human players in various economic contexts;\n(ii) evaluate agents in both individual and collective performance measures;\nand (iii) quantify the effect of the economic characteristics of the\nenvironments on the behavior of agents.\n","authors":["Eilam Shapira","Omer Madmon","Itamar Reinman","Samuel Joseph Amouyal","Roi Reichart","Moshe Tennenholtz"],"pdf_url":"https://arxiv.org/pdf/2410.05254v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.05252v1","updated":"2024-10-07T17:55:10Z","published":"2024-10-07T17:55:10Z","title":"Causal Micro-Narratives","summary":"  We present a novel approach to classify causal micro-narratives from text.\nThese narratives are sentence-level explanations of the cause(s) and/or\neffect(s) of a target subject. The approach requires only a subject-specific\nontology of causes and effects, and we demonstrate it with an application to\ninflation narratives. Using a human-annotated dataset spanning historical and\ncontemporary US news articles for training, we evaluate several large language\nmodels (LLMs) on this multi-label classification task. The best-performing\nmodel--a fine-tuned Llama 3.1 8B--achieves F1 scores of 0.87 on narrative\ndetection and 0.71 on narrative classification. Comprehensive error analysis\nreveals challenges arising from linguistic ambiguity and highlights how model\nerrors often mirror human annotator disagreements. This research establishes a\nframework for extracting causal micro-narratives from real-world data, with\nwide-ranging applications to social science research.\n","authors":["Mourad Heddaya","Qingcheng Zeng","Chenhao Tan","Rob Voigt","Alexander Zentefis"],"pdf_url":"https://arxiv.org/pdf/2410.05252v1.pdf","comment":"Accepted to EMNLP 2024 Workshop on Narrative Understanding"},{"id":"http://arxiv.org/abs/2410.05248v1","updated":"2024-10-07T17:52:21Z","published":"2024-10-07T17:52:21Z","title":"SFTMix: Elevating Language Model Instruction Tuning with Mixup Recipe","summary":"  To induce desired behaviors in large language models (LLMs) for\ninteraction-driven tasks, the instruction-tuning stage typically trains LLMs on\ninstruction-response pairs using the next-token prediction (NTP) loss. Previous\nwork aiming to improve instruction-tuning performance often emphasizes the need\nfor higher-quality supervised fine-tuning (SFT) datasets, which typically\ninvolves expensive data filtering with proprietary LLMs or labor-intensive data\ngeneration by human annotators. However, these approaches do not fully leverage\nthe datasets' intrinsic properties, resulting in high computational and labor\ncosts, thereby limiting scalability and performance gains. In this paper, we\npropose SFTMix, a novel recipe that elevates instruction-tuning performance\nbeyond the conventional NTP paradigm, without the need for well-curated\ndatasets. Observing that LLMs exhibit uneven confidence across the semantic\nrepresentation space, we argue that examples with different confidence levels\nshould play distinct roles during the instruction-tuning process. Based on this\ninsight, SFTMix leverages training dynamics to identify examples with varying\nconfidence levels, then applies a Mixup-based regularization to mitigate\noverfitting on confident examples while propagating supervision signals to\nimprove learning on relatively unconfident ones. This approach enables SFTMix\nto significantly outperform NTP across a wide range of instruction-following\nand healthcare domain-specific SFT tasks, demonstrating its adaptability to\ndiverse LLM families and scalability to datasets of any size. Comprehensive\nablation studies further verify the robustness of SFTMix's design choices,\nunderscoring its versatility in consistently enhancing performance across\ndifferent LLMs and datasets in broader natural language processing\napplications.\n","authors":["Yuxin Xiao","Shujian Zhang","Wenxuan Zhou","Marzyeh Ghassemi","Sanqiang Zhao"],"pdf_url":"https://arxiv.org/pdf/2410.05248v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.05243v1","updated":"2024-10-07T17:47:50Z","published":"2024-10-07T17:47:50Z","title":"Navigating the Digital World as Humans Do: Universal Visual Grounding\n  for GUI Agents","summary":"  Multimodal large language models (MLLMs) are transforming the capabilities of\ngraphical user interface (GUI) agents, facilitating their transition from\ncontrolled simulations to complex, real-world applications across various\nplatforms. However, the effectiveness of these agents hinges on the robustness\nof their grounding capability. Current GUI agents predominantly utilize\ntext-based representations such as HTML or accessibility trees, which, despite\ntheir utility, often introduce noise, incompleteness, and increased\ncomputational overhead. In this paper, we advocate a human-like embodiment for\nGUI agents that perceive the environment entirely visually and directly take\npixel-level operations on the GUI. The key is visual grounding models that can\naccurately map diverse referring expressions of GUI elements to their\ncoordinates on the GUI across different platforms. We show that a simple\nrecipe, which includes web-based synthetic data and slight adaptation of the\nLLaVA architecture, is surprisingly effective for training such visual\ngrounding models. We collect the largest dataset for GUI visual grounding so\nfar, containing 10M GUI elements and their referring expressions over 1.3M\nscreenshots, and use it to train UGround, a strong universal visual grounding\nmodel for GUI agents. Empirical results on six benchmarks spanning three\ncategories (grounding, offline agent, and online agent) show that 1) UGround\nsubstantially outperforms existing visual grounding models for GUI agents, by\nup to 20% absolute, and 2) agents with UGround outperform state-of-the-art\nagents, despite the fact that existing agents use additional text-based input\nwhile ours only uses visual perception. These results provide strong support\nfor the feasibility and promises of GUI agents that navigate the digital world\nas humans do.\n","authors":["Boyu Gou","Ruohan Wang","Boyuan Zheng","Yanan Xie","Cheng Chang","Yiheng Shu","Huan Sun","Yu Su"],"pdf_url":"https://arxiv.org/pdf/2410.05243v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.05235v1","updated":"2024-10-07T17:41:45Z","published":"2024-10-07T17:41:45Z","title":"CasiMedicos-Arg: A Medical Question Answering Dataset Annotated with\n  Explanatory Argumentative Structures","summary":"  Explaining Artificial Intelligence (AI) decisions is a major challenge\nnowadays in AI, in particular when applied to sensitive scenarios like medicine\nand law. However, the need to explain the rationale behind decisions is a main\nissue also for human-based deliberation as it is important to justify\n\\textit{why} a certain decision has been taken. Resident medical doctors for\ninstance are required not only to provide a (possibly correct) diagnosis, but\nalso to explain how they reached a certain conclusion. Developing new tools to\naid residents to train their explanation skills is therefore a central\nobjective of AI in education. In this paper, we follow this direction, and we\npresent, to the best of our knowledge, the first multilingual dataset for\nMedical Question Answering where correct and incorrect diagnoses for a clinical\ncase are enriched with a natural language explanation written by doctors. These\nexplanations have been manually annotated with argument components (i.e.,\npremise, claim) and argument relations (i.e., attack, support), resulting in\nthe Multilingual CasiMedicos-Arg dataset which consists of 558 clinical cases\nin four languages (English, Spanish, French, Italian) with explanations, where\nwe annotated 5021 claims, 2313 premises, 2431 support relations, and 1106\nattack relations. We conclude by showing how competitive baselines perform over\nthis challenging dataset for the argument mining task.\n","authors":["katerina Sviridova","Anar Yeginbergen","Ainara Estarrona","Elena Cabrio","Serena Villata","Rodrigo Agerri"],"pdf_url":"https://arxiv.org/pdf/2410.05235v1.pdf","comment":"9 pages"},{"id":"http://arxiv.org/abs/2410.05233v1","updated":"2024-10-07T17:41:10Z","published":"2024-10-07T17:41:10Z","title":"SimO Loss: Anchor-Free Contrastive Loss for Fine-Grained Supervised\n  Contrastive Learning","summary":"  We introduce a novel anchor-free contrastive learning (AFCL) method\nleveraging our proposed Similarity-Orthogonality (SimO) loss. Our approach\nminimizes a semi-metric discriminative loss function that simultaneously\noptimizes two key objectives: reducing the distance and orthogonality between\nembeddings of similar inputs while maximizing these metrics for dissimilar\ninputs, facilitating more fine-grained contrastive learning. The AFCL method,\npowered by SimO loss, creates a fiber bundle topological structure in the\nembedding space, forming class-specific, internally cohesive yet orthogonal\nneighborhoods. We validate the efficacy of our method on the CIFAR-10 dataset,\nproviding visualizations that demonstrate the impact of SimO loss on the\nembedding space. Our results illustrate the formation of distinct, orthogonal\nclass neighborhoods, showcasing the method's ability to create well-structured\nembeddings that balance class separation with intra-class variability. This\nwork opens new avenues for understanding and leveraging the geometric\nproperties of learned representations in various machine learning tasks.\n","authors":["Taha Bouhsine","Imad El Aaroussi","Atik Faysal","Wang Huaxia"],"pdf_url":"https://arxiv.org/pdf/2410.05233v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.05229v1","updated":"2024-10-07T17:36:37Z","published":"2024-10-07T17:36:37Z","title":"GSM-Symbolic: Understanding the Limitations of Mathematical Reasoning in\n  Large Language Models","summary":"  Recent advancements in Large Language Models (LLMs) have sparked interest in\ntheir formal reasoning capabilities, particularly in mathematics. The GSM8K\nbenchmark is widely used to assess the mathematical reasoning of models on\ngrade-school-level questions. While the performance of LLMs on GSM8K has\nsignificantly improved in recent years, it remains unclear whether their\nmathematical reasoning capabilities have genuinely advanced, raising questions\nabout the reliability of the reported metrics. To address these concerns, we\nconduct a large-scale study on several SOTA open and closed models. To overcome\nthe limitations of existing evaluations, we introduce GSM-Symbolic, an improved\nbenchmark created from symbolic templates that allow for the generation of a\ndiverse set of questions. GSM-Symbolic enables more controllable evaluations,\nproviding key insights and more reliable metrics for measuring the reasoning\ncapabilities of models.Our findings reveal that LLMs exhibit noticeable\nvariance when responding to different instantiations of the same question.\nSpecifically, the performance of all models declines when only the numerical\nvalues in the question are altered in the GSM-Symbolic benchmark. Furthermore,\nwe investigate the fragility of mathematical reasoning in these models and show\nthat their performance significantly deteriorates as the number of clauses in a\nquestion increases. We hypothesize that this decline is because current LLMs\ncannot perform genuine logical reasoning; they replicate reasoning steps from\ntheir training data. Adding a single clause that seems relevant to the question\ncauses significant performance drops (up to 65%) across all state-of-the-art\nmodels, even though the clause doesn't contribute to the reasoning chain needed\nfor the final answer. Overall, our work offers a more nuanced understanding of\nLLMs' capabilities and limitations in mathematical reasoning.\n","authors":["Iman Mirzadeh","Keivan Alizadeh","Hooman Shahrokhi","Oncel Tuzel","Samy Bengio","Mehrdad Farajtabar"],"pdf_url":"https://arxiv.org/pdf/2410.05229v1.pdf","comment":"preprint"},{"id":"http://arxiv.org/abs/2310.13391v3","updated":"2024-10-07T17:27:21Z","published":"2023-10-20T10:03:14Z","title":"Learning Successor Features with Distributed Hebbian Temporal Memory","summary":"  This paper presents a novel approach to address the challenge of online\ntemporal memory learning for decision-making under uncertainty in\nnon-stationary, partially observable environments. The proposed algorithm,\nDistributed Hebbian Temporal Memory (DHTM), is based on factor graph formalism\nand a multicomponent neuron model. DHTM aims to capture sequential data\nrelationships and make cumulative predictions about future observations,\nforming Successor Features (SF). Inspired by neurophysiological models of the\nneocortex, the algorithm utilizes distributed representations, sparse\ntransition matrices, and local Hebbian-like learning rules to overcome the\ninstability and slow learning process of traditional temporal memory algorithms\nlike RNN and HMM. Experimental results demonstrate that DHTM outperforms LSTM\nand a biologically inspired HMM-like algorithm, CSCG, in the case of\nnon-stationary datasets. Our findings suggest that DHTM is a promising approach\nfor addressing the challenges of online sequence learning and planning in\ndynamic environments.\n","authors":["Evgenii Dzhivelikian","Petr Kuderov","Aleksandr I. Panov"],"pdf_url":"https://arxiv.org/pdf/2310.13391v3.pdf","comment":"20 pages, 7 figures"},{"id":"http://arxiv.org/abs/2406.15877v3","updated":"2024-10-07T17:23:30Z","published":"2024-06-22T15:52:04Z","title":"BigCodeBench: Benchmarking Code Generation with Diverse Function Calls\n  and Complex Instructions","summary":"  Task automation has been greatly empowered by the recent advances in Large\nLanguage Models (LLMs) via Python code, where the tasks ranging from software\nengineering development to general-purpose reasoning. While current benchmarks\nhave shown that LLMs can solve tasks using programs like human developers, the\nmajority of their evaluations are limited to short and self-contained\nalgorithmic tasks or standalone function calls. Solving challenging and\npractical requires the capability of utilizing diverse function calls as tools\nto efficiently implement functionalities like data analysis and web\ndevelopment. In addition, using multiple tools to solve a task needs\ncompositional reasoning by accurately understanding complex instructions.\nFulfilling both of these characteristics can pose a great challenge for LLMs.To\nassess how well LLMs can solve challenging and practical tasks via programs, we\nintroduce BigCodeBench, a benchmark that challenges LLMs to invoke multiple\nfunction calls as tools from 139 libraries and 7 domains for 1,140 fine-grained\ntasks. To evaluate LLMs rigorously, each task encompasses 5.6 test cases with\nan average branch coverage of 99%. In addition, we propose a\nnatural-language-oriented variant of BigCodeBench, BigCodeBench-Instruct, that\nautomatically transforms the original docstrings into short instructions only\nwith essential information. Our extensive evaluation of 60 LLMs shows that LLMs\nare not yet capable of following complex instructions to use function calls\nprecisely, with scores up to 60%, significantly lower than the human\nperformance of 97%. The results underscore the need for further advancements in\nthis area.\n","authors":["Terry Yue Zhuo","Minh Chien Vu","Jenny Chim","Han Hu","Wenhao Yu","Ratnadira Widyasari","Imam Nur Bani Yusuf","Haolan Zhan","Junda He","Indraneil Paul","Simon Brunner","Chen Gong","Thong Hoang","Armel Randy Zebaze","Xiaoheng Hong","Wen-Ding Li","Jean Kaddour","Ming Xu","Zhihan Zhang","Prateek Yadav","Naman Jain","Alex Gu","Zhoujun Cheng","Jiawei Liu","Qian Liu","Zijian Wang","David Lo","Binyuan Hui","Niklas Muennighoff","Daniel Fried","Xiaoning Du","Harm de Vries","Leandro Von Werra"],"pdf_url":"https://arxiv.org/pdf/2406.15877v3.pdf","comment":"44 pages, 14 figures, 7 tables, built with love by the BigCode\n  community :)"},{"id":"http://arxiv.org/abs/2309.02233v3","updated":"2024-10-07T17:21:45Z","published":"2023-09-05T13:39:38Z","title":"Augmenting Black-box LLMs with Medical Textbooks for Biomedical Question\n  Answering (Published in Findings of EMNLP 2024)","summary":"  Large-scale language models (LLMs) like ChatGPT have demonstrated impressive\nabilities in generating responses based on human instructions. However, their\nuse in the medical field can be challenging due to their lack of specific,\nin-depth knowledge. In this study, we present a system called LLMs Augmented\nwith Medical Textbooks (LLM-AMT) designed to enhance the proficiency of LLMs in\nspecialized domains. LLM-AMT integrates authoritative medical textbooks into\nthe LLMs' framework using plug-and-play modules. These modules include a Query\nAugmenter, a Hybrid Textbook Retriever, and a Knowledge Self-Refiner. Together,\nthey incorporate authoritative medical knowledge. Additionally, an LLM Reader\naids in contextual understanding. Our experimental results on three medical QA\ntasks demonstrate that LLMAMT significantly improves response quality, with\naccuracy gains ranging from 11.6% to 16.6%. Notably, with GPT-4-Turbo as the\nbase model, LLM-AMT outperforms the specialized Med-PaLM 2 model pre-trained on\na massive amount of medical corpus by 2-3%. We found that despite being 100x\nsmaller in size, medical textbooks as a retrieval corpus is proven to be a more\neffective knowledge database than Wikipedia in the medical domain, boosting\nperformance by 7.8%-13.7%.\n","authors":["Yubo Wang","Xueguang Ma","Wenhu Chen"],"pdf_url":"https://arxiv.org/pdf/2309.02233v3.pdf","comment":"This version has been accepted and published at EMNLP Findings 2024"},{"id":"http://arxiv.org/abs/2410.05210v1","updated":"2024-10-07T17:16:20Z","published":"2024-10-07T17:16:20Z","title":"Preserving Multi-Modal Capabilities of Pre-trained VLMs for Improving\n  Vision-Linguistic Compositionality","summary":"  In this paper, we propose a new method to enhance compositional understanding\nin pre-trained vision and language models (VLMs) without sacrificing\nperformance in zero-shot multi-modal tasks. Traditional fine-tuning approaches\noften improve compositional reasoning at the cost of degrading multi-modal\ncapabilities, primarily due to the use of global hard negative (HN) loss, which\ncontrasts global representations of images and texts. This global HN loss\npushes HN texts that are highly similar to the original ones, damaging the\nmodel's multi-modal representations. To overcome this limitation, we propose\nFine-grained Selective Calibrated CLIP (FSC-CLIP), which integrates local hard\nnegative loss and selective calibrated regularization. These innovations\nprovide fine-grained negative supervision while preserving the model's\nrepresentational integrity. Our extensive evaluations across diverse benchmarks\nfor both compositionality and multi-modal tasks show that FSC-CLIP not only\nachieves compositionality on par with state-of-the-art models but also retains\nstrong multi-modal capabilities. Code is available at:\nhttps://github.com/ytaek-oh/fsc-clip.\n","authors":["Youngtaek Oh","Jae Won Cho","Dong-Jin Kim","In So Kweon","Junmo Kim"],"pdf_url":"https://arxiv.org/pdf/2410.05210v1.pdf","comment":"EMNLP 2024 (Long, Main). Project page:\n  https://ytaek-oh.github.io/fsc-clip"},{"id":"http://arxiv.org/abs/2410.02844v2","updated":"2024-10-07T17:12:15Z","published":"2024-10-03T13:57:08Z","title":"CAnDOIT: Causal Discovery with Observational and Interventional Data\n  from Time-Series","summary":"  The study of cause-and-effect is of the utmost importance in many branches of\nscience, but also for many practical applications of intelligent systems. In\nparticular, identifying causal relationships in situations that include hidden\nfactors is a major challenge for methods that rely solely on observational data\nfor building causal models. This paper proposes CAnDOIT, a causal discovery\nmethod to reconstruct causal models using both observational and interventional\ntime-series data. The use of interventional data in the causal analysis is\ncrucial for real-world applications, such as robotics, where the scenario is\nhighly complex and observational data alone are often insufficient to uncover\nthe correct causal structure. Validation of the method is performed initially\non randomly generated synthetic models and subsequently on a well-known\nbenchmark for causal structure learning in a robotic manipulation environment.\nThe experiments demonstrate that the approach can effectively handle data from\ninterventions and exploit them to enhance the accuracy of the causal analysis.\nA Python implementation of CAnDOIT has also been developed and is publicly\navailable on GitHub: https://github.com/lcastri/causalflow.\n","authors":["Luca Castri","Sariah Mghames","Marc Hanheide","Nicola Bellotto"],"pdf_url":"https://arxiv.org/pdf/2410.02844v2.pdf","comment":"Published in Advanced Intelligent Systems"},{"id":"http://arxiv.org/abs/2410.05203v1","updated":"2024-10-07T17:07:21Z","published":"2024-10-07T17:07:21Z","title":"Beyond FVD: Enhanced Evaluation Metrics for Video Generation Quality","summary":"  The Fr\\'echet Video Distance (FVD) is a widely adopted metric for evaluating\nvideo generation distribution quality. However, its effectiveness relies on\ncritical assumptions. Our analysis reveals three significant limitations: (1)\nthe non-Gaussianity of the Inflated 3D Convnet (I3D) feature space; (2) the\ninsensitivity of I3D features to temporal distortions; (3) the impractical\nsample sizes required for reliable estimation. These findings undermine FVD's\nreliability and show that FVD falls short as a standalone metric for video\ngeneration evaluation. After extensive analysis of a wide range of metrics and\nbackbone architectures, we propose JEDi, the JEPA Embedding Distance, based on\nfeatures derived from a Joint Embedding Predictive Architecture, measured using\nMaximum Mean Discrepancy with polynomial kernel. Our experiments on multiple\nopen-source datasets show clear evidence that it is a superior alternative to\nthe widely used FVD metric, requiring only 16% of the samples to reach its\nsteady value, while increasing alignment with human evaluation by 34%, on\naverage.\n","authors":["Ge Ya"," Luo","Gian Favero","Zhi Hao Luo","Alexia Jolicoeur-Martineau","Christopher Pal"],"pdf_url":"https://arxiv.org/pdf/2410.05203v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.05191v1","updated":"2024-10-07T16:49:16Z","published":"2024-10-07T16:49:16Z","title":"LADEV: A Language-Driven Testing and Evaluation Platform for\n  Vision-Language-Action Models in Robotic Manipulation","summary":"  Building on the advancements of Large Language Models (LLMs) and Vision\nLanguage Models (VLMs), recent research has introduced Vision-Language-Action\n(VLA) models as an integrated solution for robotic manipulation tasks. These\nmodels take camera images and natural language task instructions as input and\ndirectly generate control actions for robots to perform specified tasks,\ngreatly improving both decision-making capabilities and interaction with human\nusers. However, the data-driven nature of VLA models, combined with their lack\nof interpretability, makes the assurance of their effectiveness and robustness\na challenging task. This highlights the need for a reliable testing and\nevaluation platform. For this purpose, in this work, we propose LADEV, a\ncomprehensive and efficient platform specifically designed for evaluating VLA\nmodels. We first present a language-driven approach that automatically\ngenerates simulation environments from natural language inputs, mitigating the\nneed for manual adjustments and significantly improving testing efficiency.\nThen, to further assess the influence of language input on the VLA models, we\nimplement a paraphrase mechanism that produces diverse natural language task\ninstructions for testing. Finally, to expedite the evaluation process, we\nintroduce a batch-style method for conducting large-scale testing of VLA\nmodels. Using LADEV, we conducted experiments on several state-of-the-art VLA\nmodels, demonstrating its effectiveness as a tool for evaluating these models.\nOur results showed that LADEV not only enhances testing efficiency but also\nestablishes a solid baseline for evaluating VLA models, paving the way for the\ndevelopment of more intelligent and advanced robotic systems.\n","authors":["Zhijie Wang","Zhehua Zhou","Jiayang Song","Yuheng Huang","Zhan Shu","Lei Ma"],"pdf_url":"https://arxiv.org/pdf/2410.05191v1.pdf","comment":"8 pages, 4 figures"},{"id":"http://arxiv.org/abs/2410.02525v2","updated":"2024-10-07T16:46:05Z","published":"2024-10-03T14:33:34Z","title":"Contextual Document Embeddings","summary":"  Dense document embeddings are central to neural retrieval. The dominant\nparadigm is to train and construct embeddings by running encoders directly on\nindividual documents. In this work, we argue that these embeddings, while\neffective, are implicitly out-of-context for targeted use cases of retrieval,\nand that a contextualized document embedding should take into account both the\ndocument and neighboring documents in context - analogous to contextualized\nword embeddings. We propose two complementary methods for contextualized\ndocument embeddings: first, an alternative contrastive learning objective that\nexplicitly incorporates the document neighbors into the intra-batch contextual\nloss; second, a new contextual architecture that explicitly encodes neighbor\ndocument information into the encoded representation. Results show that both\nmethods achieve better performance than biencoders in several settings, with\ndifferences especially pronounced out-of-domain. We achieve state-of-the-art\nresults on the MTEB benchmark with no hard negative mining, score distillation,\ndataset-specific instructions, intra-GPU example-sharing, or extremely large\nbatch sizes. Our method can be applied to improve performance on any\ncontrastive learning dataset and any biencoder.\n","authors":["John X. Morris","Alexander M. Rush"],"pdf_url":"https://arxiv.org/pdf/2410.02525v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.00099v4","updated":"2024-10-07T16:45:42Z","published":"2024-04-30T18:00:02Z","title":"Creative Beam Search: LLM-as-a-Judge For Improving Response Generation","summary":"  Large language models are revolutionizing several areas, including artificial\ncreativity. However, the process of generation in machines profoundly diverges\nfrom that observed in humans. In particular, machine generation is\ncharacterized by a lack of intentionality and an underlying creative process.\nWe propose a method called Creative Beam Search that uses Diverse Beam Search\nand LLM-as-a-Judge to perform response generation and response validation. The\nresults of a qualitative experiment show how our approach can provide better\noutput than standard sampling techniques. We also show that the response\nvalidation step is a necessary complement to the response generation step.\n","authors":["Giorgio Franceschelli","Mirco Musolesi"],"pdf_url":"https://arxiv.org/pdf/2405.00099v4.pdf","comment":"Presented as a short paper at the 15th International Conference on\n  Computational Creativity (ICCC'24)"},{"id":"http://arxiv.org/abs/2410.05183v1","updated":"2024-10-07T16:42:10Z","published":"2024-10-07T16:42:10Z","title":"Beyond Correlation: Interpretable Evaluation of Machine Translation\n  Metrics","summary":"  Machine Translation (MT) evaluation metrics assess translation quality\nautomatically. Recently, researchers have employed MT metrics for various new\nuse cases, such as data filtering and translation re-ranking. However, most MT\nmetrics return assessments as scalar scores that are difficult to interpret,\nposing a challenge to making informed design choices. Moreover, MT metrics'\ncapabilities have historically been evaluated using correlation with human\njudgment, which, despite its efficacy, falls short of providing intuitive\ninsights into metric performance, especially in terms of new metric use cases.\nTo address these issues, we introduce an interpretable evaluation framework for\nMT metrics. Within this framework, we evaluate metrics in two scenarios that\nserve as proxies for the data filtering and translation re-ranking use cases.\nFurthermore, by measuring the performance of MT metrics using Precision,\nRecall, and F-score, we offer clearer insights into their capabilities than\ncorrelation with human judgments. Finally, we raise concerns regarding the\nreliability of manually curated data following the Direct Assessments+Scalar\nQuality Metrics (DA+SQM) guidelines, reporting a notably low agreement with\nMultidimensional Quality Metrics (MQM) annotations.\n","authors":["Stefano Perrella","Lorenzo Proietti","Pere-Lluís Huguet Cabot","Edoardo Barba","Roberto Navigli"],"pdf_url":"https://arxiv.org/pdf/2410.05183v1.pdf","comment":"Accepted at EMNLP 2024 Main Conference. 26 pages"},{"id":"http://arxiv.org/abs/2410.05182v1","updated":"2024-10-07T16:41:45Z","published":"2024-10-07T16:41:45Z","title":"MARs: Multi-view Attention Regularizations for Patch-based Feature\n  Recognition of Space Terrain","summary":"  The visual detection and tracking of surface terrain is required for\nspacecraft to safely land on or navigate within close proximity to celestial\nobjects. Current approaches rely on template matching with pre-gathered\npatch-based features, which are expensive to obtain and a limiting factor in\nperceptual capability. While recent literature has focused on in-situ detection\nmethods to enhance navigation and operational autonomy, robust description is\nstill needed. In this work, we explore metric learning as the lightweight\nfeature description mechanism and find that current solutions fail to address\ninter-class similarity and multi-view observational geometry. We attribute this\nto the view-unaware attention mechanism and introduce Multi-view Attention\nRegularizations (MARs) to constrain the channel and spatial attention across\nmultiple feature views, regularizing the what and where of attention focus. We\nthoroughly analyze many modern metric learning losses with and without MARs and\ndemonstrate improved terrain-feature recognition performance by upwards of 85%.\nWe additionally introduce the Luna-1 dataset, consisting of Moon crater\nlandmarks and reference navigation frames from NASA mission data to support\nfuture research in this difficult task. Luna-1 and source code are publicly\navailable at https://droneslab.github.io/mars/.\n","authors":["Timothy Chase Jr","Karthik Dantu"],"pdf_url":"https://arxiv.org/pdf/2410.05182v1.pdf","comment":"ECCV 2024. Project page available at\n  https://droneslab.github.io/mars/"},{"id":"http://arxiv.org/abs/2407.13493v3","updated":"2024-10-07T16:40:25Z","published":"2024-07-18T13:23:16Z","title":"Training Foundation Models as Data Compression: On Information, Model\n  Weights and Copyright Law","summary":"  The training process of foundation models as for other classes of deep\nlearning systems is based on minimizing the reconstruction error over a\ntraining set. For this reason, they are susceptible to the memorization and\nsubsequent reproduction of training samples. In this paper, we introduce a\ntraining-as-compressing perspective, wherein the model's weights embody a\ncompressed representation of the training data. From a copyright standpoint,\nthis point of view implies that the weights could be considered a reproduction\nor a derivative work of a potentially protected set of works. We investigate\nthe technical and legal challenges that emerge from this framing of the\ncopyright of outputs generated by foundation models, including their\nimplications for practitioners and researchers. We demonstrate that adopting an\ninformation-centric approach to the problem presents a promising pathway for\ntackling these emerging complex legal issues.\n","authors":["Giorgio Franceschelli","Claudia Cevenini","Mirco Musolesi"],"pdf_url":"https://arxiv.org/pdf/2407.13493v3.pdf","comment":"Spotlight presentation at GenLaw'24, see\n  https://www.genlaw.org/2024-icml-papers#training-foundation-models-as-data-compression-on-information-model-weights-and-copyright-law"},{"id":"http://arxiv.org/abs/2410.02381v2","updated":"2024-10-07T16:39:24Z","published":"2024-10-03T11:01:25Z","title":"MetaMetrics: Calibrating Metrics For Generation Tasks Using Human\n  Preferences","summary":"  Understanding the quality of a performance evaluation metric is crucial for\nensuring that model outputs align with human preferences. However, it remains\nunclear how well each metric captures the diverse aspects of these preferences,\nas metrics often excel in one particular area but not across all dimensions. To\naddress this, it is essential to systematically calibrate metrics to specific\naspects of human preference, catering to the unique characteristics of each\naspect. We introduce MetaMetrics, a calibrated meta-metric designed to evaluate\ngeneration tasks across different modalities in a supervised manner.\nMetaMetrics optimizes the combination of existing metrics to enhance their\nalignment with human preferences. Our metric demonstrates flexibility and\neffectiveness in both language and vision downstream tasks, showing significant\nbenefits across various multilingual and multi-domain scenarios. MetaMetrics\naligns closely with human preferences and is highly extendable and easily\nintegrable into any application. This makes MetaMetrics a powerful tool for\nimproving the evaluation of generation tasks, ensuring that metrics are more\nrepresentative of human judgment across diverse contexts.\n","authors":["Genta Indra Winata","David Anugraha","Lucky Susanto","Garry Kuwanto","Derry Tanti Wijaya"],"pdf_url":"https://arxiv.org/pdf/2410.02381v2.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2402.14901v2","updated":"2024-10-07T16:38:35Z","published":"2024-02-22T18:09:33Z","title":"A Usage-centric Take on Intent Understanding in E-Commerce","summary":"  Identifying and understanding user intents is a pivotal task for E-Commerce.\nDespite its essential role in product recommendation and business user\nprofiling analysis, intent understanding has not been consistently defined or\naccurately benchmarked. In this paper, we focus on predicative user intents as\n\"how a customer uses a product\", and pose intent understanding as a natural\nlanguage reasoning task, independent of product ontologies. We identify two\nweaknesses of FolkScope, the SOTA E-Commerce Intent Knowledge Graph:\ncategory-rigidity and property-ambiguity. They limit its ability to strongly\nalign user intents with products having the most desirable property, and to\nrecommend useful products across diverse categories. Following these\nobservations, we introduce a Product Recovery Benchmark featuring a novel\nevaluation framework and an example dataset. We further validate the above\nFolkScope weaknesses on this benchmark. Our code and dataset are available at\nhttps://github.com/stayones/Usgae-Centric-Intent-Understanding.\n","authors":["Wendi Zhou","Tianyi Li","Pavlos Vougiouklis","Mark Steedman","Jeff Z. Pan"],"pdf_url":"https://arxiv.org/pdf/2402.14901v2.pdf","comment":"Acepted by EMNLP 2024 main"},{"id":"http://arxiv.org/abs/2404.02151v3","updated":"2024-10-07T16:35:15Z","published":"2024-04-02T17:58:27Z","title":"Jailbreaking Leading Safety-Aligned LLMs with Simple Adaptive Attacks","summary":"  We show that even the most recent safety-aligned LLMs are not robust to\nsimple adaptive jailbreaking attacks. First, we demonstrate how to successfully\nleverage access to logprobs for jailbreaking: we initially design an\nadversarial prompt template (sometimes adapted to the target LLM), and then we\napply random search on a suffix to maximize a target logprob (e.g., of the\ntoken \"Sure\"), potentially with multiple restarts. In this way, we achieve 100%\nattack success rate -- according to GPT-4 as a judge -- on Vicuna-13B,\nMistral-7B, Phi-3-Mini, Nemotron-4-340B, Llama-2-Chat-7B/13B/70B,\nLlama-3-Instruct-8B, Gemma-7B, GPT-3.5, GPT-4o, and R2D2 from HarmBench that\nwas adversarially trained against the GCG attack. We also show how to jailbreak\nall Claude models -- that do not expose logprobs -- via either a transfer or\nprefilling attack with a 100% success rate. In addition, we show how to use\nrandom search on a restricted set of tokens for finding trojan strings in\npoisoned models -- a task that shares many similarities with jailbreaking --\nwhich is the algorithm that brought us the first place in the SaTML'24 Trojan\nDetection Competition. The common theme behind these attacks is that adaptivity\nis crucial: different models are vulnerable to different prompting templates\n(e.g., R2D2 is very sensitive to in-context learning prompts), some models have\nunique vulnerabilities based on their APIs (e.g., prefilling for Claude), and\nin some settings, it is crucial to restrict the token search space based on\nprior knowledge (e.g., for trojan detection). For reproducibility purposes, we\nprovide the code, logs, and jailbreak artifacts in the JailbreakBench format at\nhttps://github.com/tml-epfl/llm-adaptive-attacks.\n","authors":["Maksym Andriushchenko","Francesco Croce","Nicolas Flammarion"],"pdf_url":"https://arxiv.org/pdf/2404.02151v3.pdf","comment":"Updates in the v3: GPT-4o and Claude 3.5 Sonnet results, improved\n  writing. Updates in the v2: more models (Llama3, Phi-3, Nemotron-4-340B),\n  jailbreak artifacts for all attacks are available, evaluation with different\n  judges (Llama-3-70B and Llama Guard 2), more experiments (convergence plots\n  over iterations, ablation on the suffix length for random search), examples\n  of jailbroken generation"},{"id":"http://arxiv.org/abs/2310.09675v2","updated":"2024-10-07T16:28:52Z","published":"2023-10-14T22:24:26Z","title":"Efficient Model-Agnostic Multi-Group Equivariant Networks","summary":"  Constructing model-agnostic group equivariant networks, such as equitune\n(Basu et al., 2023b) and its generalizations (Kim et al., 2023), can be\ncomputationally expensive for large product groups. We address this problem by\nproviding efficient model-agnostic equivariant designs for two related\nproblems: one where the network has multiple inputs each with potentially\ndifferent groups acting on them, and another where there is a single input but\nthe group acting on it is a large product group. For the first design, we\ninitially consider a linear model and characterize the entire equivariant space\nthat satisfies this constraint. This characterization gives rise to a novel\nfusion layer between different channels that satisfies an invariance-symmetry\n(IS) constraint, which we call an IS layer. We then extend this design beyond\nlinear models, similar to equitune, consisting of equivariant and IS layers. We\nalso show that the IS layer is a universal approximator of invariant-symmetric\nfunctions. Inspired by the first design, we use the notion of the IS property\nto design a second efficient model-agnostic equivariant design for large\nproduct groups acting on a single input. For the first design, we provide\nexperiments on multi-image classification where each view is transformed\nindependently with transformations such as rotations. We find equivariant\nmodels are robust to such transformations and perform competitively otherwise.\nFor the second design, we consider three applications: language\ncompositionality on the SCAN dataset to product groups; fairness in natural\nlanguage generation from GPT-2 to address intersectionality; and robust\nzero-shot image classification with CLIP. Overall, our methods are simple and\ngeneral, competitive with equitune and its variants, while also being\ncomputationally more efficient.\n","authors":["Razan Baltaji","Sourya Basu","Lav R. Varshney"],"pdf_url":"https://arxiv.org/pdf/2310.09675v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10054v2","updated":"2024-10-07T16:26:00Z","published":"2023-11-16T17:48:55Z","title":"When \"A Helpful Assistant\" Is Not Really Helpful: Personas in System\n  Prompts Do Not Improve Performances of Large Language Models","summary":"  Prompting serves as the major way humans interact with Large Language Models\n(LLM). Commercial AI systems commonly define the role of the LLM in system\nprompts. For example, ChatGPT uses \"You are a helpful assistant\" as part of its\ndefault system prompt. Despite current practices of adding personas to system\nprompts, it remains unclear how different personas affect a model's performance\non objective tasks. In this study, we present a systematic evaluation of\npersonas in system prompts. We curate a list of 162 roles covering 6 types of\ninterpersonal relationships and 8 domains of expertise. Through extensive\nanalysis of 4 popular families of LLMs and 2,410 factual questions, we\ndemonstrate that adding personas in system prompts does not improve model\nperformance across a range of questions compared to the control setting where\nno persona is added. Nevertheless, further analysis suggests that the gender,\ntype, and domain of the persona can all influence the resulting prediction\naccuracies. We further experimented with a list of persona search strategies\nand found that, while aggregating results from the best persona for each\nquestion significantly improves prediction accuracy, automatically identifying\nthe best persona is challenging, with predictions often performing no better\nthan random selection. Overall, our findings suggest that while adding a\npersona may lead to performance gains in certain settings, the effect of each\npersona can be largely random. Code and data are available at\nhttps://github.com/Jiaxin-Pei/Prompting-with-Social-Roles.\n","authors":["Mingqian Zheng","Jiaxin Pei","Lajanugen Logeswaran","Moontae Lee","David Jurgens"],"pdf_url":"https://arxiv.org/pdf/2311.10054v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.10207v2","updated":"2024-10-07T16:25:34Z","published":"2024-07-14T14:01:38Z","title":"Learning to Steer Markovian Agents under Model Uncertainty","summary":"  Designing incentives for an adapting population is a ubiquitous problem in a\nwide array of economic applications and beyond. In this work, we study how to\ndesign additional rewards to steer multi-agent systems towards desired policies\n\\emph{without} prior knowledge of the agents' underlying learning dynamics.\nMotivated by the limitation of existing works, we consider a new and general\ncategory of learning dynamics called \\emph{Markovian agents}. We introduce a\nmodel-based non-episodic Reinforcement Learning (RL) formulation for our\nsteering problem. Importantly, we focus on learning a \\emph{history-dependent}\nsteering strategy to handle the inherent model uncertainty about the agents'\nlearning dynamics. We introduce a novel objective function to encode the\ndesiderata of achieving a good steering outcome with reasonable cost.\nTheoretically, we identify conditions for the existence of steering strategies\nto guide agents to the desired policies. Complementing our theoretical\ncontributions, we provide empirical algorithms to approximately solve our\nobjective, which effectively tackles the challenge in learning\nhistory-dependent strategies. We demonstrate the efficacy of our algorithms\nthrough empirical evaluations.\n","authors":["Jiawei Huang","Vinzenz Thoma","Zebang Shen","Heinrich H. Nax","Niao He"],"pdf_url":"https://arxiv.org/pdf/2407.10207v2.pdf","comment":"34 Pages"},{"id":"http://arxiv.org/abs/2410.02902v2","updated":"2024-10-07T16:25:04Z","published":"2024-10-03T18:48:38Z","title":"Better Instruction-Following Through Minimum Bayes Risk","summary":"  General-purpose LLM judges capable of human-level evaluation provide not only\na scalable and accurate way of evaluating instruction-following LLMs but also\nnew avenues for supervising and improving their performance. One promising way\nof leveraging LLM judges for supervision is through Minimum Bayes Risk (MBR)\ndecoding, which uses a reference-based evaluator to select a high-quality\noutput from amongst a set of candidate outputs. In the first part of this work,\nwe explore using MBR decoding as a method for improving the test-time\nperformance of instruction-following LLMs. We find that MBR decoding with\nreference-based LLM judges substantially improves over greedy decoding,\nbest-of-N decoding with reference-free judges and MBR decoding with lexical and\nembedding-based metrics on AlpacaEval and MT-Bench. These gains are consistent\nacross LLMs with up to 70B parameters, demonstrating that smaller LLM judges\ncan be used to supervise much larger LLMs. Then, seeking to retain the\nimprovements from MBR decoding while mitigating additional test-time costs, we\nexplore iterative self-training on MBR-decoded outputs. We find that\nself-training using Direct Preference Optimisation leads to significant\nperformance gains, such that the self-trained models with greedy decoding\ngenerally match and sometimes exceed the performance of their base models with\nMBR decoding.\n","authors":["Ian Wu","Patrick Fernandes","Amanda Bertsch","Seungone Kim","Sina Pakazad","Graham Neubig"],"pdf_url":"https://arxiv.org/pdf/2410.02902v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18681v2","updated":"2024-10-07T16:25:02Z","published":"2024-03-27T15:24:54Z","title":"Deep Fusion: Capturing Dependencies in Contrastive Learning via\n  Transformer Projection Heads","summary":"  Contrastive Learning (CL) has emerged as a powerful method for training\nfeature extraction models using unlabeled data. Recent studies suggest that\nincorporating a linear projection head post-backbone significantly enhances\nmodel performance. In this work, we investigate the use of a transformer model\nas a projection head within the CL framework, aiming to exploit the\ntransformer's capacity for capturing long-range dependencies across embeddings\nto further improve performance. Our key contributions are fourfold: First, we\nintroduce a novel application of transformers in the projection head role for\ncontrastive learning, marking the first endeavor of its kind. Second, our\nexperiments reveal a compelling \"Deep Fusion\" phenomenon where the attention\nmechanism progressively captures the correct relational dependencies among\nsamples from the same class in deeper layers. Third, we provide a theoretical\nframework that explains and supports this \"Deep Fusion\" behavior. Finally, we\ndemonstrate through experimental results that our model achieves superior\nperformance compared to the existing approach of using a feed-forward layer.\n","authors":["Huanran Li","Daniel Pimentel-Alarcón"],"pdf_url":"https://arxiv.org/pdf/2403.18681v2.pdf","comment":"10 pages, 2 figures"},{"id":"http://arxiv.org/abs/2410.05167v1","updated":"2024-10-07T16:24:18Z","published":"2024-10-07T16:24:18Z","title":"Presto! Distilling Steps and Layers for Accelerating Music Generation","summary":"  Despite advances in diffusion-based text-to-music (TTM) methods, efficient,\nhigh-quality generation remains a challenge. We introduce Presto!, an approach\nto inference acceleration for score-based diffusion transformers via reducing\nboth sampling steps and cost per step. To reduce steps, we develop a new\nscore-based distribution matching distillation (DMD) method for the EDM-family\nof diffusion models, the first GAN-based distillation method for TTM. To reduce\nthe cost per step, we develop a simple, but powerful improvement to a recent\nlayer distillation method that improves learning via better preserving hidden\nstate variance. Finally, we combine our step and layer distillation methods\ntogether for a dual-faceted approach. We evaluate our step and layer\ndistillation methods independently and show each yield best-in-class\nperformance. Our combined distillation method can generate high-quality outputs\nwith improved diversity, accelerating our base model by 10-18x (230/435ms\nlatency for 32 second mono/stereo 44.1kHz, 15x faster than comparable SOTA) --\nthe fastest high-quality TTM to our knowledge. Sound examples can be found at\nhttps://presto-music.github.io/web/.\n","authors":["Zachary Novack","Ge Zhu","Jonah Casebeer","Julian McAuley","Taylor Berg-Kirkpatrick","Nicholas J. Bryan"],"pdf_url":"https://arxiv.org/pdf/2410.05167v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.05160v1","updated":"2024-10-07T16:14:05Z","published":"2024-10-07T16:14:05Z","title":"VLM2Vec: Training Vision-Language Models for Massive Multimodal\n  Embedding Tasks","summary":"  Embedding models have been crucial in enabling various downstream tasks such\nas semantic similarity, information retrieval, and clustering. Recently, there\nhas been a surge of interest in developing universal text embedding models that\ncan generalize across tasks (e.g., MTEB). However, progress in learning\nuniversal multimodal embedding models has been relatively slow despite their\nimportance. In this work, we aim to explore the potential for building\nuniversal embeddings capable of handling a wide range of downstream tasks. Our\ncontributions are twofold: (1) MMEB (Massive Multimodal Embedding Benchmark),\nwhich covers 4 meta-tasks (i.e. classification, visual question answering,\nmultimodal retrieval, and visual grounding) and 36 datasets, including 20\ntraining and 16 evaluation datasets, and (2) VLM2Vec (Vision-Language Model ->\nVector), a contrastive training framework that converts any state-of-the-art\nvision-language model into an embedding model via training on MMEB. Unlike\nprevious models such as CLIP and BLIP, VLM2Vec can process any combination of\nimages and text to generate a fixed-dimensional vector based on task\ninstructions. We build a series of VLM2Vec models on Phi-3.5-V and evaluate\nthem on MMEB's evaluation split. Our results show that \\model achieves an\nabsolute average improvement of 10% to 20% over existing multimodal embedding\nmodels on both in-distribution and out-of-distribution datasets in MMEB.\n","authors":["Ziyan Jiang","Rui Meng","Xinyi Yang","Semih Yavuz","Yingbo Zhou","Wenhu Chen"],"pdf_url":"https://arxiv.org/pdf/2410.05160v1.pdf","comment":"Technical Report"},{"id":"http://arxiv.org/abs/2403.18699v2","updated":"2024-10-07T16:07:23Z","published":"2024-03-27T15:48:16Z","title":"Preventing Collapse in Contrastive Learning with Orthonormal Prototypes\n  (CLOP)","summary":"  Contrastive learning has emerged as a powerful method in deep learning,\nexcelling at learning effective representations through contrasting samples\nfrom different distributions. However, neural collapse, where embeddings\nconverge into a lower-dimensional space, poses a significant challenge,\nespecially in semi-supervised and self-supervised setups. In this paper, we\nfirst theoretically analyze the effect of large learning rates on contrastive\nlosses that solely rely on the cosine similarity metric, and derive a\ntheoretical bound to mitigate this collapse. {Building on these insights, we\npropose CLOP, a novel semi-supervised loss function designed to prevent neural\ncollapse by promoting the formation of orthogonal linear subspaces among class\nembeddings.} Unlike prior approaches that enforce a simplex ETF structure, CLOP\nfocuses on subspace separation, leading to more distinguishable embeddings.\nThrough extensive experiments on real and synthetic datasets, we demonstrate\nthat CLOP enhances performance, providing greater stability across different\nlearning rates and batch sizes.\n","authors":["Huanran Li","Manh Nguyen","Daniel Pimentel-Alarcón"],"pdf_url":"https://arxiv.org/pdf/2403.18699v2.pdf","comment":"17 pages, 8 figures"},{"id":"http://arxiv.org/abs/2410.05146v1","updated":"2024-10-07T15:58:03Z","published":"2024-10-07T15:58:03Z","title":"CTC-GMM: CTC guided modality matching for fast and accurate streaming\n  speech translation","summary":"  Models for streaming speech translation (ST) can achieve high accuracy and\nlow latency if they're developed with vast amounts of paired audio in the\nsource language and written text in the target language. Yet, these text labels\nfor the target language are often pseudo labels due to the prohibitive cost of\nmanual ST data labeling. In this paper, we introduce a methodology named\nConnectionist Temporal Classification guided modality matching (CTC-GMM) that\nenhances the streaming ST model by leveraging extensive machine translation\n(MT) text data. This technique employs CTC to compress the speech sequence into\na compact embedding sequence that matches the corresponding text sequence,\nallowing us to utilize matched {source-target} language text pairs from the MT\ncorpora to refine the streaming ST model further. Our evaluations with FLEURS\nand CoVoST2 show that the CTC-GMM approach can increase translation accuracy\nrelatively by 13.9% and 6.4% respectively, while also boosting decoding speed\nby 59.7% on GPU.\n","authors":["Rui Zhao","Jinyu Li","Ruchao Fan","Matt Post"],"pdf_url":"https://arxiv.org/pdf/2410.05146v1.pdf","comment":"Accepted by IEEE Spoken Language Technology Workshop (SLT 2024)"},{"id":"http://arxiv.org/abs/2407.10930v2","updated":"2024-10-07T15:52:48Z","published":"2024-07-15T17:30:31Z","title":"Fine-Tuning and Prompt Optimization: Two Great Steps that Work Better\n  Together","summary":"  Natural Language Processing (NLP) systems are increasingly taking the form of\nsophisticated modular pipelines, e.g., Retrieval Augmented Generation (RAG),\nwhere each module may involve a distinct Language Model (LM) and an associated\nprompt template. These compound systems often lack intermediate labels or\ngradient flow to optimize each module, making their end-to-end optimization\nchallenging. Here we seek strategies to optimize both the module-level LM\nweights and the associated prompt templates of such systems to maximize a\ndownstream task metric. We propose for the first time combining the weight and\nprompt optimization strategies to optimize a modular LM pipeline by alternating\nbetween the two to get the same LM to teach itself. In experiments with\nmulti-hop QA, mathematical reasoning, and feature-based classification using\nmistral-7b, llama-2-7b, and llama-3-8b, these BetterTogether strategies\noptimizing the weights and prompts of a pipeline together outperform directly\noptimizing weights alone and prompts alone by up to 60% and 6%, respectively,\non average across LMs and tasks. BetterTogether optimizer is released in DSPy\nat http://dspy.ai\n","authors":["Dilara Soylu","Christopher Potts","Omar Khattab"],"pdf_url":"https://arxiv.org/pdf/2407.10930v2.pdf","comment":"EMNLP 2024"},{"id":"http://arxiv.org/abs/2410.05130v1","updated":"2024-10-07T15:34:14Z","published":"2024-10-07T15:34:14Z","title":"Scalable and Accurate Graph Reasoning with LLM-based Multi-Agents","summary":"  Recent research has explored the use of Large Language Models (LLMs) for\ntackling complex graph reasoning tasks. However, due to the intricacies of\ngraph structures and the inherent limitations of LLMs in handling long text,\ncurrent approaches often fail to deliver satisfactory accuracy, even on\nsmall-scale graphs and simple tasks. To address these challenges, we introduce\nGraphAgent-Reasoner, a fine-tuning-free framework that utilizes a multi-agent\ncollaboration strategy for explicit and precise graph reasoning. Inspired by\ndistributed graph computation theory, our framework decomposes graph problems\ninto smaller, node-centric tasks that are distributed among multiple agents.\nThe agents collaborate to solve the overall problem, significantly reducing the\namount of information and complexity handled by a single LLM, thus enhancing\nthe accuracy of graph reasoning. By simply increasing the number of agents,\nGraphAgent-Reasoner can efficiently scale to accommodate larger graphs with\nover 1,000 nodes. Evaluated on the GraphInstruct dataset, our framework\ndemonstrates near-perfect accuracy on polynomial-time graph reasoning tasks,\nsignificantly outperforming the best available models, both closed-source and\nfine-tuned open-source variants. Our framework also demonstrates the capability\nto handle real-world graph reasoning applications such as webpage importance\nanalysis.\n","authors":["Yuwei Hu","Runlin Lei","Xinyi Huang","Zhewei Wei","Yongchao Liu"],"pdf_url":"https://arxiv.org/pdf/2410.05130v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16424v2","updated":"2024-10-07T15:33:37Z","published":"2024-06-24T08:18:19Z","title":"Memory-Enhanced Neural Solvers for Efficient Adaptation in Combinatorial\n  Optimization","summary":"  Combinatorial Optimization is crucial to numerous real-world applications,\nyet still presents challenges due to its (NP-)hard nature. Amongst existing\napproaches, heuristics often offer the best trade-off between quality and\nscalability, making them suitable for industrial use. While Reinforcement\nLearning (RL) offers a flexible framework for designing heuristics, its\nadoption over handcrafted heuristics remains incomplete within industrial\nsolvers. Existing learned methods still lack the ability to adapt to specific\ninstances and fully leverage the available computational budget. The current\nbest methods either rely on a collection of pre-trained policies, or on\ndata-inefficient fine-tuning; hence failing to fully utilize newly available\ninformation within the constraints of the budget. In response, we present\nMEMENTO, an approach that leverages memory to improve the adaptation of neural\nsolvers at inference time. MEMENTO enables updating the action distribution\ndynamically based on the outcome of previous decisions. We validate its\neffectiveness on benchmark problems, in particular Traveling Salesman and\nCapacitated Vehicle Routing, demonstrating its superiority over tree-search and\npolicy-gradient fine-tuning; and showing it can be zero-shot combined with\ndiversity-based solvers. We successfully train all RL auto-regressive solvers\non large instances, and show that MEMENTO can scale and is data-efficient.\nOverall, MEMENTO enables to push the state-of-the-art on 11 out of 12 evaluated\ntasks.\n","authors":["Felix Chalumeau","Refiloe Shabe","Noah De Nicola","Arnu Pretorius","Thomas D. Barrett","Nathan Grinsztajn"],"pdf_url":"https://arxiv.org/pdf/2406.16424v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.05127v1","updated":"2024-10-07T15:28:18Z","published":"2024-10-07T15:28:18Z","title":"Last Iterate Convergence in Monotone Mean Field Games","summary":"  Mean Field Game (MFG) is a framework utilized to model and approximate the\nbehavior of a large number of agents, and the computation of equilibria in MFG\nhas been a subject of interest. Despite the proposal of methods to approximate\nthe equilibria, algorithms where the sequence of updated policy converges to\nequilibrium, specifically those exhibiting last-iterate convergence, have been\nlimited. We propose the use of a simple, proximal-point-type algorithm to\ncompute equilibria for MFGs. Subsequently, we provide the first last-iterate\nconvergence guarantee under the Lasry--Lions-type monotonicity condition. We\nfurther employ the Mirror Descent algorithm for the regularized MFG to\nefficiently approximate the update rules of the proximal point method for MFGs.\nWe demonstrate that the algorithm can approximate with an accuracy of\n$\\varepsilon$ after $\\mathcal{O}({\\log(1/\\varepsilon)})$ iterations. This\nresearch offers a tractable approach for large-scale and large-population\ngames.\n","authors":["Noboru Isobe","Kenshi Abe","Kaito Ariu"],"pdf_url":"https://arxiv.org/pdf/2410.05127v1.pdf","comment":"Under review, 25 pages, 2 figures"},{"id":"http://arxiv.org/abs/2410.00428v2","updated":"2024-10-07T15:24:10Z","published":"2024-10-01T06:23:17Z","title":"LayerKV: Optimizing Large Language Model Serving with Layer-wise KV\n  Cache Management","summary":"  The expanding context windows in large language models (LLMs) have greatly\nenhanced their capabilities in various applications, but they also introduce\nsignificant challenges in maintaining low latency, particularly in Time to\nFirst Token (TTFT). This paper identifies that the sharp rise in TTFT as\ncontext length increases is predominantly driven by queuing delays, which are\ncaused by the growing demands for GPU Key-Value (KV) cache allocation clashing\nwith the limited availability of KV cache blocks. To address this issue, we\npropose LayerKV, a simple yet effective plug-in method that effectively reduces\nTTFT without requiring additional hardware or compromising output performance,\nwhile seamlessly integrating with existing parallelism strategies and\nscheduling techniques. Specifically, LayerKV introduces layer-wise KV block\nallocation, management, and offloading for fine-grained control over system\nmemory, coupled with an SLO-aware scheduler to optimize overall Service Level\nObjectives (SLOs). Comprehensive evaluations on representative models, ranging\nfrom 7B to 70B parameters, across various GPU configurations, demonstrate that\nLayerKV improves TTFT latency up to 69x and reduces SLO violation rates by\n28.7%, significantly enhancing the user experience.\n","authors":["Yi Xiong","Hao Wu","Changxu Shao","Ziqing Wang","Rui Zhang","Yuhong Guo","Junping Zhao","Ke Zhang","Zhenxuan Pan"],"pdf_url":"https://arxiv.org/pdf/2410.00428v2.pdf","comment":"11 pages, 7 figures, 1 table"},{"id":"http://arxiv.org/abs/2410.05116v1","updated":"2024-10-07T15:12:01Z","published":"2024-10-07T15:12:01Z","title":"Human-Feedback Efficient Reinforcement Learning for Online Diffusion\n  Model Finetuning","summary":"  Controllable generation through Stable Diffusion (SD) fine-tuning aims to\nimprove fidelity, safety, and alignment with human guidance. Existing\nreinforcement learning from human feedback methods usually rely on predefined\nheuristic reward functions or pretrained reward models built on large-scale\ndatasets, limiting their applicability to scenarios where collecting such data\nis costly or difficult. To effectively and efficiently utilize human feedback,\nwe develop a framework, HERO, which leverages online human feedback collected\non the fly during model learning. Specifically, HERO features two key\nmechanisms: (1) Feedback-Aligned Representation Learning, an online training\nmethod that captures human feedback and provides informative learning signals\nfor fine-tuning, and (2) Feedback-Guided Image Generation, which involves\ngenerating images from SD's refined initialization samples, enabling faster\nconvergence towards the evaluator's intent. We demonstrate that HERO is 4x more\nefficient in online feedback for body part anomaly correction compared to the\nbest existing method. Additionally, experiments show that HERO can effectively\nhandle tasks like reasoning, counting, personalization, and reducing NSFW\ncontent with only 0.5K online feedback.\n","authors":["Ayano Hiranaka","Shang-Fu Chen","Chieh-Hsin Lai","Dongjun Kim","Naoki Murata","Takashi Shibuya","Wei-Hsiang Liao","Shao-Hua Sun","Yuki Mitsufuji"],"pdf_url":"https://arxiv.org/pdf/2410.05116v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.05115v1","updated":"2024-10-07T15:10:54Z","published":"2024-10-07T15:10:54Z","title":"AlphaRouter: Quantum Circuit Routing with Reinforcement Learning and\n  Tree Search","summary":"  Quantum computers have the potential to outperform classical computers in\nimportant tasks such as optimization and number factoring. They are\ncharacterized by limited connectivity, which necessitates the routing of their\ncomputational bits, known as qubits, to specific locations during program\nexecution to carry out quantum operations. Traditionally, the NP-hard\noptimization problem of minimizing the routing overhead has been addressed\nthrough sub-optimal rule-based routing techniques with inherent human biases\nembedded within the cost function design. This paper introduces a solution that\nintegrates Monte Carlo Tree Search (MCTS) with Reinforcement Learning (RL). Our\nRL-based router, called AlphaRouter, outperforms the current state-of-the-art\nrouting methods and generates quantum programs with up to $20\\%$ less routing\noverhead, thus significantly enhancing the overall efficiency and feasibility\nof quantum computing.\n","authors":["Wei Tang","Yiheng Duan","Yaroslav Kharkov","Rasool Fakoor","Eric Kessler","Yunong Shi"],"pdf_url":"https://arxiv.org/pdf/2410.05115v1.pdf","comment":"11 pages, 11 figures, International Conference on Quantum Computing\n  and Engineering - QCE24"},{"id":"http://arxiv.org/abs/2405.14327v4","updated":"2024-10-07T15:10:03Z","published":"2024-05-23T08:57:10Z","title":"Autoregressive Image Diffusion: Generation of Image Sequence and\n  Application in MRI","summary":"  Magnetic resonance imaging (MRI) is a widely used non-invasive imaging\nmodality. However, a persistent challenge lies in balancing image quality with\nimaging speed. This trade-off is primarily constrained by k-space measurements,\nwhich traverse specific trajectories in the spatial Fourier domain (k-space).\nThese measurements are often undersampled to shorten acquisition times,\nresulting in image artifacts and compromised quality. Generative models learn\nimage distributions and can be used to reconstruct high-quality images from\nundersampled k-space data. In this work, we present the autoregressive image\ndiffusion (AID) model for image sequences and use it to sample the posterior\nfor accelerated MRI reconstruction. The algorithm incorporates both\nundersampled k-space and pre-existing information. Models trained with fastMRI\ndataset are evaluated comprehensively. The results show that the AID model can\nrobustly generate sequentially coherent image sequences. In MRI applications,\nthe AID can outperform the standard diffusion model and reduce hallucinations,\ndue to the learned inter-image dependencies. The project code is available at\nhttps://github.com/mrirecon/aid.\n","authors":["Guanxiong Luo","Shoujin Huang","Martin Uecker"],"pdf_url":"https://arxiv.org/pdf/2405.14327v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.05114v1","updated":"2024-10-07T15:09:50Z","published":"2024-10-07T15:09:50Z","title":"Synthetic Generation of Dermatoscopic Images with GAN and Closed-Form\n  Factorization","summary":"  In the realm of dermatological diagnoses, where the analysis of dermatoscopic\nand microscopic skin lesion images is pivotal for the accurate and early\ndetection of various medical conditions, the costs associated with creating\ndiverse and high-quality annotated datasets have hampered the accuracy and\ngeneralizability of machine learning models. We propose an innovative\nunsupervised augmentation solution that harnesses Generative Adversarial\nNetwork (GAN) based models and associated techniques over their latent space to\ngenerate controlled semiautomatically-discovered semantic variations in\ndermatoscopic images. We created synthetic images to incorporate the semantic\nvariations and augmented the training data with these images. With this\napproach, we were able to increase the performance of machine learning models\nand set a new benchmark amongst non-ensemble based models in skin lesion\nclassification on the HAM10000 dataset; and used the observed analytics and\ngenerated models for detailed studies on model explainability, affirming the\neffectiveness of our solution.\n","authors":["Rohan Reddy Mekala","Frederik Pahde","Simon Baur","Sneha Chandrashekar","Madeline Diep","Markus Wenzel","Eric L. Wisotzky","Galip Ümit Yolcu","Sebastian Lapuschkin","Jackie Ma","Peter Eisert","Mikael Lindvall","Adam Porter","Wojciech Samek"],"pdf_url":"https://arxiv.org/pdf/2410.05114v1.pdf","comment":"This preprint has been submitted to the Workshop on Synthetic Data\n  for Computer Vision (SyntheticData4CV 2024 is a side event on 18th European\n  Conference on Computer Vision 2024). This preprint has not undergone peer\n  review or any post-submission improvements or corrections"},{"id":"http://arxiv.org/abs/2410.05105v1","updated":"2024-10-07T15:02:47Z","published":"2024-10-07T15:02:47Z","title":"AI-Enhanced Ethical Hacking: A Linux-Focused Experiment","summary":"  This technical report investigates the integration of generative AI (GenAI),\nspecifically ChatGPT, into the practice of ethical hacking through a\ncomprehensive experimental study and conceptual analysis. Conducted in a\ncontrolled virtual environment, the study evaluates GenAI's effectiveness\nacross the key stages of penetration testing on Linux-based target machines\noperating within a virtual local area network (LAN), including reconnaissance,\nscanning and enumeration, gaining access, maintaining access, and covering\ntracks. The findings confirm that GenAI can significantly enhance and\nstreamline the ethical hacking process while underscoring the importance of\nbalanced human-AI collaboration rather than the complete replacement of human\ninput. The report also critically examines potential risks such as misuse, data\nbiases, hallucination, and over-reliance on AI. This research contributes to\nthe ongoing discussion on the ethical use of AI in cybersecurity and highlights\nthe need for continued innovation to strengthen security defences.\n","authors":["Haitham S. Al-Sinani","Chris J. Mitchell"],"pdf_url":"https://arxiv.org/pdf/2410.05105v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.15929v2","updated":"2024-10-07T15:01:48Z","published":"2024-02-24T23:16:57Z","title":"Decoding Intelligence: A Framework for Certifying Knowledge\n  Comprehension in LLMs","summary":"  Knowledge comprehension capability is an important aspect of human\nintelligence. As Large Language Models (LLMs) are being envisioned as\nsuperhuman agents, it is crucial for them to be proficient at knowledge\ncomprehension. However, existing benchmarking studies do not provide\nconsistent, generalizable, and formal guarantees on the knowledge comprehension\ncapabilities of LLMs. In this work, we propose the first framework to certify\nknowledge comprehension in LLMs with formal probabilistic guarantees. Our\ncertificates are quantitative -- they consist of high-confidence, tight bounds\non the probability that a target LLM gives the correct answer on any knowledge\ncomprehension prompt sampled from a distribution. We design and certify novel\nspecifications that precisely represent distributions of knowledge\ncomprehension prompts leveraging knowledge graphs. We certify SOTA LLMs for\nspecifications over the Wikidata5m knowledge graph. We find that the knowledge\ncomprehension capability improves significantly with scaling the size of the\nmodels.\n","authors":["Isha Chaudhary","Vedaant V. Jain","Gagandeep Singh"],"pdf_url":"https://arxiv.org/pdf/2402.15929v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.05102v1","updated":"2024-10-07T15:01:29Z","published":"2024-10-07T15:01:29Z","title":"SparsePO: Controlling Preference Alignment of LLMs via Sparse Token\n  Masks","summary":"  Preference Optimization (PO) has proven an effective step for aligning\nlanguage models to human-desired behaviors. Current variants, following the\noffline Direct Preference Optimization objective, have focused on a strict\nsetting where all tokens are contributing signals of KL divergence and rewards\nto the loss function. However, human preference is not affected by each word in\na sequence equally but is often dependent on specific words or phrases, e.g.\nexistence of toxic terms leads to non-preferred responses. Based on this\nobservation, we argue that not all tokens should be weighted equally during PO\nand propose a flexible objective termed SparsePO, that aims to automatically\nlearn to weight the KL divergence and reward corresponding to each token during\nPO training. We propose two different variants of weight-masks that can either\nbe derived from the reference model itself or learned on the fly. Notably, our\nmethod induces sparsity in the learned masks, allowing the model to learn how\nto best weight reward and KL divergence contributions at the token level,\nlearning an optimal level of mask sparsity. Extensive experiments on multiple\ndomains, including sentiment control, dialogue, text summarization and\ntext-to-code generation, illustrate that our approach assigns meaningful\nweights to tokens according to the target task, generates more responses with\nthe desired preference and improves reasoning tasks by up to 2 percentage\npoints compared to other token- and response-level PO methods.\n","authors":["Fenia Christopoulou","Ronald Cardenas","Gerasimos Lampouras","Haitham Bou-Ammar","Jun Wang"],"pdf_url":"https://arxiv.org/pdf/2410.05102v1.pdf","comment":"20 papges, 9 figures, 5 tables. Under Review"},{"id":"http://arxiv.org/abs/2410.05094v1","updated":"2024-10-07T14:48:56Z","published":"2024-10-07T14:48:56Z","title":"On the Structure of Game Provenance and its Applications","summary":"  Provenance in databases has been thoroughly studied for positive and for\nrecursive queries, then for first-order (FO) queries, i.e., having negation but\nno recursion. Query evaluation can be understood as a two-player game where the\nopponents argue whether or not a tuple is in the query answer. This\ngame-theoretic approach yields a natural provenance model for FO queries,\nunifying how and why-not provenance. Here, we study the fine-grain structure of\ngame provenance. A game $G=(V,E)$ consists of positions $V$ and moves $E$ and\ncan be solved by computing the well-founded model of a single, unstratifiable\nrule: \\[ \\text{win}(X) \\leftarrow \\text{move}(X, Y), \\neg \\, \\text{win}(Y). \\]\nIn the solved game $G^{\\lambda}$, the value of a position $x\\,{\\in}\\,V$ is\neither won, lost, or drawn. This value is explained by the provenance\n$\\mathscr{P}$(x), i.e., certain (annotated) edges reachable from $x$. We\nidentify seven edge types that give rise to new kinds of provenance, i.e.,\npotential, actual, and primary, and demonstrate that \"not all moves are created\nequal\". We describe the new provenance types, show how they can be computed\nwhile solving games, and discuss applications, e.g., for abstract argumentation\nframeworks.\n","authors":["Shawn Bowers","Yilin Xia","Bertram Ludäscher"],"pdf_url":"https://arxiv.org/pdf/2410.05094v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.02707v2","updated":"2024-10-07T14:46:11Z","published":"2024-10-03T17:31:31Z","title":"LLMs Know More Than They Show: On the Intrinsic Representation of LLM\n  Hallucinations","summary":"  Large language models (LLMs) often produce errors, including factual\ninaccuracies, biases, and reasoning failures, collectively referred to as\n\"hallucinations\". Recent studies have demonstrated that LLMs' internal states\nencode information regarding the truthfulness of their outputs, and that this\ninformation can be utilized to detect errors. In this work, we show that the\ninternal representations of LLMs encode much more information about\ntruthfulness than previously recognized. We first discover that the\ntruthfulness information is concentrated in specific tokens, and leveraging\nthis property significantly enhances error detection performance. Yet, we show\nthat such error detectors fail to generalize across datasets, implying that --\ncontrary to prior claims -- truthfulness encoding is not universal but rather\nmultifaceted. Next, we show that internal representations can also be used for\npredicting the types of errors the model is likely to make, facilitating the\ndevelopment of tailored mitigation strategies. Lastly, we reveal a discrepancy\nbetween LLMs' internal encoding and external behavior: they may encode the\ncorrect answer, yet consistently generate an incorrect one. Taken together,\nthese insights deepen our understanding of LLM errors from the model's internal\nperspective, which can guide future research on enhancing error analysis and\nmitigation.\n","authors":["Hadas Orgad","Michael Toker","Zorik Gekhman","Roi Reichart","Idan Szpektor","Hadas Kotek","Yonatan Belinkov"],"pdf_url":"https://arxiv.org/pdf/2410.02707v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.14768v2","updated":"2024-10-07T14:35:14Z","published":"2024-05-23T16:35:52Z","title":"WISE: Rethinking the Knowledge Memory for Lifelong Model Editing of\n  Large Language Models","summary":"  Large language models (LLMs) need knowledge updates to meet the ever-growing\nworld facts and correct the hallucinated responses, facilitating the methods of\nlifelong model editing. Where the updated knowledge resides in memories is a\nfundamental question for model editing. In this paper, we find that editing\neither long-term memory (direct model parameters) or working memory\n(non-parametric knowledge of neural network activations/representations by\nretrieval) will result in an impossible triangle -- reliability,\ngeneralization, and locality can not be realized together in the lifelong\nediting settings. For long-term memory, directly editing the parameters will\ncause conflicts with irrelevant pretrained knowledge or previous edits (poor\nreliability and locality). For working memory, retrieval-based activations can\nhardly make the model understand the edits and generalize (poor\ngeneralization). Therefore, we propose WISE to bridge the gap between memories.\nIn WISE, we design a dual parametric memory scheme, which consists of the main\nmemory for the pretrained knowledge and a side memory for the edited knowledge.\nWe only edit the knowledge in the side memory and train a router to decide\nwhich memory to go through when given a query. For continual editing, we devise\na knowledge-sharding mechanism where different sets of edits reside in distinct\nsubspaces of parameters, and are subsequently merged into a shared memory\nwithout conflicts. Extensive experiments show that WISE can outperform previous\nmodel editing methods and overcome the impossible triangle under lifelong model\nediting of question answering, hallucination, and out-of-distribution settings\nacross trending LLM architectures, e.g., GPT, LLaMA, and Mistral. Code is\navailable at https://github.com/zjunlp/EasyEdit.\n","authors":["Peng Wang","Zexi Li","Ningyu Zhang","Ziwen Xu","Yunzhi Yao","Yong Jiang","Pengjun Xie","Fei Huang","Huajun Chen"],"pdf_url":"https://arxiv.org/pdf/2405.14768v2.pdf","comment":"NeurIPS 2024"},{"id":"http://arxiv.org/abs/2410.05080v1","updated":"2024-10-07T14:33:50Z","published":"2024-10-07T14:33:50Z","title":"ScienceAgentBench: Toward Rigorous Assessment of Language Agents for\n  Data-Driven Scientific Discovery","summary":"  The advancements of language language models (LLMs) have piqued growing\ninterest in developing LLM-based language agents to automate scientific\ndiscovery end-to-end, which has sparked both excitement and skepticism about\nthe true capabilities of such agents. In this work, we argue that for an agent\nto fully automate scientific discovery, it must be able to complete all\nessential tasks in the workflow. Thus, we call for rigorous assessment of\nagents on individual tasks in a scientific workflow before making bold claims\non end-to-end automation. To this end, we present ScienceAgentBench, a new\nbenchmark for evaluating language agents for data-driven scientific discovery.\nTo ensure the scientific authenticity and real-world relevance of our\nbenchmark, we extract 102 tasks from 44 peer-reviewed publications in four\ndisciplines and engage nine subject matter experts to validate them. We unify\nthe target output for every task to a self-contained Python program file and\nemploy an array of evaluation metrics to examine the generated programs,\nexecution results, and costs. Each task goes through multiple rounds of manual\nvalidation by annotators and subject matter experts to ensure its annotation\nquality and scientific plausibility. We also propose two effective strategies\nto mitigate data contamination concerns. Using our benchmark, we evaluate five\nopen-weight and proprietary LLMs, each with three frameworks: direct prompting,\nOpenHands, and self-debug. Given three attempts for each task, the\nbest-performing agent can only solve 32.4% of the tasks independently and 34.3%\nwith expert-provided knowledge. These results underscore the limited capacities\nof current language agents in generating code for data-driven discovery, let\nalone end-to-end automation for scientific research.\n","authors":["Ziru Chen","Shijie Chen","Yuting Ning","Qianheng Zhang","Boshi Wang","Botao Yu","Yifei Li","Zeyi Liao","Chen Wei","Zitong Lu","Vishal Dey","Mingyi Xue","Frazier N. Baker","Benjamin Burns","Daniel Adu-Ampratwum","Xuhui Huang","Xia Ning","Song Gao","Yu Su","Huan Sun"],"pdf_url":"https://arxiv.org/pdf/2410.05080v1.pdf","comment":"55 pages"},{"id":"http://arxiv.org/abs/2403.10041v2","updated":"2024-10-07T14:33:28Z","published":"2024-03-15T06:22:32Z","title":"Towards Embedding Dynamic Personas in Interactive Robots: Masquerading\n  Animated Social Kinematics (MASK)","summary":"  This paper presents the design and development of an innovative interactive\nrobotic system to enhance audience engagement using character-like personas.\nBuilt upon the foundations of persona-driven dialog agents, this work extends\nthe agent's application to the physical realm, employing robots to provide a\nmore captivating and interactive experience. The proposed system, named the\nMasquerading Animated Social Kinematic (MASK), leverages an anthropomorphic\nrobot which interacts with guests using non-verbal interactions, including\nfacial expressions and gestures. A behavior generation system based upon a\nfinite-state machine structure effectively conditions robotic behavior to\nconvey distinct personas. The MASK framework integrates a perception engine, a\nbehavior selection engine, and a comprehensive action library to enable\nreal-time, dynamic interactions with minimal human intervention in behavior\ndesign. Throughout the user subject studies, we examined whether the users\ncould recognize the intended character in both personality- and\nfilm-character-based persona conditions. We conclude by discussing the role of\npersonas in interactive agents and the factors to consider for creating an\nengaging user experience.\n","authors":["Jeongeun Park","Taemoon Jeong","Hyeonseong Kim","Taehyun Byun","Seungyoon Shin","Keunjun Choi","Jaewoon Kwon","Taeyoon Lee","Matthew Pan","Sungjoon Choi"],"pdf_url":"https://arxiv.org/pdf/2403.10041v2.pdf","comment":"Accepted at Robotics and Automation Letters"},{"id":"http://arxiv.org/abs/2410.05078v1","updated":"2024-10-07T14:32:03Z","published":"2024-10-07T14:32:03Z","title":"Compression via Pre-trained Transformers: A Study on Byte-Level\n  Multimodal Data","summary":"  Foundation models have recently been shown to be strong data compressors.\nHowever, when accounting for their excessive parameter count, their compression\nratios are actually inferior to standard compression algorithms. Moreover,\nnaively reducing the number of parameters may not necessarily help as it leads\nto worse predictions and thus weaker compression. In this paper, we conduct a\nlarge-scale empirical study to investigate whether there is a sweet spot where\ncompetitive compression ratios with pre-trained vanilla transformers are\npossible. To this end, we train families of models on 165GB of raw byte\nsequences of either text, image, or audio data (and all possible combinations\nof the three) and then compress 1GB of out-of-distribution (OOD) data from each\nmodality. We find that relatively small models (i.e., millions of parameters)\ncan outperform standard general-purpose compression algorithms (gzip, LZMA2)\nand even domain-specific compressors (PNG, JPEG 2000, FLAC) - even when\nfactoring in parameter count. We achieve, e.g., the lowest compression ratio of\n0.49 on OOD audio data (vs. 0.54 for FLAC). To study the impact of model- and\ndataset scale, we conduct extensive ablations and hyperparameter sweeps, and we\ninvestigate the effect of unimodal versus multimodal training. We find that\neven small models can be trained to perform well on multiple modalities, but,\nin contrast to previously reported results with large-scale foundation models,\ntransfer to unseen modalities is generally weak.\n","authors":["David Heurtel-Depeiges","Anian Ruoss","Joel Veness","Tim Genewein"],"pdf_url":"https://arxiv.org/pdf/2410.05078v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.05076v1","updated":"2024-10-07T14:30:27Z","published":"2024-10-07T14:30:27Z","title":"TidalDecode: Fast and Accurate LLM Decoding with Position Persistent\n  Sparse Attention","summary":"  Large language models (LLMs) have driven significant advancements across\ndiverse NLP tasks, with long-context models gaining prominence for handling\nextended inputs. However, the expanding key-value (KV) cache size required by\nTransformer architectures intensifies the memory constraints, particularly\nduring the decoding phase, creating a significant bottleneck. Existing sparse\nattention mechanisms designed to address this bottleneck have two limitations:\n(1) they often fail to reliably identify the most relevant tokens for\nattention, and (2) they overlook the spatial coherence of token selection\nacross consecutive Transformer layers, which can lead to performance\ndegradation and substantial overhead in token selection. This paper introduces\nTidalDecode, a simple yet effective algorithm and system for fast and accurate\nLLM decoding through position persistent sparse attention. TidalDecode\nleverages the spatial coherence of tokens selected by existing sparse attention\nmethods and introduces a few token selection layers that perform full attention\nto identify the tokens with the highest attention scores, while all other\nlayers perform sparse attention with the pre-selected tokens. This design\nenables TidalDecode to substantially reduce the overhead of token selection for\nsparse attention without sacrificing the quality of the generated results.\nEvaluation on a diverse set of LLMs and tasks shows that TidalDecode closely\nmatches the generative performance of full attention methods while reducing the\nLLM decoding latency by up to 2.1x.\n","authors":["Lijie Yang","Zhihao Zhang","Zhuofu Chen","Zikun Li","Zhihao Jia"],"pdf_url":"https://arxiv.org/pdf/2410.05076v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.02458v2","updated":"2024-10-07T14:20:42Z","published":"2024-01-04T08:00:32Z","title":"Data-Centric Foundation Models in Computational Healthcare: A Survey","summary":"  The advent of foundation models (FMs) as an emerging suite of AI techniques\nhas struck a wave of opportunities in computational healthcare. The interactive\nnature of these models, guided by pre-training data and human instructions, has\nignited a data-centric AI paradigm that emphasizes better data\ncharacterization, quality, and scale. In healthcare AI, obtaining and\nprocessing high-quality clinical data records has been a longstanding\nchallenge, ranging from data quantity, annotation, patient privacy, and ethics.\nIn this survey, we investigate a wide range of data-centric approaches in the\nFM era (from model pre-training to inference) towards improving the healthcare\nworkflow. We discuss key perspectives in AI security, assessment, and alignment\nwith human values. Finally, we offer a promising outlook of FM-based analytics\nto enhance the performance of patient outcome and clinical workflow in the\nevolving landscape of healthcare and medicine. We provide an up-to-date list of\nhealthcare-related foundation models and datasets at\nhttps://github.com/Yunkun-Zhang/Data-Centric-FM-Healthcare .\n","authors":["Yunkun Zhang","Jin Gao","Zheling Tan","Lingfeng Zhou","Kexin Ding","Mu Zhou","Shaoting Zhang","Dequan Wang"],"pdf_url":"https://arxiv.org/pdf/2401.02458v2.pdf","comment":"Survey content updated to include recent research work and progress"},{"id":"http://arxiv.org/abs/2404.06474v3","updated":"2024-10-07T14:19:37Z","published":"2024-04-09T17:25:47Z","title":"Autonomous Evaluation and Refinement of Digital Agents","summary":"  We show that domain-general automatic evaluators can significantly improve\nthe performance of agents for web navigation and device control. We experiment\nwith multiple evaluation models that trade off between inference cost,\nmodularity of design, and accuracy. We validate the performance of these models\nin several popular benchmarks for digital agents, finding between 74.4 and\n92.9% agreement with oracle evaluation metrics. Finally, we use these\nevaluators to improve the performance of existing agents via fine-tuning and\ninference-time guidance. Without any additional supervision, we improve\nstate-of-the-art performance by 29% on the popular benchmark WebArena, and\nachieve around 75% relative improvement in device control settings.\n","authors":["Jiayi Pan","Yichi Zhang","Nicholas Tomlin","Yifei Zhou","Sergey Levine","Alane Suhr"],"pdf_url":"https://arxiv.org/pdf/2404.06474v3.pdf","comment":"Published at COLM 2024. Code at\n  https://github.com/Berkeley-NLP/Agent-Eval-Refine"},{"id":"http://arxiv.org/abs/2409.19745v2","updated":"2024-10-07T14:17:44Z","published":"2024-09-29T15:40:54Z","title":"PEAR: Position-Embedding-Agnostic Attention Re-weighting Enhances\n  Retrieval-Augmented Generation with Zero Inference Overhead","summary":"  Large language models (LLMs) enhanced with retrieval-augmented generation\n(RAG) have introduced a new paradigm for web search. However, the limited\ncontext awareness of LLMs degrades their performance on RAG tasks. Existing\nmethods to enhance context awareness are often inefficient, incurring time or\nmemory overhead during inference, and many are tailored to specific position\nembeddings. In this paper, we propose Position-Embedding-Agnostic attention\nRe-weighting (PEAR), which enhances the context awareness of LLMs with zero\ninference overhead. Specifically, on a proxy task focused on context copying,\nwe first detect heads which suppress the models' context awareness thereby\ndiminishing RAG performance. To weaken the impact of these heads, we re-weight\ntheir outputs with learnable coefficients. The LLM (with frozen parameters) is\noptimized by adjusting these coefficients to minimize loss on the proxy task.\nAs a result, the coefficients are optimized to values less than one, thereby\nreducing their tendency to suppress RAG performance. During inference, the\noptimized coefficients are fixed to re-weight these heads, regardless of the\nspecific task at hand. Our proposed PEAR offers two major advantages over\nprevious approaches: (1) It introduces zero additional inference overhead in\nterms of memory usage or inference time, while outperforming competitive\nbaselines in accuracy and efficiency across various RAG tasks. (2) It is\nindependent of position embedding algorithms, ensuring broader applicability.\n","authors":["Tao Tan","Yining Qian","Ang Lv","Hongzhan Lin","Songhao Wu","Yongbo Wang","Feng Wang","Jingtong Wu","Xin Lu","Rui Yan"],"pdf_url":"https://arxiv.org/pdf/2409.19745v2.pdf","comment":"preprint"},{"id":"http://arxiv.org/abs/2410.01386v2","updated":"2024-10-07T14:14:39Z","published":"2024-10-02T09:55:58Z","title":"FLAME: Adaptive and Reactive Concept Drift Mitigation for Federated\n  Learning Deployments","summary":"  This paper presents Federated Learning with Adaptive Monitoring and\nElimination (FLAME), a novel solution capable of detecting and mitigating\nconcept drift in Federated Learning (FL) Internet of Things (IoT) environments.\nConcept drift poses significant challenges for FL models deployed in dynamic\nand real-world settings. FLAME leverages an FL architecture, considers a\nreal-world FL pipeline, and proves capable of maintaining model performance and\naccuracy while addressing bandwidth and privacy constraints. Introducing\nvarious features and extensions on previous works, FLAME offers a robust\nsolution to concept drift, significantly reducing computational load and\ncommunication overhead. Compared to well-known lightweight mitigation methods,\nFLAME demonstrates superior performance in maintaining high F1 scores and\nreducing resource utilisation in large-scale IoT deployments, making it a\npromising approach for real-world applications.\n","authors":["Ioannis Mavromatis","Stefano De Feo","Aftab Khan"],"pdf_url":"https://arxiv.org/pdf/2410.01386v2.pdf","comment":"Accepted for Publication at ACM EWSN 2024 - EMERGE Workshop"},{"id":"http://arxiv.org/abs/2410.05056v1","updated":"2024-10-07T14:13:37Z","published":"2024-10-07T14:13:37Z","title":"Transition of $α$-mixing in Random Iterations with Applications in\n  Queuing Theory","summary":"  Nonlinear time series models incorporating exogenous regressors provide the\nfoundation for numerous significant models across econometrics, queuing theory,\nmachine learning, and various other disciplines. Despite their importance, the\nframework for the statistical analysis of such models is still incomplete. In\ncontrast, multiple versions of the law of large numbers and the (functional)\ncentral limit theorem have been established for weakly dependent variables. We\nprove the transition of mixing properties of the exogenous regressor to the\nresponse through a coupling argument, leveraging these established results.\nFurthermore, we study Markov chains in random environments under a suitable\nform of drift and minorization condition when the environment process is\nnon-stationary, merely having favorable mixing properties. Following a novel\nstatistical estimation theory approach and using the Cram\\'er-Rao lower bound,\nwe also establish the functional central limit theorem. Additionally, we apply\nour framework to single-server queuing models. Overall, these results open the\ndoor to the statistical analysis of a large class of random iterative models.\n","authors":["Attila Lovas"],"pdf_url":"https://arxiv.org/pdf/2410.05056v1.pdf","comment":"33 pages, 1 figure"},{"id":"http://arxiv.org/abs/2406.12058v4","updated":"2024-10-07T14:08:13Z","published":"2024-06-17T19:50:40Z","title":"WellDunn: On the Robustness and Explainability of Language Models and\n  Large Language Models in Identifying Wellness Dimensions","summary":"  Language Models (LMs) are being proposed for mental health applications where\nthe heightened risk of adverse outcomes means predictive performance may not be\na sufficient litmus test of a model's utility in clinical practice. A model\nthat can be trusted for practice should have a correspondence between\nexplanation and clinical determination, yet no prior research has examined the\nattention fidelity of these models and their effect on ground truth\nexplanations. We introduce an evaluation design that focuses on the robustness\nand explainability of LMs in identifying Wellness Dimensions (WDs). We focus on\ntwo existing mental health and well-being datasets: (a) Multi-label\nClassification-based MultiWD, and (b) WellXplain for evaluating attention\nmechanism veracity against expert-labeled explanations. The labels are based on\nHalbert Dunn's theory of wellness, which gives grounding to our evaluation. We\nreveal four surprising results about LMs/LLMs: (1) Despite their human-like\ncapabilities, GPT-3.5/4 lag behind RoBERTa, and MedAlpaca, a fine-tuned LLM on\nWellXplain fails to deliver any remarkable improvements in performance or\nexplanations. (2) Re-examining LMs' predictions based on a confidence-oriented\nloss function reveals a significant performance drop. (3) Across all LMs/LLMs,\nthe alignment between attention and explanations remains low, with LLMs scoring\na dismal 0.0. (4) Most mental health-specific LMs/LLMs overlook domain-specific\nknowledge and undervalue explanations, causing these discrepancies. This study\nhighlights the need for further research into their consistency and\nexplanations in mental health and well-being.\n","authors":["Seyedali Mohammadi","Edward Raff","Jinendra Malekar","Vedant Palit","Francis Ferraro","Manas Gaur"],"pdf_url":"https://arxiv.org/pdf/2406.12058v4.pdf","comment":"Accepted in BlackboxNLP @ EMNLP 2024"},{"id":"http://arxiv.org/abs/2410.05050v1","updated":"2024-10-07T14:05:57Z","published":"2024-10-07T14:05:57Z","title":"FreSh: Frequency Shifting for Accelerated Neural Representation Learning","summary":"  Implicit Neural Representations (INRs) have recently gained attention as a\npowerful approach for continuously representing signals such as images, videos,\nand 3D shapes using multilayer perceptrons (MLPs). However, MLPs are known to\nexhibit a low-frequency bias, limiting their ability to capture high-frequency\ndetails accurately. This limitation is typically addressed by incorporating\nhigh-frequency input embeddings or specialized activation layers. In this work,\nwe demonstrate that these embeddings and activations are often configured with\nhyperparameters that perform well on average but are suboptimal for specific\ninput signals under consideration, necessitating a costly grid search to\nidentify optimal settings. Our key observation is that the initial frequency\nspectrum of an untrained model's output correlates strongly with the model's\neventual performance on a given target signal. Leveraging this insight, we\npropose frequency shifting (or FreSh), a method that selects embedding\nhyperparameters to align the frequency spectrum of the model's initial output\nwith that of the target signal. We show that this simple initialization\ntechnique improves performance across various neural representation methods and\ntasks, achieving results comparable to extensive hyperparameter sweeps but with\nonly marginal computational overhead compared to training a single model with\ndefault hyperparameters.\n","authors":["Adam Kania","Marko Mihajlovic","Sergey Prokudin","Jacek Tabor","Przemysław Spurek"],"pdf_url":"https://arxiv.org/pdf/2410.05050v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.05047v3","updated":"2024-10-07T14:05:05Z","published":"2024-07-06T11:07:18Z","title":"MFE-ETP: A Comprehensive Evaluation Benchmark for Multi-modal Foundation\n  Models on Embodied Task Planning","summary":"  In recent years, Multi-modal Foundation Models (MFMs) and Embodied Artificial\nIntelligence (EAI) have been advancing side by side at an unprecedented pace.\nThe integration of the two has garnered significant attention from the AI\nresearch community. In this work, we attempt to provide an in-depth and\ncomprehensive evaluation of the performance of MFM s on embodied task planning,\naiming to shed light on their capabilities and limitations in this domain. To\nthis end, based on the characteristics of embodied task planning, we first\ndevelop a systematic evaluation framework, which encapsulates four crucial\ncapabilities of MFMs: object understanding, spatio-temporal perception, task\nunderstanding, and embodied reasoning. Following this, we propose a new\nbenchmark, named MFE-ETP, characterized its complex and variable task\nscenarios, typical yet diverse task types, task instances of varying\ndifficulties, and rich test case types ranging from multiple embodied question\nanswering to embodied task reasoning. Finally, we offer a simple and\neasy-to-use automatic evaluation platform that enables the automated testing of\nmultiple MFMs on the proposed benchmark. Using the benchmark and evaluation\nplatform, we evaluated several state-of-the-art MFMs and found that they\nsignificantly lag behind human-level performance. The MFE-ETP is a\nhigh-quality, large-scale, and challenging benchmark relevant to real-world\ntasks.\n","authors":["Min Zhang","Xian Fu","Jianye Hao","Peilong Han","Hao Zhang","Lei Shi","Hongyao Tang","Yan Zheng"],"pdf_url":"https://arxiv.org/pdf/2407.05047v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.05046v1","updated":"2024-10-07T14:00:18Z","published":"2024-10-07T14:00:18Z","title":"Named Clinical Entity Recognition Benchmark","summary":"  This technical report introduces a Named Clinical Entity Recognition\nBenchmark for evaluating language models in healthcare, addressing the crucial\nnatural language processing (NLP) task of extracting structured information\nfrom clinical narratives to support applications like automated coding,\nclinical trial cohort identification, and clinical decision support.\n  The leaderboard provides a standardized platform for assessing diverse\nlanguage models, including encoder and decoder architectures, on their ability\nto identify and classify clinical entities across multiple medical domains. A\ncurated collection of openly available clinical datasets is utilized,\nencompassing entities such as diseases, symptoms, medications, procedures, and\nlaboratory measurements. Importantly, these entities are standardized according\nto the Observational Medical Outcomes Partnership (OMOP) Common Data Model,\nensuring consistency and interoperability across different healthcare systems\nand datasets, and a comprehensive evaluation of model performance. Performance\nof models is primarily assessed using the F1-score, and it is complemented by\nvarious assessment modes to provide comprehensive insights into model\nperformance. The report also includes a brief analysis of models evaluated to\ndate, highlighting observed trends and limitations.\n  By establishing this benchmarking framework, the leaderboard aims to promote\ntransparency, facilitate comparative analyses, and drive innovation in clinical\nentity recognition tasks, addressing the need for robust evaluation methods in\nhealthcare NLP.\n","authors":["Wadood M Abdul","Marco AF Pimentel","Muhammad Umar Salman","Tathagata Raha","Clément Christophe","Praveen K Kanithi","Nasir Hayat","Ronnie Rajan","Shadab Khan"],"pdf_url":"https://arxiv.org/pdf/2410.05046v1.pdf","comment":"Technical Report"},{"id":"http://arxiv.org/abs/2410.05045v1","updated":"2024-10-07T14:00:08Z","published":"2024-10-07T14:00:08Z","title":"Can LLMs plan paths with extra hints from solvers?","summary":"  Large Language Models (LLMs) have shown remarkable capabilities in natural\nlanguage processing, mathematical problem solving, and tasks related to program\nsynthesis. However, their effectiveness in long-term planning and higher-order\nreasoning has been noted to be limited and fragile. This paper explores an\napproach for enhancing LLM performance in solving a classical robotic planning\ntask by integrating solver-generated feedback. We explore four different\nstrategies for providing feedback, including visual feedback, we utilize\nfine-tuning, and we evaluate the performance of three different LLMs across a\n10 standard and 100 more randomly generated planning problems. Our results\nsuggest that the solver-generated feedback improves the LLM's ability to solve\nthe moderately difficult problems, but the harder problems still remain out of\nreach. The study provides detailed analysis of the effects of the different\nhinting strategies and the different planning tendencies of the evaluated LLMs.\n","authors":["Erik Wu","Sayan Mitra"],"pdf_url":"https://arxiv.org/pdf/2410.05045v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.05044v1","updated":"2024-10-07T13:58:40Z","published":"2024-10-07T13:58:40Z","title":"PhotoReg: Photometrically Registering 3D Gaussian Splatting Models","summary":"  Building accurate representations of the environment is critical for\nintelligent robots to make decisions during deployment. Advances in\nphotorealistic environment models have enabled robots to develop\nhyper-realistic reconstructions, which can be used to generate images that are\nintuitive for human inspection. In particular, the recently introduced\n\\ac{3DGS}, which describes the scene with up to millions of primitive\nellipsoids, can be rendered in real time. \\ac{3DGS} has rapidly gained\nprominence. However, a critical unsolved problem persists: how can we fuse\nmultiple \\ac{3DGS} into a single coherent model? Solving this problem will\nenable robot teams to jointly build \\ac{3DGS} models of their surroundings. A\nkey insight of this work is to leverage the {duality} between photorealistic\nreconstructions, which render realistic 2D images from 3D structure, and\n\\emph{3D foundation models}, which predict 3D structure from image pairs. To\nthis end, we develop PhotoReg, a framework to register multiple photorealistic\n\\ac{3DGS} models with 3D foundation models. As \\ac{3DGS} models are generally\nbuilt from monocular camera images, they have \\emph{arbitrary scale}. To\nresolve this, PhotoReg actively enforces scale consistency among the different\n\\ac{3DGS} models by considering depth estimates within these models. Then, the\nalignment is iteratively refined with fine-grained photometric losses to\nproduce high-quality fused \\ac{3DGS} models. We rigorously evaluate PhotoReg on\nboth standard benchmark datasets and our custom-collected datasets, including\nwith two quadruped robots. The code is released at\n\\url{ziweny11.github.io/photoreg}.\n","authors":["Ziwen Yuan","Tianyi Zhang","Matthew Johnson-Roberson","Weiming Zhi"],"pdf_url":"https://arxiv.org/pdf/2410.05044v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.15160v2","updated":"2024-10-07T13:19:53Z","published":"2024-07-21T13:31:02Z","title":"When Can Transformers Count to n?","summary":"  Large language models based on the transformer architectures can solve highly\ncomplex tasks. But are there simple tasks that such models cannot solve? Here\nwe focus on very simple counting tasks, that involve counting how many times a\ntoken in the vocabulary have appeared in a string. We show that if the\ndimension of the transformer state is linear in the context length, this task\ncan be solved. However, the solution we propose does not scale beyond this\nlimit, and we provide theoretical arguments for why it is likely impossible for\na size limited transformer to implement this task. Our empirical results\ndemonstrate the same phase-transition in performance, as anticipated by the\ntheoretical argument. Our results demonstrate the importance of understanding\nhow transformers can solve simple tasks.\n","authors":["Gilad Yehudai","Haim Kaplan","Asma Ghandeharioun","Mor Geva","Amir Globerson"],"pdf_url":"https://arxiv.org/pdf/2407.15160v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.18376v2","updated":"2024-10-07T13:17:03Z","published":"2024-02-28T14:52:15Z","title":"Tokenization Is More Than Compression","summary":"  Tokenization is a foundational step in natural language processing (NLP)\ntasks, bridging raw text and language models. Existing tokenization approaches\nlike Byte-Pair Encoding (BPE) originate from the field of data compression, and\nit has been suggested that the effectiveness of BPE stems from its ability to\ncondense text into a relatively small number of tokens. We test the hypothesis\nthat fewer tokens lead to better downstream performance by introducing\nPathPiece, a new tokenizer that segments a document's text into the minimum\nnumber of tokens for a given vocabulary. Through extensive experimentation we\nfind this hypothesis not to be the case, casting doubt on the understanding of\nthe reasons for effective tokenization. To examine which other factors play a\nrole, we evaluate design decisions across all three phases of tokenization:\npre-tokenization, vocabulary construction, and segmentation, offering new\ninsights into the design of effective tokenizers. Specifically, we illustrate\nthe importance of pre-tokenization and the benefits of using BPE to initialize\nvocabulary construction. We train 64 language models with varying tokenization,\nranging in size from 350M to 2.4B parameters, all of which are made publicly\navailable.\n","authors":["Craig W. Schmidt","Varshini Reddy","Haoran Zhang","Alec Alameddine","Omri Uzan","Yuval Pinter","Chris Tanner"],"pdf_url":"https://arxiv.org/pdf/2402.18376v2.pdf","comment":"EMNLP 2024"},{"id":"http://arxiv.org/abs/2410.01104v2","updated":"2024-10-07T13:13:41Z","published":"2024-10-01T22:22:35Z","title":"softmax is not enough (for sharp out-of-distribution)","summary":"  A key property of reasoning systems is the ability to make sharp decisions on\ntheir input data. For contemporary AI systems, a key carrier of sharp behaviour\nis the softmax function, with its capability to perform differentiable\nquery-key lookups. It is a common belief that the predictive power of networks\nleveraging softmax arises from \"circuits\" which sharply perform certain kinds\nof computations consistently across many diverse inputs. However, for these\ncircuits to be robust, they would need to generalise well to arbitrary valid\ninputs. In this paper, we dispel this myth: even for tasks as simple as finding\nthe maximum key, any learned circuitry must disperse as the number of items\ngrows at test time. We attribute this to a fundamental limitation of the\nsoftmax function to robustly approximate sharp functions, prove this phenomenon\ntheoretically, and propose adaptive temperature as an ad-hoc technique for\nimproving the sharpness of softmax at inference time.\n","authors":["Petar Veličković","Christos Perivolaropoulos","Federico Barbero","Razvan Pascanu"],"pdf_url":"https://arxiv.org/pdf/2410.01104v2.pdf","comment":"Comments welcome. 15 pages, 7 figures"},{"id":"http://arxiv.org/abs/2404.11296v2","updated":"2024-10-07T13:06:01Z","published":"2024-04-17T12:06:17Z","title":"How to Exhibit More Predictable Behaviors","summary":"  This paper looks at predictability problems, i.e., wherein an agent must\nchoose its strategy in order to optimize the predictions that an external\nobserver could make. We address these problems while taking into account\nuncertainties on the environment dynamics and on the observed agent's policy.\nTo that end, we assume that the observer 1. seeks to predict the agent's future\naction or state at each time step, and 2. models the agent using a stochastic\npolicy computed from a known underlying problem, and we leverage on the\nframework of observer-aware Markov decision processes (OAMDPs). We propose\naction and state predictability performance criteria through reward functions\nbuilt on the observer's belief about the agent policy; show that these induced\npredictable OAMDPs can be represented by goal-oriented or discounted MDPs; and\nanalyze the properties of the proposed reward functions both theoretically and\nempirically on two types of grid-world problems.\n","authors":["Salomé Lepers","Sophie Lemonnier","Vincent Thomas","Olivier Buffet"],"pdf_url":"https://arxiv.org/pdf/2404.11296v2.pdf","comment":"21 pages, 14 figures, 2 tables"},{"id":"http://arxiv.org/abs/2410.04990v1","updated":"2024-10-07T12:45:20Z","published":"2024-10-07T12:45:20Z","title":"Stage-Wise and Prior-Aware Neural Speech Phase Prediction","summary":"  This paper proposes a novel Stage-wise and Prior-aware Neural Speech Phase\nPrediction (SP-NSPP) model, which predicts the phase spectrum from input\namplitude spectrum by two-stage neural networks. In the initial\nprior-construction stage, we preliminarily predict a rough prior phase spectrum\nfrom the amplitude spectrum. The subsequent refinement stage transforms the\namplitude spectrum into a refined high-quality phase spectrum conditioned on\nthe prior phase. Networks in both stages use ConvNeXt v2 blocks as the backbone\nand adopt adversarial training by innovatively introducing a phase spectrum\ndiscriminator (PSD). To further improve the continuity of the refined phase, we\nalso incorporate a time-frequency integrated difference (TFID) loss in the\nrefinement stage. Experimental results confirm that, compared to neural\nnetwork-based no-prior phase prediction methods, the proposed SP-NSPP achieves\nhigher phase prediction accuracy, thanks to introducing the coarse phase priors\nand diverse training criteria. Compared to iterative phase estimation\nalgorithms, our proposed SP-NSPP does not require multiple rounds of staged\niterations, resulting in higher generation efficiency.\n","authors":["Fei Liu","Yang Ai","Hui-Peng Du","Ye-Xin Lu","Rui-Chen Zheng","Zhen-Hua Ling"],"pdf_url":"https://arxiv.org/pdf/2410.04990v1.pdf","comment":"Accepted by SLT2024"},{"id":"http://arxiv.org/abs/2410.04974v1","updated":"2024-10-07T12:16:36Z","published":"2024-10-07T12:16:36Z","title":"6DGS: Enhanced Direction-Aware Gaussian Splatting for Volumetric\n  Rendering","summary":"  Novel view synthesis has advanced significantly with the development of\nneural radiance fields (NeRF) and 3D Gaussian splatting (3DGS). However,\nachieving high quality without compromising real-time rendering remains\nchallenging, particularly for physically-based ray tracing with view-dependent\neffects. Recently, N-dimensional Gaussians (N-DG) introduced a 6D\nspatial-angular representation to better incorporate view-dependent effects,\nbut the Gaussian representation and control scheme are sub-optimal. In this\npaper, we revisit 6D Gaussians and introduce 6D Gaussian Splatting (6DGS),\nwhich enhances color and opacity representations and leverages the additional\ndirectional information in the 6D space for optimized Gaussian control. Our\napproach is fully compatible with the 3DGS framework and significantly improves\nreal-time radiance field rendering by better modeling view-dependent effects\nand fine details. Experiments demonstrate that 6DGS significantly outperforms\n3DGS and N-DG, achieving up to a 15.73 dB improvement in PSNR with a reduction\nof 66.5% Gaussian points compared to 3DGS.\n","authors":["Zhongpai Gao","Benjamin Planche","Meng Zheng","Anwesa Choudhuri","Terrence Chen","Ziyan Wu"],"pdf_url":"https://arxiv.org/pdf/2410.04974v1.pdf","comment":"Demo Video: https://www.youtube.com/watch?v=77wN-K6Q9aM"},{"id":"http://arxiv.org/abs/2410.04968v1","updated":"2024-10-07T12:12:51Z","published":"2024-10-07T12:12:51Z","title":"Collaboration! Towards Robust Neural Methods for Routing Problems","summary":"  Despite enjoying desirable efficiency and reduced reliance on domain\nexpertise, existing neural methods for vehicle routing problems (VRPs) suffer\nfrom severe robustness issues -- their performance significantly deteriorates\non clean instances with crafted perturbations. To enhance robustness, we\npropose an ensemble-based Collaborative Neural Framework (CNF) w.r.t. the\ndefense of neural VRP methods, which is crucial yet underexplored in the\nliterature. Given a neural VRP method, we adversarially train multiple models\nin a collaborative manner to synergistically promote robustness against\nattacks, while boosting standard generalization on clean instances. A neural\nrouter is designed to adeptly distribute training instances among models,\nenhancing overall load balancing and collaborative efficacy. Extensive\nexperiments verify the effectiveness and versatility of CNF in defending\nagainst various attacks across different neural VRP methods. Notably, our\napproach also achieves impressive out-of-distribution generalization on\nbenchmark instances.\n","authors":["Jianan Zhou","Yaoxin Wu","Zhiguang Cao","Wen Song","Jie Zhang","Zhiqi Shen"],"pdf_url":"https://arxiv.org/pdf/2410.04968v1.pdf","comment":"Accepted at NeurIPS 2024"},{"id":"http://arxiv.org/abs/2402.02987v2","updated":"2024-10-07T12:11:58Z","published":"2024-02-05T13:18:42Z","title":"Reconstruct Your Previous Conversations! Comprehensively Investigating\n  Privacy Leakage Risks in Conversations with GPT Models","summary":"  Significant advancements have recently been made in large language models\nrepresented by GPT models. Users frequently have multi-round private\nconversations with cloud-hosted GPT models for task optimization. Yet, this\noperational paradigm introduces additional attack surfaces, particularly in\ncustom GPTs and hijacked chat sessions. In this paper, we introduce a\nstraightforward yet potent Conversation Reconstruction Attack. This attack\ntargets the contents of previous conversations between GPT models and benign\nusers, i.e., the benign users' input contents during their interaction with GPT\nmodels. The adversary could induce GPT models to leak such contents by querying\nthem with designed malicious prompts. Our comprehensive examination of privacy\nrisks during the interactions with GPT models under this attack reveals GPT-4's\nconsiderable resilience. We present two advanced attacks targeting improved\nreconstruction of past conversations, demonstrating significant privacy leakage\nacross all models under these advanced techniques. Evaluating various defense\nmechanisms, we find them ineffective against these attacks. Our findings\nhighlight the ease with which privacy can be compromised in interactions with\nGPT models, urging the community to safeguard against potential abuses of these\nmodels' capabilities.\n","authors":["Junjie Chu","Zeyang Sha","Michael Backes","Yang Zhang"],"pdf_url":"https://arxiv.org/pdf/2402.02987v2.pdf","comment":"Accepted in EMNLP 2024. 14 pages, 10 figures"},{"id":"http://arxiv.org/abs/2409.18082v2","updated":"2024-10-07T12:06:17Z","published":"2024-09-26T17:26:16Z","title":"SKT: Integrating State-Aware Keypoint Trajectories with Vision-Language\n  Models for Robotic Garment Manipulation","summary":"  Automating garment manipulation poses a significant challenge for assistive\nrobotics due to the diverse and deformable nature of garments. Traditional\napproaches typically require separate models for each garment type, which\nlimits scalability and adaptability. In contrast, this paper presents a unified\napproach using vision-language models (VLMs) to improve keypoint prediction\nacross various garment categories. By interpreting both visual and semantic\ninformation, our model enables robots to manage different garment states with a\nsingle model. We created a large-scale synthetic dataset using advanced\nsimulation techniques, allowing scalable training without extensive real-world\ndata. Experimental results indicate that the VLM-based method significantly\nenhances keypoint detection accuracy and task success rates, providing a more\nflexible and general solution for robotic garment manipulation. In addition,\nthis research also underscores the potential of VLMs to unify various garment\nmanipulation tasks within a single framework, paving the way for broader\napplications in home automation and assistive robotics for future.\n","authors":["Xin Li","Siyuan Huang","Qiaojun Yu","Zhengkai Jiang","Ce Hao","Yimeng Zhu","Hongsheng Li","Peng Gao","Cewu Lu"],"pdf_url":"https://arxiv.org/pdf/2409.18082v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.19339v2","updated":"2024-10-07T12:05:55Z","published":"2024-09-28T12:49:16Z","title":"Visual Question Decomposition on Multimodal Large Language Models","summary":"  Question decomposition has emerged as an effective strategy for prompting\nLarge Language Models (LLMs) to answer complex questions. However, while\nexisting methods primarily focus on unimodal language models, the question\ndecomposition capability of Multimodal Large Language Models (MLLMs) has yet to\nbe explored. To this end, this paper explores visual question decomposition on\nMLLMs. Specifically, we introduce a systematic evaluation framework including a\ndataset and several evaluation criteria to assess the quality of the decomposed\nsub-questions, revealing that existing MLLMs struggle to produce high-quality\nsub-questions. To address this limitation, we propose a specific finetuning\ndataset, DecoVQA+, for enhancing the model's question decomposition capability.\nAiming at enabling models to perform appropriate selective decomposition, we\npropose an efficient finetuning pipeline. The finetuning pipeline consists of\nour proposed dataset and a training objective for selective decomposition.\nFinetuned MLLMs demonstrate significant improvements in the quality of\nsub-questions and the policy of selective question decomposition. Additionally,\nthe models also achieve higher accuracy with selective decomposition on VQA\nbenchmark datasets.\n","authors":["Haowei Zhang","Jianzhe Liu","Zhen Han","Shuo Chen","Bailan He","Volker Tresp","Zhiqiang Xu","Jindong Gu"],"pdf_url":"https://arxiv.org/pdf/2409.19339v2.pdf","comment":"Accepted to EMNLP2024 Findings"},{"id":"http://arxiv.org/abs/2309.16397v3","updated":"2024-10-07T12:05:12Z","published":"2023-09-28T12:44:51Z","title":"Uncertainty-Aware Decision Transformer for Stochastic Driving\n  Environments","summary":"  Offline Reinforcement Learning (RL) enables policy learning without active\ninteractions, making it especially appealing for self-driving tasks. Recent\nsuccesses of Transformers inspire casting offline RL as sequence modeling,\nwhich, however, fails in stochastic environments with incorrect assumptions\nthat identical actions can consistently achieve the same goal. In this paper,\nwe introduce an UNcertainty-awaRE deciSion Transformer (UNREST) for planning in\nstochastic driving environments without introducing additional transition or\ncomplex generative models. Specifically, UNREST estimates uncertainties by\nconditional mutual information between transitions and returns. Discovering\n'uncertainty accumulation' and 'temporal locality' properties of driving\nenvironments, we replace the global returns in decision transformers with\ntruncated returns less affected by environments to learn from actual outcomes\nof actions rather than environment transitions. We also dynamically evaluate\nuncertainty at inference for cautious planning. Extensive experiments\ndemonstrate UNREST's superior performance in various driving scenarios and the\npower of our uncertainty estimation strategy.\n","authors":["Zenan Li","Fan Nie","Qiao Sun","Fang Da","Hang Zhao"],"pdf_url":"https://arxiv.org/pdf/2309.16397v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04962v1","updated":"2024-10-07T12:01:32Z","published":"2024-10-07T12:01:32Z","title":"Activation Scaling for Steering and Interpreting Language Models","summary":"  Given the prompt \"Rome is in\", can we steer a language model to flip its\nprediction of an incorrect token \"France\" to a correct token \"Italy\" by only\nmultiplying a few relevant activation vectors with scalars? We argue that\nsuccessfully intervening on a model is a prerequisite for interpreting its\ninternal workings. Concretely, we establish a three-term objective: a\nsuccessful intervention should flip the correct with the wrong token and vice\nversa (effectiveness), and leave other tokens unaffected (faithfulness), all\nwhile being sparse (minimality). Using gradient-based optimization, this\nobjective lets us learn (and later evaluate) a specific kind of efficient and\ninterpretable intervention: activation scaling only modifies the signed\nmagnitude of activation vectors to strengthen, weaken, or reverse the steering\ndirections already encoded in the model. On synthetic tasks, this intervention\nperforms comparably with steering vectors in terms of effectiveness and\nfaithfulness, but is much more minimal allowing us to pinpoint interpretable\nmodel components. We evaluate activation scaling from different angles, compare\nperformance on different datasets, and make activation scalars a learnable\nfunction of the activation vectors themselves to generalize to varying-length\nprompts.\n","authors":["Niklas Stoehr","Kevin Du","Vésteinn Snæbjarnarson","Robert West","Ryan Cotterell","Aaron Schein"],"pdf_url":"https://arxiv.org/pdf/2410.04962v1.pdf","comment":"Findings of the Association for Computational Linguistics: EMNLP 2024"},{"id":"http://arxiv.org/abs/2407.17023v2","updated":"2024-10-07T11:59:37Z","published":"2024-07-24T06:06:07Z","title":"DYNAMICQA: Tracing Internal Knowledge Conflicts in Language Models","summary":"  Knowledge-intensive language understanding tasks require Language Models\n(LMs) to integrate relevant context, mitigating their inherent weaknesses, such\nas incomplete or outdated knowledge. However, conflicting knowledge can be\npresent in the LM's parameters, termed intra-memory conflict, which can affect\na model's propensity to accept contextual knowledge. To study the effect of\nintra-memory conflict on an LM's ability to accept relevant context, we utilize\ntwo knowledge conflict measures and a novel dataset containing inherently\nconflicting data, DynamicQA. This dataset includes facts with a temporal\ndynamic nature where facts can change over time and disputable dynamic facts,\nwhich can change depending on the viewpoint. DynamicQA is the first to include\nreal-world knowledge conflicts and provide context to study the link between\nthe different types of knowledge conflicts. We also evaluate several measures\non their ability to reflect the presence of intra-memory conflict: semantic\nentropy and a novel coherent persuasion score. With our extensive experiments,\nwe verify that LMs exhibit a greater degree of intra-memory conflict with\ndynamic facts compared to facts that have a single truth value. Furthermore, we\nreveal that facts with intra-memory conflict are harder to update with context,\nsuggesting that retrieval-augmented generation will struggle with the most\ncommonly adapted facts.\n","authors":["Sara Vera Marjanović","Haeun Yu","Pepa Atanasova","Maria Maistro","Christina Lioma","Isabelle Augenstein"],"pdf_url":"https://arxiv.org/pdf/2407.17023v2.pdf","comment":"15 pages, 6 figures, Accepted to Findings of EMNLP 2024"},{"id":"http://arxiv.org/abs/2410.01628v2","updated":"2024-10-07T11:57:37Z","published":"2024-10-02T15:02:32Z","title":"Entropy-Based Uncertainty Modeling for Trajectory Prediction in\n  Autonomous Driving","summary":"  In autonomous driving, accurate motion prediction is essential for safe and\nefficient motion planning. To ensure safety, planners must rely on reliable\nuncertainty information about the predicted future behavior of surrounding\nagents, yet this aspect has received limited attention. This paper addresses\nthe so-far neglected problem of uncertainty modeling in trajectory prediction.\nWe adopt a holistic approach that focuses on uncertainty quantification,\ndecomposition, and the influence of model composition. Our method is based on a\ntheoretically grounded information-theoretic approach to measure uncertainty,\nallowing us to decompose total uncertainty into its aleatoric and epistemic\ncomponents. We conduct extensive experiments on the nuScenes dataset to assess\nhow different model architectures and configurations affect uncertainty\nquantification and model robustness.\n","authors":["Aron Distelzweig","Andreas Look","Eitan Kosman","Faris Janjoš","Jörg Wagner","Abhinav Valada"],"pdf_url":"https://arxiv.org/pdf/2410.01628v2.pdf","comment":"10 pages, 5 figures, submitted to International Conference on\n  Learning Representations (2025)"},{"id":"http://arxiv.org/abs/2407.10805v4","updated":"2024-10-07T11:52:50Z","published":"2024-07-15T15:20:40Z","title":"Think-on-Graph 2.0: Deep and Faithful Large Language Model Reasoning\n  with Knowledge-guided Retrieval Augmented Generation","summary":"  Retrieval-augmented generation (RAG) has enhanced large language models\n(LLMs) by using knowledge retrieval to address knowledge gaps. However,\nexisting RAG approaches often fail to ensure the depth and completeness of the\ninformation retrieved, which is essential for complex reasoning tasks. In this\nwork, we present Think-on-Graph 2.0 (ToG-2), a hybrid RAG framework that\niteratively retrieves information from both unstructured and structured\nknowledge sources in a tightly integrated manner. Specifically, ToG-2 leverages\nknowledge graphs (KGs) to connect documents via entities, facilitating deep and\nknowledge-guided context retrieval. Simultaneously, it uses documents as entity\ncontexts to enable precise and efficient graph retrieval.\n  ToG-2 alternates between graph retrieval and context retrieval to search for\nin-depth clues relevant to the question, enabling LLMs to generate accurate\nanswers. We conduct a series of experiments to demonstrate the following\nadvantages of ToG-2: (1) ToG-2 tightly integrates context retrieval and graph\nretrieval, enhancing context retrieval through the KG while enabling reliable\ngraph retrieval based on contexts; (2) it achieves deep and faithful reasoning\nin LLMs through an iterative knowledge retrieval process that integrates\ncontexts and the KG; and (3) ToG-2 is training-free and compatible with various\nLLMs as a plug-and-play solution. Extensive experiments show that ToG-2\nachieves state-of-the-art (SOTA) performance on 6 out of 7 knowledge-intensive\ndatasets with GPT-3.5, and can elevate the performance of smaller models (e.g.,\nLLAMA-2-13B) to the level of GPT-3.5's direct reasoning.\n","authors":["Shengjie Ma","Chengjin Xu","Xuhui Jiang","Muzhi Li","Huaren Qu","Cehao Yang","Jiaxin Mao","Jian Guo"],"pdf_url":"https://arxiv.org/pdf/2407.10805v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04949v1","updated":"2024-10-07T11:45:04Z","published":"2024-10-07T11:45:04Z","title":"Leverage Knowledge Graph and Large Language Model for Law Article\n  Recommendation: A Case Study of Chinese Criminal Law","summary":"  Court efficiency is vital for social stability. However, in most countries\naround the world, the grassroots courts face case backlogs, with decisions\nrelying heavily on judicial personnel's cognitive labor, lacking intelligent\ntools to improve efficiency. To address this issue, we propose an efficient law\narticle recommendation approach utilizing a Knowledge Graph (KG) and a Large\nLanguage Model (LLM). Firstly, we propose a Case-Enhanced Law Article Knowledge\nGraph (CLAKG) as a database to store current law statutes, historical case\ninformation, and correspondence between law articles and historical cases.\nAdditionally, we introduce an automated CLAKG construction method based on LLM.\nOn this basis, we propose a closed-loop law article recommendation method.\nFinally, through a series of experiments using judgment documents from the\nwebsite \"China Judgements Online\", we have improved the accuracy of law article\nrecommendation in cases from 0.549 to 0.694, demonstrating that our proposed\nmethod significantly outperforms baseline approaches.\n","authors":["Yongming Chen","Miner Chen","Ye Zhu","Juan Pei","Siyu Chen","Yu Zhou","Yi Wang","Yifan Zhou","Hao Li","Songan Zhang"],"pdf_url":"https://arxiv.org/pdf/2410.04949v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.11439v2","updated":"2024-10-07T11:44:38Z","published":"2024-09-16T09:19:19Z","title":"Machine listening in a neonatal intensive care unit","summary":"  Oxygenators, alarm devices, and footsteps are some of the most common sound\nsources in a hospital. Detecting them has scientific value for environmental\npsychology but comes with challenges of its own: namely, privacy preservation\nand limited labeled data. In this paper, we address these two challenges via a\ncombination of edge computing and cloud computing. For privacy preservation, we\nhave designed an acoustic sensor which computes third-octave spectrograms on\nthe fly instead of recording audio waveforms. For sample-efficient machine\nlearning, we have repurposed a pretrained audio neural network (PANN) via\nspectral transcoding and label space adaptation. A small-scale study in a\nneonatological intensive care unit (NICU) confirms that the time series of\ndetected events align with another modality of measurement: i.e., electronic\nbadges for parents and healthcare professionals. Hence, this paper demonstrates\nthe feasibility of polyphonic machine listening in a hospital ward while\nguaranteeing privacy by design.\n","authors":["Modan Tailleur","Vincent Lostanlen","Jean-Philippe Rivière","Pierre Aumond"],"pdf_url":"https://arxiv.org/pdf/2409.11439v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04946v1","updated":"2024-10-07T11:43:42Z","published":"2024-10-07T11:43:42Z","title":"Real-time Ship Recognition and Georeferencing for the Improvement of\n  Maritime Situational Awareness","summary":"  In an era where maritime infrastructures are crucial, advanced situational\nawareness solutions are increasingly important. The use of optical camera\nsystems can allow real-time usage of maritime footage. This thesis presents an\ninvestigation into leveraging deep learning and computer vision to advance\nreal-time ship recognition and georeferencing for the improvement of maritime\nsituational awareness. A novel dataset, ShipSG, is introduced, containing 3,505\nimages and 11,625 ship masks with corresponding class and geographic position.\nAfter an exploration of state-of-the-art, a custom real-time segmentation\narchitecture, ScatYOLOv8+CBAM, is designed for the NVIDIA Jetson AGX Xavier\nembedded system. This architecture adds the 2D scattering transform and\nattention mechanisms to YOLOv8, achieving an mAP of 75.46% and an 25.3 ms per\nframe, outperforming state-of-the-art methods by over 5%. To improve small and\ndistant ship recognition in high-resolution images on embedded systems, an\nenhanced slicing mechanism is introduced, improving mAP by 8% to 11%.\nAdditionally, a georeferencing method is proposed, achieving positioning errors\nof 18 m for ships up to 400 m away and 44 m for ships between 400 m and 1200 m.\nThe findings are also applied in real-world scenarios, such as the detection of\nabnormal ship behaviour, camera integrity assessment and 3D reconstruction. The\napproach of this thesis outperforms existing methods and provides a framework\nfor integrating recognized and georeferenced ships into real-time systems,\nenhancing operational effectiveness and decision-making for maritime\nstakeholders. This thesis contributes to the maritime computer vision field by\nestablishing a benchmark for ship segmentation and georeferencing research,\ndemonstrating the viability of deep-learning-based recognition and\ngeoreferencing methods for real-time maritime monitoring.\n","authors":["Borja Carrillo Perez"],"pdf_url":"https://arxiv.org/pdf/2410.04946v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04941v1","updated":"2024-10-07T11:35:24Z","published":"2024-10-07T11:35:24Z","title":"Detecting and Approximating Redundant Computational Blocks in Neural\n  Networks","summary":"  Deep neural networks often learn similar internal representations, both\nacross different models and within their own layers. While inter-network\nsimilarities have enabled techniques such as model stitching and merging,\nintra-network similarities present new opportunities for designing more\nefficient architectures. In this paper, we investigate the emergence of these\ninternal similarities across different layers in diverse neural architectures,\nshowing that similarity patterns emerge independently of the datataset used. We\nintroduce a simple metric, Block Redundancy, to detect redundant blocks,\nproviding a foundation for future architectural optimization methods. Building\non this, we propose Redundant Blocks Approximation (RBA), a general framework\nthat identifies and approximates one or more redundant computational blocks\nusing simpler transformations. We show that the transformation $\\mathcal{T}$\nbetween two representations can be efficiently computed in closed-form, and it\nis enough to replace the redundant blocks from the network. RBA reduces model\nparameters and time complexity while maintaining good performance. We validate\nour method on classification tasks in the vision domain using a variety of\npretrained foundational models and datasets.\n","authors":["Irene Cannistraci","Emanuele Rodolà","Bastian Rieck"],"pdf_url":"https://arxiv.org/pdf/2410.04941v1.pdf","comment":"9 pages, 10 figures, 7 tables"},{"id":"http://arxiv.org/abs/2410.04936v1","updated":"2024-10-07T11:27:45Z","published":"2024-10-07T11:27:45Z","title":"Training Interactive Agent in Large FPS Game Map with Rule-enhanced\n  Reinforcement Learning","summary":"  In the realm of competitive gaming, 3D first-person shooter (FPS) games have\ngained immense popularity, prompting the development of game AI systems to\nenhance gameplay. However, deploying game AI in practical scenarios still poses\nchallenges, particularly in large-scale and complex FPS games. In this paper,\nwe focus on the practical deployment of game AI in the online multiplayer\ncompetitive 3D FPS game called Arena Breakout, developed by Tencent Games. We\npropose a novel gaming AI system named Private Military Company Agent (PMCA),\nwhich is interactable within a large game map and engages in combat with\nplayers while utilizing tactical advantages provided by the surrounding\nterrain.\n  To address the challenges of navigation and combat in modern 3D FPS games, we\nintroduce a method that combines navigation mesh (Navmesh) and shooting-rule\nwith deep reinforcement learning (NSRL). The integration of Navmesh enhances\nthe agent's global navigation capabilities while shooting behavior is\ncontrolled using rule-based methods to ensure controllability. NSRL employs a\nDRL model to predict when to enable the navigation mesh, resulting in a diverse\nrange of behaviors for the game AI. Customized rewards for human-like behaviors\nare also employed to align PMCA's behavior with that of human players.\n","authors":["Chen Zhang","Huan Hu","Yuan Zhou","Qiyang Cao","Ruochen Liu","Wenya Wei","Elvis S. Liu"],"pdf_url":"https://arxiv.org/pdf/2410.04936v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04931v1","updated":"2024-10-07T11:24:29Z","published":"2024-10-07T11:24:29Z","title":"The Role of Governments in Increasing Interconnected Post-Deployment\n  Monitoring of AI","summary":"  Language-based AI systems are diffusing into society, bringing positive and\nnegative impacts. Mitigating negative impacts depends on accurate impact\nassessments, drawn from an empirical evidence base that makes causal\nconnections between AI usage and impacts. Interconnected post-deployment\nmonitoring combines information about model integration and use, application\nuse, and incidents and impacts. For example, inference time monitoring of\nchain-of-thought reasoning can be combined with long-term monitoring of\nsectoral AI diffusion, impacts and incidents. Drawing on information sharing\nmechanisms in other industries, we highlight example data sources and specific\ndata points that governments could collect to inform AI risk management.\n","authors":["Merlin Stein","Jamie Bernardi","Connor Dunlop"],"pdf_url":"https://arxiv.org/pdf/2410.04931v1.pdf","comment":"7 pages, 2 figures, 1 table"},{"id":"http://arxiv.org/abs/2410.04916v1","updated":"2024-10-07T11:04:38Z","published":"2024-10-07T11:04:38Z","title":"Defense-as-a-Service: Black-box Shielding against Backdoored Graph\n  Models","summary":"  With the trend of large graph learning models, business owners tend to employ\na model provided by a third party to deliver business services to users.\nHowever, these models might be backdoored, and malicious users can submit\ntrigger-embedded inputs to manipulate the model predictions. Current graph\nbackdoor defenses have several limitations: 1) depending on model-related\ndetails, 2) requiring additional model fine-tuning, and 3) relying upon extra\nexplainability tools, all of which are infeasible under stringent privacy\npolicies. To address those limitations, we propose GraphProt, which allows\nresource-constrained business owners to rely on third parties to avoid backdoor\nattacks on GNN-based graph classifiers. Our GraphProt is model-agnostic and\nonly relies on the input graph. The key insight is to leverage subgraph\ninformation for prediction, thereby mitigating backdoor effects induced by\ntriggers. GraphProt comprises two components: clustering-based trigger\nelimination and robust subgraph ensemble. Specifically, we first propose\nfeature-topology clustering that aims to remove most of the anomalous subgraphs\n(triggers). Moreover, we design subgraph sampling strategies based on\nfeature-topology clustering to build a robust classifier via majority vote.\nExperimental results across three backdoor attacks and six benchmark datasets\ndemonstrate that GraphProt significantly reduces the backdoor attack success\nrate while preserving the model accuracy on regular graph classification tasks.\n","authors":["Xiao Yang","Kai Zhou","Yuni Lai","Gaolei Li"],"pdf_url":"https://arxiv.org/pdf/2410.04916v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.07578v2","updated":"2024-10-07T11:04:31Z","published":"2024-09-11T19:10:29Z","title":"A Novel Mathematical Framework for Objective Characterization of Ideas\n  through Vector Embeddings in LLM","summary":"  The demand for innovation in product design necessitates a prolific ideation\nphase. Conversational AI (CAI) systems that use Large Language Models (LLMs)\nsuch as GPT (Generative Pre-trained Transformer) have been shown to be fruitful\nin augmenting human creativity, providing numerous novel and diverse ideas.\nDespite the success in ideation quantity, the qualitative assessment of these\nideas remains challenging and traditionally reliant on expert human evaluation.\nThis method suffers from limitations such as human judgment errors, bias, and\noversight. Addressing this gap, our study introduces a comprehensive\nmathematical framework for automated analysis to objectively evaluate the\nplethora of ideas generated by CAI systems and/or humans. This framework is\nparticularly advantageous for novice designers who lack experience in selecting\npromising ideas. By converting the ideas into higher dimensional vectors and\nquantitatively measuring the diversity between them using tools such as UMAP,\nDBSCAN and PCA, the proposed method provides a reliable and objective way of\nselecting the most promising ideas, thereby enhancing the efficiency of the\nideation phase.\n","authors":["B. Sankar","Dibakar Sen"],"pdf_url":"https://arxiv.org/pdf/2409.07578v2.pdf","comment":"20 pages, 12 figures, 5 tables"},{"id":"http://arxiv.org/abs/2403.12510v2","updated":"2024-10-07T10:31:58Z","published":"2024-03-19T07:24:54Z","title":"Generalized Consistency Trajectory Models for Image Manipulation","summary":"  Diffusion models (DMs) excel in unconditional generation, as well as on\napplications such as image editing and restoration. The success of DMs lies in\nthe iterative nature of diffusion: diffusion breaks down the complex process of\nmapping noise to data into a sequence of simple denoising tasks. Moreover, we\nare able to exert fine-grained control over the generation process by injecting\nguidance terms into each denoising step. However, the iterative process is also\ncomputationally intensive, often taking from tens up to thousands of function\nevaluations. Although consistency trajectory models (CTMs) enable traversal\nbetween any time points along the probability flow ODE (PFODE) and score\ninference with a single function evaluation, CTMs only allow translation from\nGaussian noise to data. This work aims to unlock the full potential of CTMs by\nproposing generalized CTMs (GCTMs), which translate between arbitrary\ndistributions via ODEs. We discuss the design space of GCTMs and demonstrate\ntheir efficacy in various image manipulation tasks such as image-to-image\ntranslation, restoration, and editing.\n","authors":["Beomsu Kim","Jaemin Kim","Jeongsol Kim","Jong Chul Ye"],"pdf_url":"https://arxiv.org/pdf/2403.12510v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.11834v4","updated":"2024-10-07T10:28:24Z","published":"2023-12-19T04:02:50Z","title":"Multi-agent reinforcement learning using echo-state network and its\n  application to pedestrian dynamics","summary":"  In recent years, simulations of pedestrians using the multi-agent\nreinforcement learning (MARL) have been studied. This study considered the\nroads on a grid-world environment, and implemented pedestrians as MARL agents\nusing an echo-state network and the least squares policy iteration method.\nUnder this environment, the ability of these agents to learn to move forward by\navoiding other agents was investigated. Specifically, we considered two types\nof tasks: the choice between a narrow direct route and a broad detour, and the\nbidirectional pedestrian flow in a corridor. The simulations results indicated\nthat the learning was successful when the density of the agents was not that\nhigh.\n","authors":["Hisato Komatsu"],"pdf_url":"https://arxiv.org/pdf/2312.11834v4.pdf","comment":"25 pages, 19 figures"},{"id":"http://arxiv.org/abs/2402.06165v4","updated":"2024-10-07T10:14:00Z","published":"2024-02-09T03:48:20Z","title":"Learning Contrastive Feature Representations for Facial Action Unit\n  Detection","summary":"  Facial action unit (AU) detection has long encountered the challenge of\ndetecting subtle feature differences when AUs activate. Existing methods often\nrely on encoding pixel-level information of AUs, which not only encodes\nadditional redundant information but also leads to increased model complexity\nand limited generalizability. Additionally, the accuracy of AU detection is\nnegatively impacted by the class imbalance issue of each AU type, and the\npresence of noisy and false AU labels. In this paper, we introduce a novel\ncontrastive learning framework aimed for AU detection that incorporates both\nself-supervised and supervised signals, thereby enhancing the learning of\ndiscriminative features for accurate AU detection. To tackle the class\nimbalance issue, we employ a negative sample re-weighting strategy that adjusts\nthe step size of updating parameters for minority and majority class samples.\nMoreover, to address the challenges posed by noisy and false AU labels, we\nemploy a sampling technique that encompasses three distinct types of positive\nsample pairs. This enables us to inject self-supervised signals into the\nsupervised signal, effectively mitigating the adverse effects of noisy labels.\nOur experimental assessments, conducted on four widely-utilized benchmark\ndatasets (BP4D, DISFA, GFT and Aff-Wild2), underscore the superior performance\nof our approach compared to state-of-the-art methods of AU detection. Our code\nis available at \\url{https://github.com/Ziqiao-Shang/AUNCE}.\n","authors":["Ziqiao Shang","Bin Liu","Fengmao Lv","Fei Teng","Tianrui Li"],"pdf_url":"https://arxiv.org/pdf/2402.06165v4.pdf","comment":"13 pages, 17 figures, submitted to IEEE Transactions on Circuits and\n  Systems for Video Technology (TCSVT)"},{"id":"http://arxiv.org/abs/2404.02817v5","updated":"2024-10-07T10:09:16Z","published":"2024-04-03T15:38:36Z","title":"A Survey of Optimization-based Task and Motion Planning: From Classical\n  To Learning Approaches","summary":"  Task and Motion Planning (TAMP) integrates high-level task planning and\nlow-level motion planning to equip robots with the autonomy to effectively\nreason over long-horizon, dynamic tasks. Optimization-based TAMP focuses on\nhybrid optimization approaches that define goal conditions via objective\nfunctions and are capable of handling open-ended goals, robotic dynamics, and\nphysical interaction between the robot and the environment. Therefore,\noptimization-based TAMP is particularly suited to solve highly complex,\ncontact-rich locomotion and manipulation problems. This survey provides a\ncomprehensive review on optimization-based TAMP, covering (i) planning domain\nrepresentations, including action description languages and temporal logic,\n(ii) individual solution strategies for components of TAMP, including AI\nplanning and trajectory optimization (TO), and (iii) the dynamic interplay\nbetween logic-based task planning and model-based TO. A particular focus of\nthis survey is to highlight the algorithm structures to efficiently solve TAMP,\nespecially hierarchical and distributed approaches. Additionally, the survey\nemphasizes the synergy between the classical methods and contemporary\nlearning-based innovations such as large language models. Furthermore, the\nfuture research directions for TAMP is discussed in this survey, highlighting\nboth algorithmic and application-specific challenges.\n","authors":["Zhigen Zhao","Shuo Cheng","Yan Ding","Ziyi Zhou","Shiqi Zhang","Danfei Xu","Ye Zhao"],"pdf_url":"https://arxiv.org/pdf/2404.02817v5.pdf","comment":"26 pages, 13 figures, published at IEEE/ASME Transactions on\n  Mechatronics"},{"id":"http://arxiv.org/abs/2410.04884v1","updated":"2024-10-07T10:06:01Z","published":"2024-10-07T10:06:01Z","title":"Patch is Enough: Naturalistic Adversarial Patch against Vision-Language\n  Pre-training Models","summary":"  Visual language pre-training (VLP) models have demonstrated significant\nsuccess across various domains, yet they remain vulnerable to adversarial\nattacks. Addressing these adversarial vulnerabilities is crucial for enhancing\nsecurity in multimodal learning. Traditionally, adversarial methods targeting\nVLP models involve simultaneously perturbing images and text. However, this\napproach faces notable challenges: first, adversarial perturbations often fail\nto translate effectively into real-world scenarios; second, direct\nmodifications to the text are conspicuously visible. To overcome these\nlimitations, we propose a novel strategy that exclusively employs image patches\nfor attacks, thus preserving the integrity of the original text. Our method\nleverages prior knowledge from diffusion models to enhance the authenticity and\nnaturalness of the perturbations. Moreover, to optimize patch placement and\nimprove the efficacy of our attacks, we utilize the cross-attention mechanism,\nwhich encapsulates intermodal interactions by generating attention maps to\nguide strategic patch placements. Comprehensive experiments conducted in a\nwhite-box setting for image-to-text scenarios reveal that our proposed method\nsignificantly outperforms existing techniques, achieving a 100% attack success\nrate. Additionally, it demonstrates commendable performance in transfer tasks\ninvolving text-to-image configurations.\n","authors":["Dehong Kong","Siyuan Liang","Xiaopeng Zhu","Yuansheng Zhong","Wenqi Ren"],"pdf_url":"https://arxiv.org/pdf/2410.04884v1.pdf","comment":"accepted by Visual Intelligence"},{"id":"http://arxiv.org/abs/2302.00671v2","updated":"2024-10-07T10:04:28Z","published":"2023-02-01T18:58:20Z","title":"QMP: Q-switch Mixture of Policies for Multi-Task Behavior Sharing","summary":"  Multi-task reinforcement learning (MTRL) aims to learn several tasks\nsimultaneously for better sample efficiency than learning them separately.\nTraditional methods achieve this by sharing parameters or relabeled data\nbetween tasks. In this work, we introduce a new framework for sharing\nbehavioral policies across tasks, which can be used in addition to existing\nMTRL methods. The key idea is to improve each task's off-policy data collection\nby employing behaviors from other task policies. Selectively sharing helpful\nbehaviors acquired in one task to collect training data for another task can\nlead to higher-quality trajectories, leading to more sample-efficient MTRL.\nThus, we introduce a simple and principled framework called Q-switch mixture of\npolicies (QMP) that selectively shares behavior between different task policies\nby using the task's Q-function to evaluate and select useful shareable\nbehaviors. We theoretically analyze how QMP improves the sample efficiency of\nthe underlying RL algorithm. Our experiments show that QMP's behavioral policy\nsharing provides complementary gains over many popular MTRL algorithms and\noutperforms alternative ways to share behaviors in various manipulation,\nlocomotion, and navigation environments. Videos are available at\nhttps://qmp-mtrl.github.io.\n","authors":["Grace Zhang","Ayush Jain","Injune Hwang","Shao-Hua Sun","Joseph J. Lim"],"pdf_url":"https://arxiv.org/pdf/2302.00671v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.05930v4","updated":"2024-10-07T09:58:48Z","published":"2024-01-11T14:09:09Z","title":"SH2: Self-Highlighted Hesitation Helps You Decode More Truthfully","summary":"  Large language models (LLMs) demonstrate great performance in text\ngeneration. However, LLMs are still suffering from hallucinations. In this\nwork, we propose an inference-time method, Self-Highlighted Hesitation (SH2),\nto help LLMs decode more truthfully. SH2 is based on a simple fact rooted in\ninformation theory that for an LLM, the tokens predicted with lower\nprobabilities are prone to be more informative than others. Our analysis shows\nthat the tokens assigned with lower probabilities by an LLM are more likely to\nbe closely related to factual information, such as nouns, proper nouns, and\nadjectives. Therefore, we propose to ''highlight'' the factual information by\nselecting the tokens with the lowest probabilities and concatenating them to\nthe original context, thus forcing the model to repeatedly read and hesitate on\nthese tokens before generation. During decoding, we also adopt contrastive\ndecoding to emphasize the difference in the output probabilities brought by the\nhesitation. Experimental results demonstrate that our SH2, requiring no\nadditional data or models, can effectively help LLMs elicit factual knowledge\nand distinguish hallucinated contexts. Significant and consistent improvements\nare achieved by SH2 for LLaMA-7b, LLaMA2-7b and Mistral-7b on multiple\nhallucination tasks.\n","authors":["Jushi Kai","Tianhang Zhang","Hai Hu","Zhouhan Lin"],"pdf_url":"https://arxiv.org/pdf/2401.05930v4.pdf","comment":"EMNLP 2024 Findings"},{"id":"http://arxiv.org/abs/2410.04878v1","updated":"2024-10-07T09:57:59Z","published":"2024-10-07T09:57:59Z","title":"Leveraging Grammar Induction for Language Understanding and Generation","summary":"  Grammar induction has made significant progress in recent years. However, it\nis not clear how the application of induced grammar could enhance practical\nperformance in downstream tasks. In this work, we introduce an unsupervised\ngrammar induction method for language understanding and generation. We\nconstruct a grammar parser to induce constituency structures and dependency\nrelations, which is simultaneously trained on downstream tasks without\nadditional syntax annotations. The induced grammar features are subsequently\nincorporated into Transformer as a syntactic mask to guide self-attention. We\nevaluate and apply our method to multiple machine translation tasks and natural\nlanguage understanding tasks. Our method demonstrates superior performance\ncompared to the original Transformer and other models enhanced with external\nparsers. Experimental results indicate that our method is effective in both\nfrom-scratch and pre-trained scenarios. Additionally, our research highlights\nthe contribution of explicitly modeling the grammatical structure of texts to\nneural network models.\n","authors":["Jushi Kai","Shengyuan Hou","Yusheng Huang","Zhouhan Lin"],"pdf_url":"https://arxiv.org/pdf/2410.04878v1.pdf","comment":"EMNLP 2024 Findings"},{"id":"http://arxiv.org/abs/2407.08227v2","updated":"2024-10-07T09:51:46Z","published":"2024-07-11T07:01:50Z","title":"DALL-M: Context-Aware Clinical Data Augmentation with LLMs","summary":"  X-ray images are vital in medical diagnostics, but their effectiveness is\nlimited without clinical context. Radiologists often find chest X-rays\ninsufficient for diagnosing underlying diseases, necessitating comprehensive\nclinical features and data integration. We present a novel framework to enhance\nthe clinical context through augmentation techniques with clinical tabular\ndata, thereby improving its applicability and reliability in AI medical\ndiagnostics. We introduce a pioneering approach to clinical data augmentation\nthat employs large language models to generate patient contextual synthetic\ndata. This methodology is crucial for training more robust deep learning models\nin healthcare. It preserves the integrity of real patient data while enriching\nthe dataset with contextually relevant synthetic features, significantly\nenhancing model performance. Our methodology, termed DALL-M, uses a three-phase\nfeature generation process: (i)clinical context storage, (ii)expert query\ngeneration, and (iii)context-aware feature augmentation. DALL-M generates new,\nclinically relevant features by synthesizing chest X-ray images and reports.\nApplied to 799 cases using nine features from the MIMIC-IV dataset, it created\nan augmented set of 91 features. This is the first work to generate contextual\nvalues for patients' X-ray reports. Specifically, we provide (i)the capacity of\nLLMs to generate contextual synthetic values for existing clinical features and\n(ii)their ability to create entirely new clinically relevant features.\nEmpirical validation with machine learning models showed significant\nperformance improvements. Incorporating augmented features increased the F1\nscore by 16.5% and Precision and Recall by approximately 25%. DALL-M addresses\na critical gap in clinical data augmentation, offering a robust framework for\ngenerating contextually enriched datasets.\n","authors":["Chihcheng Hsieh","Catarina Moreira","Isabel Blanco Nobre","Sandra Costa Sousa","Chun Ouyang","Margot Brereton","Joaquim Jorge","Jacinto C. Nascimento"],"pdf_url":"https://arxiv.org/pdf/2407.08227v2.pdf","comment":"we introduce a pioneering approach to clinical data augmentation that\n  employs large language models (LLMs) to generate patient contextual synthetic\n  data. It preserves the integrity of real patient data while enriching the\n  dataset with contextually relevant synthetic features, significantly\n  enhancing model performance"},{"id":"http://arxiv.org/abs/2408.15625v2","updated":"2024-10-07T09:49:08Z","published":"2024-08-28T08:25:22Z","title":"CBF-LLM: Safe Control for LLM Alignment","summary":"  This paper proposes a control-based framework for aligning large language\nmodels (LLMs) by leveraging a control barrier function (CBF) to ensure\nuser-desirable text generation. The presented framework applies the safety\nfilter, designed based on the CBF, to the output generation of the baseline\nLLM, i.e., the sequence of the token, with the aim of intervening in the\ngenerated text. The overall text-generation system is implemented with Llama 3\nand a RoBERTa model, and the source code is available at\nhttps://github.com/Mya-Mya/CBF-LLM. The experiment demonstrates its control\nability and effectiveness in reducing the number of interventions needed for\nuser-specified alignment tasks.\n","authors":["Yuya Miyaoka","Masaki Inoue"],"pdf_url":"https://arxiv.org/pdf/2408.15625v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.16665v2","updated":"2024-10-07T09:46:07Z","published":"2024-07-23T17:32:02Z","title":"A Framework for Pupil Tracking with Event Cameras","summary":"  Saccades are extremely rapid movements of both eyes that occur\nsimultaneously, typically observed when an individual shifts their focus from\none object to another. These movements are among the swiftest produced by\nhumans and possess the potential to achieve velocities greater than that of\nblinks. The peak angular speed of the eye during a saccade can reach as high as\n700{\\deg}/s in humans, especially during larger saccades that cover a visual\nangle of 25{\\deg}. Previous research has demonstrated encouraging outcomes in\ncomprehending neurological conditions through the study of saccades. A\nnecessary step in saccade detection involves accurately identifying the precise\nlocation of the pupil within the eye, from which additional information such as\ngaze angles can be inferred. Conventional frame-based cameras often struggle\nwith the high temporal precision necessary for tracking very fast movements,\nresulting in motion blur and latency issues. Event cameras, on the other hand,\noffer a promising alternative by recording changes in the visual scene\nasynchronously and providing high temporal resolution and low latency. By\nbridging the gap between traditional computer vision and event-based vision, we\npresent events as frames that can be readily utilized by standard deep learning\nalgorithms. This approach harnesses YOLOv8, a state-of-the-art object detection\ntechnology, to process these frames for pupil tracking using the publicly\naccessible Ev-Eye dataset. Experimental results demonstrate the framework's\neffectiveness, highlighting its potential applications in neuroscience,\nophthalmology, and human-computer interaction.\n","authors":["Khadija Iddrisu","Waseem Shariff","Suzanne Little"],"pdf_url":"https://arxiv.org/pdf/2407.16665v2.pdf","comment":"This paper is a preprint of a paper submitted to the 26th Irish\n  Machine Vision and Image Processing Conference (IMVIP 2024). If accepted, the\n  copy of record will be available at IET Digital Library"},{"id":"http://arxiv.org/abs/2407.15325v2","updated":"2024-10-07T09:40:07Z","published":"2024-07-22T02:06:59Z","title":"Odyssey: Empowering Minecraft Agents with Open-World Skills","summary":"  Recent studies have delved into constructing generalist agents for open-world\nenvironments like Minecraft. Despite the encouraging results, existing efforts\nmainly focus on solving basic programmatic tasks, e.g., material collection and\ntool-crafting following the Minecraft tech-tree, treating the ObtainDiamond\ntask as the ultimate goal. This limitation stems from the narrowly defined set\nof actions available to agents, requiring them to learn effective long-horizon\nstrategies from scratch. Consequently, discovering diverse gameplay\nopportunities in the open world becomes challenging. In this work, we introduce\nOdyssey, a new framework that empowers Large Language Model (LLM)-based agents\nwith open-world skills to explore the vast Minecraft world. Odyssey comprises\nthree key parts: (1) An interactive agent with an open-world skill library that\nconsists of 40 primitive skills and 183 compositional skills. (2) A fine-tuned\nLLaMA-3 model trained on a large question-answering dataset with 390k+\ninstruction entries derived from the Minecraft Wiki. (3) A new agent capability\nbenchmark includes the long-term planning task, the dynamic-immediate planning\ntask, and the autonomous exploration task. Extensive experiments demonstrate\nthat the proposed Odyssey framework can effectively evaluate different\ncapabilities of LLM-based agents. All datasets, model weights, and code are\npublicly available to motivate future research on more advanced autonomous\nagent solutions.\n","authors":["Shunyu Liu","Yaoru Li","Kongcheng Zhang","Zhenyu Cui","Wenkai Fang","Yuxuan Zheng","Tongya Zheng","Mingli Song"],"pdf_url":"https://arxiv.org/pdf/2407.15325v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04865v1","updated":"2024-10-07T09:27:51Z","published":"2024-10-07T09:27:51Z","title":"Mastering Chinese Chess AI (Xiangqi) Without Search","summary":"  We have developed a high-performance Chinese Chess AI that operates without\nreliance on search algorithms. This AI has demonstrated the capability to\ncompete at a level commensurate with the top 0.1\\% of human players. By\neliminating the search process typically associated with such systems, this AI\nachieves a Queries Per Second (QPS) rate that exceeds those of systems based on\nthe Monte Carlo Tree Search (MCTS) algorithm by over a thousandfold and\nsurpasses those based on the AlphaBeta pruning algorithm by more than a\nhundredfold. The AI training system consists of two parts: supervised learning\nand reinforcement learning. Supervised learning provides an initial human-like\nChinese chess AI, while reinforcement learning, based on supervised learning,\nelevates the strength of the entire AI to a new level. Based on this training\nsystem, we carried out enough ablation experiments and discovered that 1. The\nsame parameter amount of Transformer architecture has a higher performance than\nCNN on Chinese chess; 2. Possible moves of both sides as features can greatly\nimprove the training process; 3. Selective opponent pool, compared to pure\nself-play training, results in a faster improvement curve and a higher strength\nlimit. 4. Value Estimation with Cutoff(VECT) improves the original PPO\nalgorithm training process and we will give the explanation.\n","authors":["Yu Chen","Juntong Lin","Zhichao Shu"],"pdf_url":"https://arxiv.org/pdf/2410.04865v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04855v1","updated":"2024-10-07T09:19:13Z","published":"2024-10-07T09:19:13Z","title":"Unsupervised Skill Discovery for Robotic Manipulation through Automatic\n  Task Generation","summary":"  Learning skills that interact with objects is of major importance for robotic\nmanipulation. These skills can indeed serve as an efficient prior for solving\nvarious manipulation tasks. We propose a novel Skill Learning approach that\ndiscovers composable behaviors by solving a large and diverse number of\nautonomously generated tasks. Our method learns skills allowing the robot to\nconsistently and robustly interact with objects in its environment. The\ndiscovered behaviors are embedded in primitives which can be composed with\nHierarchical Reinforcement Learning to solve unseen manipulation tasks. In\nparticular, we leverage Asymmetric Self-Play to discover behaviors and\nMultiplicative Compositional Policies to embed them. We compare our method to\nSkill Learning baselines and find that our skills are more interactive.\nFurthermore, the learned skills can be used to solve a set of unseen\nmanipulation tasks, in simulation as well as on a real robotic platform.\n","authors":["Paul Jansonnie","Bingbing Wu","Julien Perez","Jan Peters"],"pdf_url":"https://arxiv.org/pdf/2410.04855v1.pdf","comment":"Accepted at the 2024 IEEE-RAS International Conference on Humanoid\n  Robots"},{"id":"http://arxiv.org/abs/2410.04853v1","updated":"2024-10-07T09:16:58Z","published":"2024-10-07T09:16:58Z","title":"TimeCNN: Refining Cross-Variable Interaction on Time Point for Time\n  Series Forecasting","summary":"  Time series forecasting is extensively applied across diverse domains.\nTransformer-based models demonstrate significant potential in modeling\ncross-time and cross-variable interaction. However, we notice that the\ncross-variable correlation of multivariate time series demonstrates\nmultifaceted (positive and negative correlations) and dynamic progression over\ntime, which is not well captured by existing Transformer-based models. To\naddress this issue, we propose a TimeCNN model to refine cross-variable\ninteractions to enhance time series forecasting. Its key innovation is\ntimepoint-independent, where each time point has an independent convolution\nkernel, allowing each time point to have its independent model to capture\nrelationships among variables. This approach effectively handles both positive\nand negative correlations and adapts to the evolving nature of variable\nrelationships over time. Extensive experiments conducted on 12 real-world\ndatasets demonstrate that TimeCNN consistently outperforms state-of-the-art\nmodels. Notably, our model achieves significant reductions in computational\nrequirements (approximately 60.46%) and parameter count (about 57.50%), while\ndelivering inference speeds 3 to 4 times faster than the benchmark iTransformer\nmodel\n","authors":["Ao Hu","Dongkai Wang","Yong Dai","Shiyi Qi","Liangjian Wen","Jun Wang","Zhi Chen","Xun Zhou","Zenglin Xu","Jiang Duan"],"pdf_url":"https://arxiv.org/pdf/2410.04853v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13538v5","updated":"2024-10-07T09:11:49Z","published":"2023-11-22T17:24:21Z","title":"AlignedCoT: Prompting Large Language Models via Native-Speaking\n  Demonstrations","summary":"  Large Language Models prompting, such as using in-context demonstrations, is\na mainstream technique for invoking LLMs to perform high-performance and solid\ncomplex reasoning (e.g., mathematical reasoning, commonsense reasoning), and\nhas the potential for further human-machine collaborative scientific findings.\nHowever, current LLMs are delicate and elusive in prompt words and styles. And\nthere is an unseen gap between LLM understanding and human-written prompts.\nThis paper introduces Alignedcot, an LLM-acquainted prompting technique that\nincludes proficient ``native-speaking'' in in-context learning for the LLMs.\nSpecifically, it achieves consistent and correct step-wise prompts in zero-shot\nscenarios by progressively probing, refining, and formatting the LLM chain of\nthoughts so that free from handcrafted few-shot demonstrations while\nmaintaining the prompt quality. We conduct experiments on mathematical\nreasoning and commonsense reasoning. We find that LLMs with Alignedcot perform\nsignificantly superior to them with human-crafted demonstrations. We further\napply Alignedcot for rewriting the GSM8K training set, resulting in a\nGSM8K-Align dataset. We observe its benefits for retrieval augmented\ngeneration. The code and data can be found at\nhttps://github.com/yangzhch6/AlignedCoT.\n","authors":["Zhicheng Yang","Yinya Huang","Jing Xiong","Liang Feng","Xiaodan Liang","Yiwei Wang","Jing Tang"],"pdf_url":"https://arxiv.org/pdf/2311.13538v5.pdf","comment":"Findings of EMNLP 2024"},{"id":"http://arxiv.org/abs/2410.04844v1","updated":"2024-10-07T09:04:50Z","published":"2024-10-07T09:04:50Z","title":"PostEdit: Posterior Sampling for Efficient Zero-Shot Image Editing","summary":"  In the field of image editing, three core challenges persist:\ncontrollability, background preservation, and efficiency. Inversion-based\nmethods rely on time-consuming optimization to preserve the features of the\ninitial images, which results in low efficiency due to the requirement for\nextensive network inference. Conversely, inversion-free methods lack\ntheoretical support for background similarity, as they circumvent the issue of\nmaintaining initial features to achieve efficiency. As a consequence, none of\nthese methods can achieve both high efficiency and background consistency. To\ntackle the challenges and the aforementioned disadvantages, we introduce\nPostEdit, a method that incorporates a posterior scheme to govern the diffusion\nsampling process. Specifically, a corresponding measurement term related to\nboth the initial features and Langevin dynamics is introduced to optimize the\nestimated image generated by the given target prompt. Extensive experimental\nresults indicate that the proposed PostEdit achieves state-of-the-art editing\nperformance while accurately preserving unedited regions. Furthermore, the\nmethod is both inversion- and training-free, necessitating approximately 1.5\nseconds and 18 GB of GPU memory to generate high-quality results.\n","authors":["Feng Tian","Yixuan Li","Yichao Yan","Shanyan Guan","Yanhao Ge","Xiaokang Yang"],"pdf_url":"https://arxiv.org/pdf/2410.04844v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.08313v2","updated":"2024-10-07T08:44:35Z","published":"2024-08-15T17:59:57Z","title":"Can Large Language Models Understand Symbolic Graphics Programs?","summary":"  Against the backdrop of enthusiasm for large language models (LLMs), there is\nan urgent need to scientifically assess their capabilities and shortcomings.\nThis is nontrivial in part because it is difficult to find tasks which the\nmodels have not encountered during training. Utilizing symbolic graphics\nprograms, we propose a domain well-suited to test multiple spatial-semantic\nreasoning skills of LLMs. Popular in computer graphics, these programs\nprocedurally generate visual data. While LLMs exhibit impressive skills in\ngeneral program synthesis and analysis, symbolic graphics programs offer a new\nlayer of evaluation: they allow us to test an LLM's ability to answer\ndifferent-grained semantic-level questions of the images or 3D geometries\nwithout a vision encoder. To semantically understand the symbolic programs,\nLLMs would need to possess the ability to \"imagine\" and reason how the\ncorresponding graphics content would look with only the symbolic description.\nWe use this task to evaluate LLMs by creating a large benchmark for the\nsemantic visual understanding of symbolic graphics programs, built procedurally\nwith minimal human effort. Particular emphasis is placed on transformations of\nimages that leave the image level semantics invariant while introducing\nsignificant changes to the underlying program. We evaluate commercial and\nopen-source LLMs on our benchmark to assess their ability to reason about\nvisual output of programs, finding that LLMs considered stronger at reasoning\ngenerally perform better. Lastly, we introduce a novel method to improve this\nability -- Symbolic Instruction Tuning (SIT), in which the LLM is finetuned\nwith pre-collected instruction data on symbolic graphics programs.\nInterestingly, we find that SIT not only improves LLM's understanding on\nsymbolic programs, but it also improves general reasoning ability on various\nother benchmarks.\n","authors":["Zeju Qiu","Weiyang Liu","Haiwen Feng","Zhen Liu","Tim Z. Xiao","Katherine M. Collins","Joshua B. Tenenbaum","Adrian Weller","Michael J. Black","Bernhard Schölkopf"],"pdf_url":"https://arxiv.org/pdf/2408.08313v2.pdf","comment":"Technical Report v2 (46 pages, 24 figures, project page:\n  https://sgp-bench.github.io/, substantial update from v1)"},{"id":"http://arxiv.org/abs/2410.04833v1","updated":"2024-10-07T08:40:29Z","published":"2024-10-07T08:40:29Z","title":"Multimodal Fusion Strategies for Mapping Biophysical Landscape Features","summary":"  Multimodal aerial data are used to monitor natural systems, and machine\nlearning can significantly accelerate the classification of landscape features\nwithin such imagery to benefit ecology and conservation. It remains\nunder-explored, however, how these multiple modalities ought to be fused in a\ndeep learning model. As a step towards filling this gap, we study three\nstrategies (Early fusion, Late fusion, and Mixture of Experts) for fusing\nthermal, RGB, and LiDAR imagery using a dataset of spatially-aligned\northomosaics in these three modalities. In particular, we aim to map three\necologically-relevant biophysical landscape features in African savanna\necosystems: rhino middens, termite mounds, and water. The three fusion\nstrategies differ in whether the modalities are fused early or late, and if\nlate, whether the model learns fixed weights per modality for each class or\ngenerates weights for each class adaptively, based on the input. Overall, the\nthree methods have similar macro-averaged performance with Late fusion\nachieving an AUC of 0.698, but their per-class performance varies strongly,\nwith Early fusion achieving the best recall for middens and water and Mixture\nof Experts achieving the best recall for mounds.\n","authors":["Lucia Gordon","Nico Lang","Catherine Ressijac","Andrew Davies"],"pdf_url":"https://arxiv.org/pdf/2410.04833v1.pdf","comment":"9 pages, 4 figures, ECCV 2024 Workshop in CV for Ecology"},{"id":"http://arxiv.org/abs/2405.07027v2","updated":"2024-10-07T08:28:43Z","published":"2024-05-11T14:57:42Z","title":"TD-NeRF: Novel Truncated Depth Prior for Joint Camera Pose and Neural\n  Radiance Field Optimization","summary":"  The reliance on accurate camera poses is a significant barrier to the\nwidespread deployment of Neural Radiance Fields (NeRF) models for 3D\nreconstruction and SLAM tasks. The existing method introduces monocular depth\npriors to jointly optimize the camera poses and NeRF, which fails to fully\nexploit the depth priors and neglects the impact of their inherent noise. In\nthis paper, we propose Truncated Depth NeRF (TD-NeRF), a novel approach that\nenables training NeRF from unknown camera poses - by jointly optimizing\nlearnable parameters of the radiance field and camera poses. Our approach\nexplicitly utilizes monocular depth priors through three key advancements: 1)\nwe propose a novel depth-based ray sampling strategy based on the truncated\nnormal distribution, which improves the convergence speed and accuracy of pose\nestimation; 2) to circumvent local minima and refine depth geometry, we\nintroduce a coarse-to-fine training strategy that progressively improves the\ndepth precision; 3) we propose a more robust inter-frame point constraint that\nenhances robustness against depth noise during training. The experimental\nresults on three datasets demonstrate that TD-NeRF achieves superior\nperformance in the joint optimization of camera pose and NeRF, surpassing prior\nworks, and generates more accurate depth geometry. The implementation of our\nmethod has been released at https://github.com/nubot-nudt/TD-NeRF.\n","authors":["Zhen Tan","Zongtan Zhou","Yangbing Ge","Zi Wang","Xieyuanli Chen","Dewen Hu"],"pdf_url":"https://arxiv.org/pdf/2405.07027v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.13753v3","updated":"2024-10-07T08:20:55Z","published":"2024-05-22T15:38:30Z","title":"A Dynamic Model of Performative Human-ML Collaboration: Theory and\n  Empirical Evidence","summary":"  Machine learning (ML) models are increasingly used in various applications,\nfrom recommendation systems in e-commerce to diagnosis prediction in\nhealthcare. In this paper, we present a novel dynamic framework for thinking\nabout the deployment of ML models in a performative, human-ML collaborative\nsystem. In our framework, the introduction of ML recommendations changes the\ndata-generating process of human decisions, which are only a proxy to the\nground truth and which are then used to train future versions of the model. We\nshow that this dynamic process in principle can converge to different stable\npoints, i.e. where the ML model and the Human+ML system have the same\nperformance. Some of these stable points are suboptimal with respect to the\nactual ground truth. As a proof of concept, we conduct an empirical user study\nwith 1,408 participants. In the study, humans solve instances of the knapsack\nproblem with the help of machine learning predictions of varying performance.\nThis is an ideal setting because we can identify the actual ground truth, and\nevaluate the performance of human decisions supported by ML recommendations. We\nfind that for many levels of ML performance, humans can improve upon the ML\npredictions. We also find that the improvement could be even higher if humans\nrationally followed the ML recommendations. Finally, we test whether monetary\nincentives can increase the quality of human decisions, but we fail to find any\npositive effect. Using our empirical data to approximate our collaborative\nsystem suggests that the learning process would dynamically reach an\nequilibrium performance that is around 92% of the maximum knapsack value. Our\nresults have practical implications for the deployment of ML models in contexts\nwhere human decisions may deviate from the indisputable ground truth.\n","authors":["Tom Sühr","Samira Samadi","Chiara Farronato"],"pdf_url":"https://arxiv.org/pdf/2405.13753v3.pdf","comment":"10 Pages and appendix"},{"id":"http://arxiv.org/abs/2409.06744v2","updated":"2024-10-07T08:20:32Z","published":"2024-09-10T06:52:33Z","title":"ProteinBench: A Holistic Evaluation of Protein Foundation Models","summary":"  Recent years have witnessed a surge in the development of protein foundation\nmodels, significantly improving performance in protein prediction and\ngenerative tasks ranging from 3D structure prediction and protein design to\nconformational dynamics. However, the capabilities and limitations associated\nwith these models remain poorly understood due to the absence of a unified\nevaluation framework. To fill this gap, we introduce ProteinBench, a holistic\nevaluation framework designed to enhance the transparency of protein foundation\nmodels. Our approach consists of three key components: (i) A taxonomic\nclassification of tasks that broadly encompass the main challenges in the\nprotein domain, based on the relationships between different protein\nmodalities; (ii) A multi-metric evaluation approach that assesses performance\nacross four key dimensions: quality, novelty, diversity, and robustness; and\n(iii) In-depth analyses from various user objectives, providing a holistic view\nof model performance. Our comprehensive evaluation of protein foundation models\nreveals several key findings that shed light on their current capabilities and\nlimitations. To promote transparency and facilitate further research, we\nrelease the evaluation dataset, code, and a public leaderboard publicly for\nfurther analysis and a general modular toolkit. We intend for ProteinBench to\nbe a living benchmark for establishing a standardized, in-depth evaluation\nframework for protein foundation models, driving their development and\napplication while fostering collaboration within the field.\n","authors":["Fei Ye","Zaixiang Zheng","Dongyu Xue","Yuning Shen","Lihao Wang","Yiming Ma","Yan Wang","Xinyou Wang","Xiangxin Zhou","Quanquan Gu"],"pdf_url":"https://arxiv.org/pdf/2409.06744v2.pdf","comment":"30 pages, 2 figures and 15 tables"},{"id":"http://arxiv.org/abs/2410.04817v1","updated":"2024-10-07T08:06:41Z","published":"2024-10-07T08:06:41Z","title":"Resource-Efficient Multiview Perception: Integrating Semantic Masking\n  with Masked Autoencoders","summary":"  Multiview systems have become a key technology in modern computer vision,\noffering advanced capabilities in scene understanding and analysis. However,\nthese systems face critical challenges in bandwidth limitations and\ncomputational constraints, particularly for resource-limited camera nodes like\ndrones. This paper presents a novel approach for communication-efficient\ndistributed multiview detection and tracking using masked autoencoders (MAEs).\nWe introduce a semantic-guided masking strategy that leverages pre-trained\nsegmentation models and a tunable power function to prioritize informative\nimage regions. This approach, combined with an MAE, reduces communication\noverhead while preserving essential visual information. We evaluate our method\non both virtual and real-world multiview datasets, demonstrating comparable\nperformance in terms of detection and tracking performance metrics compared to\nstate-of-the-art techniques, even at high masking ratios. Our selective masking\nalgorithm outperforms random masking, maintaining higher accuracy and precision\nas the masking ratio increases. Furthermore, our approach achieves a\nsignificant reduction in transmission data volume compared to baseline methods,\nthereby balancing multiview tracking performance with communication efficiency.\n","authors":["Kosta Dakic","Kanchana Thilakarathna","Rodrigo N. Calheiros","Teng Joon Lim"],"pdf_url":"https://arxiv.org/pdf/2410.04817v1.pdf","comment":"10 pages, conference"},{"id":"http://arxiv.org/abs/2410.04815v1","updated":"2024-10-07T08:00:41Z","published":"2024-10-07T08:00:41Z","title":"A Review of Artificial Intelligence based Biological-Tree Construction:\n  Priorities, Methods, Applications and Trends","summary":"  Biological tree analysis serves as a pivotal tool in uncovering the\nevolutionary and differentiation relationships among organisms, genes, and\ncells. Its applications span diverse fields including phylogenetics,\ndevelopmental biology, ecology, and medicine. Traditional tree inference\nmethods, while foundational in early studies, face increasing limitations in\nprocessing the large-scale, complex datasets generated by modern\nhigh-throughput technologies. Recent advances in deep learning offer promising\nsolutions, providing enhanced data processing and pattern recognition\ncapabilities. However, challenges remain, particularly in accurately\nrepresenting the inherently discrete and non-Euclidean nature of biological\ntrees. In this review, we first outline the key biological priors fundamental\nto phylogenetic and differentiation tree analyses, facilitating a deeper\ninterdisciplinary understanding between deep learning researchers and\nbiologists. We then systematically examine the commonly used data formats and\ndatabases, serving as a comprehensive resource for model testing and\ndevelopment. We provide a critical analysis of traditional tree generation\nmethods, exploring their underlying biological assumptions, technical\ncharacteristics, and limitations. Current developments in deep learning-based\ntree generation are reviewed, highlighting both recent advancements and\nexisting challenges. Furthermore, we discuss the diverse applications of\nbiological trees across various biological domains. Finally, we propose\npotential future directions and trends in leveraging deep learning for\nbiological tree research, aiming to guide further exploration and innovation in\nthis field.\n","authors":["Zelin Zang","Yongjie Xu","Chenrui Duan","Jinlin Wu","Stan Z. Li","Zhen Lei"],"pdf_url":"https://arxiv.org/pdf/2410.04815v1.pdf","comment":"83 pages, 15 figures"},{"id":"http://arxiv.org/abs/2410.04814v1","updated":"2024-10-07T07:54:53Z","published":"2024-10-07T07:54:53Z","title":"Learning Interpretable Hierarchical Dynamical Systems Models from Time\n  Series Data","summary":"  In science, we are often interested in obtaining a generative model of the\nunderlying system dynamics from observed time series. While powerful methods\nfor dynamical systems reconstruction (DSR) exist when data come from a single\ndomain, how to best integrate data from multiple dynamical regimes and leverage\nit for generalization is still an open question. This becomes particularly\nimportant when individual time series are short, and group-level information\nmay help to fill in for gaps in single-domain data. At the same time, averaging\nis not an option in DSR, as it will wipe out crucial dynamical properties\n(e.g., limit cycles in one domain vs. chaos in another). Hence, a framework is\nneeded that enables to efficiently harvest group-level (multi-domain)\ninformation while retaining all single-domain dynamical characteristics. Here\nwe provide such a hierarchical approach and showcase it on popular DSR\nbenchmarks, as well as on neuroscientific and medical time series. In addition\nto faithful reconstruction of all individual dynamical regimes, our\nunsupervised methodology discovers common low-dimensional feature spaces in\nwhich datasets with similar dynamics cluster. The features spanning these\nspaces were further dynamically highly interpretable, surprisingly in often\nlinear relation to control parameters that govern the dynamics of the\nunderlying system. Finally, we illustrate transfer learning and generalization\nto new parameter regimes.\n","authors":["Manuel Brenner","Elias Weber","Georgia Koppe","Daniel Durstewitz"],"pdf_url":"https://arxiv.org/pdf/2410.04814v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2409.14399v2","updated":"2024-10-07T07:49:27Z","published":"2024-09-22T11:35:59Z","title":"Beyond Persuasion: Towards Conversational Recommender System with\n  Credible Explanations","summary":"  With the aid of large language models, current conversational recommender\nsystem (CRS) has gaining strong abilities to persuade users to accept\nrecommended items. While these CRSs are highly persuasive, they can mislead\nusers by incorporating incredible information in their explanations, ultimately\ndamaging the long-term trust between users and the CRS. To address this, we\npropose a simple yet effective method, called PC-CRS, to enhance the\ncredibility of CRS's explanations during persuasion. It guides the explanation\ngeneration through our proposed credibility-aware persuasive strategies and\nthen gradually refines explanations via post-hoc self-reflection. Experimental\nresults demonstrate the efficacy of PC-CRS in promoting persuasive and credible\nexplanations. Further analysis reveals the reason behind current methods\nproducing incredible explanations and the potential of credible explanations to\nimprove recommendation accuracy.\n","authors":["Peixin Qin","Chen Huang","Yang Deng","Wenqiang Lei","Tat-Seng Chua"],"pdf_url":"https://arxiv.org/pdf/2409.14399v2.pdf","comment":"Findings of EMNLP 2024. Our code is available at\n  https://github.com/mumen798/PC-CRS"},{"id":"http://arxiv.org/abs/2407.19911v4","updated":"2024-10-07T07:41:11Z","published":"2024-07-29T11:39:22Z","title":"Efficient Shield Synthesis via State-Space Transformation","summary":"  We consider the problem of synthesizing safety strategies for control\nsystems, also known as shields. Since the state space is infinite, shields are\ntypically computed over a finite-state abstraction, with the most common\nabstraction being a rectangular grid. However, for many systems, such a grid\ndoes not align well with the safety property or the system dynamics. That is\nwhy a coarse grid is rarely sufficient, but a fine grid is typically\ncomputationally infeasible to obtain. In this paper, we show that appropriate\nstate-space transformations can still allow to use a coarse grid at almost no\ncomputational overhead. We demonstrate in three case studies that our\ntransformation-based synthesis outperforms a standard synthesis by several\norders of magnitude. In the first two case studies, we use domain knowledge to\nselect a suitable transformation. In the third case study, we instead report on\nresults in engineering a transformation without domain knowledge.\n","authors":["Asger Horn Brorholt","Andreas Holck Høeg-Petersen","Kim Guldstrand Larsen","Christian Schilling"],"pdf_url":"https://arxiv.org/pdf/2407.19911v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04799v1","updated":"2024-10-07T07:23:42Z","published":"2024-10-07T07:23:42Z","title":"Transforming Color: A Novel Image Colorization Method","summary":"  This paper introduces a novel method for image colorization that utilizes a\ncolor transformer and generative adversarial networks (GANs) to address the\nchallenge of generating visually appealing colorized images. Conventional\napproaches often struggle with capturing long-range dependencies and producing\nrealistic colorizations. The proposed method integrates a transformer\narchitecture to capture global information and a GAN framework to improve\nvisual quality. In this study, a color encoder that utilizes a random normal\ndistribution to generate color features is applied. These features are then\nintegrated with grayscale image features to enhance the overall representation\nof the images. Our method demonstrates superior performance compared with\nexisting approaches by utilizing the capacity of the transformer, which can\ncapture long-range dependencies and generate a realistic colorization of the\nGAN. Experimental results show that the proposed network significantly\noutperforms other state-of-the-art colorization techniques, highlighting its\npotential for image colorization. This research opens new possibilities for\nprecise and visually compelling image colorization in domains such as digital\nrestoration and historical image analysis.\n","authors":["Hamza Shafiq","Bumshik Lee"],"pdf_url":"https://arxiv.org/pdf/2410.04799v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04795v1","updated":"2024-10-07T07:14:37Z","published":"2024-10-07T07:14:37Z","title":"Representing the Under-Represented: Cultural and Core Capability\n  Benchmarks for Developing Thai Large Language Models","summary":"  The rapid advancement of large language models (LLMs) has highlighted the\nneed for robust evaluation frameworks that assess their core capabilities, such\nas reasoning, knowledge, and commonsense, leading to the inception of certain\nwidely-used benchmark suites such as the H6 benchmark. However, these benchmark\nsuites are primarily built for the English language, and there exists a lack\nthereof for under-represented languages, in terms of LLM development, such as\nThai. On the other hand, developing LLMs for Thai should also include enhancing\nthe cultural understanding as well as core capabilities. To address these dual\nchallenge in Thai LLM research, we propose two key benchmarks: Thai-H6 and Thai\nCultural and Linguistic Intelligence Benchmark (ThaiCLI). Through a thorough\nevaluation of various LLMs with multi-lingual capabilities, we provide a\ncomprehensive analysis of the proposed benchmarks and how they contribute to\nThai LLM development. Furthermore, we will make both the datasets and\nevaluation code publicly available to encourage further research and\ndevelopment for Thai LLMs.\n","authors":["Dahyun Kim","Sukyung Lee","Yungi Kim","Attapol Rutherford","Chanjun Park"],"pdf_url":"https://arxiv.org/pdf/2410.04795v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04789v1","updated":"2024-10-07T06:57:23Z","published":"2024-10-07T06:57:23Z","title":"Analysis of Hybrid Compositions in Animation Film with Weakly Supervised\n  Learning","summary":"  We present an approach for the analysis of hybrid visual compositions in\nanimation in the domain of ephemeral film. We combine ideas from\nsemi-supervised and weakly supervised learning to train a model that can\nsegment hybrid compositions without requiring pre-labeled segmentation masks.\nWe evaluate our approach on a set of ephemeral films from 13 film archives.\nResults demonstrate that the proposed learning strategy yields a performance\nclose to a fully supervised baseline. On a qualitative level the performed\nanalysis provides interesting insights on hybrid compositions in animation\nfilm.\n","authors":["Mónica Apellaniz Portos","Roberto Labadie-Tamayo","Claudius Stemmler","Erwin Feyersinger","Andreas Babic","Franziska Bruckner","Vrääth Öhner","Matthias Zeppelzauer"],"pdf_url":"https://arxiv.org/pdf/2410.04789v1.pdf","comment":"Vision for Art (VISART VII) Workshop at the European Conference of\n  Computer Vision (ECCV)"},{"id":"http://arxiv.org/abs/2410.04779v1","updated":"2024-10-07T06:38:43Z","published":"2024-10-07T06:38:43Z","title":"Fast Training of Sinusoidal Neural Fields via Scaling Initialization","summary":"  Neural fields are an emerging paradigm that represent data as continuous\nfunctions parameterized by neural networks. Despite many advantages, neural\nfields often have a high training cost, which prevents a broader adoption. In\nthis paper, we focus on a popular family of neural fields, called sinusoidal\nneural fields (SNFs), and study how it should be initialized to maximize the\ntraining speed. We find that the standard initialization scheme for SNFs --\ndesigned based on the signal propagation principle -- is suboptimal. In\nparticular, we show that by simply multiplying each weight (except for the last\nlayer) by a constant, we can accelerate SNF training by 10$\\times$. This\nmethod, coined $\\textit{weight scaling}$, consistently provides a significant\nspeedup over various data domains, allowing the SNFs to train faster than more\nrecently proposed architectures. To understand why the weight scaling works\nwell, we conduct extensive theoretical and empirical analyses which reveal that\nthe weight scaling not only resolves the spectral bias quite effectively but\nalso enjoys a well-conditioned optimization trajectory.\n","authors":["Taesun Yeom","Sangyoon Lee","Jaeho Lee"],"pdf_url":"https://arxiv.org/pdf/2410.04779v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.17642v2","updated":"2024-10-07T06:29:54Z","published":"2024-09-26T08:45:15Z","title":"AI Delegates with a Dual Focus: Ensuring Privacy and Strategic\n  Self-Disclosure","summary":"  Large language model (LLM)-based AI delegates are increasingly utilized to\nact on behalf of users, assisting them with a wide range of tasks through\nconversational interfaces. Despite their advantages, concerns arise regarding\nthe potential risk of privacy leaks, particularly in scenarios involving social\ninteractions. While existing research has focused on protecting privacy by\nlimiting the access of AI delegates to sensitive user information, many social\nscenarios require disclosing private details to achieve desired outcomes,\nnecessitating a balance between privacy protection and disclosure. To address\nthis challenge, we conduct a pilot study to investigate user preferences for AI\ndelegates across various social relations and task scenarios, and then propose\na novel AI delegate system that enables privacy-conscious self-disclosure. Our\nuser study demonstrates that the proposed AI delegate strategically protects\nprivacy, pioneering its use in diverse and dynamic social interactions.\n","authors":["Xi Chen","Zhiyang Zhang","Fangkai Yang","Xiaoting Qin","Chao Du","Xi Cheng","Hangxin Liu","Qingwei Lin","Saravan Rajmohan","Dongmei Zhang","Qi Zhang"],"pdf_url":"https://arxiv.org/pdf/2409.17642v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.13026v2","updated":"2024-10-07T06:08:09Z","published":"2024-04-19T17:41:05Z","title":"PhysDreamer: Physics-Based Interaction with 3D Objects via Video\n  Generation","summary":"  Realistic object interactions are crucial for creating immersive virtual\nexperiences, yet synthesizing realistic 3D object dynamics in response to novel\ninteractions remains a significant challenge. Unlike unconditional or\ntext-conditioned dynamics generation, action-conditioned dynamics requires\nperceiving the physical material properties of objects and grounding the 3D\nmotion prediction on these properties, such as object stiffness. However,\nestimating physical material properties is an open problem due to the lack of\nmaterial ground-truth data, as measuring these properties for real objects is\nhighly difficult. We present PhysDreamer, a physics-based approach that endows\nstatic 3D objects with interactive dynamics by leveraging the object dynamics\npriors learned by video generation models. By distilling these priors,\nPhysDreamer enables the synthesis of realistic object responses to novel\ninteractions, such as external forces or agent manipulations. We demonstrate\nour approach on diverse examples of elastic objects and evaluate the realism of\nthe synthesized interactions through a user study. PhysDreamer takes a step\ntowards more engaging and realistic virtual experiences by enabling static 3D\nobjects to dynamically respond to interactive stimuli in a physically plausible\nmanner. See our project page at https://physdreamer.github.io/.\n","authors":["Tianyuan Zhang","Hong-Xing Yu","Rundi Wu","Brandon Y. Feng","Changxi Zheng","Noah Snavely","Jiajun Wu","William T. Freeman"],"pdf_url":"https://arxiv.org/pdf/2404.13026v2.pdf","comment":"Project website at: https://physdreamer.github.io/ Appear on ECCV\n  2024"},{"id":"http://arxiv.org/abs/2410.04765v1","updated":"2024-10-07T05:44:02Z","published":"2024-10-07T05:44:02Z","title":"Molecular topological deep learning for polymer property prediction","summary":"  Accurate and efficient prediction of polymer properties is of key importance\nfor polymer design. Traditional experimental tools and density function theory\n(DFT)-based simulations for polymer property evaluation, are both expensive and\ntime-consuming. Recently, a gigantic amount of graph-based molecular models\nhave emerged and demonstrated huge potential in molecular data analysis. Even\nwith the great progresses, these models tend to ignore the high-order and\nmutliscale information within the data. In this paper, we develop molecular\ntopological deep learning (Mol-TDL) for polymer property analysis. Our Mol-TDL\nincorporates both high-order interactions and multiscale properties into\ntopological deep learning architecture. The key idea is to represent polymer\nmolecules as a series of simplicial complices at different scales and build up\nsimplical neural networks accordingly. The aggregated information from\ndifferent scales provides a more accurate prediction of polymer molecular\nproperties.\n","authors":["Cong Shen","Yipeng Zhang","Fei Han","Kelin Xia"],"pdf_url":"https://arxiv.org/pdf/2410.04765v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04759v1","updated":"2024-10-07T05:27:22Z","published":"2024-10-07T05:27:22Z","title":"Driving with Regulation: Interpretable Decision-Making for Autonomous\n  Vehicles with Retrieval-Augmented Reasoning via LLM","summary":"  This work presents an interpretable decision-making framework for autonomous\nvehicles that integrates traffic regulations, norms, and safety guidelines\ncomprehensively and enables seamless adaptation to different regions. While\ntraditional rule-based methods struggle to incorporate the full scope of\ntraffic rules, we develop a Traffic Regulation Retrieval (TRR) Agent based on\nRetrieval-Augmented Generation (RAG) to automatically retrieve relevant traffic\nrules and guidelines from extensive regulation documents and relevant records\nbased on the ego vehicle's situation. Given the semantic complexity of the\nretrieved rules, we also design a reasoning module powered by a Large Language\nModel (LLM) to interpret these rules, differentiate between mandatory rules and\nsafety guidelines, and assess actions on legal compliance and safety.\nAdditionally, the reasoning is designed to be interpretable, enhancing both\ntransparency and reliability. The framework demonstrates robust performance on\nboth hypothesized and real-world cases across diverse scenarios, along with the\nability to adapt to different regions with ease.\n","authors":["Tianhui Cai","Yifan Liu","Zewei Zhou","Haoxuan Ma","Seth Z. Zhao","Zhiwen Wu","Jiaqi Ma"],"pdf_url":"https://arxiv.org/pdf/2410.04759v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04756v1","updated":"2024-10-07T05:20:21Z","published":"2024-10-07T05:20:21Z","title":"Item Cluster-aware Prompt Learning for Session-based Recommendation","summary":"  Session-based recommendation (SBR) aims to capture dynamic user preferences\nby analyzing item sequences within individual sessions. However, most existing\napproaches focus mainly on intra-session item relationships, neglecting the\nconnections between items across different sessions (inter-session\nrelationships), which limits their ability to fully capture complex item\ninteractions. While some methods incorporate inter-session information, they\noften suffer from high computational costs, leading to longer training times\nand reduced efficiency. To address these challenges, we propose the CLIP-SBR\n(Cluster-aware Item Prompt learning for Session-Based Recommendation)\nframework. CLIP-SBR is composed of two modules: 1) an item relationship mining\nmodule that builds a global graph to effectively model both intra- and\ninter-session relationships, and 2) an item cluster-aware prompt learning\nmodule that uses soft prompts to integrate these relationships into SBR models\nefficiently. We evaluate CLIP-SBR across eight SBR models and three benchmark\ndatasets, consistently demonstrating improved recommendation performance and\nestablishing CLIP-SBR as a robust solution for session-based recommendation\ntasks.\n","authors":["Wooseong Yang","Chen Wang","Zihe Song","Weizhi Zhang","Philip S. Yu"],"pdf_url":"https://arxiv.org/pdf/2410.04756v1.pdf","comment":"9 pages"},{"id":"http://arxiv.org/abs/2410.04753v1","updated":"2024-10-07T05:14:18Z","published":"2024-10-07T05:14:18Z","title":"ImProver: Agent-Based Automated Proof Optimization","summary":"  Large language models (LLMs) have been used to generate formal proofs of\nmathematical theorems in proofs assistants such as Lean. However, we often want\nto optimize a formal proof with respect to various criteria, depending on its\ndownstream use. For example, we may want a proof to adhere to a certain style,\nor to be readable, concise, or modularly structured. Having suitably optimized\nproofs is also important for learning tasks, especially since human-written\nproofs may not optimal for that purpose. To this end, we study a new problem of\nautomated proof optimization: rewriting a proof so that it is correct and\noptimizes for an arbitrary criterion, such as length or readability. As a first\nmethod for automated proof optimization, we present ImProver, a\nlarge-language-model agent that rewrites proofs to optimize arbitrary\nuser-defined metrics in Lean. We find that naively applying LLMs to proof\noptimization falls short, and we incorporate various improvements into\nImProver, such as the use of symbolic Lean context in a novel Chain-of-States\ntechnique, as well as error-correction and retrieval. We test ImProver on\nrewriting real-world undergraduate, competition, and research-level mathematics\ntheorems, finding that ImProver is capable of rewriting proofs so that they are\nsubstantially shorter, more modular, and more readable.\n","authors":["Riyaz Ahuja","Jeremy Avigad","Prasad Tetali","Sean Welleck"],"pdf_url":"https://arxiv.org/pdf/2410.04753v1.pdf","comment":"19 pages, 21 figures"},{"id":"http://arxiv.org/abs/2312.10695v5","updated":"2024-10-07T04:36:10Z","published":"2023-12-17T12:09:42Z","title":"Nonparametric Strategy Test","summary":"  We present a nonparametric statistical test for determining whether an agent\nis following a given mixed strategy in a repeated strategic-form game given\nsamples of the agent's play. This involves two components: determining whether\nthe agent's frequencies of pure strategies are sufficiently close to the target\nfrequencies, and determining whether the pure strategies selected are\nindependent between different game iterations. Our integrated test involves\napplying a chi-squared goodness of fit test for the first component and a\ngeneralized Wald-Wolfowitz runs test for the second component. The results from\nboth tests are combined using Bonferroni correction to produce a complete test\nfor a given significance level $\\alpha.$ We applied the test to publicly\navailable data of human rock-paper-scissors play. The data consists of 50\niterations of play for 500 human players. We test with a null hypothesis that\nthe players are following a uniform random strategy independently at each game\niteration. Using a significance level of $\\alpha = 0.05$, we conclude that 305\n(61%) of the subjects are following the target strategy.\n","authors":["Sam Ganzfried"],"pdf_url":"https://arxiv.org/pdf/2312.10695v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.19270v2","updated":"2024-10-07T04:21:15Z","published":"2024-03-28T09:56:04Z","title":"sDPO: Don't Use Your Data All at Once","summary":"  As development of large language models (LLM) progresses, aligning them with\nhuman preferences has become increasingly important. We propose stepwise DPO\n(sDPO), an extension of the recently popularized direct preference optimization\n(DPO) for alignment tuning. This approach involves dividing the available\npreference datasets and utilizing them in a stepwise manner, rather than\nemploying it all at once. We demonstrate that this method facilitates the use\nof more precisely aligned reference models within the DPO training framework.\nFurthermore, sDPO trains the final model to be more performant, even\noutperforming other popular LLMs with more parameters.\n","authors":["Dahyun Kim","Yungi Kim","Wonho Song","Hyeonwoo Kim","Yunsu Kim","Sanghoon Kim","Chanjun Park"],"pdf_url":"https://arxiv.org/pdf/2403.19270v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.01677v2","updated":"2024-10-07T04:19:47Z","published":"2024-10-02T15:47:25Z","title":"Mind Scramble: Unveiling Large Language Model Psychology Via\n  Typoglycemia","summary":"  Research into the external behaviors and internal mechanisms of large\nlanguage models (LLMs) has shown promise in addressing complex tasks in the\nphysical world. Studies suggest that powerful LLMs, like GPT-4, are beginning\nto exhibit human-like cognitive abilities, including planning, reasoning, and\nreflection. In this paper, we introduce a research line and methodology called\nLLM Psychology, leveraging human psychology experiments to investigate the\ncognitive behaviors and mechanisms of LLMs. We migrate the Typoglycemia\nphenomenon from psychology to explore the \"mind\" of LLMs. Unlike human brains,\nwhich rely on context and word patterns to comprehend scrambled text, LLMs use\ndistinct encoding and decoding processes. Through Typoglycemia experiments at\nthe character, word, and sentence levels, we observe: (I) LLMs demonstrate\nhuman-like behaviors on a macro scale, such as lower task accuracy and higher\ntoken/time consumption; (II) LLMs exhibit varying robustness to scrambled\ninput, making Typoglycemia a benchmark for model evaluation without new\ndatasets; (III) Different task types have varying impacts, with complex logical\ntasks (e.g., math) being more challenging in scrambled form; (IV) Each LLM has\na unique and consistent \"cognitive pattern\" across tasks, revealing general\nmechanisms in its psychology process. We provide an in-depth analysis of hidden\nlayers to explain these phenomena, paving the way for future research in LLM\nPsychology and deeper interpretability.\n","authors":["Miao Yu","Junyuan Mao","Guibin Zhang","Jingheng Ye","Junfeng Fang","Aoxiao Zhong","Yang Liu","Yuxuan Liang","Kun Wang","Qingsong Wen"],"pdf_url":"https://arxiv.org/pdf/2410.01677v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.07930v3","updated":"2024-10-07T04:17:18Z","published":"2024-08-15T04:57:55Z","title":"MAG-SQL: Multi-Agent Generative Approach with Soft Schema Linking and\n  Iterative Sub-SQL Refinement for Text-to-SQL","summary":"  Recent In-Context Learning based methods have achieved remarkable success in\nText-to-SQL task. However, there is still a large gap between the performance\nof these models and human performance on datasets with complex database schema\nand difficult questions, such as BIRD. Besides, existing work has neglected to\nsupervise intermediate steps when solving questions iteratively with question\ndecomposition methods, and the schema linking methods used in these works are\nvery rudimentary. To address these issues, we propose MAG-SQL, a multi-agent\ngenerative approach with soft schema linking and iterative Sub-SQL refinement.\nIn our framework, an entity-based method with tables' summary is used to select\nthe columns in database, and a novel targets-conditions decomposition method is\nintroduced to decompose those complex questions. Additionally, we build a\niterative generating module which includes a Sub-SQL Generator and Sub-SQL\nRefiner, introducing external oversight for each step of generation. Through a\nseries of ablation studies, the effectiveness of each agent in our framework\nhas been demonstrated. When evaluated on the BIRD benchmark with GPT-4, MAG-SQL\nachieves an execution accuracy of 61.08%, compared to the baseline accuracy of\n46.35% for vanilla GPT-4 and the baseline accuracy of 57.56% for MAC-SQL.\nBesides, our approach makes similar progress on Spider.\n","authors":["Wenxuan Xie","Gaochen Wu","Bowen Zhou"],"pdf_url":"https://arxiv.org/pdf/2408.07930v3.pdf","comment":"22 pages, 14 figures"},{"id":"http://arxiv.org/abs/2410.04740v1","updated":"2024-10-07T04:15:48Z","published":"2024-10-07T04:15:48Z","title":"Evaluating the Generalization Ability of Spatiotemporal Model in Urban\n  Scenario","summary":"  Spatiotemporal neural networks have shown great promise in urban scenarios by\neffectively capturing temporal and spatial correlations. However, urban\nenvironments are constantly evolving, and current model evaluations are often\nlimited to traffic scenarios and use data mainly collected only a few weeks\nafter training period to evaluate model performance. The generalization ability\nof these models remains largely unexplored. To address this, we propose a\nSpatiotemporal Out-of-Distribution (ST-OOD) benchmark, which comprises six\nurban scenario: bike-sharing, 311 services, pedestrian counts, traffic speed,\ntraffic flow, ride-hailing demand, and bike-sharing, each with in-distribution\n(same year) and out-of-distribution (next years) settings. We extensively\nevaluate state-of-the-art spatiotemporal models and find that their performance\ndegrades significantly in out-of-distribution settings, with most models\nperforming even worse than a simple Multi-Layer Perceptron (MLP). Our findings\nsuggest that current leading methods tend to over-rely on parameters to overfit\ntraining data, which may lead to good performance on in-distribution data but\noften results in poor generalization. We also investigated whether dropout\ncould mitigate the negative effects of overfitting. Our results showed that a\nslight dropout rate could significantly improve generalization performance on\nmost datasets, with minimal impact on in-distribution performance. However,\nbalancing in-distribution and out-of-distribution performance remains a\nchallenging problem. We hope that the proposed benchmark will encourage further\nresearch on this critical issue.\n","authors":["Hongjun Wang","Jiyuan Chen","Tong Pan","Zheng Dong","Lingyu Zhang","Renhe Jiang","Xuan Song"],"pdf_url":"https://arxiv.org/pdf/2410.04740v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04739v1","updated":"2024-10-07T04:15:02Z","published":"2024-10-07T04:15:02Z","title":"TableRAG: Million-Token Table Understanding with Language Models","summary":"  Recent advancements in language models (LMs) have notably enhanced their\nability to reason with tabular data, primarily through program-aided mechanisms\nthat manipulate and analyze tables. However, these methods often require the\nentire table as input, leading to scalability challenges due to the positional\nbias or context length constraints. In response to these challenges, we\nintroduce TableRAG, a Retrieval-Augmented Generation (RAG) framework\nspecifically designed for LM-based table understanding. TableRAG leverages\nquery expansion combined with schema and cell retrieval to pinpoint crucial\ninformation before providing it to the LMs. This enables more efficient data\nencoding and precise retrieval, significantly reducing prompt lengths and\nmitigating information loss. We have developed two new million-token benchmarks\nfrom the Arcade and BIRD-SQL datasets to thoroughly evaluate TableRAG's\neffectiveness at scale. Our results demonstrate that TableRAG's retrieval\ndesign achieves the highest retrieval quality, leading to the new\nstate-of-the-art performance on large-scale table understanding.\n","authors":["Si-An Chen","Lesly Miculicich","Julian Martin Eisenschlos","Zifeng Wang","Zilong Wang","Yanfei Chen","Yasuhisa Fujii","Hsuan-Tien Lin","Chen-Yu Lee","Tomas Pfister"],"pdf_url":"https://arxiv.org/pdf/2410.04739v1.pdf","comment":"Accepted to NeurIPS 2024"},{"id":"http://arxiv.org/abs/2404.03133v2","updated":"2024-10-07T03:56:10Z","published":"2024-04-04T00:58:19Z","title":"A Framework for Guided Motion Planning","summary":"  Randomized sampling based algorithms are widely used in robot motion planning\ndue to the problem's intractability, and are experimentally effective on a wide\nrange of problem instances. Most variants bias their sampling using various\nheuristics related to the known underlying structure of the search space. In\nthis work, we formalize the intuitive notion of guided search by defining the\nconcept of a guiding space. This new language encapsulates many seemingly\ndistinct prior methods under the same framework, and allows us to reason about\nguidance, a previously obscured core contribution of different algorithms. We\nsuggest an information theoretic method to evaluate guidance, which\nexperimentally matches intuition when tested on known algorithms in a variety\nof environments. The language and evaluation of guidance suggests improvements\nto existing methods, and allows for simple hybrid algorithms that combine\nguidance from multiple sources.\n","authors":["Amnon Attali","Stav Ashur","Isaac Burton Love","Courtney McBeth","James Motes","Marco Morales","Nancy M. Amato"],"pdf_url":"https://arxiv.org/pdf/2404.03133v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17169v3","updated":"2024-10-07T03:48:18Z","published":"2024-06-24T23:02:56Z","title":"Multi-LogiEval: Towards Evaluating Multi-Step Logical Reasoning Ability\n  of Large Language Models","summary":"  As Large Language Models (LLMs) continue to exhibit remarkable performance in\nnatural language understanding tasks, there is a crucial need to measure their\nability for human-like multi-step logical reasoning. Existing logical reasoning\nevaluation benchmarks often focus primarily on simplistic single-step or\nmulti-step reasoning with a limited set of inference rules. Furthermore, the\nlack of datasets for evaluating non-monotonic reasoning represents a crucial\ngap since it aligns more closely with human-like reasoning. To address these\nlimitations, we propose Multi-LogiEval, a comprehensive evaluation dataset\nencompassing multi-step logical reasoning with various inference rules and\ndepths. Multi-LogiEval covers three logic types--propositional, first-order,\nand non-monotonic--consisting of more than 30 inference rules and more than 60\nof their combinations with various depths. Leveraging this dataset, we conduct\nevaluations on a range of LLMs including GPT-4, ChatGPT, Gemini-Pro, Yi, Orca,\nand Mistral, employing a zero-shot chain-of-thought. Experimental results show\nthat there is a significant drop in the performance of LLMs as the reasoning\nsteps/depth increases (average accuracy of ~68% at depth-1 to ~43% at depth-5).\nWe further conduct a thorough investigation of reasoning chains generated by\nLLMs which reveals several important findings. We believe that Multi-LogiEval\nfacilitates future research for evaluating and enhancing the logical reasoning\nability of LLMs. Data is available at\nhttps://github.com/Mihir3009/Multi-LogiEval.\n","authors":["Nisarg Patel","Mohith Kulkarni","Mihir Parmar","Aashna Budhiraja","Mutsumi Nakamura","Neeraj Varshney","Chitta Baral"],"pdf_url":"https://arxiv.org/pdf/2406.17169v3.pdf","comment":"Accepted at EMNLP 2024 Main"},{"id":"http://arxiv.org/abs/2409.10161v3","updated":"2024-10-07T03:37:36Z","published":"2024-09-16T10:52:16Z","title":"SplatSim: Zero-Shot Sim2Real Transfer of RGB Manipulation Policies Using\n  Gaussian Splatting","summary":"  Sim2Real transfer, particularly for manipulation policies relying on RGB\nimages, remains a critical challenge in robotics due to the significant domain\nshift between synthetic and real-world visual data. In this paper, we propose\nSplatSim, a novel framework that leverages Gaussian Splatting as the primary\nrendering primitive to reduce the Sim2Real gap for RGB-based manipulation\npolicies. By replacing traditional mesh representations with Gaussian Splats in\nsimulators, SplatSim produces highly photorealistic synthetic data while\nmaintaining the scalability and cost-efficiency of simulation. We demonstrate\nthe effectiveness of our framework by training manipulation policies within\nSplatSim and deploying them in the real world in a zero-shot manner, achieving\nan average success rate of 86.25%, compared to 97.5% for policies trained on\nreal-world data. Videos can be found on our project page:\nhttps://splatsim.github.io\n","authors":["Mohammad Nomaan Qureshi","Sparsh Garg","Francisco Yandun","David Held","George Kantor","Abhisesh Silwal"],"pdf_url":"https://arxiv.org/pdf/2409.10161v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04723v1","updated":"2024-10-07T03:25:46Z","published":"2024-10-07T03:25:46Z","title":"ProtoNAM: Prototypical Neural Additive Models for Interpretable Deep\n  Tabular Learning","summary":"  Generalized additive models (GAMs) have long been a powerful white-box tool\nfor the intelligible analysis of tabular data, revealing the influence of each\nfeature on the model predictions. Despite the success of neural networks (NNs)\nin various domains, their application as NN-based GAMs in tabular data analysis\nremains suboptimal compared to tree-based ones, and the opacity of encoders in\nNN-GAMs also prevents users from understanding how networks learn the\nfunctions. In this work, we propose a new deep tabular learning method, termed\nPrototypical Neural Additive Model (ProtoNAM), which introduces prototypes into\nneural networks in the framework of GAMs. With the introduced prototype-based\nfeature activation, ProtoNAM can flexibly model the irregular mapping from\ntabular features to the outputs while maintaining the explainability of the\nfinal prediction. We also propose a gradient-boosting inspired hierarchical\nshape function modeling method, facilitating the discovery of complex feature\npatterns and bringing transparency into the learning process of each network\nlayer. Our empirical evaluations demonstrate that ProtoNAM outperforms all\nexisting NN-based GAMs, while providing additional insights into the shape\nfunction learned for each feature. The source code of ProtoNAM is available at\n\\url{https://github.com/Teddy-XiongGZ/ProtoNAM}.\n","authors":["Guangzhi Xiong","Sanchit Sinha","Aidong Zhang"],"pdf_url":"https://arxiv.org/pdf/2410.04723v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17141v3","updated":"2024-10-07T03:19:16Z","published":"2024-03-25T19:28:10Z","title":"MetaAligner: Towards Generalizable Multi-Objective Alignment of Language\n  Models","summary":"  Recent advancements in large language models (LLMs) focus on aligning to\nheterogeneous human expectations and values via multi-objective preference\nalignment. However, existing methods are dependent on the policy model\nparameters, which require high-cost repetition of their alignment algorithms\nfor each new policy model, and they cannot expand to unseen objectives due to\ntheir static alignment objectives. In this work, we propose Meta-Objective\nAligner (MetaAligner), the first policy-agnostic and generalizable method for\nmulti-objective preference alignment. MetaAligner models multi-objective\nalignment into three stages: (1) dynamic objectives reformulation algorithm\nreorganizes traditional alignment datasets to supervise the model on performing\nflexible alignment across different objectives; (2) conditional weak-to-strong\ncorrection paradigm aligns the weak outputs of fixed policy models to approach\nstrong outputs with higher preferences in the corresponding alignment\nobjectives, enabling plug-and-play inferences on any policy models, which\nsignificantly reduces training costs and facilitates alignment on close-source\npolicy models; (3) generalizable inference method flexibly adjusts target\nobjectives by updating their text descriptions in the prompts, facilitating\ngeneralizable alignment to unseen objectives. Experimental results show that\nMetaAligner achieves significant and balanced improvements in multi-objective\nalignments on 10 state-of-the-art policy models, and saves up to 93.63% of GPU\ntraining hours compared to previous alignment methods. The model also\neffectively aligns unseen objectives, marking the first step towards\ngeneralizable multi-objective preference alignment.\n","authors":["Kailai Yang","Zhiwei Liu","Qianqian Xie","Jimin Huang","Tianlin Zhang","Sophia Ananiadou"],"pdf_url":"https://arxiv.org/pdf/2403.17141v3.pdf","comment":"Accepted by NeurIPS 2024 main track"},{"id":"http://arxiv.org/abs/2410.04717v1","updated":"2024-10-07T03:15:11Z","published":"2024-10-07T03:15:11Z","title":"$\\textbf{Only-IF}$:Revealing the Decisive Effect of Instruction\n  Diversity on Generalization","summary":"  Understanding and accurately following instructions is critical for large\nlanguage models (LLMs) to be effective across diverse tasks. In this work, we\nrigorously examine the key factors that enable models to generalize to unseen\ninstructions, providing insights to guide the collection of data for\ninstruction-tuning. Through controlled experiments, inspired by the\nTuring-complete Markov algorithm, we demonstrate that such generalization\n$\\textbf{only emerges}$ when training data is diversified enough across\nsemantic domains. Our findings also reveal that merely diversifying within\nlimited domains fails to ensure robust generalization. In contrast,\ncross-domain data diversification, even under constrained data budgets,\nsignificantly enhances a model's adaptability. We further extend our analysis\nto real-world scenarios, including fine-tuning of\n$\\textit{$\\textbf{specialist}$}$ and $\\textit{$\\textbf{generalist}$}$ models.\nIn both cases, we demonstrate that 1) better performance can be achieved by\nincreasing the diversity of an established dataset while keeping the data size\nconstant, and 2) when scaling up the data, diversifying the semantics of\ninstructions is more effective than simply increasing the quantity of similar\ndata. Our research provides important insights for dataset collation,\nparticularly when optimizing model performance by expanding training data for\nboth specialist and generalist scenarios. We show that careful consideration of\ndata diversification is key: training specialist models with data extending\nbeyond their core domain leads to significant performance improvements, while\ngeneralist models benefit from diverse data mixtures that enhance their overall\ninstruction-following capabilities across a wide range of applications. Our\nresults highlight the critical role of strategic diversification and offer\nclear guidelines for improving data quality.\n","authors":["Dylan Zhang","Justin Wang","Francois Charton"],"pdf_url":"https://arxiv.org/pdf/2410.04717v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.05208v4","updated":"2024-10-07T03:13:37Z","published":"2024-09-08T19:52:00Z","title":"Influence-based Attributions can be Manipulated","summary":"  Influence Functions are a standard tool for attributing predictions to\ntraining data in a principled manner and are widely used in applications such\nas data valuation and fairness. In this work, we present realistic incentives\nto manipulate influence-based attributions and investigate whether these\nattributions can be \\textit{systematically} tampered by an adversary. We show\nthat this is indeed possible for logistic regression models trained on ResNet\nfeature embeddings and standard tabular fairness datasets and provide efficient\nattacks with backward-friendly implementations. Our work raises questions on\nthe reliability of influence-based attributions in adversarial circumstances.\nCode is available at :\n\\url{https://github.com/infinite-pursuits/influence-based-attributions-can-be-manipulated}\n","authors":["Chhavi Yadav","Ruihan Wu","Kamalika Chaudhuri"],"pdf_url":"https://arxiv.org/pdf/2409.05208v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04715v1","updated":"2024-10-07T03:13:06Z","published":"2024-10-07T03:13:06Z","title":"Rule-based Data Selection for Large Language Models","summary":"  The quality of training data significantly impacts the performance of large\nlanguage models (LLMs). There are increasing studies using LLMs to rate and\nselect data based on several human-crafted metrics (rules). However, these\nconventional rule-based approaches often depend too heavily on human\nheuristics, lack effective metrics for assessing rules, and exhibit limited\nadaptability to new tasks. In our study, we introduce an innovative rule-based\nframework that utilizes the orthogonality of score vectors associated with\nrules as a novel metric for rule evaluations. Our approach includes an\nautomated pipeline that first uses LLMs to generate a diverse set of rules,\nencompassing various rating dimensions to evaluate data quality. Then it rates\na batch of data based on these rules and uses the determinantal point process\n(DPP) from random matrix theory to select the most orthogonal score vectors,\nthereby identifying a set of independent rules. These rules are subsequently\nused to evaluate all data, selecting samples with the highest average scores\nfor downstream tasks such as LLM training. We verify the effectiveness of our\nmethod through two experimental setups: 1) comparisons with ground truth\nratings and 2) benchmarking LLMs trained with the chosen data. Our\ncomprehensive experiments cover a range of scenarios, including general\npre-training and domain-specific fine-tuning in areas such as IMDB, Medical,\nMath, and Code. The outcomes demonstrate that our DPP-based rule rating method\nconsistently outperforms other approaches, including rule-free rating, uniform\nsampling, importance resampling, and QuRating, in terms of both rating\nprecision and model performance.\n","authors":["Xiaomin Li","Mingye Gao","Zhiwei Zhang","Chang Yue","Hong Hu"],"pdf_url":"https://arxiv.org/pdf/2410.04715v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.12327v3","updated":"2024-10-07T03:08:12Z","published":"2024-07-17T05:53:20Z","title":"Spectra: A Comprehensive Study of Ternary, Quantized, and FP16 Language\n  Models","summary":"  Rapid advancements in GPU computational power has outpaced memory capacity\nand bandwidth growth, creating bottlenecks in Large Language Model (LLM)\ninference. Post-training quantization is the leading method for addressing\nmemory-related bottlenecks in LLM inference, but it suffers from significant\nperformance degradation below 4-bit precision. This paper addresses these\nchallenges by investigating the pretraining of low-bitwidth models specifically\nTernary Language Models (TriLMs) as an alternative to traditional\nfloating-point models (FloatLMs) and their post-training quantized versions\n(QuantLMs). We present Spectra LLM suite, the first open suite of LLMs spanning\nmultiple bit-widths, including FloatLMs, QuantLMs, and TriLMs, ranging from 99M\nto 3.9B parameters trained on 300B tokens. Our comprehensive evaluation\ndemonstrates that TriLMs offer superior scaling behavior in terms of model size\n(in bits). Surprisingly, at scales exceeding one billion parameters, TriLMs\nconsistently outperform their QuantLM and FloatLM counterparts for a given bit\nsize across various benchmarks. Notably, the 3.9B parameter TriLM matches the\nperformance of the FloatLM 3.9B across all benchmarks, despite having fewer\nbits than FloatLM 830M. Overall, this research provides valuable insights into\nthe feasibility and scalability of low-bitwidth language models, paving the way\nfor the development of more efficient LLMs.\n  To enhance understanding of low-bitwidth models, we are releasing 500+\nintermediate checkpoints of the Spectra suite at\n\\href{https://github.com/NolanoOrg/SpectraSuite}{https://github.com/NolanoOrg/SpectraSuite}.\n","authors":["Ayush Kaushal","Tejas Vaidhya","Arnab Kumar Mondal","Tejas Pandey","Aaryan Bhagat","Irina Rish"],"pdf_url":"https://arxiv.org/pdf/2407.12327v3.pdf","comment":"42 pages, 21 figures, and 13 tables"},{"id":"http://arxiv.org/abs/2405.15984v3","updated":"2024-10-07T03:07:58Z","published":"2024-05-24T23:56:36Z","title":"Evaluating and Safeguarding the Adversarial Robustness of\n  Retrieval-Based In-Context Learning","summary":"  With the emergence of large language models, such as LLaMA and OpenAI GPT-3,\nIn-Context Learning (ICL) gained significant attention due to its effectiveness\nand efficiency. However, ICL is very sensitive to the choice, order, and\nverbaliser used to encode the demonstrations in the prompt. Retrieval-Augmented\nICL methods try to address this problem by leveraging retrievers to extract\nsemantically related examples as demonstrations. While this approach yields\nmore accurate results, its robustness against various types of adversarial\nattacks, including perturbations on test samples, demonstrations, and retrieved\ndata, remains under-explored. Our study reveals that retrieval-augmented models\ncan enhance robustness against test sample attacks, outperforming vanilla ICL\nwith a 4.87% reduction in Attack Success Rate (ASR); however, they exhibit\noverconfidence in the demonstrations, leading to a 2% increase in ASR for\ndemonstration attacks. Adversarial training can help improve the robustness of\nICL methods to adversarial attacks; however, such a training scheme can be too\ncostly in the context of LLMs. As an alternative, we introduce an effective\ntraining-free adversarial defence method, DARD, which enriches the example pool\nwith those attacked samples. We show that DARD yields improvements in\nperformance and robustness, achieving a 15% reduction in ASR over the\nbaselines. Code and data are released to encourage further research:\nhttps://github.com/simonucl/adv-retreival-icl\n","authors":["Simon Yu","Jie He","Pasquale Minervini","Jeff Z. Pan"],"pdf_url":"https://arxiv.org/pdf/2405.15984v3.pdf","comment":"COLM 2024, 30 pages, 6 figures"},{"id":"http://arxiv.org/abs/2410.04708v1","updated":"2024-10-07T02:57:26Z","published":"2024-10-07T02:57:26Z","title":"Tight Stability, Convergence, and Robustness Bounds for Predictive\n  Coding Networks","summary":"  Energy-based learning algorithms, such as predictive coding (PC), have\ngarnered significant attention in the machine learning community due to their\ntheoretical properties, such as local operations and biologically plausible\nmechanisms for error correction. In this work, we rigorously analyze the\nstability, robustness, and convergence of PC through the lens of dynamical\nsystems theory. We show that, first, PC is Lyapunov stable under mild\nassumptions on its loss and residual energy functions, which implies intrinsic\nrobustness to small random perturbations due to its well-defined\nenergy-minimizing dynamics. Second, we formally establish that the PC updates\napproximate quasi-Newton methods by incorporating higher-order curvature\ninformation, which makes them more stable and able to converge with fewer\niterations compared to models trained via backpropagation (BP). Furthermore,\nusing this dynamical framework, we provide new theoretical bounds on the\nsimilarity between PC and other algorithms, i.e., BP and target propagation\n(TP), by precisely characterizing the role of higher-order derivatives. These\nbounds, derived through detailed analysis of the Hessian structures, show that\nPC is significantly closer to quasi-Newton updates than TP, providing a deeper\nunderstanding of the stability and efficiency of PC compared to conventional\nlearning methods.\n","authors":["Ankur Mali","Tommaso Salvatori","Alexander Ororbia"],"pdf_url":"https://arxiv.org/pdf/2410.04708v1.pdf","comment":"29 pages, 9 theorems"},{"id":"http://arxiv.org/abs/2410.04707v1","updated":"2024-10-07T02:52:30Z","published":"2024-10-07T02:52:30Z","title":"Learning How Hard to Think: Input-Adaptive Allocation of LM Computation","summary":"  Computationally intensive decoding procedures--including search, reranking,\nand self-critique--can improve the quality of language model (LM) outputs in\nproblems spanning code generation, numerical reasoning, and dialog. Existing\nwork typically applies the same decoding procedure for every input to an LM.\nBut not all inputs require the same amount of computation to process. Can we\nallocate decoding computation adaptively, using more resources to answer\nquestions whose answers will be harder to compute? We present an approach that\npredicts the distribution of rewards given an input and computation budget,\nthen allocates additional computation to inputs for which it is predicted to be\nmost useful. We apply this approach in two decoding procedures: first, an\nadaptive best-of-k procedure that dynamically selects the number of samples to\ngenerate as input to a reranker; second, a routing procedure that dynamically\nresponds to a query using a decoding procedure that is expensive but accurate,\nor one that is cheaper but less capable. Across a suite of programming,\nmathematics, and dialog tasks, we show that accurate computation-allocation\nprocedures can be learned, and reduce computation by up to 50% at no cost to\nresponse quality, or improve quality by up to 10% at a fixed computational\nbudget.\n","authors":["Mehul Damani","Idan Shenfeld","Andi Peng","Andreea Bobu","Jacob Andreas"],"pdf_url":"https://arxiv.org/pdf/2410.04707v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.00943v2","updated":"2024-10-07T02:47:36Z","published":"2024-04-01T06:03:39Z","title":"Evalverse: Unified and Accessible Library for Large Language Model\n  Evaluation","summary":"  This paper introduces Evalverse, a novel library that streamlines the\nevaluation of Large Language Models (LLMs) by unifying disparate evaluation\ntools into a single, user-friendly framework. Evalverse enables individuals\nwith limited knowledge of artificial intelligence to easily request LLM\nevaluations and receive detailed reports, facilitated by an integration with\ncommunication platforms like Slack. Thus, Evalverse serves as a powerful tool\nfor the comprehensive assessment of LLMs, offering both researchers and\npractitioners a centralized and easily accessible evaluation framework.\nFinally, we also provide a demo video for Evalverse, showcasing its\ncapabilities and implementation in a two-minute format.\n","authors":["Jihoo Kim","Wonho Song","Dahyun Kim","Yunsu Kim","Yungi Kim","Chanjun Park"],"pdf_url":"https://arxiv.org/pdf/2404.00943v2.pdf","comment":"Accepted to EMNLP 2024 Demo Track"},{"id":"http://arxiv.org/abs/2403.05010v3","updated":"2024-10-07T02:08:05Z","published":"2024-03-08T03:16:47Z","title":"RFWave: Multi-band Rectified Flow for Audio Waveform Reconstruction","summary":"  Recent advancements in generative modeling have significantly enhanced the\nreconstruction of audio waveforms from various representations. While diffusion\nmodels are adept at this task, they are hindered by latency issues due to their\noperation at the individual sample point level and the need for numerous\nsampling steps. In this study, we introduce RFWave, a cutting-edge multi-band\nRectified Flow approach designed to reconstruct high-fidelity audio waveforms\nfrom Mel-spectrograms or discrete acoustic tokens. RFWave uniquely generates\ncomplex spectrograms and operates at the frame level, processing all subbands\nsimultaneously to boost efficiency. Leveraging Rectified Flow, which targets a\nstraight transport trajectory, RFWave achieves reconstruction with just 10\nsampling steps. Our empirical evaluations show that RFWave not only provides\noutstanding reconstruction quality but also offers vastly superior\ncomputational efficiency, enabling audio generation at speeds up to 160 times\nfaster than real-time on a GPU. An online demonstration is available at:\nhttps://rfwave-demo.github.io/rfwave/.\n","authors":["Peng Liu","Dongyang Dai","Zhiyong Wu"],"pdf_url":"https://arxiv.org/pdf/2403.05010v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.15851v2","updated":"2024-10-07T02:03:30Z","published":"2024-07-03T18:07:57Z","title":"A Survey on Trustworthiness in Foundation Models for Medical Image\n  Analysis","summary":"  The rapid advancement of foundation models in medical imaging represents a\nsignificant leap toward enhancing diagnostic accuracy and personalized\ntreatment. However, the deployment of foundation models in healthcare\nnecessitates a rigorous examination of their trustworthiness, encompassing\nprivacy, robustness, reliability, explainability, and fairness. The current\nbody of survey literature on foundation models in medical imaging reveals\nconsiderable gaps, particularly in the area of trustworthiness. Additionally,\nexisting surveys on the trustworthiness of foundation models do not adequately\naddress their specific variations and applications within the medical imaging\ndomain. This survey aims to fill that gap by presenting a novel taxonomy of\nfoundation models used in medical imaging and analyzing the key motivations for\nensuring their trustworthiness. We review current research on foundation models\nin major medical imaging applications, focusing on segmentation, medical report\ngeneration, medical question and answering (Q\\&A), and disease diagnosis. These\nareas are highlighted because they have seen a relatively mature and\nsubstantial number of foundation models compared to other applications. We\nfocus on literature that discusses trustworthiness in medical image analysis\nmanuscripts. We explore the complex challenges of building trustworthy\nfoundation models for each application, summarizing current concerns and\nstrategies for enhancing trustworthiness. Furthermore, we examine the potential\nof these models to revolutionize patient care. Our analysis underscores the\nimperative for advancing towards trustworthy AI in medical image analysis,\nadvocating for a balanced approach that fosters innovation while ensuring\nethical and equitable healthcare delivery.\n","authors":["Congzhen Shi","Ryan Rezai","Jiaxi Yang","Qi Dou","Xiaoxiao Li"],"pdf_url":"https://arxiv.org/pdf/2407.15851v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.08464v2","updated":"2024-10-07T01:45:38Z","published":"2024-06-12T17:52:30Z","title":"Magpie: Alignment Data Synthesis from Scratch by Prompting Aligned LLMs\n  with Nothing","summary":"  High-quality instruction data is critical for aligning large language models\n(LLMs). Although some models, such as Llama-3-Instruct, have open weights,\ntheir alignment data remain private, which hinders the democratization of AI.\nHigh human labor costs and a limited, predefined scope for prompting prevent\nexisting open-source data creation methods from scaling effectively,\npotentially limiting the diversity and quality of public alignment datasets. Is\nit possible to synthesize high-quality instruction data at scale by extracting\nit directly from an aligned LLM? We present a self-synthesis method for\ngenerating large-scale alignment data named Magpie. Our key observation is that\naligned LLMs like Llama-3-Instruct can generate a user query when we input only\nthe left-side templates up to the position reserved for user messages, thanks\nto their auto-regressive nature. We use this method to prompt Llama-3-Instruct\nand generate 4 million instructions along with their corresponding responses.\nWe perform a comprehensive analysis of the extracted data and select 300K\nhigh-quality instances. To compare Magpie data with other public instruction\ndatasets, we fine-tune Llama-3-8B-Base with each dataset and evaluate the\nperformance of the fine-tuned models. Our results indicate that in some tasks,\nmodels fine-tuned with Magpie perform comparably to the official\nLlama-3-8B-Instruct, despite the latter being enhanced with 10 million data\npoints through supervised fine-tuning (SFT) and subsequent feedback learning.\nWe also show that using Magpie solely for SFT can surpass the performance of\nprevious public datasets utilized for both SFT and preference optimization,\nsuch as direct preference optimization with UltraFeedback. This advantage is\nevident on alignment benchmarks such as AlpacaEval, ArenaHard, and WildBench.\n","authors":["Zhangchen Xu","Fengqing Jiang","Luyao Niu","Yuntian Deng","Radha Poovendran","Yejin Choi","Bill Yuchen Lin"],"pdf_url":"https://arxiv.org/pdf/2406.08464v2.pdf","comment":"Link: https://magpie-align.github.io/"},{"id":"http://arxiv.org/abs/2410.02874v2","updated":"2024-10-07T01:39:25Z","published":"2024-10-03T18:02:56Z","title":"Real-World Cooking Robot System from Recipes Based on Food State\n  Recognition Using Foundation Models and PDDL","summary":"  Although there is a growing demand for cooking behaviours as one of the\nexpected tasks for robots, a series of cooking behaviours based on new recipe\ndescriptions by robots in the real world has not yet been realised. In this\nstudy, we propose a robot system that integrates real-world executable robot\ncooking behaviour planning using the Large Language Model (LLM) and classical\nplanning of PDDL descriptions, and food ingredient state recognition learning\nfrom a small number of data using the Vision-Language model (VLM). We succeeded\nin experiments in which PR2, a dual-armed wheeled robot, performed cooking from\narranged new recipes in a real-world environment, and confirmed the\neffectiveness of the proposed system.\n","authors":["Naoaki Kanazawa","Kento Kawaharazuka","Yoshiki Obinata","Kei Okada","Masayuki Inaba"],"pdf_url":"https://arxiv.org/pdf/2410.02874v2.pdf","comment":"Accepted at Advanced Robotics, website -\n  https://kanazawanaoaki.github.io/cook-from-recipe-pddl/"},{"id":"http://arxiv.org/abs/2410.04683v1","updated":"2024-10-07T01:34:42Z","published":"2024-10-07T01:34:42Z","title":"Towards Measuring Goal-Directedness in AI Systems","summary":"  Recent advances in deep learning have brought attention to the possibility of\ncreating advanced, general AI systems that outperform humans across many tasks.\nHowever, if these systems pursue unintended goals, there could be catastrophic\nconsequences. A key prerequisite for AI systems pursuing unintended goals is\nwhether they will behave in a coherent and goal-directed manner in the first\nplace, optimizing for some unknown goal; there exists significant research\ntrying to evaluate systems for said behaviors. However, the most rigorous\ndefinitions of goal-directedness we currently have are difficult to compute in\nreal-world settings. Drawing upon this previous literature, we explore policy\ngoal-directedness within reinforcement learning (RL) environments. In our\nfindings, we propose a different family of definitions of the goal-directedness\nof a policy that analyze whether it is well-modeled as near-optimal for many\n(sparse) reward functions. We operationalize this preliminary definition of\ngoal-directedness and test it in toy Markov decision process (MDP)\nenvironments. Furthermore, we explore how goal-directedness could be measured\nin frontier large-language models (LLMs). Our contribution is a definition of\ngoal-directedness that is simpler and more easily computable in order to\napproach the question of whether AI systems could pursue dangerous goals. We\nrecommend further exploration of measuring coherence and goal-directedness,\nbased on our findings.\n","authors":["Dylan Xu","Juan-Pablo Rivera"],"pdf_url":"https://arxiv.org/pdf/2410.04683v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.16406v3","updated":"2024-10-07T01:27:59Z","published":"2024-05-26T02:15:49Z","title":"SpinQuant: LLM quantization with learned rotations","summary":"  Post-training quantization (PTQ) techniques applied to weights, activations,\nand the KV cache greatly reduce memory usage, latency, and power consumption of\nLarge Language Models (LLMs), but may lead to large quantization errors when\noutliers are present. Rotating activation or weight matrices helps remove\noutliers and benefits quantization. In this work, we identify a collection of\napplicable rotation parameterizations that lead to identical outputs in\nfull-precision Transformer architectures while enhancing quantization accuracy.\nIn addition, we find that some random rotations lead to much better\nquantization than others, with an up to 13 points difference in downstream\nzero-shot reasoning performance. As a result, we propose SpinQuant, a novel\napproach that incorporates learned rotation matrices for optimal quantized\nnetwork accuracy. With 4-bit quantization of weight, activation, and KV-cache,\nSpinQuant narrows the accuracy gap on zero-shot reasoning tasks with full\nprecision to merely 2.9 points on the LLaMA-2 7B model, surpassing LLM-QAT by\n19.1 points and SmoothQuant by 25.0 points. Furthermore, SpinQuant also\noutperforms concurrent work QuaRot, which applies random rotations to remove\noutliers. In particular, for LLaMA-3 8B models that are hard to quantize,\nSpinQuant reduces the gap to full precision by up to 45.1% relative to QuaRot.\n","authors":["Zechun Liu","Changsheng Zhao","Igor Fedorov","Bilge Soran","Dhruv Choudhary","Raghuraman Krishnamoorthi","Vikas Chandra","Yuandong Tian","Tijmen Blankevoort"],"pdf_url":"https://arxiv.org/pdf/2405.16406v3.pdf","comment":null}],"Software Engineering":[{"id":"http://arxiv.org/abs/2410.05251v1","updated":"2024-10-07T17:54:13Z","published":"2024-10-07T17:54:13Z","title":"Block MedCare: Advancing healthcare through blockchain integration","summary":"  In an era driven by information exchange, transparency and security hold\ncrucial importance, particularly within the healthcare industry, where data\nintegrity and confidentiality are paramount. This paper investigates the\nintegration of blockchain technology in healthcare, focusing on its potential\nto revolutionize Electronic Health Records (EHR) management and data sharing.\nBy leveraging Ethereum-based blockchain implementations and smart contracts, we\npropose a novel system that empowers patients to securely store and manage\ntheir medical data. Our research addresses critical challenges in implementing\nblockchain in healthcare, including scalability, user privacy, and regulatory\ncompliance. We propose a solution that combines digital signatures, Role-Based\nAccess Control, and a multi-layered architecture to enhance security and ensure\ncontrolled access. The system's key functions, including user registration,\ndata append, and data retrieval, are facilitated through smart contracts,\nproviding a secure and efficient mechanism for managing health information. To\nvalidate our approach, we developed a decentralized application (dApp) that\ndemonstrates the practical implementation of our blockchain-based healthcare\nsolution. The dApp incorporates user-friendly interfaces for patients, doctors,\nand administrators, showcasing the system's potential to streamline healthcare\nprocesses while maintaining data security and integrity. Additionally, we\nconducted a survey to gain insights into the perceived benefits and challenges\nof blockchain adoption in healthcare. The results indicate strong interest\namong healthcare professionals and IT experts, while also highlighting concerns\nabout integration costs and technological complexity. Our findings...\n","authors":["Oliver Simonoski","Dijana Capeska Bogatinoska"],"pdf_url":"https://arxiv.org/pdf/2410.05251v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.15877v3","updated":"2024-10-07T17:23:30Z","published":"2024-06-22T15:52:04Z","title":"BigCodeBench: Benchmarking Code Generation with Diverse Function Calls\n  and Complex Instructions","summary":"  Task automation has been greatly empowered by the recent advances in Large\nLanguage Models (LLMs) via Python code, where the tasks ranging from software\nengineering development to general-purpose reasoning. While current benchmarks\nhave shown that LLMs can solve tasks using programs like human developers, the\nmajority of their evaluations are limited to short and self-contained\nalgorithmic tasks or standalone function calls. Solving challenging and\npractical requires the capability of utilizing diverse function calls as tools\nto efficiently implement functionalities like data analysis and web\ndevelopment. In addition, using multiple tools to solve a task needs\ncompositional reasoning by accurately understanding complex instructions.\nFulfilling both of these characteristics can pose a great challenge for LLMs.To\nassess how well LLMs can solve challenging and practical tasks via programs, we\nintroduce BigCodeBench, a benchmark that challenges LLMs to invoke multiple\nfunction calls as tools from 139 libraries and 7 domains for 1,140 fine-grained\ntasks. To evaluate LLMs rigorously, each task encompasses 5.6 test cases with\nan average branch coverage of 99%. In addition, we propose a\nnatural-language-oriented variant of BigCodeBench, BigCodeBench-Instruct, that\nautomatically transforms the original docstrings into short instructions only\nwith essential information. Our extensive evaluation of 60 LLMs shows that LLMs\nare not yet capable of following complex instructions to use function calls\nprecisely, with scores up to 60%, significantly lower than the human\nperformance of 97%. The results underscore the need for further advancements in\nthis area.\n","authors":["Terry Yue Zhuo","Minh Chien Vu","Jenny Chim","Han Hu","Wenhao Yu","Ratnadira Widyasari","Imam Nur Bani Yusuf","Haolan Zhan","Junda He","Indraneil Paul","Simon Brunner","Chen Gong","Thong Hoang","Armel Randy Zebaze","Xiaoheng Hong","Wen-Ding Li","Jean Kaddour","Ming Xu","Zhihan Zhang","Prateek Yadav","Naman Jain","Alex Gu","Zhoujun Cheng","Jiawei Liu","Qian Liu","Zijian Wang","David Lo","Binyuan Hui","Niklas Muennighoff","Daniel Fried","Xiaoning Du","Harm de Vries","Leandro Von Werra"],"pdf_url":"https://arxiv.org/pdf/2406.15877v3.pdf","comment":"44 pages, 14 figures, 7 tables, built with love by the BigCode\n  community :)"},{"id":"http://arxiv.org/abs/2405.08704v2","updated":"2024-10-07T17:23:25Z","published":"2024-05-14T15:42:55Z","title":"Full Line Code Completion: Bringing AI to Desktop","summary":"  In recent years, several industrial solutions for the problem of multi-token\ncode completion appeared, each making a great advance in the area but mostly\nfocusing on cloud-based runtime and avoiding working on the end user's device.\n  In this work, we describe our approach for building a multi-token code\ncompletion feature for the JetBrains' IntelliJ Platform, which we call Full\nLine Code Completion. The feature suggests only syntactically correct code and\nworks fully locally, i.e., data querying and the generation of suggestions\nhappens on the end user's machine. We share important time and\nmemory-consumption restrictions, as well as design principles that a code\ncompletion engine should satisfy. Working entirely on the end user's device,\nour code completion engine enriches user experience while being not only fast\nand compact but also secure. We share a number of useful techniques to meet the\nstated development constraints and also describe offline and online evaluation\npipelines that allowed us to make better decisions.\n  Our online evaluation shows that the usage of the tool leads to 1.3 times\nmore Python code in the IDE being produced by code completion. The described\nsolution was initially started with a help of researchers and was then bundled\ninto all JetBrains IDEs where it is now used by millions of users. Thus, we\nbelieve that this work is useful for bridging academia and industry, providing\nresearchers with the knowledge of what happens when complex research-based\nsolutions are integrated into real products.\n","authors":["Anton Semenkin","Vitaliy Bibaev","Yaroslav Sokolov","Kirill Krylov","Alexey Kalina","Anna Khannanova","Danila Savenkov","Darya Rovdo","Igor Davidenko","Kirill Karnaukhov","Maxim Vakhrushev","Mikhail Kostyukov","Mikhail Podvitskii","Petr Surkov","Yaroslav Golubev","Nikita Povarov","Timofey Bryksin"],"pdf_url":"https://arxiv.org/pdf/2405.08704v2.pdf","comment":"12 pages, 4 figures"},{"id":"http://arxiv.org/abs/2410.03480v2","updated":"2024-10-07T16:28:39Z","published":"2024-10-04T14:52:18Z","title":"SeBS-Flow: Benchmarking Serverless Cloud Function Workflows","summary":"  Serverless computing has emerged as a prominent paradigm, with a significant\nadoption rate among cloud customers. While this model offers advantages such as\nabstraction from the deployment and resource scheduling, it also poses\nlimitations in handling complex use cases due to the restricted nature of\nindividual functions. Serverless workflows address this limitation by\norchestrating multiple functions into a cohesive application. However, existing\nserverless workflow platforms exhibit significant differences in their\nprogramming models and infrastructure, making fair and consistent performance\nevaluations difficult in practice. To address this gap, we propose the first\nserverless workflow benchmarking suite SeBS-Flow, providing a platform-agnostic\nworkflow model that enables consistent benchmarking across various platforms.\nSeBS-Flow includes six real-world application benchmarks and four\nmicrobenchmarks representing different computational patterns. We conduct\ncomprehensive evaluations on three major cloud platforms, assessing\nperformance, cost, scalability, and runtime deviations. We make our benchmark\nsuite open-source, enabling rigorous and comparable evaluations of serverless\nworkflows over time.\n","authors":["Larissa Schmid","Marcin Copik","Alexandru Calotoiu","Laurin Brandner","Anne Koziolek","Torsten Hoefler"],"pdf_url":"https://arxiv.org/pdf/2410.03480v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.05095v1","updated":"2024-10-07T14:50:19Z","published":"2024-10-07T14:50:19Z","title":"Towards a Modern and Lightweight Rendering Engine for Dynamic Robotic\n  Simulations","summary":"  Interactive dynamic simulators are an accelerator for developing novel\nrobotic control algorithms and complex systems involving humans and robots. In\nuser training and synthetic data generation applications, a high-fidelity\nvisualization of the simulation is essential. Visual fidelity is dependent on\nthe quality of the computer graphics algorithms used to render the simulated\nscene. Furthermore, the rendering algorithms must be implemented on the\ngraphics processing unit (GPU) to achieve real-time performance, requiring the\nuse of a graphics application programming interface (API). This paper presents\na performance-focused and lightweight rendering engine supporting the Vulkan\ngraphics API. The engine is designed to modernize the legacy rendering pipeline\nof Asynchronous Multi-Body Framework (AMBF), a dynamic simulation framework\nused extensively for interactive robotics simulation development. This new\nrendering engine implements graphical features such as physically based\nrendering (PBR), anti-aliasing, and ray-traced shadows, significantly improving\nthe image quality of AMBF. Computational experiments show that the engine can\nrender a simulated scene with over seven million triangles while maintaining\nGPU computation times within two milliseconds.\n","authors":["Christopher John Allison","Haoying Zhou","Adnan Munawar","Peter Kazanzides","Juan Antonio Barragan"],"pdf_url":"https://arxiv.org/pdf/2410.05095v1.pdf","comment":"8 pages, 8 figures, submitted to the 2024 IEEE International\n  Conference on Robotic Computing (IRC)"},{"id":"http://arxiv.org/abs/2410.04986v1","updated":"2024-10-07T12:34:20Z","published":"2024-10-07T12:34:20Z","title":"Finding Safety Violations of AI-Enabled Control Systems through the Lens\n  of Synthesized Proxy Programs","summary":"  Given the increasing adoption of modern AI-enabled control systems, ensuring\ntheir safety and reliability has become a critical task in software testing.\nOne prevalent approach to testing control systems is falsification, which aims\nto find an input signal that causes the control system to violate a formal\nsafety specification using optimization algorithms. However, applying\nfalsification to AI-enabled control systems poses two significant challenges:\n(1)~it requires the system to execute numerous candidate test inputs, which can\nbe time-consuming, particularly for systems with AI models that have many\nparameters, and (2)~multiple safety requirements are typically defined as a\nconjunctive specification, which is difficult for existing falsification\napproaches to comprehensively cover.\n  This paper introduces Synthify, a falsification framework tailored for\nAI-enabled control systems. Our approach performs falsification in a two-phase\nprocess. At the start, Synthify synthesizes a program that implements one or a\nfew linear controllers to serve as a proxy for the AI controller. This proxy\nprogram mimics the AI controller's functionality but is computationally more\nefficient. Then, Synthify employs the $\\epsilon$-greedy strategy to sample a\npromising sub-specification from the conjunctive safety specification. It then\nuses a Simulated Annealing-based falsification algorithm to find violations of\nthe sampled sub-specification for the control system. To evaluate Synthify, we\ncompare it to PSY-TaLiRo, a state-of-the-art and industrial-strength\nfalsification tool, on 8 publicly available control systems. On average,\nSynthify achieves a 83.5% higher success rate in falsification compared to\nPSY-TaLiRo with the same budget of falsification trials. The safety violations\nfound by Synthify are also more diverse than those found by PSY-TaLiRo,\ncovering 137.7% more sub-specifications.\n","authors":["Jieke Shi","Zhou Yang","Junda He","Bowen Xu","Dongsun Kim","DongGyun Han","David Lo"],"pdf_url":"https://arxiv.org/pdf/2410.04986v1.pdf","comment":"Under Review by ACM Transactions on Software Engineering and\n  Methodology (TOSEM)"},{"id":"http://arxiv.org/abs/2404.02525v3","updated":"2024-10-07T11:52:19Z","published":"2024-04-03T07:27:33Z","title":"Large Language Model for Vulnerability Detection and Repair: Literature\n  Review and the Road Ahead","summary":"  The significant advancements in Large Language Models (LLMs) have resulted in\ntheir widespread adoption across various tasks within Software Engineering\n(SE), including vulnerability detection and repair. Numerous studies have\ninvestigated the application of LLMs to enhance vulnerability detection and\nrepair tasks. Despite the increasing research interest, there is currently no\nexisting survey that focuses on the utilization of LLMs for vulnerability\ndetection and repair. In this paper, we aim to bridge this gap by offering a\nsystematic literature review of approaches aimed at improving vulnerability\ndetection and repair through the utilization of LLMs. The review encompasses\nresearch work from leading SE, AI, and Security conferences and journals,\nencompassing 43 papers published across 25 distinct venues, along with 15\nhigh-quality preprint papers, bringing the total to 58 papers. By answering\nthree key research questions, we aim to (1) summarize the LLMs employed in the\nrelevant literature, (2) categorize various LLM adaptation techniques in\nvulnerability detection, and (3) classify various LLM adaptation techniques in\nvulnerability repair. Based on our findings, we have identified a series of\nlimitations of existing studies. Additionally, we have outlined a roadmap\nhighlighting potential opportunities that we believe are pertinent and crucial\nfor future research endeavors.\n","authors":["Xin Zhou","Sicong Cao","Xiaobing Sun","David Lo"],"pdf_url":"https://arxiv.org/pdf/2404.02525v3.pdf","comment":"24 pages"},{"id":"http://arxiv.org/abs/2404.04834v2","updated":"2024-10-07T10:28:25Z","published":"2024-04-07T07:05:40Z","title":"LLM-Based Multi-Agent Systems for Software Engineering: Vision and the\n  Road Ahead","summary":"  Integrating Large Language Models(LLMs) into autonomous agents marks a\nsignificant shift in the research landscape by offering cognitive abilities\ncompetitive to human planning and reasoning. This paper envisions the evolution\nof LLM-based Multi-Agent (LMA) systems in addressing complex and multi-faceted\nsoftware engineering challenges. LMA systems introduce numerous benefits,\nincluding enhanced robustness through collaborative cross-examination,\nautonomous problem-solving, and scalable solutions to complex software\nprojects. By examining the role of LMA systems in future software engineering\npractices, this vision paper highlights the potential applications and emerging\nchallenges. We further point to specific opportunities for research and\nconclude with a research agenda with a set of research questions to guide\nfuture research directions.\n","authors":["Junda He","Christoph Treude","David Lo"],"pdf_url":"https://arxiv.org/pdf/2404.04834v2.pdf","comment":"Under Review"},{"id":"http://arxiv.org/abs/2410.04717v1","updated":"2024-10-07T03:15:11Z","published":"2024-10-07T03:15:11Z","title":"$\\textbf{Only-IF}$:Revealing the Decisive Effect of Instruction\n  Diversity on Generalization","summary":"  Understanding and accurately following instructions is critical for large\nlanguage models (LLMs) to be effective across diverse tasks. In this work, we\nrigorously examine the key factors that enable models to generalize to unseen\ninstructions, providing insights to guide the collection of data for\ninstruction-tuning. Through controlled experiments, inspired by the\nTuring-complete Markov algorithm, we demonstrate that such generalization\n$\\textbf{only emerges}$ when training data is diversified enough across\nsemantic domains. Our findings also reveal that merely diversifying within\nlimited domains fails to ensure robust generalization. In contrast,\ncross-domain data diversification, even under constrained data budgets,\nsignificantly enhances a model's adaptability. We further extend our analysis\nto real-world scenarios, including fine-tuning of\n$\\textit{$\\textbf{specialist}$}$ and $\\textit{$\\textbf{generalist}$}$ models.\nIn both cases, we demonstrate that 1) better performance can be achieved by\nincreasing the diversity of an established dataset while keeping the data size\nconstant, and 2) when scaling up the data, diversifying the semantics of\ninstructions is more effective than simply increasing the quantity of similar\ndata. Our research provides important insights for dataset collation,\nparticularly when optimizing model performance by expanding training data for\nboth specialist and generalist scenarios. We show that careful consideration of\ndata diversification is key: training specialist models with data extending\nbeyond their core domain leads to significant performance improvements, while\ngeneralist models benefit from diverse data mixtures that enhance their overall\ninstruction-following capabilities across a wide range of applications. Our\nresults highlight the critical role of strategic diversification and offer\nclear guidelines for improving data quality.\n","authors":["Dylan Zhang","Justin Wang","Francois Charton"],"pdf_url":"https://arxiv.org/pdf/2410.04717v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04678v1","updated":"2024-10-07T01:18:56Z","published":"2024-10-07T01:18:56Z","title":"Deciphering Refactoring Branch Dynamics in Modern Code Review: An\n  Empirical Study on Qt","summary":"  Context: Modern code review is a widely employed technique in both industrial\nand open-source projects, serving to enhance software quality, share knowledge,\nand ensure compliance with coding standards and guidelines. While code review\nis extensively studied for its general challenges, best practices, outcomes,\nand socio-technical aspects, little attention has been paid to how refactoring\nis reviewed and what developers prioritize when reviewing refactored code in\nthe Refactor branch. Objective: The goal is to understand the review process\nfor refactoring changes in the Refactor branch and to identify what developers\ncare about when reviewing code in this branch. Method: In this study, we\npresent a quantitative and qualitative examination to understand the main\ncriteria developers use to decide whether to accept or reject refactored code\nsubmissions and identify the challenges inherent in this process. Results:\nAnalyzing 2,154 refactoring and non-refactoring reviews across Qt open-source\nprojects, we find that reviews involving refactoring from the Refactor branch\ntake significantly less time to resolve in terms of code review efforts.\nAdditionally, documentation of developer intent is notably sparse within the\nRefactor branch compared to other branches. Furthermore, through thematic\nanalysis of a substantial sample of refactoring code review discussions, we\nconstruct a comprehensive taxonomy consisting of 12 refactoring review\ncriteria.\n","authors":["Eman Abdullah AlOmar"],"pdf_url":"https://arxiv.org/pdf/2410.04678v1.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2203.14404"}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2410.05270v1","updated":"2024-10-07T17:59:59Z","published":"2024-10-07T17:59:59Z","title":"Fine-Tuning CLIP's Last Visual Projector: A Few-Shot Cornucopia","summary":"  We consider the problem of adapting a contrastively pretrained\nvision-language model like CLIP (Radford et al., 2021) for few-shot\nclassification. The existing literature addresses this problem by learning a\nlinear classifier of the frozen visual features, optimizing word embeddings, or\nlearning external feature adapters. This paper introduces an alternative way\nfor CLIP adaptation without adding 'external' parameters to optimize. We find\nthat simply fine-tuning the last projection matrix of the vision encoder leads\nto strong performance compared to the existing baselines. Furthermore, we show\nthat regularizing training with the distance between the fine-tuned and\npretrained matrices adds reliability for adapting CLIP through this layer.\nPerhaps surprisingly, this approach, coined ProLIP, yields performances on par\nor better than state of the art on 11 few-shot classification benchmarks,\nfew-shot domain generalization, cross-dataset transfer and test-time\nadaptation. Code will be made available at\nhttps://github.com/astra-vision/ProLIP .\n","authors":["Mohammad Fahes","Tuan-Hung Vu","Andrei Bursuc","Patrick Pérez","Raoul de Charette"],"pdf_url":"https://arxiv.org/pdf/2410.05270v1.pdf","comment":"Preprint,under review"},{"id":"http://arxiv.org/abs/2410.05267v1","updated":"2024-10-07T17:59:48Z","published":"2024-10-07T17:59:48Z","title":"Grounding Partially-Defined Events in Multimodal Data","summary":"  How are we able to learn about complex current events just from short\nsnippets of video? While natural language enables straightforward ways to\nrepresent under-specified, partially observable events, visual data does not\nfacilitate analogous methods and, consequently, introduces unique challenges in\nevent understanding. With the growing prevalence of vision-capable AI agents,\nthese systems must be able to model events from collections of unstructured\nvideo data. To tackle robust event modeling in multimodal settings, we\nintroduce a multimodal formulation for partially-defined events and cast the\nextraction of these events as a three-stage span retrieval task. We propose a\ncorresponding benchmark for this task, MultiVENT-G, that consists of 14.5 hours\nof densely annotated current event videos and 1,168 text documents, containing\n22.8K labeled event-centric entities. We propose a collection of LLM-driven\napproaches to the task of multimodal event analysis, and evaluate them on\nMultiVENT-G. Results illustrate the challenges that abstract event\nunderstanding poses and demonstrates promise in event-centric video-language\nsystems.\n","authors":["Kate Sanders","Reno Kriz","David Etter","Hannah Recknor","Alexander Martin","Cameron Carpenter","Jingyang Lin","Benjamin Van Durme"],"pdf_url":"https://arxiv.org/pdf/2410.05267v1.pdf","comment":"Preprint; 9 pages; 2024 EMNLP Findings"},{"id":"http://arxiv.org/abs/2410.05266v1","updated":"2024-10-07T17:59:45Z","published":"2024-10-07T17:59:45Z","title":"Brain Mapping with Dense Features: Grounding Cortical Semantic\n  Selectivity in Natural Images With Vision Transformers","summary":"  Advances in large-scale artificial neural networks have facilitated novel\ninsights into the functional topology of the brain. Here, we leverage this\napproach to study how semantic categories are organized in the human visual\ncortex. To overcome the challenge presented by the co-occurrence of multiple\ncategories in natural images, we introduce BrainSAIL (Semantic Attribution and\nImage Localization), a method for isolating specific neurally-activating visual\nconcepts in images. BrainSAIL exploits semantically consistent, dense spatial\nfeatures from pre-trained vision models, building upon their demonstrated\nability to robustly predict neural activity. This method derives clean,\nspatially dense embeddings without requiring any additional training, and\nemploys a novel denoising process that leverages the semantic consistency of\nimages under random augmentations. By unifying the space of whole-image\nembeddings and dense visual features and then applying voxel-wise encoding\nmodels to these features, we enable the identification of specific subregions\nof each image which drive selectivity patterns in different areas of the higher\nvisual cortex. We validate BrainSAIL on cortical regions with known category\nselectivity, demonstrating its ability to accurately localize and disentangle\nselectivity to diverse visual concepts. Next, we demonstrate BrainSAIL's\nability to characterize high-level visual selectivity to scene properties and\nlow-level visual features such as depth, luminance, and saturation, providing\ninsights into the encoding of complex visual information. Finally, we use\nBrainSAIL to directly compare the feature selectivity of different brain\nencoding models across different regions of interest in visual cortex. Our\ninnovative method paves the way for significant advances in mapping and\ndecomposing high-level visual representations in the human brain.\n","authors":["Andrew F. Luo","Jacob Yeung","Rushikesh Zawar","Shaurya Dewan","Margaret M. Henderson","Leila Wehbe","Michael J. Tarr"],"pdf_url":"https://arxiv.org/pdf/2410.05266v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.11839v2","updated":"2024-10-07T17:59:42Z","published":"2024-06-17T17:59:58Z","title":"mDPO: Conditional Preference Optimization for Multimodal Large Language\n  Models","summary":"  Direct preference optimization (DPO) has shown to be an effective method for\nlarge language model (LLM) alignment. Recent works have attempted to apply DPO\nto multimodal scenarios but have found it challenging to achieve consistent\nimprovement. Through a comparative experiment, we identify the unconditional\npreference problem in multimodal preference optimization, where the model\noverlooks the image condition. To address this problem, we propose mDPO, a\nmultimodal DPO objective that prevents the over-prioritization of language-only\npreferences by also optimizing image preference. Moreover, we introduce a\nreward anchor that forces the reward to be positive for chosen responses,\nthereby avoiding the decrease in their likelihood -- an intrinsic problem of\nrelative preference optimization. Experiments on two multimodal LLMs of\ndifferent sizes and three widely used benchmarks demonstrate that mDPO\neffectively addresses the unconditional preference problem in multimodal\npreference optimization and significantly improves model performance,\nparticularly in reducing hallucination.\n","authors":["Fei Wang","Wenxuan Zhou","James Y. Huang","Nan Xu","Sheng Zhang","Hoifung Poon","Muhao Chen"],"pdf_url":"https://arxiv.org/pdf/2406.11839v2.pdf","comment":"Accepted to EMNLP 2024 Main Conference. Project website:\n  https://feiwang96.github.io/mDPO"},{"id":"http://arxiv.org/abs/2410.05261v1","updated":"2024-10-07T17:58:35Z","published":"2024-10-07T17:58:35Z","title":"TextHawk2: A Large Vision-Language Model Excels in Bilingual OCR and\n  Grounding with 16x Fewer Tokens","summary":"  Reading dense text and locating objects within images are fundamental\nabilities for Large Vision-Language Models (LVLMs) tasked with advanced jobs.\nPrevious LVLMs, including superior proprietary models like GPT-4o, have\nstruggled to excel in both tasks simultaneously. Moreover, previous LVLMs with\nfine-grained perception cost thousands of tokens per image, making them\nresource-intensive. We present TextHawk2, a bilingual LVLM featuring efficient\nfine-grained perception and demonstrating cutting-edge performance across\ngeneral-purpose, OCR, and grounding tasks with 16 times fewer image tokens.\nCritical improvements include: (1) Token Compression: Building on the efficient\narchitecture of its predecessor, TextHawk2 significantly reduces the number of\ntokens per image by 16 times, facilitating training and deployment of the\nTextHawk series with minimal resources. (2) Visual Encoder Reinforcement: We\nenhance the visual encoder through LVLM co-training, unlocking its potential\nfor previously unseen tasks like Chinese OCR and grounding. (3) Data Diversity:\nWe maintain a comparable scale of 100 million samples while diversifying the\nsources of pre-training data. We assess TextHawk2 across multiple benchmarks,\nwhere it consistently delivers superior performance and outperforms\nclosed-source models of similar scale, such as achieving 78.4% accuracy on\nOCRBench, 81.4% accuracy on ChartQA, 89.6% ANLS on DocVQA, and 88.1%\naccuracy@0.5 on RefCOCOg-test.\n","authors":["Ya-Qi Yu","Minghui Liao","Jiwen Zhang","Jihao Wu"],"pdf_url":"https://arxiv.org/pdf/2410.05261v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.05260v1","updated":"2024-10-07T17:58:22Z","published":"2024-10-07T17:58:22Z","title":"DART: A Diffusion-Based Autoregressive Motion Model for Real-Time\n  Text-Driven Motion Control","summary":"  Text-conditioned human motion generation, which allows for user interaction\nthrough natural language, has become increasingly popular. Existing methods\ntypically generate short, isolated motions based on a single input sentence.\nHowever, human motions are continuous and can extend over long periods,\ncarrying rich semantics. Creating long, complex motions that precisely respond\nto streams of text descriptions, particularly in an online and real-time\nsetting, remains a significant challenge. Furthermore, incorporating spatial\nconstraints into text-conditioned motion generation presents additional\nchallenges, as it requires aligning the motion semantics specified by text\ndescriptions with geometric information, such as goal locations and 3D scene\ngeometry. To address these limitations, we propose DART, a Diffusion-based\nAutoregressive motion primitive model for Real-time Text-driven motion control.\nOur model, DART, effectively learns a compact motion primitive space jointly\nconditioned on motion history and text inputs using latent diffusion models. By\nautoregressively generating motion primitives based on the preceding history\nand current text input, DART enables real-time, sequential motion generation\ndriven by natural language descriptions. Additionally, the learned motion\nprimitive space allows for precise spatial motion control, which we formulate\neither as a latent noise optimization problem or as a Markov decision process\naddressed through reinforcement learning. We present effective algorithms for\nboth approaches, demonstrating our model's versatility and superior performance\nin various motion synthesis tasks. Experiments show our method outperforms\nexisting baselines in motion realism, efficiency, and controllability. Video\nresults are available on the project page: https://zkf1997.github.io/DART/.\n","authors":["Kaifeng Zhao","Gen Li","Siyu Tang"],"pdf_url":"https://arxiv.org/pdf/2410.05260v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.05259v1","updated":"2024-10-07T17:58:20Z","published":"2024-10-07T17:58:20Z","title":"GS-VTON: Controllable 3D Virtual Try-on with Gaussian Splatting","summary":"  Diffusion-based 2D virtual try-on (VTON) techniques have recently\ndemonstrated strong performance, while the development of 3D VTON has largely\nlagged behind. Despite recent advances in text-guided 3D scene editing,\nintegrating 2D VTON into these pipelines to achieve vivid 3D VTON remains\nchallenging. The reasons are twofold. First, text prompts cannot provide\nsufficient details in describing clothing. Second, 2D VTON results generated\nfrom different viewpoints of the same 3D scene lack coherence and spatial\nrelationships, hence frequently leading to appearance inconsistencies and\ngeometric distortions. To resolve these problems, we introduce an\nimage-prompted 3D VTON method (dubbed GS-VTON) which, by leveraging 3D Gaussian\nSplatting (3DGS) as the 3D representation, enables the transfer of pre-trained\nknowledge from 2D VTON models to 3D while improving cross-view consistency. (1)\nSpecifically, we propose a personalized diffusion model that utilizes low-rank\nadaptation (LoRA) fine-tuning to incorporate personalized information into\npre-trained 2D VTON models. To achieve effective LoRA training, we introduce a\nreference-driven image editing approach that enables the simultaneous editing\nof multi-view images while ensuring consistency. (2) Furthermore, we propose a\npersona-aware 3DGS editing framework to facilitate effective editing while\nmaintaining consistent cross-view appearance and high-quality 3D geometry. (3)\nAdditionally, we have established a new 3D VTON benchmark, 3D-VTONBench, which\nfacilitates comprehensive qualitative and quantitative 3D VTON evaluations.\nThrough extensive experiments and comparative analyses with existing methods,\nthe proposed \\OM has demonstrated superior fidelity and advanced editing\ncapabilities, affirming its effectiveness for 3D VTON.\n","authors":["Yukang Cao","Masoud Hadi","Liang Pan","Ziwei Liu"],"pdf_url":"https://arxiv.org/pdf/2410.05259v1.pdf","comment":"21 pages, 11 figures"},{"id":"http://arxiv.org/abs/2410.05255v1","updated":"2024-10-07T17:56:53Z","published":"2024-10-07T17:56:53Z","title":"SePPO: Semi-Policy Preference Optimization for Diffusion Alignment","summary":"  Reinforcement learning from human feedback (RLHF) methods are emerging as a\nway to fine-tune diffusion models (DMs) for visual generation. However,\ncommonly used on-policy strategies are limited by the generalization capability\nof the reward model, while off-policy approaches require large amounts of\ndifficult-to-obtain paired human-annotated data, particularly in visual\ngeneration tasks. To address the limitations of both on- and off-policy RLHF,\nwe propose a preference optimization method that aligns DMs with preferences\nwithout relying on reward models or paired human-annotated data. Specifically,\nwe introduce a Semi-Policy Preference Optimization (SePPO) method. SePPO\nleverages previous checkpoints as reference models while using them to generate\non-policy reference samples, which replace \"losing images\" in preference pairs.\nThis approach allows us to optimize using only off-policy \"winning images.\"\nFurthermore, we design a strategy for reference model selection that expands\nthe exploration in the policy space. Notably, we do not simply treat reference\nsamples as negative examples for learning. Instead, we design an anchor-based\ncriterion to assess whether the reference samples are likely to be winning or\nlosing images, allowing the model to selectively learn from the generated\nreference samples. This approach mitigates performance degradation caused by\nthe uncertainty in reference sample quality. We validate SePPO across both\ntext-to-image and text-to-video benchmarks. SePPO surpasses all previous\napproaches on the text-to-image benchmarks and also demonstrates outstanding\nperformance on the text-to-video benchmarks. Code will be released in\nhttps://github.com/DwanZhang-AI/SePPO.\n","authors":["Daoan Zhang","Guangchen Lan","Dong-Jun Han","Wenlin Yao","Xiaoman Pan","Hongming Zhang","Mingxiao Li","Pengcheng Chen","Yu Dong","Christopher Brinton","Jiebo Luo"],"pdf_url":"https://arxiv.org/pdf/2410.05255v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.05249v1","updated":"2024-10-07T17:52:56Z","published":"2024-10-07T17:52:56Z","title":"LoTLIP: Improving Language-Image Pre-training for Long Text\n  Understanding","summary":"  Understanding long text is of great demands in practice but beyond the reach\nof most language-image pre-training (LIP) models. In this work, we empirically\nconfirm that the key reason causing such an issue is that the training images\nare usually paired with short captions, leaving certain tokens easily\novershadowed by salient tokens. Towards this problem, our initial attempt is to\nrelabel the data with long captions, however, directly learning with which may\nlead to performance degradation in understanding short text (e.g., in the image\nclassification task). Then, after incorporating corner tokens to aggregate\ndiverse textual information, we manage to help the model catch up to its\noriginal level of short text understanding yet greatly enhance its capability\nof long text understanding. We further look into whether the model can\ncontinuously benefit from longer captions and notice a clear trade-off between\nthe performance and the efficiency. Finally, we validate the effectiveness of\nour approach using a self-constructed large-scale dataset, which consists of\n100M long caption oriented text-image pairs. It is noteworthy that, on the task\nof long-text image retrieval, we beat the competitor using long captions with\n11.1% improvement (i.e., from 72.62% to 83.72%). We will release the code, the\nmodel, and the new dataset to facilitate the reproducibility and further\nresearch. The project page is available at https://wuw2019.github.io/lotlip.\n","authors":["Wei Wu","Kecheng Zheng","Shuailei Ma","Fan Lu","Yuxin Guo","Yifei Zhang","Wei Chen","Qingpei Guo","Yujun Shen","Zheng-Jun Zha"],"pdf_url":"https://arxiv.org/pdf/2410.05249v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.05243v1","updated":"2024-10-07T17:47:50Z","published":"2024-10-07T17:47:50Z","title":"Navigating the Digital World as Humans Do: Universal Visual Grounding\n  for GUI Agents","summary":"  Multimodal large language models (MLLMs) are transforming the capabilities of\ngraphical user interface (GUI) agents, facilitating their transition from\ncontrolled simulations to complex, real-world applications across various\nplatforms. However, the effectiveness of these agents hinges on the robustness\nof their grounding capability. Current GUI agents predominantly utilize\ntext-based representations such as HTML or accessibility trees, which, despite\ntheir utility, often introduce noise, incompleteness, and increased\ncomputational overhead. In this paper, we advocate a human-like embodiment for\nGUI agents that perceive the environment entirely visually and directly take\npixel-level operations on the GUI. The key is visual grounding models that can\naccurately map diverse referring expressions of GUI elements to their\ncoordinates on the GUI across different platforms. We show that a simple\nrecipe, which includes web-based synthetic data and slight adaptation of the\nLLaVA architecture, is surprisingly effective for training such visual\ngrounding models. We collect the largest dataset for GUI visual grounding so\nfar, containing 10M GUI elements and their referring expressions over 1.3M\nscreenshots, and use it to train UGround, a strong universal visual grounding\nmodel for GUI agents. Empirical results on six benchmarks spanning three\ncategories (grounding, offline agent, and online agent) show that 1) UGround\nsubstantially outperforms existing visual grounding models for GUI agents, by\nup to 20% absolute, and 2) agents with UGround outperform state-of-the-art\nagents, despite the fact that existing agents use additional text-based input\nwhile ours only uses visual perception. These results provide strong support\nfor the feasibility and promises of GUI agents that navigate the digital world\nas humans do.\n","authors":["Boyu Gou","Ruohan Wang","Boyuan Zheng","Yanan Xie","Cheng Chang","Yiheng Shu","Huan Sun","Yu Su"],"pdf_url":"https://arxiv.org/pdf/2410.05243v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.05239v1","updated":"2024-10-07T17:42:53Z","published":"2024-10-07T17:42:53Z","title":"TuneVLSeg: Prompt Tuning Benchmark for Vision-Language Segmentation\n  Models","summary":"  Vision-Language Models (VLMs) have shown impressive performance in vision\ntasks, but adapting them to new domains often requires expensive fine-tuning.\nPrompt tuning techniques, including textual, visual, and multimodal prompting,\noffer efficient alternatives by leveraging learnable prompts. However, their\napplication to Vision-Language Segmentation Models (VLSMs) and evaluation under\nsignificant domain shifts remain unexplored. This work presents an open-source\nbenchmarking framework, TuneVLSeg, to integrate various unimodal and multimodal\nprompt tuning techniques into VLSMs, making prompt tuning usable for downstream\nsegmentation datasets with any number of classes. TuneVLSeg includes $6$ prompt\ntuning strategies on various prompt depths used in $2$ VLSMs totaling of $8$\ndifferent combinations. We test various prompt tuning on $8$ diverse medical\ndatasets, including $3$ radiology datasets (breast tumor, echocardiograph,\nchest X-ray pathologies) and $5$ non-radiology datasets (polyp, ulcer, skin\ncancer), and two natural domain segmentation datasets. Our study found that\ntextual prompt tuning struggles under significant domain shifts, from\nnatural-domain images to medical data. Furthermore, visual prompt tuning, with\nfewer hyperparameters than multimodal prompt tuning, often achieves performance\ncompetitive to multimodal approaches, making it a valuable first attempt. Our\nwork advances the understanding and applicability of different prompt-tuning\ntechniques for robust domain-specific segmentation. The source code is\navailable at https://github.com/naamiinepal/tunevlseg.\n","authors":["Rabin Adhikari","Safal Thapaliya","Manish Dhakal","Bishesh Khanal"],"pdf_url":"https://arxiv.org/pdf/2410.05239v1.pdf","comment":"Accepted at ACCV 2024 (oral presentation)"},{"id":"http://arxiv.org/abs/2410.05234v1","updated":"2024-10-07T17:41:35Z","published":"2024-10-07T17:41:35Z","title":"DiffuseReg: Denoising Diffusion Model for Obtaining Deformation Fields\n  in Unsupervised Deformable Image Registration","summary":"  Deformable image registration aims to precisely align medical images from\ndifferent modalities or times. Traditional deep learning methods, while\neffective, often lack interpretability, real-time observability and adjustment\ncapacity during registration inference. Denoising diffusion models present an\nalternative by reformulating registration as iterative image denoising.\nHowever, existing diffusion registration approaches do not fully harness\ncapabilities, neglecting the critical sampling phase that enables continuous\nobservability during the inference. Hence, we introduce DiffuseReg, an\ninnovative diffusion-based method that denoises deformation fields instead of\nimages for improved transparency. We also propose a novel denoising network\nupon Swin Transformer, which better integrates moving and fixed images with\ndiffusion time step throughout the denoising process. Furthermore, we enhance\ncontrol over the denoising registration process with a novel similarity\nconsistency regularization. Experiments on ACDC datasets demonstrate DiffuseReg\noutperforms existing diffusion registration methods by 1.32 in Dice score. The\nsampling process in DiffuseReg enables real-time output observability and\nadjustment unmatched by previous deep models.\n","authors":["Yongtai Zhuo","Yiqing Shen"],"pdf_url":"https://arxiv.org/pdf/2410.05234v1.pdf","comment":"MICCAI 2024, W-AM-067, https://github.com/YutaZhuo/DiffuseReg"},{"id":"http://arxiv.org/abs/2410.05233v1","updated":"2024-10-07T17:41:10Z","published":"2024-10-07T17:41:10Z","title":"SimO Loss: Anchor-Free Contrastive Loss for Fine-Grained Supervised\n  Contrastive Learning","summary":"  We introduce a novel anchor-free contrastive learning (AFCL) method\nleveraging our proposed Similarity-Orthogonality (SimO) loss. Our approach\nminimizes a semi-metric discriminative loss function that simultaneously\noptimizes two key objectives: reducing the distance and orthogonality between\nembeddings of similar inputs while maximizing these metrics for dissimilar\ninputs, facilitating more fine-grained contrastive learning. The AFCL method,\npowered by SimO loss, creates a fiber bundle topological structure in the\nembedding space, forming class-specific, internally cohesive yet orthogonal\nneighborhoods. We validate the efficacy of our method on the CIFAR-10 dataset,\nproviding visualizations that demonstrate the impact of SimO loss on the\nembedding space. Our results illustrate the formation of distinct, orthogonal\nclass neighborhoods, showcasing the method's ability to create well-structured\nembeddings that balance class separation with intra-class variability. This\nwork opens new avenues for understanding and leveraging the geometric\nproperties of learned representations in various machine learning tasks.\n","authors":["Taha Bouhsine","Imad El Aaroussi","Atik Faysal","Wang Huaxia"],"pdf_url":"https://arxiv.org/pdf/2410.05233v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.00700v4","updated":"2024-10-07T17:40:32Z","published":"2023-12-01T16:33:57Z","title":"Generative Parameter-Efficient Fine-Tuning","summary":"  We present Generative Parameter-Efficient Fine-Tuning (GIFT) for adapting\npretrained Transformer backbones on downstream tasks. GIFT learns to generate\nthe fine-tuned weights for a layer directly from its pretrained weights. The\nGIFT network is parameterized in a minimally-simple way by two linear layers\n(without bias terms), and is shared by different pretrained layers selected for\nfine-tuning (e.g., the Query layers), which result in significantly fewer\ntrainable parameters compared to the layer-specific methods like Low-Rank\nAdapter (LoRA). We also show this formulation bridges parameter-efficient\nfine-tuning and representation fine-tuning. We perform comprehensive\nexperiments on natural language tasks (commonsense and arithmetic reasoning,\ninstruction tuning, and sequence classification) and computer vision tasks\n(fine-grained classification). We obtain the best performance and parameter\nefficiency among baselines on commonsense and arithmetic reasoning, and\ninstruction following using the Llama family of models and on visual\nrecognition benchmarks using Vision Transformers. Notably, compared to LoRA, we\nobtain 5.7% absolute increase in average accuracy with 14 times reduction of\nparameters on Commonsense170k using Llama-3 (8B), and 5.4% absolute increase in\nthe win rate with 4 times reduction of parameters using Llama-2 (7B) during\ninstruction tuning. Our GIFT also obtains a slightly higher win rate on\ninstruction tuning than GPT 3.5 (Turbo 1106).\n","authors":["Chinmay Savadikar","Xi Song","Tianfu Wu"],"pdf_url":"https://arxiv.org/pdf/2312.00700v4.pdf","comment":"Project page and code: https://savadikarc.github.io/gift"},{"id":"http://arxiv.org/abs/2408.06157v2","updated":"2024-10-07T17:39:52Z","published":"2024-08-12T13:53:40Z","title":"3D-free meets 3D priors: Novel View Synthesis from a Single Image with\n  Pretrained Diffusion Guidance","summary":"  Recent 3D novel view synthesis (NVS) methods are limited to\nsingle-object-centric scenes and struggle with complex environments. They often\nrequire extensive 3D data for training, lacking generalization beyond the\ntraining distribution. Conversely, 3D-free methods can generate text-controlled\nviews of complex, in-the-wild scenes using a pretrained stable diffusion model\nwithout the need for a large amount of 3D-based training data, but lack camera\ncontrol. In this paper, we introduce a method capable of generating\ncamera-controlled viewpoints from a single input image, by combining the\nbenefits of 3D-free and 3D-based approaches. Our method excels in handling\ncomplex and diverse scenes without extensive training or additional 3D and\nmultiview data. It leverages widely available pretrained NVS models for weak\nguidance, integrating this knowledge into a 3D-free view synthesis approach to\nachieve the desired results. Experimental results demonstrate that our method\noutperforms existing models in both qualitative and quantitative evaluations,\nproviding high-fidelity and consistent novel view synthesis at desired camera\nangles across a wide variety of scenes.\n","authors":["Taewon Kang","Divya Kothandaraman","Dinesh Manocha","Ming C. Lin"],"pdf_url":"https://arxiv.org/pdf/2408.06157v2.pdf","comment":"13 pages, 12 figures, v2: analysis studies and more results added"},{"id":"http://arxiv.org/abs/2410.05227v1","updated":"2024-10-07T17:35:10Z","published":"2024-10-07T17:35:10Z","title":"The Dawn of Video Generation: Preliminary Explorations with SORA-like\n  Models","summary":"  High-quality video generation, encompassing text-to-video (T2V),\nimage-to-video (I2V), and video-to-video (V2V) generation, holds considerable\nsignificance in content creation to benefit anyone express their inherent\ncreativity in new ways and world simulation to modeling and understanding the\nworld. Models like SORA have advanced generating videos with higher resolution,\nmore natural motion, better vision-language alignment, and increased\ncontrollability, particularly for long video sequences. These improvements have\nbeen driven by the evolution of model architectures, shifting from UNet to more\nscalable and parameter-rich DiT models, along with large-scale data expansion\nand refined training strategies. However, despite the emergence of DiT-based\nclosed-source and open-source models, a comprehensive investigation into their\ncapabilities and limitations remains lacking. Furthermore, the rapid\ndevelopment has made it challenging for recent benchmarks to fully cover\nSORA-like models and recognize their significant advancements. Additionally,\nevaluation metrics often fail to align with human preferences.\n","authors":["Ailing Zeng","Yuhang Yang","Weidong Chen","Wei Liu"],"pdf_url":"https://arxiv.org/pdf/2410.05227v1.pdf","comment":"project: https://ailab-cvc.github.io/VideoGen-Eval/"},{"id":"http://arxiv.org/abs/2410.05222v1","updated":"2024-10-07T17:26:31Z","published":"2024-10-07T17:26:31Z","title":"Precise Model Benchmarking with Only a Few Observations","summary":"  How can we precisely estimate a large language model's (LLM) accuracy on\nquestions belonging to a specific topic within a larger question-answering\ndataset? The standard direct estimator, which averages the model's accuracy on\nthe questions in each subgroup, may exhibit high variance for subgroups\n(topics) with small sample sizes. Synthetic regression modeling, which\nleverages the model's accuracy on questions about other topics, may yield\nbiased estimates that are too unreliable for large subgroups. We prescribe a\nsimple yet effective solution: an empirical Bayes (EB) estimator that balances\ndirect and regression estimates for each subgroup separately, improving the\nprecision of subgroup-level estimates of model performance. Our experiments on\nmultiple datasets show that this approach consistently provides more precise\nestimates of the LLM performance compared to the direct and regression\napproaches, achieving substantial reductions in the mean squared error.\nConfidence intervals for EB estimates also have near-nominal coverage and are\nnarrower compared to those for the direct estimator. Additional experiments on\ntabular and vision data validate the benefits of this EB approach.\n","authors":["Riccardo Fogliato","Pratik Patil","Nil-Jana Akpinar","Mathew Monfort"],"pdf_url":"https://arxiv.org/pdf/2410.05222v1.pdf","comment":"To appear at EMNLP 2024"},{"id":"http://arxiv.org/abs/2410.05217v1","updated":"2024-10-07T17:21:46Z","published":"2024-10-07T17:21:46Z","title":"Organizing Unstructured Image Collections using Natural Language","summary":"  Organizing unstructured visual data into semantic clusters is a key challenge\nin computer vision. Traditional deep clustering (DC) approaches focus on a\nsingle partition of data, while multiple clustering (MC) methods address this\nlimitation by uncovering distinct clustering solutions. The rise of large\nlanguage models (LLMs) and multimodal LLMs (MLLMs) has enhanced MC by allowing\nusers to define clustering criteria in natural language. However, manually\nspecifying criteria for large datasets is impractical. In this work, we\nintroduce the task Semantic Multiple Clustering (SMC) that aims to\nautomatically discover clustering criteria from large image collections,\nuncovering interpretable substructures without requiring human input. Our\nframework, Text Driven Semantic Multiple Clustering (TeDeSC), uses text as a\nproxy to concurrently reason over large image collections, discover\npartitioning criteria, expressed in natural language, and reveal semantic\nsubstructures. To evaluate TeDeSC, we introduce the COCO-4c and Food-4c\nbenchmarks, each containing four grouping criteria and ground-truth\nannotations. We apply TeDeSC to various applications, such as discovering\nbiases and analyzing social media image popularity, demonstrating its utility\nas a tool for automatically organizing image collections and revealing novel\ninsights.\n","authors":["Mingxuan Liu","Zhun Zhong","Jun Li","Gianni Franchi","Subhankar Roy","Elisa Ricci"],"pdf_url":"https://arxiv.org/pdf/2410.05217v1.pdf","comment":"Preprint. Project webpage: https://oatmealliu.github.io/smc.html"},{"id":"http://arxiv.org/abs/2410.05210v1","updated":"2024-10-07T17:16:20Z","published":"2024-10-07T17:16:20Z","title":"Preserving Multi-Modal Capabilities of Pre-trained VLMs for Improving\n  Vision-Linguistic Compositionality","summary":"  In this paper, we propose a new method to enhance compositional understanding\nin pre-trained vision and language models (VLMs) without sacrificing\nperformance in zero-shot multi-modal tasks. Traditional fine-tuning approaches\noften improve compositional reasoning at the cost of degrading multi-modal\ncapabilities, primarily due to the use of global hard negative (HN) loss, which\ncontrasts global representations of images and texts. This global HN loss\npushes HN texts that are highly similar to the original ones, damaging the\nmodel's multi-modal representations. To overcome this limitation, we propose\nFine-grained Selective Calibrated CLIP (FSC-CLIP), which integrates local hard\nnegative loss and selective calibrated regularization. These innovations\nprovide fine-grained negative supervision while preserving the model's\nrepresentational integrity. Our extensive evaluations across diverse benchmarks\nfor both compositionality and multi-modal tasks show that FSC-CLIP not only\nachieves compositionality on par with state-of-the-art models but also retains\nstrong multi-modal capabilities. Code is available at:\nhttps://github.com/ytaek-oh/fsc-clip.\n","authors":["Youngtaek Oh","Jae Won Cho","Dong-Jin Kim","In So Kweon","Junmo Kim"],"pdf_url":"https://arxiv.org/pdf/2410.05210v1.pdf","comment":"EMNLP 2024 (Long, Main). Project page:\n  https://ytaek-oh.github.io/fsc-clip"},{"id":"http://arxiv.org/abs/2404.05729v2","updated":"2024-10-07T17:10:52Z","published":"2024-04-08T17:59:46Z","title":"Finding Visual Task Vectors","summary":"  Visual Prompting is a technique for teaching models to perform a visual task\nvia in-context examples, without any additional training. In this work, we\nanalyze the activations of MAE-VQGAN, a recent Visual Prompting model, and find\ntask vectors, activations that encode task-specific information. Equipped with\nthis insight, we demonstrate that it is possible to identify the task vectors\nand use them to guide the network towards performing different tasks without\nproviding any input-output examples. To find task vectors, we compute the\naverage intermediate activations per task and use the REINFORCE algorithm to\nsearch for the subset of task vectors. The resulting task vectors guide the\nmodel towards performing a task better than the original model without the need\nfor input-output examples.\n","authors":["Alberto Hojel","Yutong Bai","Trevor Darrell","Amir Globerson","Amir Bar"],"pdf_url":"https://arxiv.org/pdf/2404.05729v2.pdf","comment":"https://github.com/alhojel/visual_task_vectors"},{"id":"http://arxiv.org/abs/2410.05206v1","updated":"2024-10-07T17:09:03Z","published":"2024-10-07T17:09:03Z","title":"Studying and Mitigating Biases in Sign Language Understanding Models","summary":"  Ensuring that the benefits of sign language technologies are distributed\nequitably among all community members is crucial. Thus, it is important to\naddress potential biases and inequities that may arise from the design or use\nof these resources. Crowd-sourced sign language datasets, such as the ASL\nCitizen dataset, are great resources for improving accessibility and preserving\nlinguistic diversity, but they must be used thoughtfully to avoid reinforcing\nexisting biases.\n  In this work, we utilize the rich information about participant demographics\nand lexical features present in the ASL Citizen dataset to study and document\nthe biases that may result from models trained on crowd-sourced sign datasets.\nFurther, we apply several bias mitigation techniques during model training, and\nfind that these techniques reduce performance disparities without decreasing\naccuracy. With the publication of this work, we release the demographic\ninformation about the participants in the ASL Citizen dataset to encourage\nfuture bias mitigation work in this space.\n","authors":["Katherine Atwell","Danielle Bragg","Malihe Alikhani"],"pdf_url":"https://arxiv.org/pdf/2410.05206v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.05203v1","updated":"2024-10-07T17:07:21Z","published":"2024-10-07T17:07:21Z","title":"Beyond FVD: Enhanced Evaluation Metrics for Video Generation Quality","summary":"  The Fr\\'echet Video Distance (FVD) is a widely adopted metric for evaluating\nvideo generation distribution quality. However, its effectiveness relies on\ncritical assumptions. Our analysis reveals three significant limitations: (1)\nthe non-Gaussianity of the Inflated 3D Convnet (I3D) feature space; (2) the\ninsensitivity of I3D features to temporal distortions; (3) the impractical\nsample sizes required for reliable estimation. These findings undermine FVD's\nreliability and show that FVD falls short as a standalone metric for video\ngeneration evaluation. After extensive analysis of a wide range of metrics and\nbackbone architectures, we propose JEDi, the JEPA Embedding Distance, based on\nfeatures derived from a Joint Embedding Predictive Architecture, measured using\nMaximum Mean Discrepancy with polynomial kernel. Our experiments on multiple\nopen-source datasets show clear evidence that it is a superior alternative to\nthe widely used FVD metric, requiring only 16% of the samples to reach its\nsteady value, while increasing alignment with human evaluation by 34%, on\naverage.\n","authors":["Ge Ya"," Luo","Gian Favero","Zhi Hao Luo","Alexia Jolicoeur-Martineau","Christopher Pal"],"pdf_url":"https://arxiv.org/pdf/2410.05203v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.00678v2","updated":"2024-10-07T16:45:55Z","published":"2024-06-30T12:33:56Z","title":"A Narrative Review of Image Processing Techniques Related to Prostate\n  Ultrasound","summary":"  Prostate cancer (PCa) poses a significant threat to men's health, with early\ndiagnosis being crucial for improving prognosis and reducing mortality rates.\nTransrectal ultrasound (TRUS) plays a vital role in the diagnosis and\nimage-guided intervention of PCa.To facilitate physicians with more accurate\nand efficient computer-assisted diagnosis and interventions, many image\nprocessing algorithms in TRUS have been proposed and achieved state-of-the-art\nperformance in several tasks, including prostate gland segmentation, prostate\nimage registration, PCa classification and detection, and interventional needle\ndetection. The rapid development of these algorithms over the past two decades\nnecessitates a comprehensive summary. In consequence, this survey provides a\n\\textcolor{blue}{narrative } analysis of this field, outlining the evolution of\nimage processing methods in the context of TRUS image analysis and meanwhile\nhighlighting their relevant contributions. Furthermore, this survey discusses\ncurrent challenges and suggests future research directions to possibly advance\nthis field further.\n","authors":["Haiqiao Wang","Hong Wu","Zhuoyuan Wang","Peiyan Yue","Dong Ni","Pheng-Ann Heng","Yi Wang"],"pdf_url":"https://arxiv.org/pdf/2407.00678v2.pdf","comment":"Accepted by Ultrasound in Medicine & Biology"},{"id":"http://arxiv.org/abs/2410.05182v1","updated":"2024-10-07T16:41:45Z","published":"2024-10-07T16:41:45Z","title":"MARs: Multi-view Attention Regularizations for Patch-based Feature\n  Recognition of Space Terrain","summary":"  The visual detection and tracking of surface terrain is required for\nspacecraft to safely land on or navigate within close proximity to celestial\nobjects. Current approaches rely on template matching with pre-gathered\npatch-based features, which are expensive to obtain and a limiting factor in\nperceptual capability. While recent literature has focused on in-situ detection\nmethods to enhance navigation and operational autonomy, robust description is\nstill needed. In this work, we explore metric learning as the lightweight\nfeature description mechanism and find that current solutions fail to address\ninter-class similarity and multi-view observational geometry. We attribute this\nto the view-unaware attention mechanism and introduce Multi-view Attention\nRegularizations (MARs) to constrain the channel and spatial attention across\nmultiple feature views, regularizing the what and where of attention focus. We\nthoroughly analyze many modern metric learning losses with and without MARs and\ndemonstrate improved terrain-feature recognition performance by upwards of 85%.\nWe additionally introduce the Luna-1 dataset, consisting of Moon crater\nlandmarks and reference navigation frames from NASA mission data to support\nfuture research in this difficult task. Luna-1 and source code are publicly\navailable at https://droneslab.github.io/mars/.\n","authors":["Timothy Chase Jr","Karthik Dantu"],"pdf_url":"https://arxiv.org/pdf/2410.05182v1.pdf","comment":"ECCV 2024. Project page available at\n  https://droneslab.github.io/mars/"},{"id":"http://arxiv.org/abs/2410.02381v2","updated":"2024-10-07T16:39:24Z","published":"2024-10-03T11:01:25Z","title":"MetaMetrics: Calibrating Metrics For Generation Tasks Using Human\n  Preferences","summary":"  Understanding the quality of a performance evaluation metric is crucial for\nensuring that model outputs align with human preferences. However, it remains\nunclear how well each metric captures the diverse aspects of these preferences,\nas metrics often excel in one particular area but not across all dimensions. To\naddress this, it is essential to systematically calibrate metrics to specific\naspects of human preference, catering to the unique characteristics of each\naspect. We introduce MetaMetrics, a calibrated meta-metric designed to evaluate\ngeneration tasks across different modalities in a supervised manner.\nMetaMetrics optimizes the combination of existing metrics to enhance their\nalignment with human preferences. Our metric demonstrates flexibility and\neffectiveness in both language and vision downstream tasks, showing significant\nbenefits across various multilingual and multi-domain scenarios. MetaMetrics\naligns closely with human preferences and is highly extendable and easily\nintegrable into any application. This makes MetaMetrics a powerful tool for\nimproving the evaluation of generation tasks, ensuring that metrics are more\nrepresentative of human judgment across diverse contexts.\n","authors":["Genta Indra Winata","David Anugraha","Lucky Susanto","Garry Kuwanto","Derry Tanti Wijaya"],"pdf_url":"https://arxiv.org/pdf/2410.02381v2.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2406.01029v2","updated":"2024-10-07T16:20:39Z","published":"2024-06-03T06:24:55Z","title":"CYCLO: Cyclic Graph Transformer Approach to Multi-Object Relationship\n  Modeling in Aerial Videos","summary":"  Video scene graph generation (VidSGG) has emerged as a transformative\napproach to capturing and interpreting the intricate relationships among\nobjects and their temporal dynamics in video sequences. In this paper, we\nintroduce the new AeroEye dataset that focuses on multi-object relationship\nmodeling in aerial videos. Our AeroEye dataset features various drone scenes\nand includes a visually comprehensive and precise collection of predicates that\ncapture the intricate relationships and spatial arrangements among objects. To\nthis end, we propose the novel Cyclic Graph Transformer (CYCLO) approach that\nallows the model to capture both direct and long-range temporal dependencies by\ncontinuously updating the history of interactions in a circular manner. The\nproposed approach also allows one to handle sequences with inherent cyclical\npatterns and process object relationships in the correct sequential order.\nTherefore, it can effectively capture periodic and overlapping relationships\nwhile minimizing information loss. The extensive experiments on the AeroEye\ndataset demonstrate the effectiveness of the proposed CYCLO model,\ndemonstrating its potential to perform scene understanding on drone videos.\nFinally, the CYCLO method consistently achieves State-of-the-Art (SOTA) results\non two in-the-wild scene graph generation benchmarks, i.e., PVSG and ASPIRe.\n","authors":["Trong-Thuan Nguyen","Pha Nguyen","Xin Li","Jackson Cothren","Alper Yilmaz","Khoa Luu"],"pdf_url":"https://arxiv.org/pdf/2406.01029v2.pdf","comment":"Accepted to NeurIPS 2024"},{"id":"http://arxiv.org/abs/2408.03361v6","updated":"2024-10-07T16:18:21Z","published":"2024-08-06T17:59:21Z","title":"GMAI-MMBench: A Comprehensive Multimodal Evaluation Benchmark Towards\n  General Medical AI","summary":"  Large Vision-Language Models (LVLMs) are capable of handling diverse data\ntypes such as imaging, text, and physiological signals, and can be applied in\nvarious fields. In the medical field, LVLMs have a high potential to offer\nsubstantial assistance for diagnosis and treatment. Before that, it is crucial\nto develop benchmarks to evaluate LVLMs' effectiveness in various medical\napplications. Current benchmarks are often built upon specific academic\nliterature, mainly focusing on a single domain, and lacking varying perceptual\ngranularities. Thus, they face specific challenges, including limited clinical\nrelevance, incomplete evaluations, and insufficient guidance for interactive\nLVLMs. To address these limitations, we developed the GMAI-MMBench, the most\ncomprehensive general medical AI benchmark with well-categorized data structure\nand multi-perceptual granularity to date. It is constructed from 284 datasets\nacross 38 medical image modalities, 18 clinical-related tasks, 18 departments,\nand 4 perceptual granularities in a Visual Question Answering (VQA) format.\nAdditionally, we implemented a lexical tree structure that allows users to\ncustomize evaluation tasks, accommodating various assessment needs and\nsubstantially supporting medical AI research and applications. We evaluated 50\nLVLMs, and the results show that even the advanced GPT-4o only achieves an\naccuracy of 53.96%, indicating significant room for improvement. Moreover, we\nidentified five key insufficiencies in current cutting-edge LVLMs that need to\nbe addressed to advance the development of better medical applications. We\nbelieve that GMAI-MMBench will stimulate the community to build the next\ngeneration of LVLMs toward GMAI.\n","authors":["Pengcheng Chen","Jin Ye","Guoan Wang","Yanjun Li","Zhongying Deng","Wei Li","Tianbin Li","Haodong Duan","Ziyan Huang","Yanzhou Su","Benyou Wang","Shaoting Zhang","Bin Fu","Jianfei Cai","Bohan Zhuang","Eric J Seibel","Junjun He","Yu Qiao"],"pdf_url":"https://arxiv.org/pdf/2408.03361v6.pdf","comment":"GitHub: https://github.com/uni-medical/GMAI-MMBench; Hugging face:\n  https://huggingface.co/datasets/OpenGVLab/GMAI-MMBench"},{"id":"http://arxiv.org/abs/2310.03986v6","updated":"2024-10-07T16:15:36Z","published":"2023-10-06T03:04:21Z","title":"Robust Multimodal Learning with Missing Modalities via\n  Parameter-Efficient Adaptation","summary":"  Multimodal learning seeks to utilize data from multiple sources to improve\nthe overall performance of downstream tasks. It is desirable for redundancies\nin the data to make multimodal systems robust to missing or corrupted\nobservations in some correlated modalities. However, we observe that the\nperformance of several existing multimodal networks significantly deteriorates\nif one or multiple modalities are absent at test time. To enable robustness to\nmissing modalities, we propose a simple and parameter-efficient adaptation\nprocedure for pretrained multimodal networks. In particular, we exploit\nmodulation of intermediate features to compensate for the missing modalities.\nWe demonstrate that such adaptation can partially bridge performance drop due\nto missing modalities and outperform independent, dedicated networks trained\nfor the available modality combinations in some cases. The proposed adaptation\nrequires extremely small number of parameters (e.g., fewer than 1% of the total\nparameters) and applicable to a wide range of modality combinations and tasks.\nWe conduct a series of experiments to highlight the missing modality robustness\nof our proposed method on five different multimodal tasks across seven\ndatasets. Our proposed method demonstrates versatility across various tasks and\ndatasets, and outperforms existing methods for robust multimodal learning with\nmissing modalities.\n","authors":["Md Kaykobad Reza","Ashley Prater-Bennette","M. Salman Asif"],"pdf_url":"https://arxiv.org/pdf/2310.03986v6.pdf","comment":"Accepted by IEEE Transactions on Pattern Analysis and Machine\n  Intelligence (TPAMI). 28 pages, 6 figures, 17 tables"},{"id":"http://arxiv.org/abs/2410.05160v1","updated":"2024-10-07T16:14:05Z","published":"2024-10-07T16:14:05Z","title":"VLM2Vec: Training Vision-Language Models for Massive Multimodal\n  Embedding Tasks","summary":"  Embedding models have been crucial in enabling various downstream tasks such\nas semantic similarity, information retrieval, and clustering. Recently, there\nhas been a surge of interest in developing universal text embedding models that\ncan generalize across tasks (e.g., MTEB). However, progress in learning\nuniversal multimodal embedding models has been relatively slow despite their\nimportance. In this work, we aim to explore the potential for building\nuniversal embeddings capable of handling a wide range of downstream tasks. Our\ncontributions are twofold: (1) MMEB (Massive Multimodal Embedding Benchmark),\nwhich covers 4 meta-tasks (i.e. classification, visual question answering,\nmultimodal retrieval, and visual grounding) and 36 datasets, including 20\ntraining and 16 evaluation datasets, and (2) VLM2Vec (Vision-Language Model ->\nVector), a contrastive training framework that converts any state-of-the-art\nvision-language model into an embedding model via training on MMEB. Unlike\nprevious models such as CLIP and BLIP, VLM2Vec can process any combination of\nimages and text to generate a fixed-dimensional vector based on task\ninstructions. We build a series of VLM2Vec models on Phi-3.5-V and evaluate\nthem on MMEB's evaluation split. Our results show that \\model achieves an\nabsolute average improvement of 10% to 20% over existing multimodal embedding\nmodels on both in-distribution and out-of-distribution datasets in MMEB.\n","authors":["Ziyan Jiang","Rui Meng","Xinyi Yang","Semih Yavuz","Yingbo Zhou","Wenhu Chen"],"pdf_url":"https://arxiv.org/pdf/2410.05160v1.pdf","comment":"Technical Report"},{"id":"http://arxiv.org/abs/2410.05159v1","updated":"2024-10-07T16:13:49Z","published":"2024-10-07T16:13:49Z","title":"MIBench: A Comprehensive Benchmark for Model Inversion Attack and\n  Defense","summary":"  Model Inversion (MI) attacks aim at leveraging the output information of\ntarget models to reconstruct privacy-sensitive training data, raising\nwidespread concerns on privacy threats of Deep Neural Networks (DNNs).\nUnfortunately, in tandem with the rapid evolution of MI attacks, the lack of a\ncomprehensive, aligned, and reliable benchmark has emerged as a formidable\nchallenge. This deficiency leads to inadequate comparisons between different\nattack methods and inconsistent experimental setups. In this paper, we\nintroduce the first practical benchmark for model inversion attacks and\ndefenses to address this critical gap, which is named \\textit{MIBench}. This\nbenchmark serves as an extensible and reproducible modular-based toolbox and\ncurrently integrates a total of 16 state-of-the-art attack and defense methods.\nMoreover, we furnish a suite of assessment tools encompassing 9 commonly used\nevaluation protocols to facilitate standardized and fair evaluation and\nanalysis. Capitalizing on this foundation, we conduct extensive experiments\nfrom multiple perspectives to holistically compare and analyze the performance\nof various methods across different scenarios, which overcomes the misalignment\nissues and discrepancy prevalent in previous works. Based on the collected\nattack methods and defense strategies, we analyze the impact of target\nresolution, defense robustness, model predictive power, model architectures,\ntransferability and loss function. Our hope is that this \\textit{MIBench} could\nprovide a unified, practical and extensible toolbox and is widely utilized by\nresearchers in the field to rigorously test and compare their novel methods,\nensuring equitable evaluations and thereby propelling further advancements in\nthe future development.\n","authors":["Yixiang Qiu","Hongyao Yu","Hao Fang","Wenbo Yu","Bin Chen","Xuan Wang","Shu-Tao Xia","Ke Xu"],"pdf_url":"https://arxiv.org/pdf/2410.05159v1.pdf","comment":"23 pages"},{"id":"http://arxiv.org/abs/2309.15608v2","updated":"2024-10-07T16:05:53Z","published":"2023-09-27T12:15:05Z","title":"NoSENSE: Learned unrolled cardiac MRI reconstruction without explicit\n  sensitivity maps","summary":"  We present a novel learned image reconstruction method for accelerated\ncardiac MRI with multiple receiver coils based on deep convolutional neural\nnetworks (CNNs) and algorithm unrolling. In contrast to many existing learned\nMR image reconstruction techniques that necessitate coil-sensitivity map (CSM)\nestimation as a distinct network component, our proposed approach avoids\nexplicit CSM estimation. Instead, it implicitly captures and learns to exploit\nthe inter-coil relationships of the images. Our method consists of a series of\nnovel learned image and k-space blocks with shared latent information and\nadaptation to the acquisition parameters by feature-wise modulation (FiLM), as\nwell as coil-wise data-consistency (DC) blocks.\n  Our method achieved PSNR values of 34.89 and 35.56 and SSIM values of 0.920\nand 0.942 in the cine track and mapping track validation leaderboard of the\nMICCAI STACOM CMRxRecon Challenge, respectively, ranking 4th among different\nteams at the time of writing.\n  Code will be made available at https://github.com/fzimmermann89/CMRxRecon\n","authors":["Felix Frederik Zimmermann","Andreas Kofler"],"pdf_url":"https://arxiv.org/pdf/2309.15608v2.pdf","comment":"Accepted at MICCAI STACOM 2023"},{"id":"http://arxiv.org/abs/2410.05143v1","updated":"2024-10-07T15:55:02Z","published":"2024-10-07T15:55:02Z","title":"Leveraging Multimodal Diffusion Models to Accelerate Imaging with Side\n  Information","summary":"  Diffusion models have found phenomenal success as expressive priors for\nsolving inverse problems, but their extension beyond natural images to more\nstructured scientific domains remains limited. Motivated by applications in\nmaterials science, we aim to reduce the number of measurements required from an\nexpensive imaging modality of interest, by leveraging side information from an\nauxiliary modality that is much cheaper to obtain. To deal with the\nnon-differentiable and black-box nature of the forward model, we propose a\nframework to train a multimodal diffusion model over the joint modalities,\nturning inverse problems with black-box forward models into simple linear\ninpainting problems. Numerically, we demonstrate the feasibility of training\ndiffusion models over materials imagery data, and show that our approach\nachieves superior image reconstruction by leveraging the available side\ninformation, requiring significantly less amount of data from the expensive\nmicroscopy modality.\n","authors":["Timofey Efimov","Harry Dong","Megna Shah","Jeff Simmons","Sean Donegan","Yuejie Chi"],"pdf_url":"https://arxiv.org/pdf/2410.05143v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.16756v2","updated":"2024-10-07T15:53:26Z","published":"2024-09-25T09:07:46Z","title":"Navigating the Maze of Explainable AI: A Systematic Approach to\n  Evaluating Methods and Metrics","summary":"  Explainable AI (XAI) is a rapidly growing domain with a myriad of proposed\nmethods as well as metrics aiming to evaluate their efficacy. However, current\nstudies are often of limited scope, examining only a handful of XAI methods and\nignoring underlying design parameters for performance, such as the model\narchitecture or the nature of input data. Moreover, they often rely on one or a\nfew metrics and neglect thorough validation, increasing the risk of selection\nbias and ignoring discrepancies among metrics. These shortcomings leave\npractitioners confused about which method to choose for their problem. In\nresponse, we introduce LATEC, a large-scale benchmark that critically evaluates\n17 prominent XAI methods using 20 distinct metrics. We systematically\nincorporate vital design parameters like varied architectures and diverse input\nmodalities, resulting in 7,560 examined combinations. Through LATEC, we\nshowcase the high risk of conflicting metrics leading to unreliable rankings\nand consequently propose a more robust evaluation scheme. Further, we\ncomprehensively evaluate various XAI methods to assist practitioners in\nselecting appropriate methods aligning with their needs. Curiously, the\nemerging top-performing method, Expected Gradients, is not examined in any\nrelevant related study. LATEC reinforces its role in future XAI research by\npublicly releasing all 326k saliency maps and 378k metric scores as a\n(meta-)evaluation dataset. The benchmark is hosted at:\nhttps://github.com/IML-DKFZ/latec.\n","authors":["Lukas Klein","Carsten T. Lüth","Udo Schlegel","Till J. Bungert","Mennatallah El-Assady","Paul F. Jäger"],"pdf_url":"https://arxiv.org/pdf/2409.16756v2.pdf","comment":"Accepted at NeurIPS 2024"},{"id":"http://arxiv.org/abs/2311.18193v3","updated":"2024-10-07T15:36:17Z","published":"2023-11-30T02:24:44Z","title":"Persistent Test-time Adaptation in Recurring Testing Scenarios","summary":"  Current test-time adaptation (TTA) approaches aim to adapt to environments\nthat change continuously. Yet, it is unclear whether TTA methods can maintain\ntheir adaptability over prolonged periods. To answer this question, we\nintroduce a diagnostic setting - **recurring TTA** where environments not only\nchange but also recur over time, creating an extensive data stream. This\nsetting allows us to examine the error accumulation of TTA models, in the most\nbasic scenario, when they are regularly exposed to previous testing\nenvironments. Furthermore, we simulate a TTA process on a simple yet\nrepresentative $\\epsilon$-**perturbed Gaussian Mixture Model Classifier**,\nderiving theoretical insights into the dataset- and algorithm-dependent factors\ncontributing to gradual performance degradation. Our investigation leads us to\npropose **persistent TTA (PeTTA)**, which senses when the model is diverging\ntowards collapse and adjusts the adaptation strategy, striking a balance\nbetween the dual objectives of adaptation and model collapse prevention. The\nsupreme stability of PeTTA over existing approaches, in the face of lifelong\nTTA scenarios, has been demonstrated over comprehensive experiments on various\nbenchmarks.\n","authors":["Trung-Hieu Hoang","Duc Minh Vo","Minh N. Do"],"pdf_url":"https://arxiv.org/pdf/2311.18193v3.pdf","comment":"Accepted to the 38th Conference on Neural Information Processing\n  Systems (NeurIPS 2024)"},{"id":"http://arxiv.org/abs/2410.05116v1","updated":"2024-10-07T15:12:01Z","published":"2024-10-07T15:12:01Z","title":"Human-Feedback Efficient Reinforcement Learning for Online Diffusion\n  Model Finetuning","summary":"  Controllable generation through Stable Diffusion (SD) fine-tuning aims to\nimprove fidelity, safety, and alignment with human guidance. Existing\nreinforcement learning from human feedback methods usually rely on predefined\nheuristic reward functions or pretrained reward models built on large-scale\ndatasets, limiting their applicability to scenarios where collecting such data\nis costly or difficult. To effectively and efficiently utilize human feedback,\nwe develop a framework, HERO, which leverages online human feedback collected\non the fly during model learning. Specifically, HERO features two key\nmechanisms: (1) Feedback-Aligned Representation Learning, an online training\nmethod that captures human feedback and provides informative learning signals\nfor fine-tuning, and (2) Feedback-Guided Image Generation, which involves\ngenerating images from SD's refined initialization samples, enabling faster\nconvergence towards the evaluator's intent. We demonstrate that HERO is 4x more\nefficient in online feedback for body part anomaly correction compared to the\nbest existing method. Additionally, experiments show that HERO can effectively\nhandle tasks like reasoning, counting, personalization, and reducing NSFW\ncontent with only 0.5K online feedback.\n","authors":["Ayano Hiranaka","Shang-Fu Chen","Chieh-Hsin Lai","Dongjun Kim","Naoki Murata","Takashi Shibuya","Wei-Hsiang Liao","Shao-Hua Sun","Yuki Mitsufuji"],"pdf_url":"https://arxiv.org/pdf/2410.05116v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.14327v4","updated":"2024-10-07T15:10:03Z","published":"2024-05-23T08:57:10Z","title":"Autoregressive Image Diffusion: Generation of Image Sequence and\n  Application in MRI","summary":"  Magnetic resonance imaging (MRI) is a widely used non-invasive imaging\nmodality. However, a persistent challenge lies in balancing image quality with\nimaging speed. This trade-off is primarily constrained by k-space measurements,\nwhich traverse specific trajectories in the spatial Fourier domain (k-space).\nThese measurements are often undersampled to shorten acquisition times,\nresulting in image artifacts and compromised quality. Generative models learn\nimage distributions and can be used to reconstruct high-quality images from\nundersampled k-space data. In this work, we present the autoregressive image\ndiffusion (AID) model for image sequences and use it to sample the posterior\nfor accelerated MRI reconstruction. The algorithm incorporates both\nundersampled k-space and pre-existing information. Models trained with fastMRI\ndataset are evaluated comprehensively. The results show that the AID model can\nrobustly generate sequentially coherent image sequences. In MRI applications,\nthe AID can outperform the standard diffusion model and reduce hallucinations,\ndue to the learned inter-image dependencies. The project code is available at\nhttps://github.com/mrirecon/aid.\n","authors":["Guanxiong Luo","Shoujin Huang","Martin Uecker"],"pdf_url":"https://arxiv.org/pdf/2405.14327v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.05114v1","updated":"2024-10-07T15:09:50Z","published":"2024-10-07T15:09:50Z","title":"Synthetic Generation of Dermatoscopic Images with GAN and Closed-Form\n  Factorization","summary":"  In the realm of dermatological diagnoses, where the analysis of dermatoscopic\nand microscopic skin lesion images is pivotal for the accurate and early\ndetection of various medical conditions, the costs associated with creating\ndiverse and high-quality annotated datasets have hampered the accuracy and\ngeneralizability of machine learning models. We propose an innovative\nunsupervised augmentation solution that harnesses Generative Adversarial\nNetwork (GAN) based models and associated techniques over their latent space to\ngenerate controlled semiautomatically-discovered semantic variations in\ndermatoscopic images. We created synthetic images to incorporate the semantic\nvariations and augmented the training data with these images. With this\napproach, we were able to increase the performance of machine learning models\nand set a new benchmark amongst non-ensemble based models in skin lesion\nclassification on the HAM10000 dataset; and used the observed analytics and\ngenerated models for detailed studies on model explainability, affirming the\neffectiveness of our solution.\n","authors":["Rohan Reddy Mekala","Frederik Pahde","Simon Baur","Sneha Chandrashekar","Madeline Diep","Markus Wenzel","Eric L. Wisotzky","Galip Ümit Yolcu","Sebastian Lapuschkin","Jackie Ma","Peter Eisert","Mikael Lindvall","Adam Porter","Wojciech Samek"],"pdf_url":"https://arxiv.org/pdf/2410.05114v1.pdf","comment":"This preprint has been submitted to the Workshop on Synthetic Data\n  for Computer Vision (SyntheticData4CV 2024 is a side event on 18th European\n  Conference on Computer Vision 2024). This preprint has not undergone peer\n  review or any post-submission improvements or corrections"},{"id":"http://arxiv.org/abs/2410.05111v1","updated":"2024-10-07T15:07:56Z","published":"2024-10-07T15:07:56Z","title":"LiDAR-GS:Real-time LiDAR Re-Simulation using Gaussian Splatting","summary":"  LiDAR simulation plays a crucial role in closed-loop simulation for\nautonomous driving. Although recent advancements, such as the use of\nreconstructed mesh and Neural Radiance Fields (NeRF), have made progress in\nsimulating the physical properties of LiDAR, these methods have struggled to\nachieve satisfactory frame rates and rendering quality. To address these\nlimitations, we present LiDAR-GS, the first LiDAR Gaussian Splatting method,\nfor real-time high-fidelity re-simulation of LiDAR sensor scans in public urban\nroad scenes. The vanilla Gaussian Splatting, designed for camera models, cannot\nbe directly applied to LiDAR re-simulation. To bridge the gap between passive\ncamera and active LiDAR, our LiDAR-GS designs a differentiable laser beam\nsplatting, grounded in the LiDAR range view model. This innovation allows for\nprecise surface splatting by projecting lasers onto micro cross-sections,\neffectively eliminating artifacts associated with local affine approximations.\nAdditionally, LiDAR-GS leverages Neural Gaussian Fields, which further\nintegrate view-dependent clues, to represent key LiDAR properties that are\ninfluenced by the incident angle and external factors. Combining these\npractices with some essential adaptations, e.g., dynamic instances\ndecomposition, our approach succeeds in simultaneously re-simulating depth,\nintensity, and ray-drop channels, achieving state-of-the-art results in both\nrendering frame rate and quality on publically available large scene datasets.\nOur source code will be made publicly available.\n","authors":["Qifeng Chen","Sheng Yang","Sicong Du","Tao Tang","Peng Chen","Yuchi Huo"],"pdf_url":"https://arxiv.org/pdf/2410.05111v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.05103v1","updated":"2024-10-07T15:01:57Z","published":"2024-10-07T15:01:57Z","title":"MetaDD: Boosting Dataset Distillation with Neural Network\n  Architecture-Invariant Generalization","summary":"  Dataset distillation (DD) entails creating a refined, compact distilled\ndataset from a large-scale dataset to facilitate efficient training. A\nsignificant challenge in DD is the dependency between the distilled dataset and\nthe neural network (NN) architecture used. Training a different NN architecture\nwith a distilled dataset distilled using a specific architecture often results\nin diminished trainning performance for other architectures. This paper\nintroduces MetaDD, designed to enhance the generalizability of DD across\nvarious NN architectures. Specifically, MetaDD partitions distilled data into\nmeta features (i.e., the data's common characteristics that remain consistent\nacross different NN architectures) and heterogeneous features (i.e., the data's\nunique feature to each NN architecture). Then, MetaDD employs an\narchitecture-invariant loss function for multi-architecture feature alignment,\nwhich increases meta features and reduces heterogeneous features in distilled\ndata. As a low-memory consumption component, MetaDD can be seamlessly\nintegrated into any DD methodology. Experimental results demonstrate that\nMetaDD significantly improves performance across various DD methods. On the\nDistilled Tiny-Imagenet with Sre2L (50 IPC), MetaDD achieves cross-architecture\nNN accuracy of up to 30.1\\%, surpassing the second-best method (GLaD) by 1.7\\%.\n","authors":["Yunlong Zhao","Xiaoheng Deng","Xiu Su","Hongyan Xu","Xiuxing Li","Yijing Liu","Shan You"],"pdf_url":"https://arxiv.org/pdf/2410.05103v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.05100v1","updated":"2024-10-07T14:55:50Z","published":"2024-10-07T14:55:50Z","title":"IGroupSS-Mamba: Interval Group Spatial-Spectral Mamba for Hyperspectral\n  Image Classification","summary":"  Hyperspectral image (HSI) classification has garnered substantial attention\nin remote sensing fields. Recent Mamba architectures built upon the Selective\nState Space Models (S6) have demonstrated enormous potential in long-range\nsequence modeling. However, the high dimensionality of hyperspectral data and\ninformation redundancy pose challenges to the application of Mamba in HSI\nclassification, suffering from suboptimal performance and computational\nefficiency. In light of this, this paper investigates a lightweight Interval\nGroup Spatial-Spectral Mamba framework (IGroupSS-Mamba) for HSI classification,\nwhich allows for multi-directional and multi-scale global spatial-spectral\ninformation extraction in a grouping and hierarchical manner. Technically, an\nInterval Group S6 Mechanism (IGSM) is developed as the core component, which\npartitions high-dimensional features into multiple non-overlapping groups at\nintervals, and then integrates a unidirectional S6 for each group with a\nspecific scanning direction to achieve non-redundant sequence modeling.\nCompared to conventional applying multi-directional scanning to all bands, this\ngrouping strategy leverages the complementary strengths of different scanning\ndirections while decreasing computational costs. To adequately capture the\nspatial-spectral contextual information, an Interval Group Spatial-Spectral\nBlock (IGSSB) is introduced, in which two IGSM-based spatial and spectral\noperators are cascaded to characterize the global spatial-spectral relationship\nalong the spatial and spectral dimensions, respectively. IGroupSS-Mamba is\nconstructed as a hierarchical structure stacked by multiple IGSSB blocks,\nintegrating a pixel aggregation-based downsampling strategy for multiscale\nspatial-spectral semantic learning from shallow to deep stages. Extensive\nexperiments demonstrate that IGroupSS-Mamba outperforms the state-of-the-art\nmethods.\n","authors":["Yan He","Bing Tu","Puzhao Jiang","Bo Liu","Jun Li","Antonio Plaza"],"pdf_url":"https://arxiv.org/pdf/2410.05100v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.05097v1","updated":"2024-10-07T14:51:54Z","published":"2024-10-07T14:51:54Z","title":"DreamSat: Towards a General 3D Model for Novel View Synthesis of Space\n  Objects","summary":"  Novel view synthesis (NVS) enables to generate new images of a scene or\nconvert a set of 2D images into a comprehensive 3D model. In the context of\nSpace Domain Awareness, since space is becoming increasingly congested, NVS can\naccurately map space objects and debris, improving the safety and efficiency of\nspace operations. Similarly, in Rendezvous and Proximity Operations missions,\n3D models can provide details about a target object's shape, size, and\norientation, allowing for better planning and prediction of the target's\nbehavior. In this work, we explore the generalization abilities of these\nreconstruction techniques, aiming to avoid the necessity of retraining for each\nnew scene, by presenting a novel approach to 3D spacecraft reconstruction from\nsingle-view images, DreamSat, by fine-tuning the Zero123 XL, a state-of-the-art\nsingle-view reconstruction model, on a high-quality dataset of 190 high-quality\nspacecraft models and integrating it into the DreamGaussian framework. We\ndemonstrate consistent improvements in reconstruction quality across multiple\nmetrics, including Contrastive Language-Image Pretraining (CLIP) score\n(+0.33%), Peak Signal-to-Noise Ratio (PSNR) (+2.53%), Structural Similarity\nIndex (SSIM) (+2.38%), and Learned Perceptual Image Patch Similarity (LPIPS)\n(+0.16%) on a test set of 30 previously unseen spacecraft images. Our method\naddresses the lack of domain-specific 3D reconstruction tools in the space\nindustry by leveraging state-of-the-art diffusion models and 3D Gaussian\nsplatting techniques. This approach maintains the efficiency of the\nDreamGaussian framework while enhancing the accuracy and detail of spacecraft\nreconstructions. The code for this work can be accessed on GitHub\n(https://github.com/ARCLab-MIT/space-nvs).\n","authors":["Nidhi Mathihalli","Audrey Wei","Giovanni Lavezzi","Peng Mun Siew","Victor Rodriguez-Fernandez","Hodei Urrutxua","Richard Linares"],"pdf_url":"https://arxiv.org/pdf/2410.05097v1.pdf","comment":"Presented at the 75th International Astronautical Congress, October\n  2024, Milan, Italy"},{"id":"http://arxiv.org/abs/2410.05096v1","updated":"2024-10-07T14:50:56Z","published":"2024-10-07T14:50:56Z","title":"Human-in-the-loop Reasoning For Traffic Sign Detection: Collaborative\n  Approach Yolo With Video-llava","summary":"  Traffic Sign Recognition (TSR) detection is a crucial component of autonomous\nvehicles. While You Only Look Once (YOLO) is a popular real-time object\ndetection algorithm, factors like training data quality and adverse weather\nconditions (e.g., heavy rain) can lead to detection failures. These failures\ncan be particularly dangerous when visual similarities between objects exist,\nsuch as mistaking a 30 km/h sign for a higher speed limit sign. This paper\nproposes a method that combines video analysis and reasoning, prompting with a\nhuman-in-the-loop guide large vision model to improve YOLOs accuracy in\ndetecting road speed limit signs, especially in semi-real-world conditions. It\nis hypothesized that the guided prompting and reasoning abilities of\nVideo-LLava can enhance YOLOs traffic sign detection capabilities. This\nhypothesis is supported by an evaluation based on human-annotated accuracy\nmetrics within a dataset of recorded videos from the CARLA car simulator. The\nresults demonstrate that a collaborative approach combining YOLO with\nVideo-LLava and reasoning can effectively address challenging situations such\nas heavy rain and overcast conditions that hinder YOLOs detection capabilities.\n","authors":["Mehdi Azarafza","Fatima Idrees","Ali Ehteshami Bejnordi","Charles Steinmetz","Stefan Henkler","Achim Rettberg"],"pdf_url":"https://arxiv.org/pdf/2410.05096v1.pdf","comment":"10 pages, 6 figures"},{"id":"http://arxiv.org/abs/2405.14768v2","updated":"2024-10-07T14:35:14Z","published":"2024-05-23T16:35:52Z","title":"WISE: Rethinking the Knowledge Memory for Lifelong Model Editing of\n  Large Language Models","summary":"  Large language models (LLMs) need knowledge updates to meet the ever-growing\nworld facts and correct the hallucinated responses, facilitating the methods of\nlifelong model editing. Where the updated knowledge resides in memories is a\nfundamental question for model editing. In this paper, we find that editing\neither long-term memory (direct model parameters) or working memory\n(non-parametric knowledge of neural network activations/representations by\nretrieval) will result in an impossible triangle -- reliability,\ngeneralization, and locality can not be realized together in the lifelong\nediting settings. For long-term memory, directly editing the parameters will\ncause conflicts with irrelevant pretrained knowledge or previous edits (poor\nreliability and locality). For working memory, retrieval-based activations can\nhardly make the model understand the edits and generalize (poor\ngeneralization). Therefore, we propose WISE to bridge the gap between memories.\nIn WISE, we design a dual parametric memory scheme, which consists of the main\nmemory for the pretrained knowledge and a side memory for the edited knowledge.\nWe only edit the knowledge in the side memory and train a router to decide\nwhich memory to go through when given a query. For continual editing, we devise\na knowledge-sharding mechanism where different sets of edits reside in distinct\nsubspaces of parameters, and are subsequently merged into a shared memory\nwithout conflicts. Extensive experiments show that WISE can outperform previous\nmodel editing methods and overcome the impossible triangle under lifelong model\nediting of question answering, hallucination, and out-of-distribution settings\nacross trending LLM architectures, e.g., GPT, LLaMA, and Mistral. Code is\navailable at https://github.com/zjunlp/EasyEdit.\n","authors":["Peng Wang","Zexi Li","Ningyu Zhang","Ziwen Xu","Yunzhi Yao","Yong Jiang","Pengjun Xie","Fei Huang","Huajun Chen"],"pdf_url":"https://arxiv.org/pdf/2405.14768v2.pdf","comment":"NeurIPS 2024"},{"id":"http://arxiv.org/abs/2410.05074v1","updated":"2024-10-07T14:29:24Z","published":"2024-10-07T14:29:24Z","title":"xLSTM-FER: Enhancing Student Expression Recognition with Extended Vision\n  Long Short-Term Memory Network","summary":"  Student expression recognition has become an essential tool for assessing\nlearning experiences and emotional states. This paper introduces xLSTM-FER, a\nnovel architecture derived from the Extended Long Short-Term Memory (xLSTM),\ndesigned to enhance the accuracy and efficiency of expression recognition\nthrough advanced sequence processing capabilities for student facial expression\nrecognition. xLSTM-FER processes input images by segmenting them into a series\nof patches and leveraging a stack of xLSTM blocks to handle these patches.\nxLSTM-FER can capture subtle changes in real-world students' facial expressions\nand improve recognition accuracy by learning spatial-temporal relationships\nwithin the sequence. Experiments on CK+, RAF-DF, and FERplus demonstrate the\npotential of xLSTM-FER in expression recognition tasks, showing better\nperformance compared to state-of-the-art methods on standard datasets. The\nlinear computational and memory complexity of xLSTM-FER make it particularly\nsuitable for handling high-resolution images. Moreover, the design of xLSTM-FER\nallows for efficient processing of non-sequential inputs such as images without\nadditional computation.\n","authors":["Qionghao Huang","Jili Chen"],"pdf_url":"https://arxiv.org/pdf/2410.05074v1.pdf","comment":"The paper, consisting of 10 pages and 3 figures, has been accepted by\n  the AIEDM Workshop at the 8th APWeb-WAIM Joint International Conference on\n  Web and Big Data"},{"id":"http://arxiv.org/abs/2410.03171v2","updated":"2024-10-07T14:28:41Z","published":"2024-10-04T06:05:26Z","title":"Selective Transformer for Hyperspectral Image Classification","summary":"  Transformer has achieved satisfactory results in the field of hyperspectral\nimage (HSI) classification. However, existing Transformer models face two key\nchallenges when dealing with HSI scenes characterized by diverse land cover\ntypes and rich spectral information: (1) fixed receptive field representation\noverlooks effective contextual information; (2) redundant self-attention\nfeature representation. To address these limitations, we propose a novel\nSelective Transformer (SFormer) for HSI classification. The SFormer is designed\nto dynamically select receptive fields for capturing both spatial and spectral\ncontextual information, while mitigating the impact of redundant data by\nprioritizing the most relevant features. This enables a highly accurate\nclassification of the land covers of the HSI. Specifically, a Kernel Selective\nTransformer Block (KSTB) is first utilized to dynamically select an appropriate\nreceptive field range to effectively extract spatial-spectral features.\nFurthermore, to capture the most crucial tokens, a Token Selective Transformer\nBlock (TSTB) is introduced, which selects the most relevant tokens based on the\nranking of attention scores for each query. Extensive experiments on four\nbenchmark HSI datasets demonstrate that the proposed SFormer outperforms the\nstate-of-the-art HSI classification models. The codes will be released.\n","authors":["Yichu Xu","Di Wang","Lefei Zhang","Liangpei Zhang"],"pdf_url":"https://arxiv.org/pdf/2410.03171v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.05063v1","updated":"2024-10-07T14:21:51Z","published":"2024-10-07T14:21:51Z","title":"Control-oriented Clustering of Visual Latent Representation","summary":"  We initiate a study of the geometry of the visual representation space -- the\ninformation channel from the vision encoder to the action decoder -- in an\nimage-based control pipeline learned from behavior cloning. Inspired by the\nphenomenon of neural collapse (NC) in image classification, we investigate\nwhether a similar law of clustering emerges in the visual representation space.\nSince image-based control is a regression task without explicitly defined\nclasses, the central piece of the puzzle lies in determining according to what\nimplicit classes the visual features cluster, if such a law exists. Focusing on\nimage-based planar pushing, we posit the most important role of the visual\nrepresentation in a control task is to convey a goal to the action decoder. We\nthen classify training samples of expert demonstrations into eight\n\"control-oriented\" classes based on (a) the relative pose between the object\nand the target in the input or (b) the relative pose of the object induced by\nexpert actions in the output, where one class corresponds to one relative pose\northant (REPO). Across four different instantiations of architecture, we report\nthe prevalent emergence of control-oriented clustering in the visual\nrepresentation space according to the eight REPOs. Beyond empirical\nobservation, we show such a law of clustering can be leveraged as an\nalgorithmic tool to improve test-time performance when training a policy with\nlimited expert demonstrations. Particularly, we pretrain the vision encoder\nusing NC as a regularization to encourage control-oriented clustering of the\nvisual features. Surprisingly, such an NC-pretrained vision encoder, when\nfinetuned end-to-end with the action decoder, boosts the test-time performance\nby 10% to 35% in the low-data regime. Real-world vision-based planar pushing\nexperiments confirmed the surprising advantage of control-oriented visual\nrepresentation pretraining.\n","authors":["Han Qi","Haocheng Yin","Heng Yang"],"pdf_url":"https://arxiv.org/pdf/2410.05063v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.05058v1","updated":"2024-10-07T14:18:32Z","published":"2024-10-07T14:18:32Z","title":"Improving Object Detection via Local-global Contrastive Learning","summary":"  Visual domain gaps often impact object detection performance. Image-to-image\ntranslation can mitigate this effect, where contrastive approaches enable\nlearning of the image-to-image mapping under unsupervised regimes. However,\nexisting methods often fail to handle content-rich scenes with multiple object\ninstances, which manifests in unsatisfactory detection performance. Sensitivity\nto such instance-level content is typically only gained through object\nannotations, which can be expensive to obtain. Towards addressing this issue,\nwe present a novel image-to-image translation method that specifically targets\ncross-domain object detection. We formulate our approach as a contrastive\nlearning framework with an inductive prior that optimises the appearance of\nobject instances through spatial attention masks, implicitly delineating the\nscene into foreground regions associated with the target object instances and\nbackground non-object regions. Instead of relying on object annotations to\nexplicitly account for object instances during translation, our approach learns\nto represent objects by contrasting local-global information. This affords\ninvestigation of an under-explored challenge: obtaining performant detection,\nunder domain shifts, without relying on object annotations nor detector model\nfine-tuning. We experiment with multiple cross-domain object detection settings\nacross three challenging benchmarks and report state-of-the-art performance.\nProject page: https://local-global-detection.github.io\n","authors":["Danai Triantafyllidou","Sarah Parisot","Ales Leonardis","Steven McDonagh"],"pdf_url":"https://arxiv.org/pdf/2410.05058v1.pdf","comment":"BMVC 2024 - Project page: https://local-global-detection.github.io"},{"id":"http://arxiv.org/abs/2410.05057v1","updated":"2024-10-07T14:14:38Z","published":"2024-10-07T14:14:38Z","title":"SELECT: A Large-Scale Benchmark of Data Curation Strategies for Image\n  Classification","summary":"  Data curation is the problem of how to collect and organize samples into a\ndataset that supports efficient learning. Despite the centrality of the task,\nlittle work has been devoted towards a large-scale, systematic comparison of\nvarious curation methods. In this work, we take steps towards a formal\nevaluation of data curation strategies and introduce SELECT, the first\nlarge-scale benchmark of curation strategies for image classification.\n  In order to generate baseline methods for the SELECT benchmark, we create a\nnew dataset, ImageNet++, which constitutes the largest superset of ImageNet-1K\nto date. Our dataset extends ImageNet with 5 new training-data shifts, each\napproximately the size of ImageNet-1K itself, and each assembled using a\ndistinct curation strategy. We evaluate our data curation baselines in two\nways: (i) using each training-data shift to train identical image\nclassification models from scratch (ii) using the data itself to fit a\npretrained self-supervised representation.\n  Our findings show interesting trends, particularly pertaining to recent\nmethods for data curation such as synthetic data generation and lookup based on\nCLIP embeddings. We show that although these strategies are highly competitive\nfor certain tasks, the curation strategy used to assemble the original\nImageNet-1K dataset remains the gold standard. We anticipate that our benchmark\ncan illuminate the path for new methods to further reduce the gap. We release\nour checkpoints, code, documentation, and a link to our dataset at\nhttps://github.com/jimmyxu123/SELECT.\n","authors":["Benjamin Feuer","Jiawei Xu","Niv Cohen","Patrick Yubeaton","Govind Mittal","Chinmay Hegde"],"pdf_url":"https://arxiv.org/pdf/2410.05057v1.pdf","comment":"NeurIPS 2024, Datasets and Benchmarks Track"},{"id":"http://arxiv.org/abs/2410.05051v1","updated":"2024-10-07T14:06:16Z","published":"2024-10-07T14:06:16Z","title":"HE-Drive: Human-Like End-to-End Driving with Vision Language Models","summary":"  In this paper, we propose HE-Drive: the first human-like-centric end-to-end\nautonomous driving system to generate trajectories that are both temporally\nconsistent and comfortable. Recent studies have shown that imitation\nlearning-based planners and learning-based trajectory scorers can effectively\ngenerate and select accuracy trajectories that closely mimic expert\ndemonstrations. However, such trajectory planners and scorers face the dilemma\nof generating temporally inconsistent and uncomfortable trajectories. To solve\nthe above problems, Our HE-Drive first extracts key 3D spatial representations\nthrough sparse perception, which then serves as conditional inputs for a\nConditional Denoising Diffusion Probabilistic Models (DDPMs)-based motion\nplanner to generate temporal consistency multi-modal trajectories. A\nVision-Language Models (VLMs)-guided trajectory scorer subsequently selects the\nmost comfortable trajectory from these candidates to control the vehicle,\nensuring human-like end-to-end driving. Experiments show that HE-Drive not only\nachieves state-of-the-art performance (i.e., reduces the average collision rate\nby 71% than VAD) and efficiency (i.e., 1.9X faster than SparseDrive) on the\nchallenging nuScenes and OpenScene datasets but also provides the most\ncomfortable driving experience on real-world data.For more information, visit\nthe project website: https://jmwang0117.github.io/HE-Drive/.\n","authors":["Junming Wang","Xingyu Zhang","Zebin Xing","Songen Gu","Xiaoyang Guo","Yang Hu","Ziying Song","Qian Zhang","Xiaoxiao Long","Wei Yin"],"pdf_url":"https://arxiv.org/pdf/2410.05051v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.05044v1","updated":"2024-10-07T13:58:40Z","published":"2024-10-07T13:58:40Z","title":"PhotoReg: Photometrically Registering 3D Gaussian Splatting Models","summary":"  Building accurate representations of the environment is critical for\nintelligent robots to make decisions during deployment. Advances in\nphotorealistic environment models have enabled robots to develop\nhyper-realistic reconstructions, which can be used to generate images that are\nintuitive for human inspection. In particular, the recently introduced\n\\ac{3DGS}, which describes the scene with up to millions of primitive\nellipsoids, can be rendered in real time. \\ac{3DGS} has rapidly gained\nprominence. However, a critical unsolved problem persists: how can we fuse\nmultiple \\ac{3DGS} into a single coherent model? Solving this problem will\nenable robot teams to jointly build \\ac{3DGS} models of their surroundings. A\nkey insight of this work is to leverage the {duality} between photorealistic\nreconstructions, which render realistic 2D images from 3D structure, and\n\\emph{3D foundation models}, which predict 3D structure from image pairs. To\nthis end, we develop PhotoReg, a framework to register multiple photorealistic\n\\ac{3DGS} models with 3D foundation models. As \\ac{3DGS} models are generally\nbuilt from monocular camera images, they have \\emph{arbitrary scale}. To\nresolve this, PhotoReg actively enforces scale consistency among the different\n\\ac{3DGS} models by considering depth estimates within these models. Then, the\nalignment is iteratively refined with fine-grained photometric losses to\nproduce high-quality fused \\ac{3DGS} models. We rigorously evaluate PhotoReg on\nboth standard benchmark datasets and our custom-collected datasets, including\nwith two quadruped robots. The code is released at\n\\url{ziweny11.github.io/photoreg}.\n","authors":["Ziwen Yuan","Tianyi Zhang","Matthew Johnson-Roberson","Weiming Zhi"],"pdf_url":"https://arxiv.org/pdf/2410.05044v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.05041v1","updated":"2024-10-07T13:53:17Z","published":"2024-10-07T13:53:17Z","title":"Systematic Literature Review of Vision-Based Approaches to Outdoor\n  Livestock Monitoring with Lessons from Wildlife Studies","summary":"  Precision livestock farming (PLF) aims to improve the health and welfare of\nlivestock animals and farming outcomes through the use of advanced\ntechnologies. Computer vision, combined with recent advances in machine\nlearning and deep learning artificial intelligence approaches, offers a\npossible solution to the PLF ideal of 24/7 livestock monitoring that helps\nfacilitate early detection of animal health and welfare issues. However, a\nsignificant number of livestock species are raised in large outdoor habitats\nthat pose technological challenges for computer vision approaches. This review\nprovides a comprehensive overview of computer vision methods and open\nchallenges in outdoor animal monitoring. We include research from both the\nlivestock and wildlife fields in the review because of the similarities in\nappearance, behaviour, and habitat for many livestock and wildlife. We focus on\nlarge terrestrial mammals, such as cattle, horses, deer, goats, sheep, koalas,\ngiraffes, and elephants. We use an image processing pipeline to frame our\ndiscussion and highlight the current capabilities and open technical challenges\nat each stage of the pipeline. The review found a clear trend towards the use\nof deep learning approaches for animal detection, counting, and multi-species\nclassification. We discuss in detail the applicability of current vision-based\nmethods to PLF contexts and promising directions for future research.\n","authors":["Stacey D. Scott","Zayn J. Abbas","Feerass Ellid","Eli-Henry Dykhne","Muhammad Muhaiminul Islam","Weam Ayad","Kristina Kacmorova","Dan Tulpan","Minglun Gong"],"pdf_url":"https://arxiv.org/pdf/2410.05041v1.pdf","comment":"28 pages, 5 figures, 2 tables"},{"id":"http://arxiv.org/abs/2405.18213v2","updated":"2024-10-07T13:52:00Z","published":"2024-05-28T14:17:41Z","title":"NeRAF: 3D Scene Infused Neural Radiance and Acoustic Fields","summary":"  Sound plays a major role in human perception. Along with vision, it provides\nessential information for understanding our surroundings. Despite advances in\nneural implicit representations, learning acoustics that align with visual\nscenes remains a challenge. We propose NeRAF, a method that jointly learns\nacoustic and radiance fields. NeRAF synthesizes both novel views and\nspatialized room impulse responses (RIR) at new positions by conditioning the\nacoustic field on 3D scene geometric and appearance priors from the radiance\nfield. The generated RIR can be applied to auralize any audio signal. Each\nmodality can be rendered independently and at spatially distinct positions,\noffering greater versatility. We demonstrate that NeRAF generates high-quality\naudio on SoundSpaces and RAF datasets, achieving significant performance\nimprovements over prior methods while being more data-efficient. Additionally,\nNeRAF enhances novel view synthesis of complex scenes trained with sparse data\nthrough cross-modal learning. NeRAF is designed as a Nerfstudio module,\nproviding convenient access to realistic audio-visual generation.\n","authors":["Amandine Brunetto","Sascha Hornauer","Fabien Moutarde"],"pdf_url":"https://arxiv.org/pdf/2405.18213v2.pdf","comment":"Project Page: https://amandinebtto.github.io/NeRAF"},{"id":"http://arxiv.org/abs/2409.16845v2","updated":"2024-10-07T13:39:35Z","published":"2024-09-25T11:53:58Z","title":"IRASNet: Improved Feature-Level Clutter Reduction for Domain Generalized\n  SAR-ATR","summary":"  Recently, computer-aided design models and electromagnetic simulations have\nbeen used to augment synthetic aperture radar (SAR) data for deep learning.\nHowever, an automatic target recognition (ATR) model struggles with domain\nshift when using synthetic data because the model learns specific clutter\npatterns present in such data, which disturbs performance when applied to\nmeasured data with different clutter distributions. This study proposes a\nframework particularly designed for domain-generalized SAR-ATR called IRASNet,\nenabling effective feature-level clutter reduction and domain-invariant feature\nlearning. First, we propose a clutter reduction module (CRM) that maximizes the\nsignal-to-clutter ratio on feature maps. The module reduces the impact of\nclutter at the feature level while preserving target and shadow information,\nthereby improving ATR performance. Second, we integrate adversarial learning\nwith CRM to extract clutter-reduced domain-invariant features. The integration\nbridges the gap between synthetic and measured datasets without requiring\nmeasured data during training. Third, we improve feature extraction from target\nand shadow regions by implementing a positional supervision task using mask\nground truth encoding. The improvement enhances the ability of the model to\ndiscriminate between classes. Our proposed IRASNet presents new\nstate-of-the-art public SAR datasets utilizing target and shadow information to\nachieve superior performance across various test conditions. IRASNet not only\nenhances generalization performance but also significantly improves\nfeature-level clutter reduction, making it a valuable advancement in the field\nof radar image pattern recognition.\n","authors":["Oh-Tae Jang","Hae-Kang Song","Min-Jun Kim","Kyung-Hwan Lee","Geon Lee","Sung-Ho Kim","Hee-Sub Shin","Jae-Woo Ok","Min-Young Back","Jae-Hyuk Yoon","Kyung-Tae Kim"],"pdf_url":"https://arxiv.org/pdf/2409.16845v2.pdf","comment":"16 pages, 11 figures"},{"id":"http://arxiv.org/abs/2407.10389v3","updated":"2024-10-07T13:27:28Z","published":"2024-07-15T01:58:54Z","title":"Boost Your NeRF: A Model-Agnostic Mixture of Experts Framework for High\n  Quality and Efficient Rendering","summary":"  Since the introduction of NeRFs, considerable attention has been focused on\nimproving their training and inference times, leading to the development of\nFast-NeRFs models. Despite demonstrating impressive rendering speed and\nquality, the rapid convergence of such models poses challenges for further\nimproving reconstruction quality. Common strategies to improve rendering\nquality involves augmenting model parameters or increasing the number of\nsampled points. However, these computationally intensive approaches encounter\nlimitations in achieving significant quality enhancements. This study\nintroduces a model-agnostic framework inspired by Sparsely-Gated Mixture of\nExperts to enhance rendering quality without escalating computational\ncomplexity. Our approach enables specialization in rendering different scene\ncomponents by employing a mixture of experts with varying resolutions. We\npresent a novel gate formulation designed to maximize expert capabilities and\npropose a resolution-based routing technique to effectively induce sparsity and\ndecompose scenes. Our work significantly improves reconstruction quality while\nmaintaining competitive performance.\n","authors":["Francesco Di Sario","Riccardo Renzulli","Enzo Tartaglione","Marco Grangetto"],"pdf_url":"https://arxiv.org/pdf/2407.10389v3.pdf","comment":"The paper has been accepted to the ECCV 2024 conference"},{"id":"http://arxiv.org/abs/2310.19351v3","updated":"2024-10-07T13:23:08Z","published":"2023-10-30T08:46:26Z","title":"Seeking Flat Minima with Mean Teacher on Semi- and Weakly-Supervised\n  Domain Generalization for Object Detection","summary":"  Object detectors do not work well when domains largely differ between\ntraining and testing data. To overcome this domain gap in object detection\nwithout requiring expensive annotations, we consider two problem settings:\nsemi-supervised domain generalizable object detection (SS-DGOD) and\nweakly-supervised DGOD (WS-DGOD). In contrast to the conventional domain\ngeneralization for object detection that requires labeled data from multiple\ndomains, SS-DGOD and WS-DGOD require labeled data only from one domain and\nunlabeled or weakly-labeled data from multiple domains for training. In this\npaper, we show that object detectors can be effectively trained on the two\nsettings with the same Mean Teacher learning framework, where a student network\nis trained with pseudo-labels output from a teacher on the unlabeled or\nweakly-labeled data. We provide novel interpretations of why the Mean Teacher\nlearning framework works well on the two settings in terms of the relationships\nbetween the generalization gap and flat minima in parameter space. On the basis\nof the interpretations, we also show that incorporating a simple regularization\nmethod into the Mean Teacher learning framework leads to flatter minima. The\nexperimental results demonstrate that the regularization leads to flatter\nminima and boosts the performance of the detectors trained with the Mean\nTeacher learning framework on the two settings.\n","authors":["Ryosuke Furuta","Yoichi Sato"],"pdf_url":"https://arxiv.org/pdf/2310.19351v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16204v2","updated":"2024-10-07T13:11:05Z","published":"2024-06-23T20:00:20Z","title":"Breaking the Frame: Visual Place Recognition by Overlap Prediction","summary":"  Visual place recognition methods struggle with occlusions and partial visual\noverlaps. We propose a novel visual place recognition approach based on overlap\nprediction, called VOP, shifting from traditional reliance on global image\nsimilarities and local features to image overlap prediction. VOP proceeds\nco-visible image sections by obtaining patch-level embeddings using a Vision\nTransformer backbone and establishing patch-to-patch correspondences without\nrequiring expensive feature detection and matching. Our approach uses a voting\nmechanism to assess overlap scores for potential database images. It provides a\nnuanced image retrieval metric in challenging scenarios. Experimental results\nshow that VOP leads to more accurate relative pose estimation and localization\nresults on the retrieved image pairs than state-of-the-art baselines on a\nnumber of large-scale, real-world indoor and outdoor benchmarks. The code is\navailable at https://github.com/weitong8591/vop.git.\n","authors":["Tong Wei","Philipp Lindenberger","Jiri Matas","Daniel Barath"],"pdf_url":"https://arxiv.org/pdf/2406.16204v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.16017v2","updated":"2024-10-07T12:52:19Z","published":"2024-02-25T07:28:28Z","title":"Spectrum Extraction and Clipping for Implicitly Linear Layers","summary":"  We show the effectiveness of automatic differentiation in efficiently and\ncorrectly computing and controlling the spectrum of implicitly linear\noperators, a rich family of layer types including all standard convolutional\nand dense layers. We provide the first clipping method which is correct for\ngeneral convolution layers, and illuminate the representational limitation that\ncaused correctness issues in prior work. We study the effect of the batch\nnormalization layers when concatenated with convolutional layers and show how\nour clipping method can be applied to their composition. By comparing the\naccuracy and performance of our algorithms to the state-of-the-art methods,\nusing various experiments, we show they are more precise and efficient and lead\nto better generalization and adversarial robustness. We provide the code for\nusing our methods at https://github.com/Ali-E/FastClip.\n","authors":["Ali Ebrahimpour Boroojeny","Matus Telgarsky","Hari Sundaram"],"pdf_url":"https://arxiv.org/pdf/2402.16017v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04989v1","updated":"2024-10-07T12:43:50Z","published":"2024-10-07T12:43:50Z","title":"Conditional Variational Autoencoders for Probabilistic Pose Regression","summary":"  Robots rely on visual relocalization to estimate their pose from camera\nimages when they lose track. One of the challenges in visual relocalization is\nrepetitive structures in the operation environment of the robot. This calls for\nprobabilistic methods that support multiple hypotheses for robot's pose. We\npropose such a probabilistic method to predict the posterior distribution of\ncamera poses given an observed image. Our proposed training strategy results in\na generative model of camera poses given an image, which can be used to draw\nsamples from the pose posterior distribution. Our method is streamlined and\nwell-founded in theory and outperforms existing methods on localization in\npresence of ambiguities.\n","authors":["Fereidoon Zangeneh","Leonard Bruns","Amit Dekel","Alessandro Pieropan","Patric Jensfelt"],"pdf_url":"https://arxiv.org/pdf/2410.04989v1.pdf","comment":"Accepted at IROS 2024"},{"id":"http://arxiv.org/abs/2405.15118v2","updated":"2024-10-07T12:28:43Z","published":"2024-05-24T00:18:15Z","title":"GS-Hider: Hiding Messages into 3D Gaussian Splatting","summary":"  3D Gaussian Splatting (3DGS) has already become the emerging research focus\nin the fields of 3D scene reconstruction and novel view synthesis. Given that\ntraining a 3DGS requires a significant amount of time and computational cost,\nit is crucial to protect the copyright, integrity, and privacy of such 3D\nassets. Steganography, as a crucial technique for encrypted transmission and\ncopyright protection, has been extensively studied. However, it still lacks\nprofound exploration targeted at 3DGS. Unlike its predecessor NeRF, 3DGS\npossesses two distinct features: 1) explicit 3D representation; and 2)\nreal-time rendering speeds. These characteristics result in the 3DGS point\ncloud files being public and transparent, with each Gaussian point having a\nclear physical significance. Therefore, ensuring the security and fidelity of\nthe original 3D scene while embedding information into the 3DGS point cloud\nfiles is an extremely challenging task. To solve the above-mentioned issue, we\nfirst propose a steganography framework for 3DGS, dubbed GS-Hider, which can\nembed 3D scenes and images into original GS point clouds in an invisible manner\nand accurately extract the hidden messages. Specifically, we design a coupled\nsecured feature attribute to replace the original 3DGS's spherical harmonics\ncoefficients and then use a scene decoder and a message decoder to disentangle\nthe original RGB scene and the hidden message. Extensive experiments\ndemonstrated that the proposed GS-Hider can effectively conceal multimodal\nmessages without compromising rendering quality and possesses exceptional\nsecurity, robustness, capacity, and flexibility. Our project is available at:\nhttps://xuanyuzhang21.github.io/project/gshider.\n","authors":["Xuanyu Zhang","Jiarui Meng","Runyi Li","Zhipei Xu","Yongbing Zhang","Jian Zhang"],"pdf_url":"https://arxiv.org/pdf/2405.15118v2.pdf","comment":"Accepted by NeurIPS 2024, 3DGS steganography"},{"id":"http://arxiv.org/abs/2410.04983v1","updated":"2024-10-07T12:26:22Z","published":"2024-10-07T12:26:22Z","title":"RoWeeder: Unsupervised Weed Mapping through Crop-Row Detection","summary":"  Precision agriculture relies heavily on effective weed management to ensure\nrobust crop yields. This study presents RoWeeder, an innovative framework for\nunsupervised weed mapping that combines crop-row detection with a\nnoise-resilient deep learning model. By leveraging crop-row information to\ncreate a pseudo-ground truth, our method trains a lightweight deep learning\nmodel capable of distinguishing between crops and weeds, even in the presence\nof noisy data. Evaluated on the WeedMap dataset, RoWeeder achieves an F1 score\nof 75.3, outperforming several baselines. Comprehensive ablation studies\nfurther validated the model's performance. By integrating RoWeeder with drone\ntechnology, farmers can conduct real-time aerial surveys, enabling precise weed\nmanagement across large fields. The code is available at:\n\\url{https://github.com/pasqualedem/RoWeeder}.\n","authors":["Pasquale De Marinis","Rino Vessio","Giovanna Castellano"],"pdf_url":"https://arxiv.org/pdf/2410.04983v1.pdf","comment":"Computer Vision for Plant Phenotyping and Agriculture (CVPPA)\n  workshop at ECCV 2024"},{"id":"http://arxiv.org/abs/2410.04980v1","updated":"2024-10-07T12:21:49Z","published":"2024-10-07T12:21:49Z","title":"Comparison of marker-less 2D image-based methods for infant pose\n  estimation","summary":"  There are increasing efforts to automate clinical methods for early diagnosis\nof developmental disorders, among them the General Movement Assessment (GMA), a\nvideo-based tool to classify infant motor functioning. Optimal pose estimation\nis a crucial part of the automated GMA. In this study we compare the\nperformance of available generic- and infant-pose estimators, and the choice of\nviewing angle for optimal recordings, i.e., conventional diagonal view used in\nGMA vs. top-down view. For this study, we used 4500 annotated video-frames from\n75 recordings of infant spontaneous motor functions from 4 to 26 weeks. To\ndetermine which available pose estimation method and camera angle yield the\nbest pose estimation accuracy on infants in a GMA related setting, the distance\nto human annotations as well as the percentage of correct key-points (PCK) were\ncomputed and compared. The results show that the best performing generic model\ntrained on adults, ViTPose, also performs best on infants. We see no\nimprovement from using specialized infant-pose estimators over the generic pose\nestimators on our own infant dataset. However, when retraining a generic model\non our data, there is a significant improvement in pose estimation accuracy.\nThe pose estimation accuracy obtained from the top-down view is significantly\nbetter than that obtained from the diagonal view, especially for the detection\nof the hip key-points. The results also indicate only limited generalization\ncapabilities of infant-pose estimators to other infant datasets, which hints\nthat one should be careful when choosing infant pose estimators and using them\non infant datasets which they were not trained on. While the standard GMA\nmethod uses a diagonal view for assessment, pose estimation accuracy\nsignificantly improves using a top-down view. This suggests that a top-down\nview should be included in recording setups for automated GMA research.\n","authors":["Lennart Jahn","Sarah Flügge","Dajie Zhang","Luise Poustka","Sven Bölte","Florentin Wörgötter","Peter B Marschik","Tomas Kulvicius"],"pdf_url":"https://arxiv.org/pdf/2410.04980v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04974v1","updated":"2024-10-07T12:16:36Z","published":"2024-10-07T12:16:36Z","title":"6DGS: Enhanced Direction-Aware Gaussian Splatting for Volumetric\n  Rendering","summary":"  Novel view synthesis has advanced significantly with the development of\nneural radiance fields (NeRF) and 3D Gaussian splatting (3DGS). However,\nachieving high quality without compromising real-time rendering remains\nchallenging, particularly for physically-based ray tracing with view-dependent\neffects. Recently, N-dimensional Gaussians (N-DG) introduced a 6D\nspatial-angular representation to better incorporate view-dependent effects,\nbut the Gaussian representation and control scheme are sub-optimal. In this\npaper, we revisit 6D Gaussians and introduce 6D Gaussian Splatting (6DGS),\nwhich enhances color and opacity representations and leverages the additional\ndirectional information in the 6D space for optimized Gaussian control. Our\napproach is fully compatible with the 3DGS framework and significantly improves\nreal-time radiance field rendering by better modeling view-dependent effects\nand fine details. Experiments demonstrate that 6DGS significantly outperforms\n3DGS and N-DG, achieving up to a 15.73 dB improvement in PSNR with a reduction\nof 66.5% Gaussian points compared to 3DGS.\n","authors":["Zhongpai Gao","Benjamin Planche","Meng Zheng","Anwesa Choudhuri","Terrence Chen","Ziyan Wu"],"pdf_url":"https://arxiv.org/pdf/2410.04974v1.pdf","comment":"Demo Video: https://www.youtube.com/watch?v=77wN-K6Q9aM"},{"id":"http://arxiv.org/abs/2410.04972v1","updated":"2024-10-07T12:16:21Z","published":"2024-10-07T12:16:21Z","title":"L-C4: Language-Based Video Colorization for Creative and Consistent\n  Color","summary":"  Automatic video colorization is inherently an ill-posed problem because each\nmonochrome frame has multiple optional color candidates. Previous\nexemplar-based video colorization methods restrict the user's imagination due\nto the elaborate retrieval process. Alternatively, conditional image\ncolorization methods combined with post-processing algorithms still struggle to\nmaintain temporal consistency. To address these issues, we present\nLanguage-based video Colorization for Creative and Consistent Colors (L-C4) to\nguide the colorization process using user-provided language descriptions. Our\nmodel is built upon a pre-trained cross-modality generative model, leveraging\nits comprehensive language understanding and robust color representation\nabilities. We introduce the cross-modality pre-fusion module to generate\ninstance-aware text embeddings, enabling the application of creative colors.\nAdditionally, we propose temporally deformable attention to prevent flickering\nor color shifts, and cross-clip fusion to maintain long-term color consistency.\nExtensive experimental results demonstrate that L-C4 outperforms relevant\nmethods, achieving semantically accurate colors, unrestricted creative\ncorrespondence, and temporally robust consistency.\n","authors":["Zheng Chang","Shuchen Weng","Huan Ouyang","Yu Li","Si Li","Boxin Shi"],"pdf_url":"https://arxiv.org/pdf/2410.04972v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.18082v2","updated":"2024-10-07T12:06:17Z","published":"2024-09-26T17:26:16Z","title":"SKT: Integrating State-Aware Keypoint Trajectories with Vision-Language\n  Models for Robotic Garment Manipulation","summary":"  Automating garment manipulation poses a significant challenge for assistive\nrobotics due to the diverse and deformable nature of garments. Traditional\napproaches typically require separate models for each garment type, which\nlimits scalability and adaptability. In contrast, this paper presents a unified\napproach using vision-language models (VLMs) to improve keypoint prediction\nacross various garment categories. By interpreting both visual and semantic\ninformation, our model enables robots to manage different garment states with a\nsingle model. We created a large-scale synthetic dataset using advanced\nsimulation techniques, allowing scalable training without extensive real-world\ndata. Experimental results indicate that the VLM-based method significantly\nenhances keypoint detection accuracy and task success rates, providing a more\nflexible and general solution for robotic garment manipulation. In addition,\nthis research also underscores the potential of VLMs to unify various garment\nmanipulation tasks within a single framework, paving the way for broader\napplications in home automation and assistive robotics for future.\n","authors":["Xin Li","Siyuan Huang","Qiaojun Yu","Zhengkai Jiang","Ce Hao","Yimeng Zhu","Hongsheng Li","Peng Gao","Cewu Lu"],"pdf_url":"https://arxiv.org/pdf/2409.18082v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.19339v2","updated":"2024-10-07T12:05:55Z","published":"2024-09-28T12:49:16Z","title":"Visual Question Decomposition on Multimodal Large Language Models","summary":"  Question decomposition has emerged as an effective strategy for prompting\nLarge Language Models (LLMs) to answer complex questions. However, while\nexisting methods primarily focus on unimodal language models, the question\ndecomposition capability of Multimodal Large Language Models (MLLMs) has yet to\nbe explored. To this end, this paper explores visual question decomposition on\nMLLMs. Specifically, we introduce a systematic evaluation framework including a\ndataset and several evaluation criteria to assess the quality of the decomposed\nsub-questions, revealing that existing MLLMs struggle to produce high-quality\nsub-questions. To address this limitation, we propose a specific finetuning\ndataset, DecoVQA+, for enhancing the model's question decomposition capability.\nAiming at enabling models to perform appropriate selective decomposition, we\npropose an efficient finetuning pipeline. The finetuning pipeline consists of\nour proposed dataset and a training objective for selective decomposition.\nFinetuned MLLMs demonstrate significant improvements in the quality of\nsub-questions and the policy of selective question decomposition. Additionally,\nthe models also achieve higher accuracy with selective decomposition on VQA\nbenchmark datasets.\n","authors":["Haowei Zhang","Jianzhe Liu","Zhen Han","Shuo Chen","Bailan He","Volker Tresp","Zhiqiang Xu","Jindong Gu"],"pdf_url":"https://arxiv.org/pdf/2409.19339v2.pdf","comment":"Accepted to EMNLP2024 Findings"},{"id":"http://arxiv.org/abs/2410.04965v1","updated":"2024-10-07T12:04:39Z","published":"2024-10-07T12:04:39Z","title":"Revealing Directions for Text-guided 3D Face Editing","summary":"  3D face editing is a significant task in multimedia, aimed at the\nmanipulation of 3D face models across various control signals. The success of\n3D-aware GAN provides expressive 3D models learned from 2D single-view images\nonly, encouraging researchers to discover semantic editing directions in its\nlatent space. However, previous methods face challenges in balancing quality,\nefficiency, and generalization. To solve the problem, we explore the\npossibility of introducing the strength of diffusion model into 3D-aware GANs.\nIn this paper, we present Face Clan, a fast and text-general approach for\ngenerating and manipulating 3D faces based on arbitrary attribute descriptions.\nTo achieve disentangled editing, we propose to diffuse on the latent space\nunder a pair of opposite prompts to estimate the mask indicating the region of\ninterest on latent codes. Based on the mask, we then apply denoising to the\nmasked latent codes to reveal the editing direction. Our method offers a\nprecisely controllable manipulation method, allowing users to intuitively\ncustomize regions of interest with the text description. Experiments\ndemonstrate the effectiveness and generalization of our Face Clan for various\npre-trained GANs. It offers an intuitive and wide application for text-guided\nface editing that contributes to the landscape of multimedia content creation.\n","authors":["Zhuo Chen","Yichao Yan","Sehngqi Liu","Yuhao Cheng","Weiming Zhao","Lincheng Li","Mengxiao Bi","Xiaokang Yang"],"pdf_url":"https://arxiv.org/pdf/2410.04965v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.15341v2","updated":"2024-10-07T12:04:11Z","published":"2024-09-09T21:09:47Z","title":"StructuReiser: A Structure-preserving Video Stylization Method","summary":"  We introduce StructuReiser, a novel video-to-video translation method that\ntransforms input videos into stylized sequences using a set of user-provided\nkeyframes. Unlike existing approaches, StructuReiser maintains strict adherence\nto the structural elements of the target video, preserving the original\nidentity while seamlessly applying the desired stylistic transformations. This\nenables a level of control and consistency that was previously unattainable\nwith traditional text-driven or keyframe-based methods. Furthermore,\nStructuReiser supports real-time inference and custom keyframe editing, making\nit ideal for interactive applications and expanding the possibilities for\ncreative expression and video manipulation.\n","authors":["Radim Spetlik","David Futschik","Daniel Sykora"],"pdf_url":"https://arxiv.org/pdf/2409.15341v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04960v1","updated":"2024-10-07T11:59:54Z","published":"2024-10-07T11:59:54Z","title":"On Efficient Variants of Segment Anything Model: A Survey","summary":"  The Segment Anything Model (SAM) is a foundational model for image\nsegmentation tasks, known for its strong generalization across diverse\napplications. However, its impressive performance comes with significant\ncomputational and resource demands, making it challenging to deploy in\nresource-limited environments such as mobile devices. To address this, a\nvariety of SAM variants have been proposed to enhance efficiency without\nsacrificing accuracy. This survey provides the first comprehensive review of\nthese efficient SAM variants. We begin by exploring the motivations driving\nthis research. We then present core techniques used in SAM and model\nacceleration. This is followed by an in-depth analysis of various acceleration\nstrategies, categorized by approach. Finally, we offer a unified and extensive\nevaluation of these methods, assessing their efficiency and accuracy on\nrepresentative benchmarks, and providing a clear comparison of their overall\nperformance.\n","authors":["Xiaorui Sun","Jun Liu","Heng Tao Shen","Xiaofeng Zhu","Ping Hu"],"pdf_url":"https://arxiv.org/pdf/2410.04960v1.pdf","comment":"Report in progress"},{"id":"http://arxiv.org/abs/2410.04946v1","updated":"2024-10-07T11:43:42Z","published":"2024-10-07T11:43:42Z","title":"Real-time Ship Recognition and Georeferencing for the Improvement of\n  Maritime Situational Awareness","summary":"  In an era where maritime infrastructures are crucial, advanced situational\nawareness solutions are increasingly important. The use of optical camera\nsystems can allow real-time usage of maritime footage. This thesis presents an\ninvestigation into leveraging deep learning and computer vision to advance\nreal-time ship recognition and georeferencing for the improvement of maritime\nsituational awareness. A novel dataset, ShipSG, is introduced, containing 3,505\nimages and 11,625 ship masks with corresponding class and geographic position.\nAfter an exploration of state-of-the-art, a custom real-time segmentation\narchitecture, ScatYOLOv8+CBAM, is designed for the NVIDIA Jetson AGX Xavier\nembedded system. This architecture adds the 2D scattering transform and\nattention mechanisms to YOLOv8, achieving an mAP of 75.46% and an 25.3 ms per\nframe, outperforming state-of-the-art methods by over 5%. To improve small and\ndistant ship recognition in high-resolution images on embedded systems, an\nenhanced slicing mechanism is introduced, improving mAP by 8% to 11%.\nAdditionally, a georeferencing method is proposed, achieving positioning errors\nof 18 m for ships up to 400 m away and 44 m for ships between 400 m and 1200 m.\nThe findings are also applied in real-world scenarios, such as the detection of\nabnormal ship behaviour, camera integrity assessment and 3D reconstruction. The\napproach of this thesis outperforms existing methods and provides a framework\nfor integrating recognized and georeferenced ships into real-time systems,\nenhancing operational effectiveness and decision-making for maritime\nstakeholders. This thesis contributes to the maritime computer vision field by\nestablishing a benchmark for ship segmentation and georeferencing research,\ndemonstrating the viability of deep-learning-based recognition and\ngeoreferencing methods for real-time maritime monitoring.\n","authors":["Borja Carrillo Perez"],"pdf_url":"https://arxiv.org/pdf/2410.04946v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04940v1","updated":"2024-10-07T11:32:17Z","published":"2024-10-07T11:32:17Z","title":"Next state prediction gives rise to entangled, yet compositional\n  representations of objects","summary":"  Compositional representations are thought to enable humans to generalize\nacross combinatorially vast state spaces. Models with learnable object slots,\nwhich encode information about objects in separate latent codes, have shown\npromise for this type of generalization but rely on strong architectural\npriors. Models with distributed representations, on the other hand, use\noverlapping, potentially entangled neural codes, and their ability to support\ncompositional generalization remains underexplored. In this paper we examine\nwhether distributed models can develop linearly separable representations of\nobjects, like slotted models, through unsupervised training on videos of object\ninteractions. We show that, surprisingly, models with distributed\nrepresentations often match or outperform models with object slots in\ndownstream prediction tasks. Furthermore, we find that linearly separable\nobject representations can emerge without object-centric priors, with auxiliary\nobjectives like next-state prediction playing a key role. Finally, we observe\nthat distributed models' object representations are never fully disentangled,\neven if they are linearly separable: Multiple objects can be encoded through\npartially overlapping neural populations while still being highly separable\nwith a linear classifier. We hypothesize that maintaining partially shared\ncodes enables distributed models to better compress object dynamics,\npotentially enhancing generalization.\n","authors":["Tankred Saanum","Luca M. Schulze Buschoff","Peter Dayan","Eric Schulz"],"pdf_url":"https://arxiv.org/pdf/2410.04940v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04939v1","updated":"2024-10-07T11:31:12Z","published":"2024-10-07T11:31:12Z","title":"PRFusion: Toward Effective and Robust Multi-Modal Place Recognition with\n  Image and Point Cloud Fusion","summary":"  Place recognition plays a crucial role in the fields of robotics and computer\nvision, finding applications in areas such as autonomous driving, mapping, and\nlocalization. Place recognition identifies a place using query sensor data and\na known database. One of the main challenges is to develop a model that can\ndeliver accurate results while being robust to environmental variations. We\npropose two multi-modal place recognition models, namely PRFusion and\nPRFusion++. PRFusion utilizes global fusion with manifold metric attention,\nenabling effective interaction between features without requiring camera-LiDAR\nextrinsic calibrations. In contrast, PRFusion++ assumes the availability of\nextrinsic calibrations and leverages pixel-point correspondences to enhance\nfeature learning on local windows. Additionally, both models incorporate neural\ndiffusion layers, which enable reliable operation even in challenging\nenvironments. We verify the state-of-the-art performance of both models on\nthree large-scale benchmarks. Notably, they outperform existing models by a\nsubstantial margin of +3.0 AR@1 on the demanding Boreas dataset. Furthermore,\nwe conduct ablation studies to validate the effectiveness of our proposed\nmethods. The codes are available at: https://github.com/sijieaaa/PRFusion\n","authors":["Sijie Wang","Qiyu Kang","Rui She","Kai Zhao","Yang Song","Wee Peng Tay"],"pdf_url":"https://arxiv.org/pdf/2410.04939v1.pdf","comment":"accepted by IEEE TITS 2024"},{"id":"http://arxiv.org/abs/2107.07243v3","updated":"2024-10-07T11:27:30Z","published":"2021-07-15T11:05:00Z","title":"VILENS: Visual, Inertial, Lidar, and Leg Odometry for All-Terrain Legged\n  Robots","summary":"  We present visual inertial lidar legged navigation system (VILENS), an\nodometry system for legged robots based on factor graphs. The key novelty is\nthe tight fusion of four different sensor modalities to achieve reliable\noperation when the individual sensors would otherwise produce degenerate\nestimation. To minimize leg odometry drift, we extend the robot's state with a\nlinear velocity bias term, which is estimated online. This bias is observable\nbecause of the tight fusion of this preintegrated velocity factor with vision,\nlidar, and inertial measurement unit (IMU) factors. Extensive experimental\nvalidation on different ANYmal quadruped robots is presented, for a total\nduration of 2 h and 1.8 km traveled. The experiments involved dynamic\nlocomotion over loose rocks, slopes, and mud, which caused challenges such as\nslippage and terrain deformation. Perceptual challenges included dark and dusty\nunderground caverns, and open and feature-deprived areas. We show an average\nimprovement of 62% translational and 51% rotational errors compared to a\nstate-of-the-art loosely coupled approach. To demonstrate its robustness,\nVILENS was also integrated with a perceptive controller and a local path\nplanner.\n","authors":["David Wisth","Marco Camurri","Maurice Fallon"],"pdf_url":"https://arxiv.org/pdf/2107.07243v3.pdf","comment":"Video: https://youtu.be/NG4pkjJKhus"},{"id":"http://arxiv.org/abs/2410.04932v1","updated":"2024-10-07T11:26:13Z","published":"2024-10-07T11:26:13Z","title":"OmniBooth: Learning Latent Control for Image Synthesis with Multi-modal\n  Instruction","summary":"  We present OmniBooth, an image generation framework that enables spatial\ncontrol with instance-level multi-modal customization. For all instances, the\nmultimodal instruction can be described through text prompts or image\nreferences. Given a set of user-defined masks and associated text or image\nguidance, our objective is to generate an image, where multiple objects are\npositioned at specified coordinates and their attributes are precisely aligned\nwith the corresponding guidance. This approach significantly expands the scope\nof text-to-image generation, and elevates it to a more versatile and practical\ndimension in controllability. In this paper, our core contribution lies in the\nproposed latent control signals, a high-dimensional spatial feature that\nprovides a unified representation to integrate the spatial, textual, and image\nconditions seamlessly. The text condition extends ControlNet to provide\ninstance-level open-vocabulary generation. The image condition further enables\nfine-grained control with personalized identity. In practice, our method\nempowers users with more flexibility in controllable generation, as users can\nchoose multi-modal conditions from text or images as needed. Furthermore,\nthorough experiments demonstrate our enhanced performance in image synthesis\nfidelity and alignment across different tasks and datasets. Project page:\nhttps://len-li.github.io/omnibooth-web/\n","authors":["Leheng Li","Weichao Qiu","Xu Yan","Jing He","Kaiqiang Zhou","Yingjie Cai","Qing Lian","Bingbing Liu","Ying-Cong Chen"],"pdf_url":"https://arxiv.org/pdf/2410.04932v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04906v1","updated":"2024-10-07T10:48:08Z","published":"2024-10-07T10:48:08Z","title":"Art2Mus: Bridging Visual Arts and Music through Cross-Modal Generation","summary":"  Artificial Intelligence and generative models have revolutionized music\ncreation, with many models leveraging textual or visual prompts for guidance.\nHowever, existing image-to-music models are limited to simple images, lacking\nthe capability to generate music from complex digitized artworks. To address\nthis gap, we introduce $\\mathcal{A}\\textit{rt2}\\mathcal{M}\\textit{us}$, a novel\nmodel designed to create music from digitized artworks or text inputs.\n$\\mathcal{A}\\textit{rt2}\\mathcal{M}\\textit{us}$ extends the AudioLDM~2\narchitecture, a text-to-audio model, and employs our newly curated datasets,\ncreated via ImageBind, which pair digitized artworks with music. Experimental\nresults demonstrate that $\\mathcal{A}\\textit{rt2}\\mathcal{M}\\textit{us}$ can\ngenerate music that resonates with the input stimuli. These findings suggest\npromising applications in multimedia art, interactive installations, and\nAI-driven creative tools.\n","authors":["Ivan Rinaldi","Nicola Fanelli","Giovanna Castellano","Gennaro Vessio"],"pdf_url":"https://arxiv.org/pdf/2410.04906v1.pdf","comment":"Presented at the AI for Visual Arts (AI4VA) workshop at ECCV 2024"},{"id":"http://arxiv.org/abs/2403.12510v2","updated":"2024-10-07T10:31:58Z","published":"2024-03-19T07:24:54Z","title":"Generalized Consistency Trajectory Models for Image Manipulation","summary":"  Diffusion models (DMs) excel in unconditional generation, as well as on\napplications such as image editing and restoration. The success of DMs lies in\nthe iterative nature of diffusion: diffusion breaks down the complex process of\nmapping noise to data into a sequence of simple denoising tasks. Moreover, we\nare able to exert fine-grained control over the generation process by injecting\nguidance terms into each denoising step. However, the iterative process is also\ncomputationally intensive, often taking from tens up to thousands of function\nevaluations. Although consistency trajectory models (CTMs) enable traversal\nbetween any time points along the probability flow ODE (PFODE) and score\ninference with a single function evaluation, CTMs only allow translation from\nGaussian noise to data. This work aims to unlock the full potential of CTMs by\nproposing generalized CTMs (GCTMs), which translate between arbitrary\ndistributions via ODEs. We discuss the design space of GCTMs and demonstrate\ntheir efficacy in various image manipulation tasks such as image-to-image\ntranslation, restoration, and editing.\n","authors":["Beomsu Kim","Jaemin Kim","Jeongsol Kim","Jong Chul Ye"],"pdf_url":"https://arxiv.org/pdf/2403.12510v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04889v1","updated":"2024-10-07T10:17:46Z","published":"2024-10-07T10:17:46Z","title":"D-PoSE: Depth as an Intermediate Representation for 3D Human Pose and\n  Shape Estimation","summary":"  We present D-PoSE (Depth as an Intermediate Representation for 3D Human Pose\nand Shape Estimation), a one-stage method that estimates human pose and SMPL-X\nshape parameters from a single RGB image. Recent works use larger models with\ntransformer backbones and decoders to improve the accuracy in human pose and\nshape (HPS) benchmarks. D-PoSE proposes a vision based approach that uses the\nestimated human depth-maps as an intermediate representation for HPS and\nleverages training with synthetic data and the ground-truth depth-maps provided\nwith them for depth supervision during training. Although trained on synthetic\ndatasets, D-PoSE achieves state-of-the-art performance on the real-world\nbenchmark datasets, EMDB and 3DPW. Despite its simple lightweight design and\nthe CNN backbone, it outperforms ViT-based models that have a number of\nparameters that is larger by almost an order of magnitude. D-PoSE code is\navailable at: https://github.com/nvasilik/D-PoSE\n","authors":["Nikolaos Vasilikopoulos","Drosakis Drosakis","Antonis Argyros"],"pdf_url":"https://arxiv.org/pdf/2410.04889v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.06165v4","updated":"2024-10-07T10:14:00Z","published":"2024-02-09T03:48:20Z","title":"Learning Contrastive Feature Representations for Facial Action Unit\n  Detection","summary":"  Facial action unit (AU) detection has long encountered the challenge of\ndetecting subtle feature differences when AUs activate. Existing methods often\nrely on encoding pixel-level information of AUs, which not only encodes\nadditional redundant information but also leads to increased model complexity\nand limited generalizability. Additionally, the accuracy of AU detection is\nnegatively impacted by the class imbalance issue of each AU type, and the\npresence of noisy and false AU labels. In this paper, we introduce a novel\ncontrastive learning framework aimed for AU detection that incorporates both\nself-supervised and supervised signals, thereby enhancing the learning of\ndiscriminative features for accurate AU detection. To tackle the class\nimbalance issue, we employ a negative sample re-weighting strategy that adjusts\nthe step size of updating parameters for minority and majority class samples.\nMoreover, to address the challenges posed by noisy and false AU labels, we\nemploy a sampling technique that encompasses three distinct types of positive\nsample pairs. This enables us to inject self-supervised signals into the\nsupervised signal, effectively mitigating the adverse effects of noisy labels.\nOur experimental assessments, conducted on four widely-utilized benchmark\ndatasets (BP4D, DISFA, GFT and Aff-Wild2), underscore the superior performance\nof our approach compared to state-of-the-art methods of AU detection. Our code\nis available at \\url{https://github.com/Ziqiao-Shang/AUNCE}.\n","authors":["Ziqiao Shang","Bin Liu","Fengmao Lv","Fei Teng","Tianrui Li"],"pdf_url":"https://arxiv.org/pdf/2402.06165v4.pdf","comment":"13 pages, 17 figures, submitted to IEEE Transactions on Circuits and\n  Systems for Video Technology (TCSVT)"},{"id":"http://arxiv.org/abs/2410.04884v1","updated":"2024-10-07T10:06:01Z","published":"2024-10-07T10:06:01Z","title":"Patch is Enough: Naturalistic Adversarial Patch against Vision-Language\n  Pre-training Models","summary":"  Visual language pre-training (VLP) models have demonstrated significant\nsuccess across various domains, yet they remain vulnerable to adversarial\nattacks. Addressing these adversarial vulnerabilities is crucial for enhancing\nsecurity in multimodal learning. Traditionally, adversarial methods targeting\nVLP models involve simultaneously perturbing images and text. However, this\napproach faces notable challenges: first, adversarial perturbations often fail\nto translate effectively into real-world scenarios; second, direct\nmodifications to the text are conspicuously visible. To overcome these\nlimitations, we propose a novel strategy that exclusively employs image patches\nfor attacks, thus preserving the integrity of the original text. Our method\nleverages prior knowledge from diffusion models to enhance the authenticity and\nnaturalness of the perturbations. Moreover, to optimize patch placement and\nimprove the efficacy of our attacks, we utilize the cross-attention mechanism,\nwhich encapsulates intermodal interactions by generating attention maps to\nguide strategic patch placements. Comprehensive experiments conducted in a\nwhite-box setting for image-to-text scenarios reveal that our proposed method\nsignificantly outperforms existing techniques, achieving a 100% attack success\nrate. Additionally, it demonstrates commendable performance in transfer tasks\ninvolving text-to-image configurations.\n","authors":["Dehong Kong","Siyuan Liang","Xiaopeng Zhu","Yuansheng Zhong","Wenqi Ren"],"pdf_url":"https://arxiv.org/pdf/2410.04884v1.pdf","comment":"accepted by Visual Intelligence"},{"id":"http://arxiv.org/abs/2410.04880v1","updated":"2024-10-07T10:01:30Z","published":"2024-10-07T10:01:30Z","title":"Improved detection of discarded fish species through BoxAL active\n  learning","summary":"  In recent years, powerful data-driven deep-learning techniques have been\ndeveloped and applied for automated catch registration. However, these methods\nare dependent on the labelled data, which is time-consuming, labour-intensive,\nexpensive to collect and need expert knowledge. In this study, we present an\nactive learning technique, named BoxAL, which includes estimation of epistemic\ncertainty of the Faster R-CNN object-detection model. The method allows\nselecting the most uncertain training images from an unlabeled pool, which are\nthen used to train the object-detection model. To evaluate the method, we used\nan open-source image dataset obtained with a dedicated image-acquisition system\ndeveloped for commercial trawlers targeting demersal species. We demonstrated,\nthat our approach allows reaching the same object-detection performance as with\nthe random sampling using 400 fewer labelled images. Besides, mean AP score was\nsignificantly higher at the last training iteration with 1100 training images,\nspecifically, 39.0&plusmn;1.6 and 34.8&plusmn;1.8 for certainty-based sampling\nand random sampling, respectively. Additionally, we showed that epistemic\ncertainty is a suitable method to sample images that the current iteration of\nthe model cannot deal with yet. Our study additionally showed that the sampled\nnew data is more valuable for training than the remaining unlabeled data. Our\nsoftware is available on https://github.com/pieterblok/boxal.\n","authors":["Maria Sokolova","Pieter M. Blok","Angelo Mencarelli","Arjan Vroegop","Aloysius van Helmond","Gert Kootstra"],"pdf_url":"https://arxiv.org/pdf/2410.04880v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2308.06300v3","updated":"2024-10-07T09:48:14Z","published":"2023-08-11T07:57:12Z","title":"Classification of All Blood Cell Images using ML and DL Models","summary":"  Human blood primarily comprises plasma, red blood cells, white blood cells,\nand platelets. It plays a vital role in transporting nutrients to different\norgans, where it stores essential health-related data about the human body.\nBlood cells are utilized to defend the body against diverse infections,\nincluding fungi, viruses, and bacteria. Hence, blood analysis can help\nphysicians assess an individual's physiological condition. Blood cells have\nbeen sub-classified into eight groups: Neutrophils, eosinophils, basophils,\nlymphocytes, monocytes, immature granulocytes (promyelocytes, myelocytes, and\nmetamyelocytes), erythroblasts, and platelets or thrombocytes on the basis of\ntheir nucleus, shape, and cytoplasm. Traditionally, pathologists and\nhematologists in laboratories have examined these blood cells using a\nmicroscope before manually classifying them. The manual approach is slower and\nmore prone to human error. Therefore, it is essential to automate this process.\nIn our paper, transfer learning with CNN pre-trained models. VGG16, VGG19,\nResNet-50, ResNet-101, ResNet-152, InceptionV3, MobileNetV2, and DenseNet-20\napplied to the PBC dataset's normal DIB. The overall accuracy achieved with\nthese models lies between 91.375 and 94.72%. Hence, inspired by these\npre-trained architectures, a model has been proposed to automatically classify\nthe ten types of blood cells with increased accuracy. A novel CNN-based\nframework has been presented to improve accuracy. The proposed CNN model has\nbeen tested on the PBC dataset normal DIB. The outcomes of the experiments\ndemonstrate that our CNN-based framework designed for blood cell classification\nattains an accuracy of 99.91% on the PBC dataset. Our proposed convolutional\nneural network model performs competitively when compared to earlier results\nreported in the literature.\n","authors":["Rabia Asghar","Sanjay Kumar","Paul Hynds","Abeera Mahfooz"],"pdf_url":"https://arxiv.org/pdf/2308.06300v3.pdf","comment":"15"},{"id":"http://arxiv.org/abs/2407.16665v2","updated":"2024-10-07T09:46:07Z","published":"2024-07-23T17:32:02Z","title":"A Framework for Pupil Tracking with Event Cameras","summary":"  Saccades are extremely rapid movements of both eyes that occur\nsimultaneously, typically observed when an individual shifts their focus from\none object to another. These movements are among the swiftest produced by\nhumans and possess the potential to achieve velocities greater than that of\nblinks. The peak angular speed of the eye during a saccade can reach as high as\n700{\\deg}/s in humans, especially during larger saccades that cover a visual\nangle of 25{\\deg}. Previous research has demonstrated encouraging outcomes in\ncomprehending neurological conditions through the study of saccades. A\nnecessary step in saccade detection involves accurately identifying the precise\nlocation of the pupil within the eye, from which additional information such as\ngaze angles can be inferred. Conventional frame-based cameras often struggle\nwith the high temporal precision necessary for tracking very fast movements,\nresulting in motion blur and latency issues. Event cameras, on the other hand,\noffer a promising alternative by recording changes in the visual scene\nasynchronously and providing high temporal resolution and low latency. By\nbridging the gap between traditional computer vision and event-based vision, we\npresent events as frames that can be readily utilized by standard deep learning\nalgorithms. This approach harnesses YOLOv8, a state-of-the-art object detection\ntechnology, to process these frames for pupil tracking using the publicly\naccessible Ev-Eye dataset. Experimental results demonstrate the framework's\neffectiveness, highlighting its potential applications in neuroscience,\nophthalmology, and human-computer interaction.\n","authors":["Khadija Iddrisu","Waseem Shariff","Suzanne Little"],"pdf_url":"https://arxiv.org/pdf/2407.16665v2.pdf","comment":"This paper is a preprint of a paper submitted to the 26th Irish\n  Machine Vision and Image Processing Conference (IMVIP 2024). If accepted, the\n  copy of record will be available at IET Digital Library"},{"id":"http://arxiv.org/abs/2410.04873v1","updated":"2024-10-07T09:43:28Z","published":"2024-10-07T09:43:28Z","title":"TeX-NeRF: Neural Radiance Fields from Pseudo-TeX Vision","summary":"  Neural radiance fields (NeRF) has gained significant attention for its\nexceptional visual effects. However, most existing NeRF methods reconstruct 3D\nscenes from RGB images captured by visible light cameras. In practical\nscenarios like darkness, low light, or bad weather, visible light cameras\nbecome ineffective. Therefore, we propose TeX-NeRF, a 3D reconstruction method\nusing only infrared images, which introduces the object material emissivity as\na priori, preprocesses the infrared images using Pseudo-TeX vision, and maps\nthe temperatures (T), emissivities (e), and textures (X) of the scene into the\nsaturation (S), hue (H), and value (V) channels of the HSV color space,\nrespectively. Novel view synthesis using the processed images has yielded\nexcellent results. Additionally, we introduce 3D-TeX Datasets, the first\ndataset comprising infrared images and their corresponding Pseudo-TeX vision\nimages. Experiments demonstrate that our method not only matches the quality of\nscene reconstruction achieved with high-quality RGB images but also provides\naccurate temperature estimations for objects in the scene.\n","authors":["Chonghao Zhong","Chao Xu"],"pdf_url":"https://arxiv.org/pdf/2410.04873v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.19890v2","updated":"2024-10-07T09:35:44Z","published":"2024-09-30T02:39:42Z","title":"Universal Medical Image Representation Learning with Compositional\n  Decoders","summary":"  Visual-language models have advanced the development of universal models, yet\ntheir application in medical imaging remains constrained by specific functional\nrequirements and the limited data. Current general-purpose models are typically\ndesigned with task-specific branches and heads, which restricts the shared\nfeature space and the flexibility of model. To address these challenges, we\nhave developed a decomposed-composed universal medical imaging paradigm\n(UniMed) that supports tasks at all levels. To this end, we first propose a\ndecomposed decoder that can predict two types of outputs -- pixel and semantic,\nbased on a defined input queue. Additionally, we introduce a composed decoder\nthat unifies the input and output spaces and standardizes task annotations\nacross different levels into a discrete token format. The coupled design of\nthese two components enables the model to flexibly combine tasks and mutual\nbenefits. Moreover, our joint representation learning strategy skilfully\nleverages large amounts of unlabeled data and unsupervised loss, achieving\nefficient one-stage pretraining for more robust performance. Experimental\nresults show that UniMed achieves state-of-the-art performance on eight\ndatasets across all three tasks and exhibits strong zero-shot and 100-shot\ntransferability. We will release the code and trained models upon the paper's\nacceptance.\n","authors":["Kaini Wang","Ling Yang","Siping Zhou","Guangquan Zhou","Wentao Zhang","Bin Cui","Shuo Li"],"pdf_url":"https://arxiv.org/pdf/2409.19890v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04866v1","updated":"2024-10-07T09:32:11Z","published":"2024-10-07T09:32:11Z","title":"Art Forgery Detection using Kolmogorov Arnold and Convolutional Neural\n  Networks","summary":"  Art authentication has historically established itself as a task requiring\nprofound connoisseurship of one particular artist. Nevertheless, famous art\nforgers such as Wolfgang Beltracchi were able to deceive dozens of art experts.\nIn recent years Artificial Intelligence algorithms have been successfully\napplied to various image processing tasks. In this work, we leverage the\ngrowing improvements in AI to present an art authentication framework for the\nidentification of the forger Wolfgang Beltracchi. Differently from existing\nliterature on AI-aided art authentication, we focus on a specialized model of a\nforger, rather than an artist, flipping the approach of traditional AI methods.\nWe use a carefully compiled dataset of known artists forged by Beltracchi and a\nset of known works by the forger to train a multiclass image classification\nmodel based on EfficientNet. We compare the results with Kolmogorov Arnold\nNetworks (KAN) which, to the best of our knowledge, have never been tested in\nthe art domain. The results show a general agreement between the different\nmodels' predictions on artworks flagged as forgeries, which are then closely\nstudied using visual analysis.\n","authors":["Sandro Boccuzzo","Deborah Desirée Meyer","Ludovica Schaerf"],"pdf_url":"https://arxiv.org/pdf/2410.04866v1.pdf","comment":"Accepted to ECCV 2024 workshop AI4VA, oral presentation"},{"id":"http://arxiv.org/abs/2407.11514v2","updated":"2024-10-07T09:22:36Z","published":"2024-07-16T08:51:01Z","title":"ColorwAI: Generative Colorways of Textiles through GAN and Diffusion\n  Disentanglement","summary":"  Colorway creation is the task of generating textile samples in alternate\ncolor variations maintaining an underlying pattern. The individuation of a\nsuitable color palette for a colorway is a complex creative task, responding to\nclient and market needs, stylistic and cultural specifications, and mood. We\nintroduce a modification of this task, the \"generative colorway\" creation, that\nincludes minimal shape modifications, and propose a framework, \"ColorwAI\", to\ntackle this task using color disentanglement on StyleGAN and Diffusion. We\nintroduce a variation of the InterfaceGAN method for supervised\ndisentanglement, ShapleyVec. We use Shapley values to subselect a few\ndimensions of the detected latent direction. Moreover, we introduce a general\nframework to adopt common disentanglement methods on any architecture with a\nsemantic latent space and test it on Diffusion and GANs. We interpret the color\nrepresentations within the models' latent space. We find StyleGAN's W space to\nbe the most aligned with human notions of color. Finally, we suggest that\ndisentanglement can solicit a creative system for colorway creation, and\nevaluate it through expert questionnaires and creativity theory.\n","authors":["Ludovica Schaerf","Andrea Alfarano","Eric Postma"],"pdf_url":"https://arxiv.org/pdf/2407.11514v2.pdf","comment":"Accepted to ECCV 2024 VISART workshop, oral presentation"},{"id":"http://arxiv.org/abs/2410.04847v1","updated":"2024-10-07T09:08:32Z","published":"2024-10-07T09:08:32Z","title":"Causal Context Adjustment Loss for Learned Image Compression","summary":"  In recent years, learned image compression (LIC) technologies have surpassed\nconventional methods notably in terms of rate-distortion (RD) performance. Most\npresent learned techniques are VAE-based with an autoregressive entropy model,\nwhich obviously promotes the RD performance by utilizing the decoded causal\ncontext. However, extant methods are highly dependent on the fixed hand-crafted\ncausal context. The question of how to guide the auto-encoder to generate a\nmore effective causal context benefit for the autoregressive entropy models is\nworth exploring. In this paper, we make the first attempt in investigating the\nway to explicitly adjust the causal context with our proposed Causal Context\nAdjustment loss (CCA-loss). By imposing the CCA-loss, we enable the neural\nnetwork to spontaneously adjust important information into the early stage of\nthe autoregressive entropy model. Furthermore, as transformer technology\ndevelops remarkably, variants of which have been adopted by many\nstate-of-the-art (SOTA) LIC techniques. The existing computing devices have not\nadapted the calculation of the attention mechanism well, which leads to a\nburden on computation quantity and inference latency. To overcome it, we\nestablish a convolutional neural network (CNN) image compression model and\nadopt the unevenly channel-wise grouped strategy for high efficiency.\nUltimately, the proposed CNN-based LIC network trained with our Causal Context\nAdjustment loss attains a great trade-off between inference latency and\nrate-distortion performance.\n","authors":["Minghao Han","Shiyin Jiang","Shengxi Li","Xin Deng","Mai Xu","Ce Zhu","Shuhang Gu"],"pdf_url":"https://arxiv.org/pdf/2410.04847v1.pdf","comment":"Accepted to NeurIPS 2024"},{"id":"http://arxiv.org/abs/2410.04844v1","updated":"2024-10-07T09:04:50Z","published":"2024-10-07T09:04:50Z","title":"PostEdit: Posterior Sampling for Efficient Zero-Shot Image Editing","summary":"  In the field of image editing, three core challenges persist:\ncontrollability, background preservation, and efficiency. Inversion-based\nmethods rely on time-consuming optimization to preserve the features of the\ninitial images, which results in low efficiency due to the requirement for\nextensive network inference. Conversely, inversion-free methods lack\ntheoretical support for background similarity, as they circumvent the issue of\nmaintaining initial features to achieve efficiency. As a consequence, none of\nthese methods can achieve both high efficiency and background consistency. To\ntackle the challenges and the aforementioned disadvantages, we introduce\nPostEdit, a method that incorporates a posterior scheme to govern the diffusion\nsampling process. Specifically, a corresponding measurement term related to\nboth the initial features and Langevin dynamics is introduced to optimize the\nestimated image generated by the given target prompt. Extensive experimental\nresults indicate that the proposed PostEdit achieves state-of-the-art editing\nperformance while accurately preserving unedited regions. Furthermore, the\nmethod is both inversion- and training-free, necessitating approximately 1.5\nseconds and 18 GB of GPU memory to generate high-quality results.\n","authors":["Feng Tian","Yixuan Li","Yichao Yan","Shanyan Guan","Yanhao Ge","Xiaokang Yang"],"pdf_url":"https://arxiv.org/pdf/2410.04844v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04842v1","updated":"2024-10-07T08:59:05Z","published":"2024-10-07T08:59:05Z","title":"A Simple Image Segmentation Framework via In-Context Examples","summary":"  Recently, there have been explorations of generalist segmentation models that\ncan effectively tackle a variety of image segmentation tasks within a unified\nin-context learning framework. However, these methods still struggle with task\nambiguity in in-context segmentation, as not all in-context examples can\naccurately convey the task information. In order to address this issue, we\npresent SINE, a simple image Segmentation framework utilizing in-context\nexamples. Our approach leverages a Transformer encoder-decoder structure, where\nthe encoder provides high-quality image representations, and the decoder is\ndesigned to yield multiple task-specific output masks to effectively eliminate\ntask ambiguity. Specifically, we introduce an In-context Interaction module to\ncomplement in-context information and produce correlations between the target\nimage and the in-context example and a Matching Transformer that uses fixed\nmatching and a Hungarian algorithm to eliminate differences between different\ntasks. In addition, we have further perfected the current evaluation system for\nin-context image segmentation, aiming to facilitate a holistic appraisal of\nthese models. Experiments on various segmentation tasks show the effectiveness\nof the proposed method.\n","authors":["Yang Liu","Chenchen Jing","Hengtao Li","Muzhi Zhu","Hao Chen","Xinlong Wang","Chunhua Shen"],"pdf_url":"https://arxiv.org/pdf/2410.04842v1.pdf","comment":"Accepted to Proc. Conference on Neural Information Processing Systems\n  (NeurIPS) 2024. Webpage: https://github.com/aim-uofa/SINE"},{"id":"http://arxiv.org/abs/2402.14407v3","updated":"2024-10-07T08:45:35Z","published":"2024-02-22T09:48:47Z","title":"Learning an Actionable Discrete Diffusion Policy via Large-Scale\n  Actionless Video Pre-Training","summary":"  Learning a generalist embodied agent capable of completing multiple tasks\nposes challenges, primarily stemming from the scarcity of action-labeled\nrobotic datasets. In contrast, a vast amount of human videos exist, capturing\nintricate tasks and interactions with the physical world. Promising prospects\narise for utilizing actionless human videos for pre-training and transferring\nthe knowledge to facilitate robot policy learning through limited robot\ndemonstrations. However, it remains a challenge due to the domain gap between\nhumans and robots. Moreover, it is difficult to extract useful information\nrepresenting the dynamic world from human videos, because of its noisy and\nmultimodal data structure. In this paper, we introduce a novel framework to\ntackle these challenges, which leverages a unified discrete diffusion to\ncombine generative pre-training on human videos and policy fine-tuning on a\nsmall number of action-labeled robot videos. We start by compressing both human\nand robot videos into unified video tokens. In the pre-training stage, we\nemploy a discrete diffusion model with a mask-and-replace diffusion strategy to\npredict future video tokens in the latent space. In the fine-tuning stage, we\nharness the imagined future videos to guide low-level action learning with a\nlimited set of robot data. Experiments demonstrate that our method generates\nhigh-fidelity future videos for planning and enhances the fine-tuned policies\ncompared to previous state-of-the-art approaches with superior performance. Our\nproject website is available at https://video-diff.github.io/.\n","authors":["Haoran He","Chenjia Bai","Ling Pan","Weinan Zhang","Bin Zhao","Xuelong Li"],"pdf_url":"https://arxiv.org/pdf/2402.14407v3.pdf","comment":"Accepted by NeurIPS 2024. 24 pages"},{"id":"http://arxiv.org/abs/2408.08313v2","updated":"2024-10-07T08:44:35Z","published":"2024-08-15T17:59:57Z","title":"Can Large Language Models Understand Symbolic Graphics Programs?","summary":"  Against the backdrop of enthusiasm for large language models (LLMs), there is\nan urgent need to scientifically assess their capabilities and shortcomings.\nThis is nontrivial in part because it is difficult to find tasks which the\nmodels have not encountered during training. Utilizing symbolic graphics\nprograms, we propose a domain well-suited to test multiple spatial-semantic\nreasoning skills of LLMs. Popular in computer graphics, these programs\nprocedurally generate visual data. While LLMs exhibit impressive skills in\ngeneral program synthesis and analysis, symbolic graphics programs offer a new\nlayer of evaluation: they allow us to test an LLM's ability to answer\ndifferent-grained semantic-level questions of the images or 3D geometries\nwithout a vision encoder. To semantically understand the symbolic programs,\nLLMs would need to possess the ability to \"imagine\" and reason how the\ncorresponding graphics content would look with only the symbolic description.\nWe use this task to evaluate LLMs by creating a large benchmark for the\nsemantic visual understanding of symbolic graphics programs, built procedurally\nwith minimal human effort. Particular emphasis is placed on transformations of\nimages that leave the image level semantics invariant while introducing\nsignificant changes to the underlying program. We evaluate commercial and\nopen-source LLMs on our benchmark to assess their ability to reason about\nvisual output of programs, finding that LLMs considered stronger at reasoning\ngenerally perform better. Lastly, we introduce a novel method to improve this\nability -- Symbolic Instruction Tuning (SIT), in which the LLM is finetuned\nwith pre-collected instruction data on symbolic graphics programs.\nInterestingly, we find that SIT not only improves LLM's understanding on\nsymbolic programs, but it also improves general reasoning ability on various\nother benchmarks.\n","authors":["Zeju Qiu","Weiyang Liu","Haiwen Feng","Zhen Liu","Tim Z. Xiao","Katherine M. Collins","Joshua B. Tenenbaum","Adrian Weller","Michael J. Black","Bernhard Schölkopf"],"pdf_url":"https://arxiv.org/pdf/2408.08313v2.pdf","comment":"Technical Report v2 (46 pages, 24 figures, project page:\n  https://sgp-bench.github.io/, substantial update from v1)"},{"id":"http://arxiv.org/abs/2410.04833v1","updated":"2024-10-07T08:40:29Z","published":"2024-10-07T08:40:29Z","title":"Multimodal Fusion Strategies for Mapping Biophysical Landscape Features","summary":"  Multimodal aerial data are used to monitor natural systems, and machine\nlearning can significantly accelerate the classification of landscape features\nwithin such imagery to benefit ecology and conservation. It remains\nunder-explored, however, how these multiple modalities ought to be fused in a\ndeep learning model. As a step towards filling this gap, we study three\nstrategies (Early fusion, Late fusion, and Mixture of Experts) for fusing\nthermal, RGB, and LiDAR imagery using a dataset of spatially-aligned\northomosaics in these three modalities. In particular, we aim to map three\necologically-relevant biophysical landscape features in African savanna\necosystems: rhino middens, termite mounds, and water. The three fusion\nstrategies differ in whether the modalities are fused early or late, and if\nlate, whether the model learns fixed weights per modality for each class or\ngenerates weights for each class adaptively, based on the input. Overall, the\nthree methods have similar macro-averaged performance with Late fusion\nachieving an AUC of 0.698, but their per-class performance varies strongly,\nwith Early fusion achieving the best recall for middens and water and Mixture\nof Experts achieving the best recall for mounds.\n","authors":["Lucia Gordon","Nico Lang","Catherine Ressijac","Andrew Davies"],"pdf_url":"https://arxiv.org/pdf/2410.04833v1.pdf","comment":"9 pages, 4 figures, ECCV 2024 Workshop in CV for Ecology"},{"id":"http://arxiv.org/abs/2405.07027v2","updated":"2024-10-07T08:28:43Z","published":"2024-05-11T14:57:42Z","title":"TD-NeRF: Novel Truncated Depth Prior for Joint Camera Pose and Neural\n  Radiance Field Optimization","summary":"  The reliance on accurate camera poses is a significant barrier to the\nwidespread deployment of Neural Radiance Fields (NeRF) models for 3D\nreconstruction and SLAM tasks. The existing method introduces monocular depth\npriors to jointly optimize the camera poses and NeRF, which fails to fully\nexploit the depth priors and neglects the impact of their inherent noise. In\nthis paper, we propose Truncated Depth NeRF (TD-NeRF), a novel approach that\nenables training NeRF from unknown camera poses - by jointly optimizing\nlearnable parameters of the radiance field and camera poses. Our approach\nexplicitly utilizes monocular depth priors through three key advancements: 1)\nwe propose a novel depth-based ray sampling strategy based on the truncated\nnormal distribution, which improves the convergence speed and accuracy of pose\nestimation; 2) to circumvent local minima and refine depth geometry, we\nintroduce a coarse-to-fine training strategy that progressively improves the\ndepth precision; 3) we propose a more robust inter-frame point constraint that\nenhances robustness against depth noise during training. The experimental\nresults on three datasets demonstrate that TD-NeRF achieves superior\nperformance in the joint optimization of camera pose and NeRF, surpassing prior\nworks, and generates more accurate depth geometry. The implementation of our\nmethod has been released at https://github.com/nubot-nudt/TD-NeRF.\n","authors":["Zhen Tan","Zongtan Zhou","Yangbing Ge","Zi Wang","Xieyuanli Chen","Dewen Hu"],"pdf_url":"https://arxiv.org/pdf/2405.07027v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.03961v2","updated":"2024-10-07T08:23:50Z","published":"2024-06-06T11:13:44Z","title":"Exploring Distortion Prior with Latent Diffusion Models for Remote\n  Sensing Image Compression","summary":"  Deep learning-based image compression algorithms typically focus on designing\nencoding and decoding networks and improving the accuracy of entropy model\nestimation to enhance the rate-distortion (RD) performance. However, few\nalgorithms leverage the compression distortion prior from existing compression\nalgorithms to improve RD performance. In this paper, we propose a latent\ndiffusion model-based remote sensing image compression (LDM-RSIC) method, which\naims to enhance the final decoding quality of RS images by utilizing the\ngenerated distortion prior from a LDM. Our approach consists of two stages. In\nthe first stage, a self-encoder learns prior from the high-quality input image.\nIn the second stage, the prior is generated through an LDM, conditioned on the\ndecoded image of an existing learning-based image compression algorithm, to be\nused as auxiliary information for generating the texture-rich enhanced image.\nTo better utilize the prior, a channel attention and gate-based dynamic feature\nattention module (DFAM) is embedded into a Transformer-based multi-scale\nenhancement network (MEN) for image enhancement. Extensive experiments\ndemonstrate the proposed LDM-RSIC significantly outperforms existing\nstate-of-the-art traditional and learning-based image compression algorithms in\nterms of both subjective perception and objective metrics. Additionally, we use\nthe LDM-based scheme to improve the traditional image compression algorithm\nJPEG2000 and obtain 32.00% bit savings on the DOTA testing set. The code will\nbe available at https://github.com/mlkk518/LDM-RSIC.\n","authors":["Junhui Li","Jutao Li","Xingsong Hou","Huake Wang"],"pdf_url":"https://arxiv.org/pdf/2406.03961v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.07389v2","updated":"2024-10-07T08:20:03Z","published":"2024-07-10T06:28:25Z","title":"Greit-HRNet: Grouped Lightweight High-Resolution Network for Human Pose\n  Estimation","summary":"  As multi-scale features are necessary for human pose estimation tasks,\nhigh-resolution networks are widely applied.\n  To improve efficiency, lightweight modules are proposed to replace costly\npoint-wise convolutions in high-resolution networks, including channel\nweighting and spatial weighting methods.\n  However, they fail to maintain the consistency of weights and capture global\nspatial information.\n  To address these problems, we present a Grouped lightweight High-Resolution\nNetwork (Greit-HRNet), in which we propose a Greit block including a group\nmethod Grouped Channel Weighting (GCW) and a spatial weighting method Global\nSpatial Weighting (GSW).\n  GCW modules group conditional channel weighting to make weights stable and\nmaintain the high-resolution features with the deepening of the network, while\nGSW modules effectively extract global spatial information and exchange\ninformation across channels.\n  In addition, we apply the Large Kernel Attention (LKA) method to improve the\nwhole efficiency of our Greit-HRNet.\n  Our experiments on both MS-COCO and MPII human pose estimation datasets\ndemonstrate the superior performance of our Greit-HRNet, outperforming other\nstate-of-the-art lightweight networks.\n","authors":["Junjia Han"],"pdf_url":"https://arxiv.org/pdf/2407.07389v2.pdf","comment":"16 pages, 4 figures"},{"id":"http://arxiv.org/abs/2410.04823v1","updated":"2024-10-07T08:14:17Z","published":"2024-10-07T08:14:17Z","title":"CAT: Concept-level backdoor ATtacks for Concept Bottleneck Models","summary":"  Despite the transformative impact of deep learning across multiple domains,\nthe inherent opacity of these models has driven the development of Explainable\nArtificial Intelligence (XAI). Among these efforts, Concept Bottleneck Models\n(CBMs) have emerged as a key approach to improve interpretability by leveraging\nhigh-level semantic information. However, CBMs, like other machine learning\nmodels, are susceptible to security threats, particularly backdoor attacks,\nwhich can covertly manipulate model behaviors. Understanding that the community\nhas not yet studied the concept level backdoor attack of CBM, because of\n\"Better the devil you know than the devil you don't know.\", we introduce CAT\n(Concept-level Backdoor ATtacks), a methodology that leverages the conceptual\nrepresentations within CBMs to embed triggers during training, enabling\ncontrolled manipulation of model predictions at inference time. An enhanced\nattack pattern, CAT+, incorporates a correlation function to systematically\nselect the most effective and stealthy concept triggers, thereby optimizing the\nattack's impact. Our comprehensive evaluation framework assesses both the\nattack success rate and stealthiness, demonstrating that CAT and CAT+ maintain\nhigh performance on clean data while achieving significant targeted effects on\nbackdoored datasets. This work underscores the potential security risks\nassociated with CBMs and provides a robust testing methodology for future\nsecurity assessments.\n","authors":["Songning Lai","Jiayu Yang","Yu Huang","Lijie Hu","Tianlang Xue","Zhangyi Hu","Jiaxu Li","Haicheng Liao","Yutao Yue"],"pdf_url":"https://arxiv.org/pdf/2410.04823v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04817v1","updated":"2024-10-07T08:06:41Z","published":"2024-10-07T08:06:41Z","title":"Resource-Efficient Multiview Perception: Integrating Semantic Masking\n  with Masked Autoencoders","summary":"  Multiview systems have become a key technology in modern computer vision,\noffering advanced capabilities in scene understanding and analysis. However,\nthese systems face critical challenges in bandwidth limitations and\ncomputational constraints, particularly for resource-limited camera nodes like\ndrones. This paper presents a novel approach for communication-efficient\ndistributed multiview detection and tracking using masked autoencoders (MAEs).\nWe introduce a semantic-guided masking strategy that leverages pre-trained\nsegmentation models and a tunable power function to prioritize informative\nimage regions. This approach, combined with an MAE, reduces communication\noverhead while preserving essential visual information. We evaluate our method\non both virtual and real-world multiview datasets, demonstrating comparable\nperformance in terms of detection and tracking performance metrics compared to\nstate-of-the-art techniques, even at high masking ratios. Our selective masking\nalgorithm outperforms random masking, maintaining higher accuracy and precision\nas the masking ratio increases. Furthermore, our approach achieves a\nsignificant reduction in transmission data volume compared to baseline methods,\nthereby balancing multiview tracking performance with communication efficiency.\n","authors":["Kosta Dakic","Kanchana Thilakarathna","Rodrigo N. Calheiros","Teng Joon Lim"],"pdf_url":"https://arxiv.org/pdf/2410.04817v1.pdf","comment":"10 pages, conference"},{"id":"http://arxiv.org/abs/2404.12372v2","updated":"2024-10-07T08:06:13Z","published":"2024-04-18T17:53:19Z","title":"MedThink: Explaining Medical Visual Question Answering via Multimodal\n  Decision-Making Rationale","summary":"  Medical Visual Question Answering (MedVQA), which offers language responses\nto image-based medical inquiries, represents a challenging task and significant\nadvancement in healthcare. It assists medical experts to swiftly interpret\nmedical images, thereby enabling faster and more accurate diagnoses. However,\nthe model interpretability and transparency of existing MedVQA solutions are\noften limited, posing challenges in understanding their decision-making\nprocesses. To address this issue, we devise a semi-automated annotation process\nto streamline data preparation and build new benchmark MedVQA datasets R-RAD,\nR-SLAKE and R-Path. These datasets provide intermediate medical decision-making\nrationales generated by multimodal large language models and human annotations\nfor question-answering pairs in existing MedVQA datasets, i.e., VQA-RAD, SLAKE\nand PathVQA. Moreover, we design a novel framework, MedThink, which finetunes\nlightweight pretrained generative models by incorporating medical\ndecision-making rationales. MedThink includes three distinct strategies to\ngenerate decision outcomes and corresponding rationales, thereby clearly\nshowcasing the medical decision-making process during reasoning. Our\ncomprehensive experiments show that our method achieves an accuracy of 83.5% on\nR-RAD, 86.3% on R-SLAKE and 87.2% on R-Path. These results significantly exceed\nthose of existing state-of-the-art models with comparable parameters. Datasets\nand code will be released.\n","authors":["Xiaotang Gai","Chenyi Zhou","Jiaxiang Liu","Yang Feng","Jian Wu","Zuozhu Liu"],"pdf_url":"https://arxiv.org/pdf/2404.12372v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.19215v2","updated":"2024-10-07T07:47:45Z","published":"2024-09-28T02:51:59Z","title":"1st Place Solution to the 8th HANDS Workshop Challenge -- ARCTIC Track:\n  3DGS-based Bimanual Category-agnostic Interaction Reconstruction","summary":"  This report describes our 1st place solution to the 8th HANDS workshop\nchallenge (ARCTIC track) in conjunction with ECCV 2024. In this challenge, we\naddress the task of bimanual category-agnostic hand-object interaction\nreconstruction, which aims to generate 3D reconstructions of both hands and the\nobject from a monocular video, without relying on predefined templates. This\ntask is particularly challenging due to the significant occlusion and dynamic\ncontact between the hands and the object during bimanual manipulation. We\nworked to resolve these issues by introducing a mask loss and a 3D contact\nloss, respectively. Moreover, we applied 3D Gaussian Splatting (3DGS) to this\ntask. As a result, our method achieved a value of 38.69 in the main metric,\nCD$_h$, on the ARCTIC test set.\n","authors":["Jeongwan On","Kyeonghwan Gwak","Gunyoung Kang","Hyein Hwang","Soohyun Hwang","Junuk Cha","Jaewook Han","Seungryul Baek"],"pdf_url":"https://arxiv.org/pdf/2409.19215v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04811v1","updated":"2024-10-07T07:46:08Z","published":"2024-10-07T07:46:08Z","title":"Learning Efficient and Effective Trajectories for Differential\n  Equation-based Image Restoration","summary":"  The differential equation-based image restoration approach aims to establish\nlearnable trajectories connecting high-quality images to a tractable\ndistribution, e.g., low-quality images or a Gaussian distribution. In this\npaper, we reformulate the trajectory optimization of this kind of method,\nfocusing on enhancing both reconstruction quality and efficiency. Initially, we\nnavigate effective restoration paths through a reinforcement learning process,\ngradually steering potential trajectories toward the most precise options.\nAdditionally, to mitigate the considerable computational burden associated with\niterative sampling, we propose cost-aware trajectory distillation to streamline\ncomplex paths into several manageable steps with adaptable sizes. Moreover, we\nfine-tune a foundational diffusion model (FLUX) with 12B parameters by using\nour algorithms, producing a unified framework for handling 7 kinds of image\nrestoration tasks. Extensive experiments showcase the significant superiority\nof the proposed method, achieving a maximum PSNR improvement of 2.1 dB over\nstate-of-the-art methods, while also greatly enhancing visual perceptual\nquality. Project page: \\url{https://zhu-zhiyu.github.io/FLUX-IR/}.\n","authors":["Zhiyu Zhu","Jinhui Hou","Hui Liu","Huanqiang Zeng","Junhui Hou"],"pdf_url":"https://arxiv.org/pdf/2410.04811v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.01449v3","updated":"2024-10-07T07:46:00Z","published":"2024-06-27T15:45:29Z","title":"ColPali: Efficient Document Retrieval with Vision Language Models","summary":"  Documents are visually rich structures that convey information through text,\nas well as tables, figures, page layouts, or fonts. While modern document\nretrieval systems exhibit strong performance on query-to-text matching, they\nstruggle to exploit visual cues efficiently, hindering their performance on\npractical document retrieval applications such as Retrieval Augmented\nGeneration. To benchmark current systems on visually rich document retrieval,\nwe introduce the Visual Document Retrieval Benchmark ViDoRe, composed of\nvarious page-level retrieving tasks spanning multiple domains, languages, and\nsettings. The inherent shortcomings of modern systems motivate the introduction\nof a new retrieval model architecture, ColPali, which leverages the document\nunderstanding capabilities of recent Vision Language Models to produce\nhigh-quality contextualized embeddings solely from images of document pages.\nCombined with a late interaction matching mechanism, ColPali largely\noutperforms modern document retrieval pipelines while being drastically faster\nand end-to-end trainable.\n","authors":["Manuel Faysse","Hugues Sibille","Tony Wu","Bilel Omrani","Gautier Viaud","Céline Hudelot","Pierre Colombo"],"pdf_url":"https://arxiv.org/pdf/2407.01449v3.pdf","comment":"Under Review"},{"id":"http://arxiv.org/abs/2410.04810v1","updated":"2024-10-07T07:45:18Z","published":"2024-10-07T07:45:18Z","title":"FedBiP: Heterogeneous One-Shot Federated Learning with Personalized\n  Latent Diffusion Models","summary":"  One-Shot Federated Learning (OSFL), a special decentralized machine learning\nparadigm, has recently gained significant attention. OSFL requires only a\nsingle round of client data or model upload, which reduces communication costs\nand mitigates privacy threats compared to traditional FL. Despite these\npromising prospects, existing methods face challenges due to client data\nheterogeneity and limited data quantity when applied to real-world OSFL\nsystems. Recently, Latent Diffusion Models (LDM) have shown remarkable\nadvancements in synthesizing high-quality images through pretraining on\nlarge-scale datasets, thereby presenting a potential solution to overcome these\nissues. However, directly applying pretrained LDM to heterogeneous OSFL results\nin significant distribution shifts in synthetic data, leading to performance\ndegradation in classification models trained on such data. This issue is\nparticularly pronounced in rare domains, such as medical imaging, which are\nunderrepresented in LDM's pretraining data. To address this challenge, we\npropose Federated Bi-Level Personalization (FedBiP), which personalizes the\npretrained LDM at both instance-level and concept-level. Hereby, FedBiP\nsynthesizes images following the client's local data distribution without\ncompromising the privacy regulations. FedBiP is also the first approach to\nsimultaneously address feature space heterogeneity and client data scarcity in\nOSFL. Our method is validated through extensive experiments on three OSFL\nbenchmarks with feature space heterogeneity, as well as on challenging medical\nand satellite image datasets with label heterogeneity. The results demonstrate\nthe effectiveness of FedBiP, which substantially outperforms other OSFL\nmethods.\n","authors":["Haokun Chen","Hang Li","Yao Zhang","Gengyuan Zhang","Jinhe Bi","Philip Torr","Jindong Gu","Denis Krompass","Volker Tresp"],"pdf_url":"https://arxiv.org/pdf/2410.04810v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.09365v2","updated":"2024-10-07T07:39:40Z","published":"2024-05-15T14:17:44Z","title":"SARatrX: Towards Building A Foundation Model for SAR Target Recognition","summary":"  Despite the remarkable progress in synthetic aperture radar automatic target\nrecognition (SAR ATR), recent efforts have concentrated on the detection or\nclassification of a specific and coarse category, e.g., vehicles, ships,\nairplanes, or buildings. One of the fundamental limitations of the\ntop-performing SAR ATR methods is that the learning paradigm is supervised,\ntask-specific, limited-category, closed-world learning, which depends on\nmassive amounts of accurately annotated samples that are expensively labeled by\nexpert SAR analysts and has limited generalization capability and scalability.\nIn this work, we make the first attempt towards building a foundation model for\nSAR ATR, termed SARatrX. SARatrX learns generalizable representations via\nself-supervised learning (SSL) and provides a basis for label-efficient model\nadaptation to generic SAR target detection and classification tasks.\nSpecifically, SARatrX is trained on 0.18 M unlabelled SAR target samples, which\nare curated by combining contemporary benchmarks and constitute the largest\npublicly available dataset till now. Considering the characteristics of SAR\nimages, a backbone tailored for SAR ATR is carefully designed, and a two-step\nSSL method endowed with multi-scale gradient features was applied to ensure the\nfeature diversity and model scalability of SARatrX. The capabilities of SARatrX\nare evaluated on classification under few-shot and robustness settings and\ndetection across various categories and scenes, and impressive performance is\nachieved, often competitive with or even superior to prior fully supervised,\nsemi-supervised, or self-supervised algorithms. Our SARatrX and the curated\ndataset are released at https://github.com/waterdisappear/SARatrX to foster\nresearch into foundation models for SAR ATR and SAR image interpretation.\n","authors":["Weijie Li","Wei Yang","Yuenan Hou","Li Liu","Yongxiang Liu","Xiang Li"],"pdf_url":"https://arxiv.org/pdf/2405.09365v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04802v1","updated":"2024-10-07T07:26:38Z","published":"2024-10-07T07:26:38Z","title":"Building Damage Assessment in Conflict Zones: A Deep Learning Approach\n  Using Geospatial Sub-Meter Resolution Data","summary":"  Very High Resolution (VHR) geospatial image analysis is crucial for\nhumanitarian assistance in both natural and anthropogenic crises, as it allows\nto rapidly identify the most critical areas that need support. Nonetheless,\nmanually inspecting large areas is time-consuming and requires domain\nexpertise. Thanks to their accuracy, generalization capabilities, and highly\nparallelizable workload, Deep Neural Networks (DNNs) provide an excellent way\nto automate this task. Nevertheless, there is a scarcity of VHR data pertaining\nto conflict situations, and consequently, of studies on the effectiveness of\nDNNs in those scenarios. Motivated by this, our work extensively studies the\napplicability of a collection of state-of-the-art Convolutional Neural Networks\n(CNNs) originally developed for natural disasters damage assessment in a war\nscenario. To this end, we build an annotated dataset with pre- and\npost-conflict images of the Ukrainian city of Mariupol. We then explore the\ntransferability of the CNN models in both zero-shot and learning scenarios,\ndemonstrating their potential and limitations. To the best of our knowledge,\nthis is the first study to use sub-meter resolution imagery to assess building\ndamage in combat zones.\n","authors":["Matteo Risso","Alessia Goffi","Beatrice Alessandra Motetti","Alessio Burrello","Jean Baptiste Bove","Enrico Macii","Massimo Poncino","Daniele Jahier Pagliari","Giuseppe Maffeis"],"pdf_url":"https://arxiv.org/pdf/2410.04802v1.pdf","comment":"This paper has been accepted for publication in the Sixth IEEE\n  International Conference on Image Processing Applications and Systems 2024\n  copyright IEEE"},{"id":"http://arxiv.org/abs/2410.04801v1","updated":"2024-10-07T07:26:10Z","published":"2024-10-07T07:26:10Z","title":"Improving Image Clustering with Artifacts Attenuation via Inference-Time\n  Attention Engineering","summary":"  The goal of this paper is to improve the performance of pretrained Vision\nTransformer (ViT) models, particularly DINOv2, in image clustering task without\nrequiring re-training or fine-tuning. As model size increases, high-norm\nartifacts anomaly appears in the patches of multi-head attention. We observe\nthat this anomaly leads to reduced accuracy in zero-shot image clustering.\nThese artifacts are characterized by disproportionately large values in the\nattention map compared to other patch tokens. To address these artifacts, we\npropose an approach called Inference-Time Attention Engineering (ITAE), which\nmanipulates attention function during inference. Specifically, we identify the\nartifacts by investigating one of the Query-Key-Value (QKV) patches in the\nmulti-head attention and attenuate their corresponding attention values inside\nthe pretrained models. ITAE shows improved clustering accuracy on multiple\ndatasets by exhibiting more expressive features in latent space. Our findings\nhighlight the potential of ITAE as a practical solution for reducing artifacts\nin pretrained ViT models and improving model performance in clustering tasks\nwithout the need for re-training or fine-tuning.\n","authors":["Kazumoto Nakamura","Yuji Nozawa","Yu-Chieh Lin","Kengo Nakata","Youyang Ng"],"pdf_url":"https://arxiv.org/pdf/2410.04801v1.pdf","comment":"Accepted to ACCV 2024"},{"id":"http://arxiv.org/abs/2410.04799v1","updated":"2024-10-07T07:23:42Z","published":"2024-10-07T07:23:42Z","title":"Transforming Color: A Novel Image Colorization Method","summary":"  This paper introduces a novel method for image colorization that utilizes a\ncolor transformer and generative adversarial networks (GANs) to address the\nchallenge of generating visually appealing colorized images. Conventional\napproaches often struggle with capturing long-range dependencies and producing\nrealistic colorizations. The proposed method integrates a transformer\narchitecture to capture global information and a GAN framework to improve\nvisual quality. In this study, a color encoder that utilizes a random normal\ndistribution to generate color features is applied. These features are then\nintegrated with grayscale image features to enhance the overall representation\nof the images. Our method demonstrates superior performance compared with\nexisting approaches by utilizing the capacity of the transformer, which can\ncapture long-range dependencies and generate a realistic colorization of the\nGAN. Experimental results show that the proposed network significantly\noutperforms other state-of-the-art colorization techniques, highlighting its\npotential for image colorization. This research opens new possibilities for\nprecise and visually compelling image colorization in domains such as digital\nrestoration and historical image analysis.\n","authors":["Hamza Shafiq","Bumshik Lee"],"pdf_url":"https://arxiv.org/pdf/2410.04799v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10988v2","updated":"2024-10-07T07:15:19Z","published":"2023-11-18T06:49:17Z","title":"Expanding Scene Graph Boundaries: Fully Open-vocabulary Scene Graph\n  Generation via Visual-Concept Alignment and Retention","summary":"  Scene Graph Generation (SGG) offers a structured representation critical in\nmany computer vision applications. Traditional SGG approaches, however, are\nlimited by a closed-set assumption, restricting their ability to recognize only\npredefined object and relation categories. To overcome this, we categorize SGG\nscenarios into four distinct settings based on the node and edge: Closed-set\nSGG, Open Vocabulary (object) Detection-based SGG (OvD-SGG), Open Vocabulary\nRelation-based SGG (OvR-SGG), and Open Vocabulary Detection + Relationbased SGG\n(OvD+R-SGG). While object-centric open vocabulary SGG has been studied\nrecently, the more challenging problem of relation-involved open-vocabulary SGG\nremains relatively unexplored. To fill this gap, we propose a unified framework\nnamed OvSGTR towards fully open vocabulary SGG from a holistic view. The\nproposed framework is an end-to-end transformer architecture, which learns a\nvisual-concept alignment for both nodes and edges, enabling the model to\nrecognize unseen categories. For the more challenging settings of\nrelation-involved open vocabulary SGG, the proposed approach integrates\nrelation-aware pretraining utilizing image-caption data and retains\nvisual-concept alignment through knowledge distillation. Comprehensive\nexperimental results on the Visual Genome benchmark demonstrate the\neffectiveness and superiority of the proposed framework. Our code is available\nat https://github.com/gpt4vision/OvSGTR/.\n","authors":["Zuyao Chen","Jinlin Wu","Zhen Lei","Zhaoxiang Zhang","Changwen Chen"],"pdf_url":"https://arxiv.org/pdf/2311.10988v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.00036v2","updated":"2024-10-07T07:14:23Z","published":"2023-12-29T18:35:04Z","title":"Discrete Distribution Networks","summary":"  We introduce a novel generative model, the Discrete Distribution Networks\n(DDN), that approximates data distribution using hierarchical discrete\ndistributions. We posit that since the features within a network inherently\ncapture distributional information, enabling the network to generate multiple\nsamples simultaneously, rather than a single output, may offer an effective way\nto represent distributions. Therefore, DDN fits the target distribution,\nincluding continuous ones, by generating multiple discrete sample points. To\ncapture finer details of the target data, DDN selects the output that is\nclosest to the Ground Truth (GT) from the coarse results generated in the first\nlayer. This selected output is then fed back into the network as a condition\nfor the second layer, thereby generating new outputs more similar to the GT. As\nthe number of DDN layers increases, the representational space of the outputs\nexpands exponentially, and the generated samples become increasingly similar to\nthe GT. This hierarchical output pattern of discrete distributions endows DDN\nwith unique property: more general zero-shot conditional generation. We\ndemonstrate the efficacy of DDN and its intriguing properties through\nexperiments on CIFAR-10 and FFHQ. The code is available at\nhttps://discrete-distribution-networks.github.io/\n","authors":["Lei Yang"],"pdf_url":"https://arxiv.org/pdf/2401.00036v2.pdf","comment":"TL;DR: A Novel Generative Model with Simple Principles and Unique\n  Properties"},{"id":"http://arxiv.org/abs/2408.02901v3","updated":"2024-10-07T07:13:24Z","published":"2024-08-06T02:15:12Z","title":"Lighthouse: A User-Friendly Library for Reproducible Video Moment\n  Retrieval and Highlight Detection","summary":"  We propose Lighthouse, a user-friendly library for reproducible video moment\nretrieval and highlight detection (MR-HD). Although researchers proposed\nvarious MR-HD approaches, the research community holds two main issues. The\nfirst is a lack of comprehensive and reproducible experiments across various\nmethods, datasets, and video-text features. This is because no unified training\nand evaluation codebase covers multiple settings. The second is user-unfriendly\ndesign. Because previous works use different libraries, researchers set up\nindividual environments. In addition, most works release only the training\ncodes, requiring users to implement the whole inference process of MR-HD.\nLighthouse addresses these issues by implementing a unified reproducible\ncodebase that includes six models, three features, and five datasets. In\naddition, it provides an inference API and web demo to make these methods\neasily accessible for researchers and developers. Our experiments demonstrate\nthat Lighthouse generally reproduces the reported scores in the reference\npapers. The code is available at https://github.com/line/lighthouse.\n","authors":["Taichi Nishimura","Shota Nakada","Hokuto Munakata","Tatsuya Komatsu"],"pdf_url":"https://arxiv.org/pdf/2408.02901v3.pdf","comment":"accepted at EMNLP2024 - system demonstration track"},{"id":"http://arxiv.org/abs/2410.04789v1","updated":"2024-10-07T06:57:23Z","published":"2024-10-07T06:57:23Z","title":"Analysis of Hybrid Compositions in Animation Film with Weakly Supervised\n  Learning","summary":"  We present an approach for the analysis of hybrid visual compositions in\nanimation in the domain of ephemeral film. We combine ideas from\nsemi-supervised and weakly supervised learning to train a model that can\nsegment hybrid compositions without requiring pre-labeled segmentation masks.\nWe evaluate our approach on a set of ephemeral films from 13 film archives.\nResults demonstrate that the proposed learning strategy yields a performance\nclose to a fully supervised baseline. On a qualitative level the performed\nanalysis provides interesting insights on hybrid compositions in animation\nfilm.\n","authors":["Mónica Apellaniz Portos","Roberto Labadie-Tamayo","Claudius Stemmler","Erwin Feyersinger","Andreas Babic","Franziska Bruckner","Vrääth Öhner","Matthias Zeppelzauer"],"pdf_url":"https://arxiv.org/pdf/2410.04789v1.pdf","comment":"Vision for Art (VISART VII) Workshop at the European Conference of\n  Computer Vision (ECCV)"},{"id":"http://arxiv.org/abs/2410.04780v1","updated":"2024-10-07T06:45:22Z","published":"2024-10-07T06:45:22Z","title":"Mitigating Modality Prior-Induced Hallucinations in Multimodal Large\n  Language Models via Deciphering Attention Causality","summary":"  Multimodal Large Language Models (MLLMs) have emerged as a central focus in\nboth industry and academia, but often suffer from biases introduced by visual\nand language priors, which can lead to multimodal hallucination. These biases\narise from the visual encoder and the Large Language Model (LLM) backbone,\naffecting the attention mechanism responsible for aligning multimodal inputs.\nExisting decoding-based mitigation methods focus on statistical correlations\nand overlook the causal relationships between attention mechanisms and model\noutput, limiting their effectiveness in addressing these biases. To tackle this\nissue, we propose a causal inference framework termed CausalMM that applies\nstructural causal modeling to MLLMs, treating modality priors as a confounder\nbetween attention mechanisms and output. Specifically, by employing backdoor\nadjustment and counterfactual reasoning at both the visual and language\nattention levels, our method mitigates the negative effects of modality priors\nand enhances the alignment of MLLM's inputs and outputs, with a maximum score\nimprovement of 65.3% on 6 VLind-Bench indicators and 164 points on MME\nBenchmark compared to conventional methods. Extensive experiments validate the\neffectiveness of our approach while being a plug-and-play solution. Our code is\navailable at: https://github.com/The-Martyr/CausalMM\n","authors":["Guanyu Zhou","Yibo Yan","Xin Zou","Kun Wang","Aiwei Liu","Xuming Hu"],"pdf_url":"https://arxiv.org/pdf/2410.04780v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04778v1","updated":"2024-10-07T06:36:55Z","published":"2024-10-07T06:36:55Z","title":"MM-R$^3$: On (In-)Consistency of Multi-modal Large Language Models\n  (MLLMs)","summary":"  With the advent of Large Language Models (LLMs) and Multimodal\n(Visio-lingual) LLMs, a flurry of research has emerged, analyzing the\nperformance of such models across a diverse array of tasks. While most studies\nfocus on evaluating the capabilities of state-of-the-art (SoTA) MLLM models\nthrough task accuracy (e.g., Visual Question Answering, grounding) across\nvarious datasets, our work explores the related but complementary aspect of\nconsistency - the ability of an MLLM model to produce semantically similar or\nidentical responses to semantically similar queries. We note that consistency\nis a fundamental prerequisite (necessary but not sufficient condition) for\nrobustness and trust in MLLMs. Humans, in particular, are known to be highly\nconsistent (even if not always accurate) in their responses, and consistency is\ninherently expected from AI systems. Armed with this perspective, we propose\nthe MM-R$^3$ benchmark, which analyses the performance in terms of consistency\nand accuracy in SoTA MLLMs with three tasks: Question Rephrasing, Image\nRestyling, and Context Reasoning. Our analysis reveals that consistency does\nnot always align with accuracy, indicating that models with higher accuracy are\nnot necessarily more consistent, and vice versa. Furthermore, we propose a\nsimple yet effective mitigation strategy in the form of an adapter module\ntrained to minimize inconsistency across prompts. With our proposed strategy,\nwe are able to achieve absolute improvements of 5.7% and 12.5%, on average on\nwidely used MLLMs such as BLIP-2 and LLaVa 1.5M in terms of consistency over\ntheir existing counterparts.\n","authors":["Shih-Han Chou","Shivam Chandhok","James J. Little","Leonid Sigal"],"pdf_url":"https://arxiv.org/pdf/2410.04778v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.17996v2","updated":"2024-10-07T06:23:51Z","published":"2024-09-26T16:07:24Z","title":"PhoCoLens: Photorealistic and Consistent Reconstruction in Lensless\n  Imaging","summary":"  Lensless cameras offer significant advantages in size, weight, and cost\ncompared to traditional lens-based systems. Without a focusing lens, lensless\ncameras rely on computational algorithms to recover the scenes from multiplexed\nmeasurements. However, current algorithms struggle with inaccurate forward\nimaging models and insufficient priors to reconstruct high-quality images. To\novercome these limitations, we introduce a novel two-stage approach for\nconsistent and photorealistic lensless image reconstruction. The first stage of\nour approach ensures data consistency by focusing on accurately reconstructing\nthe low-frequency content with a spatially varying deconvolution method that\nadjusts to changes in the Point Spread Function (PSF) across the camera's field\nof view. The second stage enhances photorealism by incorporating a generative\nprior from pre-trained diffusion models. By conditioning on the low-frequency\ncontent retrieved in the first stage, the diffusion model effectively\nreconstructs the high-frequency details that are typically lost in the lensless\nimaging process, while also maintaining image fidelity. Our method achieves a\nsuperior balance between data fidelity and visual quality compared to existing\nmethods, as demonstrated with two popular lensless systems, PhlatCam and\nDiffuserCam. Project website: https://phocolens.github.io/.\n","authors":["Xin Cai","Zhiyuan You","Hailong Zhang","Wentao Liu","Jinwei Gu","Tianfan Xue"],"pdf_url":"https://arxiv.org/pdf/2409.17996v2.pdf","comment":"NeurIPS 2024 Spotlight"},{"id":"http://arxiv.org/abs/2404.13026v2","updated":"2024-10-07T06:08:09Z","published":"2024-04-19T17:41:05Z","title":"PhysDreamer: Physics-Based Interaction with 3D Objects via Video\n  Generation","summary":"  Realistic object interactions are crucial for creating immersive virtual\nexperiences, yet synthesizing realistic 3D object dynamics in response to novel\ninteractions remains a significant challenge. Unlike unconditional or\ntext-conditioned dynamics generation, action-conditioned dynamics requires\nperceiving the physical material properties of objects and grounding the 3D\nmotion prediction on these properties, such as object stiffness. However,\nestimating physical material properties is an open problem due to the lack of\nmaterial ground-truth data, as measuring these properties for real objects is\nhighly difficult. We present PhysDreamer, a physics-based approach that endows\nstatic 3D objects with interactive dynamics by leveraging the object dynamics\npriors learned by video generation models. By distilling these priors,\nPhysDreamer enables the synthesis of realistic object responses to novel\ninteractions, such as external forces or agent manipulations. We demonstrate\nour approach on diverse examples of elastic objects and evaluate the realism of\nthe synthesized interactions through a user study. PhysDreamer takes a step\ntowards more engaging and realistic virtual experiences by enabling static 3D\nobjects to dynamically respond to interactive stimuli in a physically plausible\nmanner. See our project page at https://physdreamer.github.io/.\n","authors":["Tianyuan Zhang","Hong-Xing Yu","Rundi Wu","Brandon Y. Feng","Changxi Zheng","Noah Snavely","Jiajun Wu","William T. Freeman"],"pdf_url":"https://arxiv.org/pdf/2404.13026v2.pdf","comment":"Project website at: https://physdreamer.github.io/ Appear on ECCV\n  2024"},{"id":"http://arxiv.org/abs/2410.04762v1","updated":"2024-10-07T05:36:11Z","published":"2024-10-07T05:36:11Z","title":"WTCL-Dehaze: Rethinking Real-world Image Dehazing via Wavelet Transform\n  and Contrastive Learning","summary":"  Images captured in hazy outdoor conditions often suffer from colour\ndistortion, low contrast, and loss of detail, which impair high-level vision\ntasks. Single image dehazing is essential for applications such as autonomous\ndriving and surveillance, with the aim of restoring image clarity. In this\nwork, we propose WTCL-Dehaze an enhanced semi-supervised dehazing network that\nintegrates Contrastive Loss and Discrete Wavelet Transform (DWT). We\nincorporate contrastive regularization to enhance feature representation by\ncontrasting hazy and clear image pairs. Additionally, we utilize DWT for\nmulti-scale feature extraction, effectively capturing high-frequency details\nand global structures. Our approach leverages both labelled and unlabelled data\nto mitigate the domain gap and improve generalization. The model is trained on\na combination of synthetic and real-world datasets, ensuring robust performance\nacross different scenarios. Extensive experiments demonstrate that our proposed\nalgorithm achieves superior performance and improved robustness compared to\nstate-of-the-art single image dehazing methods on both benchmark datasets and\nreal-world images.\n","authors":["Divine Joseph Appiah","Donghai Guan","Abdul Nasser Kasule","Mingqiang Wei"],"pdf_url":"https://arxiv.org/pdf/2410.04762v1.pdf","comment":"15 pages,4 figures"},{"id":"http://arxiv.org/abs/2410.04751v1","updated":"2024-10-07T05:07:01Z","published":"2024-10-07T05:07:01Z","title":"Intriguing Properties of Large Language and Vision Models","summary":"  Recently, large language and vision models (LLVMs) have received significant\nattention and development efforts due to their remarkable generalization\nperformance across a wide range of tasks requiring perception and cognitive\nabilities. A key factor behind their success is their simple architecture,\nwhich consists of a vision encoder, a projector, and a large language model\n(LLM). Despite their achievements in advanced reasoning tasks, their\nperformance on fundamental perception-related tasks (e.g., MMVP) remains\nsurprisingly low. This discrepancy raises the question of how LLVMs truly\nperceive images and exploit the advantages of the vision encoder. To address\nthis, we systematically investigate this question regarding several aspects:\npermutation invariance, robustness, math reasoning, alignment preserving and\nimportance, by evaluating the most common LLVM's families (i.e., LLaVA) across\n10 evaluation benchmarks. Our extensive experiments reveal several intriguing\nproperties of current LLVMs: (1) they internally process the image in a global\nmanner, even when the order of visual patch sequences is randomly permuted; (2)\nthey are sometimes able to solve math problems without fully perceiving\ndetailed numerical information; (3) the cross-modal alignment is overfitted to\ncomplex reasoning tasks, thereby, causing them to lose some of the original\nperceptual capabilities of their vision encoder; (4) the representation space\nin the lower layers (<25%) plays a crucial role in determining performance and\nenhancing visual understanding. Lastly, based on the above observations, we\nsuggest potential future directions for building better LLVMs and constructing\nmore challenging evaluation benchmarks.\n","authors":["Young-Jun Lee","Byungsoo Ko","Han-Gyu Kim","Yechan Hwang","Ho-Jin Choi"],"pdf_url":"https://arxiv.org/pdf/2410.04751v1.pdf","comment":"Code is available in https://github.com/passing2961/IP-LLVM"},{"id":"http://arxiv.org/abs/2410.04749v1","updated":"2024-10-07T04:59:08Z","published":"2024-10-07T04:59:08Z","title":"LLaVA Needs More Knowledge: Retrieval Augmented Natural Language\n  Generation with Knowledge Graph for Explaining Thoracic Pathologies","summary":"  Generating Natural Language Explanations (NLEs) for model predictions on\nmedical images, particularly those depicting thoracic pathologies, remains a\ncritical and challenging task. Existing methodologies often struggle due to\ngeneral models' insufficient domain-specific medical knowledge and privacy\nconcerns associated with retrieval-based augmentation techniques. To address\nthese issues, we propose a novel Vision-Language framework augmented with a\nKnowledge Graph (KG)-based datastore, which enhances the model's understanding\nby incorporating additional domain-specific medical knowledge essential for\ngenerating accurate and informative NLEs. Our framework employs a KG-based\nretrieval mechanism that not only improves the precision of the generated\nexplanations but also preserves data privacy by avoiding direct data retrieval.\nThe KG datastore is designed as a plug-and-play module, allowing for seamless\nintegration with various model architectures. We introduce and evaluate three\ndistinct frameworks within this paradigm: KG-LLaVA, which integrates the\npre-trained LLaVA model with KG-RAG; Med-XPT, a custom framework combining\nMedCLIP, a transformer-based projector, and GPT-2; and Bio-LLaVA, which adapts\nLLaVA by incorporating the Bio-ViT-L vision model. These frameworks are\nvalidated on the MIMIC-NLE dataset, where they achieve state-of-the-art\nresults, underscoring the effectiveness of KG augmentation in generating\nhigh-quality NLEs for thoracic pathologies.\n","authors":["Ameer Hamza"," Abdullah","Yong Hyun Ahn","Sungyoung Lee","Seong Tae Kim"],"pdf_url":"https://arxiv.org/pdf/2410.04749v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.07972v2","updated":"2024-10-07T04:17:01Z","published":"2024-09-12T12:12:19Z","title":"Deep Height Decoupling for Precise Vision-based 3D Occupancy Prediction","summary":"  The task of vision-based 3D occupancy prediction aims to reconstruct 3D\ngeometry and estimate its semantic classes from 2D color images, where the\n2D-to-3D view transformation is an indispensable step. Most previous methods\nconduct forward projection, such as BEVPooling and VoxelPooling, both of which\nmap the 2D image features into 3D grids. However, the current grid representing\nfeatures within a certain height range usually introduces many confusing\nfeatures that belong to other height ranges. To address this challenge, we\npresent Deep Height Decoupling (DHD), a novel framework that incorporates\nexplicit height prior to filter out the confusing features. Specifically, DHD\nfirst predicts height maps via explicit supervision. Based on the height\ndistribution statistics, DHD designs Mask Guided Height Sampling (MGHS) to\nadaptively decouple the height map into multiple binary masks. MGHS projects\nthe 2D image features into multiple subspaces, where each grid contains\nfeatures within reasonable height ranges. Finally, a Synergistic Feature\nAggregation (SFA) module is deployed to enhance the feature representation\nthrough channel and spatial affinities, enabling further occupancy refinement.\nOn the popular Occ3D-nuScenes benchmark, our method achieves state-of-the-art\nperformance even with minimal input frames. Code is available at\nhttps://github.com/yanzq95/DHD.\n","authors":["Yuan Wu","Zhiqiang Yan","Zhengxue Wang","Xiang Li","Le Hui","Jian Yang"],"pdf_url":"https://arxiv.org/pdf/2409.07972v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04738v1","updated":"2024-10-07T04:12:23Z","published":"2024-10-07T04:12:23Z","title":"Diffusion Models in 3D Vision: A Survey","summary":"  In recent years, 3D vision has become a crucial field within computer vision,\npowering a wide range of applications such as autonomous driving, robotics,\naugmented reality (AR), and medical imaging. This field relies on the accurate\nperception, understanding, and reconstruction of 3D scenes from 2D data sources\nlike images and videos. Diffusion models, originally designed for 2D generative\ntasks, offer the potential for more flexible, probabilistic approaches that can\nbetter capture the variability and uncertainty present in real-world 3D data.\nHowever, traditional methods often struggle with efficiency and scalability. In\nthis paper, we review the state-of-the-art approaches that leverage diffusion\nmodels for 3D visual tasks, including but not limited to 3D object generation,\nshape completion, point cloud reconstruction, and scene understanding. We\nprovide an in-depth discussion of the underlying mathematical principles of\ndiffusion models, outlining their forward and reverse processes, as well as the\nvarious architectural advancements that enable these models to work with 3D\ndatasets. We also discuss the key challenges in applying diffusion models to 3D\nvision, such as handling occlusions and varying point densities, and the\ncomputational demands of high-dimensional data. Finally, we discuss potential\nsolutions, including improving computational efficiency, enhancing multimodal\nfusion, and exploring the use of large-scale pretraining for better\ngeneralization across 3D tasks. This paper serves as a foundation for future\nexploration and development in this rapidly evolving field.\n","authors":["Zhen Wang","Dongyuan Li","Renhe Jiang"],"pdf_url":"https://arxiv.org/pdf/2410.04738v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04734v1","updated":"2024-10-07T04:00:22Z","published":"2024-10-07T04:00:22Z","title":"TLDR: Token-Level Detective Reward Model for Large Vision Language\n  Models","summary":"  Although reward models have been successful in improving multimodal large\nlanguage models, the reward models themselves remain brutal and contain minimal\ninformation. Notably, existing reward models only mimic human annotations by\nassigning only one binary feedback to any text, no matter how long the text is.\nIn the realm of multimodal language models, where models are required to\nprocess both images and texts, a naive reward model may learn implicit biases\ntoward texts and become less grounded in images. In this paper, we propose a\n$\\textbf{T}$oken-$\\textbf{L}$evel $\\textbf{D}$etective $\\textbf{R}$eward Model\n($\\textbf{TLDR}$) to provide fine-grained annotations to each text token. We\nfirst introduce a perturbation-based method to generate synthetic hard\nnegatives and their token-level labels to train TLDR models. Then we show the\nrich usefulness of TLDR models both in assisting off-the-shelf models to\nself-correct their generations, and in serving as a hallucination evaluation\ntool. Finally, we show that TLDR models can significantly speed up human\nannotation by 3 times to acquire a broader range of high-quality vision\nlanguage data.\n","authors":["Deqing Fu","Tong Xiao","Rui Wang","Wang Zhu","Pengchuan Zhang","Guan Pang","Robin Jia","Lawrence Chen"],"pdf_url":"https://arxiv.org/pdf/2410.04734v1.pdf","comment":"Work done at Meta"},{"id":"http://arxiv.org/abs/2312.06038v2","updated":"2024-10-07T03:59:27Z","published":"2023-12-10T23:35:13Z","title":"Correcting Diffusion Generation through Resampling","summary":"  Despite diffusion models' superior capabilities in modeling complex\ndistributions, there are still non-trivial distributional discrepancies between\ngenerated and ground-truth images, which has resulted in several notable\nproblems in image generation, including missing object errors in text-to-image\ngeneration and low image quality. Existing methods that attempt to address\nthese problems mostly do not tend to address the fundamental cause behind these\nproblems, which is the distributional discrepancies, and hence achieve\nsub-optimal results. In this paper, we propose a particle filtering framework\nthat can effectively address both problems by explicitly reducing the\ndistributional discrepancies. Specifically, our method relies on a set of\nexternal guidance, including a small set of real images and a pre-trained\nobject detector, to gauge the distribution gap, and then design the resampling\nweight accordingly to correct the gap. Experiments show that our methods can\neffectively correct missing object errors and improve image quality in various\nimage generation tasks. Notably, our method outperforms the existing strongest\nbaseline by 5% in object occurrence and 1.0 in FID on MS-COCO. Our code is\npublicly available at\nhttps://github.com/UCSB-NLP-Chang/diffusion_resampling.git.\n","authors":["Yujian Liu","Yang Zhang","Tommi Jaakkola","Shiyu Chang"],"pdf_url":"https://arxiv.org/pdf/2312.06038v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.03141v2","updated":"2024-10-07T03:53:15Z","published":"2024-10-04T04:37:29Z","title":"Machine Learning for Asymptomatic Ratoon Stunting Disease Detection With\n  Freely Available Satellite Based Multispectral Imaging","summary":"  Disease detection in sugarcane, particularly the identification of\nasymptomatic infectious diseases such as Ratoon Stunting Disease (RSD), is\ncritical for effective crop management. This study employed various machine\nlearning techniques to detect the presence of RSD in different sugarcane\nvarieties, using vegetation indices derived from freely available\nsatellite-based spectral data. Our results show that the Support Vector Machine\nwith a Radial Basis Function Kernel (SVM-RBF) was the most effective algorithm,\nachieving classification accuracy between 85.64% and 96.55%, depending on the\nvariety. Gradient Boosting and Random Forest also demonstrated high performance\nachieving accuracy between 83.33% to 96.55%, while Logistic Regression and\nQuadratic Discriminant Analysis showed variable results across different\nvarieties. The inclusion of sugarcane variety and vegetation indices was\nimportant in the detection of RSD. This agreed with what was identified in the\ncurrent literature. Our study highlights the potential of satellite-based\nremote sensing as a cost-effective and efficient method for large-scale\nsugarcane disease detection alternative to traditional manual laboratory\ntesting methods.\n","authors":["Ethan Kane Waters","Carla Chia-ming Chen","Mostafa Rahimi Azghadi"],"pdf_url":"https://arxiv.org/pdf/2410.03141v2.pdf","comment":"13 pages, 1 figure and 3 tables (main text), 1 figure and 2 tables\n  (appendices). Submitted to \"Computers and Electronics in Agriculture\""},{"id":"http://arxiv.org/abs/2410.04733v1","updated":"2024-10-07T03:52:06Z","published":"2024-10-07T03:52:06Z","title":"PredFormer: Transformers Are Effective Spatial-Temporal Predictive\n  Learners","summary":"  Spatiotemporal predictive learning methods generally fall into two\ncategories: recurrent-based approaches, which face challenges in\nparallelization and performance, and recurrent-free methods, which employ\nconvolutional neural networks (CNNs) as encoder-decoder architectures. These\nmethods benefit from strong inductive biases but often at the expense of\nscalability and generalization. This paper proposes PredFormer, a pure\ntransformer-based framework for spatiotemporal predictive learning. Motivated\nby the Vision Transformers (ViT) design, PredFormer leverages carefully\ndesigned Gated Transformer blocks, following a comprehensive analysis of 3D\nattention mechanisms, including full-, factorized-, and interleaved-\nspatial-temporal attention. With its recurrent-free, transformer-based design,\nPredFormer is both simple and efficient, significantly outperforming previous\nmethods by large margins. Extensive experiments on synthetic and real-world\ndatasets demonstrate that PredFormer achieves state-of-the-art performance. On\nMoving MNIST, PredFormer achieves a 51.3% reduction in MSE relative to SimVP.\nFor TaxiBJ, the model decreases MSE by 33.1% and boosts FPS from 533 to 2364.\nAdditionally, on WeatherBench, it reduces MSE by 11.1% while enhancing FPS from\n196 to 404. These performance gains in both accuracy and efficiency demonstrate\nPredFormer's potential for real-world applications. The source code will be\nreleased at https://github.com/yyyujintang/PredFormer.\n","authors":["Yujin Tang","Lu Qi","Fei Xie","Xiangtai Li","Chao Ma","Ming-Hsuan Yang"],"pdf_url":"https://arxiv.org/pdf/2410.04733v1.pdf","comment":"15 pages, 7 figures"},{"id":"http://arxiv.org/abs/2409.10161v3","updated":"2024-10-07T03:37:36Z","published":"2024-09-16T10:52:16Z","title":"SplatSim: Zero-Shot Sim2Real Transfer of RGB Manipulation Policies Using\n  Gaussian Splatting","summary":"  Sim2Real transfer, particularly for manipulation policies relying on RGB\nimages, remains a critical challenge in robotics due to the significant domain\nshift between synthetic and real-world visual data. In this paper, we propose\nSplatSim, a novel framework that leverages Gaussian Splatting as the primary\nrendering primitive to reduce the Sim2Real gap for RGB-based manipulation\npolicies. By replacing traditional mesh representations with Gaussian Splats in\nsimulators, SplatSim produces highly photorealistic synthetic data while\nmaintaining the scalability and cost-efficiency of simulation. We demonstrate\nthe effectiveness of our framework by training manipulation policies within\nSplatSim and deploying them in the real world in a zero-shot manner, achieving\nan average success rate of 86.25%, compared to 97.5% for policies trained on\nreal-world data. Videos can be found on our project page:\nhttps://splatsim.github.io\n","authors":["Mohammad Nomaan Qureshi","Sparsh Garg","Francisco Yandun","David Held","George Kantor","Abhisesh Silwal"],"pdf_url":"https://arxiv.org/pdf/2409.10161v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.03209v3","updated":"2024-10-07T03:37:15Z","published":"2024-09-05T03:07:26Z","title":"iSeg: An Iterative Refinement-based Framework for Training-free\n  Segmentation","summary":"  Stable diffusion has demonstrated strong image synthesis ability to given\ntext descriptions, suggesting it to contain strong semantic clue for grouping\nobjects. The researchers have explored employing stable diffusion for\ntraining-free segmentation. Most existing approaches refine cross-attention map\nby self-attention map once, demonstrating that self-attention map contains\nuseful semantic information to improve segmentation. To fully utilize\nself-attention map, we present a deep experimental analysis on iteratively\nrefining cross-attention map with self-attention map, and propose an effective\niterative refinement framework for training-free segmentation, named iSeg. The\nproposed iSeg introduces an entropy-reduced self-attention module that utilizes\na gradient descent scheme to reduce the entropy of self-attention map, thereby\nsuppressing the weak responses corresponding to irrelevant global information.\nLeveraging the entropy-reduced self-attention module, our iSeg stably improves\nrefined cross-attention map with iterative refinement. Further, we design a\ncategory-enhanced cross-attention module to generate accurate cross-attention\nmap, providing a better initial input for iterative refinement. Extensive\nexperiments across different datasets and diverse segmentation tasks reveal the\nmerits of proposed contributions, leading to promising performance on diverse\nsegmentation tasks. For unsupervised semantic segmentation on Cityscapes, our\niSeg achieves an absolute gain of 3.8% in terms of mIoU compared to the best\nexisting training-free approach in literature. Moreover, our proposed iSeg can\nsupport segmentation with different kinds of images and interactions. The\nproject is available at https://linsun449.github.io/iSeg.\n","authors":["Lin Sun","Jiale Cao","Jin Xie","Fahad Shahbaz Khan","Yanwei Pang"],"pdf_url":"https://arxiv.org/pdf/2409.03209v3.pdf","comment":"Project Page: https://linsun449.github.io/iSeg/ Code:\n  https://github.com/linsun449/iseg.code"},{"id":"http://arxiv.org/abs/2410.04721v1","updated":"2024-10-07T03:22:51Z","published":"2024-10-07T03:22:51Z","title":"ACDC: Autoregressive Coherent Multimodal Generation using Diffusion\n  Correction","summary":"  Autoregressive models (ARMs) and diffusion models (DMs) represent two leading\nparadigms in generative modeling, each excelling in distinct areas: ARMs in\nglobal context modeling and long-sequence generation, and DMs in generating\nhigh-quality local contexts, especially for continuous data such as images and\nshort videos. However, ARMs often suffer from exponential error accumulation\nover long sequences, leading to physically implausible results, while DMs are\nlimited by their local context generation capabilities. In this work, we\nintroduce Autoregressive Coherent multimodal generation with Diffusion\nCorrection (ACDC), a zero-shot approach that combines the strengths of both\nARMs and DMs at the inference stage without the need for additional\nfine-tuning. ACDC leverages ARMs for global context generation and\nmemory-conditioned DMs for local correction, ensuring high-quality outputs by\ncorrecting artifacts in generated multimodal tokens. In particular, we propose\na memory module based on large language models (LLMs) that dynamically adjusts\nthe conditioning texts for the DMs, preserving crucial global context\ninformation. Our experiments on multimodal tasks, including coherent\nmulti-frame story generation and autoregressive video generation, demonstrate\nthat ACDC effectively mitigates the accumulation of errors and significantly\nenhances the quality of generated outputs, achieving superior performance while\nremaining agnostic to specific ARM and DM architectures. Project page:\nhttps://acdc2025.github.io/\n","authors":["Hyungjin Chung","Dohun Lee","Jong Chul Ye"],"pdf_url":"https://arxiv.org/pdf/2410.04721v1.pdf","comment":"25 pages, 10 figures. Project page: https://acdc2025.github.io/"},{"id":"http://arxiv.org/abs/2410.04716v1","updated":"2024-10-07T03:13:19Z","published":"2024-10-07T03:13:19Z","title":"H-SIREN: Improving implicit neural representations with hyperbolic\n  periodic functions","summary":"  Implicit neural representations (INR) have been recently adopted in various\napplications ranging from computer vision tasks to physics simulations by\nsolving partial differential equations. Among existing INR-based works,\nmulti-layer perceptrons with sinusoidal activation functions find widespread\napplications and are also frequently treated as a baseline for the development\nof better activation functions for INR applications. Recent investigations\nclaim that the use of sinusoidal activation functions could be sub-optimal due\nto their limited supported frequency set as well as their tendency to generate\nover-smoothed solutions. We provide a simple solution to mitigate such an issue\nby changing the activation function at the first layer from $\\sin(x)$ to\n$\\sin(\\sinh(2x))$. We demonstrate H-SIREN in various computer vision and fluid\nflow problems, where it surpasses the performance of several state-of-the-art\nINRs.\n","authors":["Rui Gao","Rajeev K. Jaiman"],"pdf_url":"https://arxiv.org/pdf/2410.04716v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.03226v2","updated":"2024-10-07T03:01:01Z","published":"2024-10-04T08:26:06Z","title":"Frame-Voyager: Learning to Query Frames for Video Large Language Models","summary":"  Video Large Language Models (Video-LLMs) have made remarkable progress in\nvideo understanding tasks. However, they are constrained by the maximum length\nof input tokens, making it impractical to input entire videos. Existing frame\nselection approaches, such as uniform frame sampling and text-frame retrieval,\nfail to account for the information density variations in the videos or the\ncomplex instructions in the tasks, leading to sub-optimal performance. In this\npaper, we propose Frame-Voyager that learns to query informative frame\ncombinations, based on the given textual queries in the task. To train\nFrame-Voyager, we introduce a new data collection and labeling pipeline, by\nranking frame combinations using a pre-trained Video-LLM. Given a video of M\nframes, we traverse its T-frame combinations, feed them into a Video-LLM, and\nrank them based on Video-LLM's prediction losses. Using this ranking as\nsupervision, we train Frame-Voyager to query the frame combinations with lower\nlosses. In experiments, we evaluate Frame-Voyager on four Video Question\nAnswering benchmarks by plugging it into two different Video-LLMs. The\nexperimental results demonstrate that Frame-Voyager achieves impressive results\nin all settings, highlighting its potential as a plug-and-play solution for\nVideo-LLMs.\n","authors":["Sicheng Yu","Chengkai Jin","Huanyu Wang","Zhenghao Chen","Sheng Jin","Zhongrong Zuo","Xiaolei Xu","Zhenbang Sun","Bingni Zhang","Jiawei Wu","Hao Zhang","Qianru Sun"],"pdf_url":"https://arxiv.org/pdf/2410.03226v2.pdf","comment":"19 pages, 10 figures"},{"id":"http://arxiv.org/abs/2410.01225v2","updated":"2024-10-07T02:28:08Z","published":"2024-10-02T04:03:07Z","title":"Perceptual Piercing: Human Visual Cue-based Object Detection in Low\n  Visibility Conditions","summary":"  This study proposes a novel deep learning framework inspired by atmospheric\nscattering and human visual cortex mechanisms to enhance object detection under\npoor visibility scenarios such as fog, smoke, and haze. These conditions pose\nsignificant challenges for object recognition, impacting various sectors,\nincluding autonomous driving, aviation management, and security systems. The\nobjective is to enhance the precision and reliability of detection systems\nunder adverse environmental conditions. The research investigates the\nintegration of human-like visual cues, particularly focusing on selective\nattention and environmental adaptability, to ascertain their impact on object\ndetection's computational efficiency and accuracy. This paper proposes a\nmulti-tiered strategy that integrates an initial quick detection process,\nfollowed by targeted region-specific dehazing, and concludes with an in-depth\ndetection phase. The approach is validated using the Foggy Cityscapes,\nRESIDE-beta (OTS and RTTS) datasets and is anticipated to set new performance\nstandards in detection accuracy while significantly optimizing computational\nefficiency. The findings offer a viable solution for enhancing object detection\nin poor visibility and contribute to the broader understanding of integrating\nhuman visual principles into deep learning algorithms for intricate visual\nrecognition challenges.\n","authors":["Ashutosh Kumar"],"pdf_url":"https://arxiv.org/pdf/2410.01225v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.03038v2","updated":"2024-10-07T02:04:21Z","published":"2024-10-03T22:58:56Z","title":"CPFD: Confidence-aware Privileged Feature Distillation for Short Video\n  Classification","summary":"  Dense features, customized for different business scenarios, are essential in\nshort video classification. However, their complexity, specific adaptation\nrequirements, and high computational costs make them resource-intensive and\nless accessible during online inference. Consequently, these dense features are\ncategorized as `Privileged Dense Features'.Meanwhile, end-to-end multi-modal\nmodels have shown promising results in numerous computer vision tasks. In\nindustrial applications, prioritizing end-to-end multi-modal features, can\nenhance efficiency but often leads to the loss of valuable information from\nhistorical privileged dense features. To integrate both features while\nmaintaining efficiency and manageable resource costs, we present\nConfidence-aware Privileged Feature Distillation (CPFD), which empowers\nfeatures of an end-to-end multi-modal model by adaptively distilling privileged\nfeatures during training. Unlike existing privileged feature distillation (PFD)\nmethods, which apply uniform weights to all instances during distillation,\npotentially causing unstable performance across different business scenarios\nand a notable performance gap between teacher model (Dense Feature enhanced\nmultimodal-model DF-X-VLM) and student model (multimodal-model only X-VLM), our\nCPFD leverages confidence scores derived from the teacher model to adaptively\nmitigate the performance variance with the student model. We conducted\nextensive offline experiments on five diverse tasks demonstrating that CPFD\nimproves the video classification F1 score by 6.76% compared with end-to-end\nmultimodal-model (X-VLM) and by 2.31% with vanilla PFD on-average. And it\nreduces the performance gap by 84.6% and achieves results comparable to teacher\nmodel DF-X-VLM. The effectiveness of CPFD is further substantiated by online\nexperiments, and our framework has been deployed in production systems for over\na dozen models.\n","authors":["Jinghao Shi","Xiang Shen","Kaili Zhao","Xuedong Wang","Vera Wen","Zixuan Wang","Yifan Wu","Zhixin Zhang"],"pdf_url":"https://arxiv.org/pdf/2410.03038v2.pdf","comment":"Camera ready for CIKM 2024"},{"id":"http://arxiv.org/abs/2407.15851v2","updated":"2024-10-07T02:03:30Z","published":"2024-07-03T18:07:57Z","title":"A Survey on Trustworthiness in Foundation Models for Medical Image\n  Analysis","summary":"  The rapid advancement of foundation models in medical imaging represents a\nsignificant leap toward enhancing diagnostic accuracy and personalized\ntreatment. However, the deployment of foundation models in healthcare\nnecessitates a rigorous examination of their trustworthiness, encompassing\nprivacy, robustness, reliability, explainability, and fairness. The current\nbody of survey literature on foundation models in medical imaging reveals\nconsiderable gaps, particularly in the area of trustworthiness. Additionally,\nexisting surveys on the trustworthiness of foundation models do not adequately\naddress their specific variations and applications within the medical imaging\ndomain. This survey aims to fill that gap by presenting a novel taxonomy of\nfoundation models used in medical imaging and analyzing the key motivations for\nensuring their trustworthiness. We review current research on foundation models\nin major medical imaging applications, focusing on segmentation, medical report\ngeneration, medical question and answering (Q\\&A), and disease diagnosis. These\nareas are highlighted because they have seen a relatively mature and\nsubstantial number of foundation models compared to other applications. We\nfocus on literature that discusses trustworthiness in medical image analysis\nmanuscripts. We explore the complex challenges of building trustworthy\nfoundation models for each application, summarizing current concerns and\nstrategies for enhancing trustworthiness. Furthermore, we examine the potential\nof these models to revolutionize patient care. Our analysis underscores the\nimperative for advancing towards trustworthy AI in medical image analysis,\nadvocating for a balanced approach that fosters innovation while ensuring\nethical and equitable healthcare delivery.\n","authors":["Congzhen Shi","Ryan Rezai","Jiaxi Yang","Qi Dou","Xiaoxiao Li"],"pdf_url":"https://arxiv.org/pdf/2407.15851v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04689v1","updated":"2024-10-07T02:00:13Z","published":"2024-10-07T02:00:13Z","title":"Low-Rank Continual Pyramid Vision Transformer: Incrementally Segment\n  Whole-Body Organs in CT with Light-Weighted Adaptation","summary":"  Deep segmentation networks achieve high performance when trained on specific\ndatasets. However, in clinical practice, it is often desirable that pretrained\nsegmentation models can be dynamically extended to enable segmenting new organs\nwithout access to previous training datasets or without training from scratch.\nThis would ensure a much more efficient model development and deployment\nparadigm accounting for the patient privacy and data storage issues. This\nclinically preferred process can be viewed as a continual semantic segmentation\n(CSS) problem. Previous CSS works would either experience catastrophic\nforgetting or lead to unaffordable memory costs as models expand. In this work,\nwe propose a new continual whole-body organ segmentation model with\nlight-weighted low-rank adaptation (LoRA). We first train and freeze a pyramid\nvision transformer (PVT) base segmentation model on the initial task, then\ncontinually add light-weighted trainable LoRA parameters to the frozen model\nfor each new learning task. Through a holistically exploration of the\narchitecture modification, we identify three most important layers (i.e.,\npatch-embedding, multi-head attention and feed forward layers) that are\ncritical in adapting to the new segmentation tasks, while retaining the\nmajority of the pretrained parameters fixed. Our proposed model continually\nsegments new organs without catastrophic forgetting and meanwhile maintaining a\nlow parameter increasing rate. Continually trained and tested on four datasets\ncovering different body parts of a total of 121 organs, results show that our\nmodel achieves high segmentation accuracy, closely reaching the PVT and nnUNet\nupper bounds, and significantly outperforms other regularization-based CSS\nmethods. When comparing to the leading architecture-based CSS method, our model\nhas a substantial lower parameter increasing rate while achieving comparable\nperformance.\n","authors":["Vince Zhu","Zhanghexuan Ji","Dazhou Guo","Puyang Wang","Yingda Xia","Le Lu","Xianghua Ye","Wei Zhu","Dakai Jin"],"pdf_url":"https://arxiv.org/pdf/2410.04689v1.pdf","comment":"Accepted by Medical Image Computing and Computer Assisted\n  Intervention -- MICCAI 2024"},{"id":"http://arxiv.org/abs/2405.15269v2","updated":"2024-10-07T01:47:28Z","published":"2024-05-24T06:52:54Z","title":"BDetCLIP: Multimodal Prompting Contrastive Test-Time Backdoor Detection","summary":"  Multimodal contrastive learning methods (e.g., CLIP) have shown impressive\nzero-shot classification performance due to their strong ability to joint\nrepresentation learning for visual and textual modalities. However, recent\nresearch revealed that multimodal contrastive learning on poisoned pre-training\ndata with a small proportion of maliciously backdoored data can induce\nbackdoored CLIP that could be attacked by inserted triggers in downstream tasks\nwith a high success rate. To defend against backdoor attacks on CLIP, existing\ndefense methods focus on either the pre-training stage or the fine-tuning\nstage, which would unfortunately cause high computational costs due to numerous\nparameter updates. In this paper, we provide the first attempt at a\ncomputationally efficient backdoor detection method to defend against\nbackdoored CLIP in the inference stage. We empirically find that the visual\nrepresentations of backdoored images are insensitive to both benign and\nmalignant changes in class description texts. Motivated by this observation, we\npropose BDetCLIP, a novel test-time backdoor detection method based on\ncontrastive prompting. Specifically, we first prompt the language model (e.g.,\nGPT-4) to produce class-related description texts (benign) and class-perturbed\nrandom texts (malignant) by specially designed instructions. Then, the\ndistribution difference in cosine similarity between images and the two types\nof class description texts can be used as the criterion to detect backdoor\nsamples. Extensive experiments validate that our proposed BDetCLIP is superior\nto state-of-the-art backdoor detection methods, in terms of both effectiveness\nand efficiency.\n","authors":["Yuwei Niu","Shuo He","Qi Wei","Zongyu Wu","Feng Liu","Lei Feng"],"pdf_url":"https://arxiv.org/pdf/2405.15269v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04682v1","updated":"2024-10-07T01:29:19Z","published":"2024-10-07T01:29:19Z","title":"On the Adversarial Risk of Test Time Adaptation: An Investigation into\n  Realistic Test-Time Data Poisoning","summary":"  Test-time adaptation (TTA) updates the model weights during the inference\nstage using testing data to enhance generalization. However, this practice\nexposes TTA to adversarial risks. Existing studies have shown that when TTA is\nupdated with crafted adversarial test samples, also known as test-time poisoned\ndata, the performance on benign samples can deteriorate. Nonetheless, the\nperceived adversarial risk may be overstated if the poisoned data is generated\nunder overly strong assumptions. In this work, we first review realistic\nassumptions for test-time data poisoning, including white-box versus grey-box\nattacks, access to benign data, attack budget, and more. We then propose an\neffective and realistic attack method that better produces poisoned samples\nwithout access to benign samples, and derive an effective in-distribution\nattack objective. We also design two TTA-aware attack objectives. Our\nbenchmarks of existing attack methods reveal that the TTA methods are more\nrobust than previously believed. In addition, we analyze effective defense\nstrategies to help develop adversarially robust TTA methods.\n","authors":["Yongyi Su","Yushu Li","Nanqing Liu","Kui Jia","Xulei Yang","Chuan-Sheng Foo","Xun Xu"],"pdf_url":"https://arxiv.org/pdf/2410.04682v1.pdf","comment":"19 pages, 4 figures, 8 tables"},{"id":"http://arxiv.org/abs/2303.04508v3","updated":"2024-10-07T01:29:12Z","published":"2023-03-08T10:57:14Z","title":"InFusionSurf: Refining Neural RGB-D Surface Reconstruction Using\n  Per-Frame Intrinsic Refinement and TSDF Fusion Prior Learning","summary":"  We introduce InFusionSurf, an innovative enhancement for neural radiance\nfield (NeRF) frameworks in 3D surface reconstruction using RGB-D video frames.\nBuilding upon previous methods that have employed feature encoding to improve\noptimization speed, we further improve the reconstruction quality with minimal\nimpact on optimization time by refining depth information. InFusionSurf\naddresses camera motion-induced blurs in each depth frame through a per-frame\nintrinsic refinement scheme. It incorporates the truncated signed distance\nfield (TSDF) Fusion, a classical real-time 3D surface reconstruction method, as\na pretraining tool for the feature grid, enhancing reconstruction details and\ntraining speed. Comparative quantitative and qualitative analyses show that\nInFusionSurf reconstructs scenes with high accuracy while maintaining\noptimization efficiency. The effectiveness of our intrinsic refinement and TSDF\nFusion-based pretraining is further validated through an ablation study.\n","authors":["Seunghwan Lee","Gwanmo Park","Hyewon Son","Jiwon Ryu","Han Joo Chae"],"pdf_url":"https://arxiv.org/pdf/2303.04508v3.pdf","comment":"ICME'24 (Oral), Project page:\n  https://rokit-healthcare.github.io/InFusionSurf/"},{"id":"http://arxiv.org/abs/2405.16406v3","updated":"2024-10-07T01:27:59Z","published":"2024-05-26T02:15:49Z","title":"SpinQuant: LLM quantization with learned rotations","summary":"  Post-training quantization (PTQ) techniques applied to weights, activations,\nand the KV cache greatly reduce memory usage, latency, and power consumption of\nLarge Language Models (LLMs), but may lead to large quantization errors when\noutliers are present. Rotating activation or weight matrices helps remove\noutliers and benefits quantization. In this work, we identify a collection of\napplicable rotation parameterizations that lead to identical outputs in\nfull-precision Transformer architectures while enhancing quantization accuracy.\nIn addition, we find that some random rotations lead to much better\nquantization than others, with an up to 13 points difference in downstream\nzero-shot reasoning performance. As a result, we propose SpinQuant, a novel\napproach that incorporates learned rotation matrices for optimal quantized\nnetwork accuracy. With 4-bit quantization of weight, activation, and KV-cache,\nSpinQuant narrows the accuracy gap on zero-shot reasoning tasks with full\nprecision to merely 2.9 points on the LLaMA-2 7B model, surpassing LLM-QAT by\n19.1 points and SmoothQuant by 25.0 points. Furthermore, SpinQuant also\noutperforms concurrent work QuaRot, which applies random rotations to remove\noutliers. In particular, for LLaMA-3 8B models that are hard to quantize,\nSpinQuant reduces the gap to full precision by up to 45.1% relative to QuaRot.\n","authors":["Zechun Liu","Changsheng Zhao","Igor Fedorov","Bilge Soran","Dhruv Choudhary","Raghuraman Krishnamoorthi","Vikas Chandra","Yuandong Tian","Tijmen Blankevoort"],"pdf_url":"https://arxiv.org/pdf/2405.16406v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04680v1","updated":"2024-10-07T01:24:39Z","published":"2024-10-07T01:24:39Z","title":"Next Best Sense: Guiding Vision and Touch with FisherRF for 3D Gaussian\n  Splatting","summary":"  We propose a framework for active next best view and touch selection for\nrobotic manipulators using 3D Gaussian Splatting (3DGS). 3DGS is emerging as a\nuseful explicit 3D scene representation for robotics, as it has the ability to\nrepresent scenes in a both photorealistic and geometrically accurate manner.\nHowever, in real-world, online robotic scenes where the number of views is\nlimited given efficiency requirements, random view selection for 3DGS becomes\nimpractical as views are often overlapping and redundant. We address this issue\nby proposing an end-to-end online training and active view selection pipeline,\nwhich enhances the performance of 3DGS in few-view robotics settings. We first\nelevate the performance of few-shot 3DGS with a novel semantic depth alignment\nmethod using Segment Anything Model 2 (SAM2) that we supplement with Pearson\ndepth and surface normal loss to improve color and depth reconstruction of\nreal-world scenes. We then extend FisherRF, a next-best-view selection method\nfor 3DGS, to select views and touch poses based on depth uncertainty. We\nperform online view selection on a real robot system during live 3DGS training.\nWe motivate our improvements to few-shot GS scenes, and extend depth-based\nFisherRF to them, where we demonstrate both qualitative and quantitative\nimprovements on challenging robot scenes. For more information, please see our\nproject page at https://armlabstanford.github.io/next-best-sense.\n","authors":["Matthew Strong","Boshu Lei","Aiden Swann","Wen Jiang","Kostas Daniilidis","Monroe Kennedy III"],"pdf_url":"https://arxiv.org/pdf/2410.04680v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.17137v2","updated":"2024-10-07T01:00:46Z","published":"2024-09-25T17:56:00Z","title":"PACE: marrying generalization in PArameter-efficient fine-tuning with\n  Consistency rEgularization","summary":"  Parameter-Efficient Fine-Tuning (PEFT) effectively adapts pre-trained vision\ntransformers to downstream tasks. However, the optimization for tasks\nperformance often comes at the cost of generalizability in fine-tuned models.\nTo address this issue, we theoretically connect smaller weight gradient norms\nduring training and larger datasets to the improved model generalization.\nMotivated by this connection, we propose reducing gradient norms for enhanced\ngeneralization and aligning fine-tuned model with the pre-trained counterpart\nto retain knowledge from large-scale pre-training data. Yet, naive alignment\ndoes not guarantee gradient reduction and can potentially cause gradient\nexplosion, complicating efforts to manage gradients. To address such issues, we\npropose PACE, marrying generalization of PArameter-efficient fine-tuning with\nConsistency rEgularization. We perturb features learned from the adapter with\nthe multiplicative noise and ensure the fine-tuned model remains consistent for\nsame sample under different perturbations. Theoretical analysis shows that PACE\nnot only implicitly regularizes gradients for enhanced generalization, but also\nimplicitly aligns the fine-tuned and pre-trained models to retain knowledge.\nExperimental evidence supports our theories. PACE outperforms existing PEFT\nmethods in four visual adaptation tasks: VTAB-1k, FGVC, few-shot learning and\ndomain adaptation. Code will be available at\nhttps://github.com/MaxwellYaoNi/PACE\n","authors":["Yao Ni","Shan Zhang","Piotr Koniusz"],"pdf_url":"https://arxiv.org/pdf/2409.17137v2.pdf","comment":"Accepted by NeurIPS 2024 as a spotlight. This preliminary version\n  will soon be extended with the experiments and analyses from the rebuttal"},{"id":"http://arxiv.org/abs/2410.04671v1","updated":"2024-10-07T00:55:42Z","published":"2024-10-07T00:55:42Z","title":"CAR: Controllable Autoregressive Modeling for Visual Generation","summary":"  Controllable generation, which enables fine-grained control over generated\noutputs, has emerged as a critical focus in visual generative models.\nCurrently, there are two primary technical approaches in visual generation:\ndiffusion models and autoregressive models. Diffusion models, as exemplified by\nControlNet and T2I-Adapter, offer advanced control mechanisms, whereas\nautoregressive models, despite showcasing impressive generative quality and\nscalability, remain underexplored in terms of controllability and flexibility.\nIn this study, we introduce Controllable AutoRegressive Modeling (CAR), a\nnovel, plug-and-play framework that integrates conditional control into\nmulti-scale latent variable modeling, enabling efficient control generation\nwithin a pre-trained visual autoregressive model. CAR progressively refines and\ncaptures control representations, which are injected into each autoregressive\nstep of the pre-trained model to guide the generation process. Our approach\ndemonstrates excellent controllability across various types of conditions and\ndelivers higher image quality compared to previous methods. Additionally, CAR\nachieves robust generalization with significantly fewer training resources\ncompared to those required for pre-training the model. To the best of our\nknowledge, we are the first to propose a control framework for pre-trained\nautoregressive visual generation models.\n","authors":["Ziyu Yao","Jialin Li","Yifeng Zhou","Yong Liu","Xi Jiang","Chengjie Wang","Feng Zheng","Yuexian Zou","Lei Li"],"pdf_url":"https://arxiv.org/pdf/2410.04671v1.pdf","comment":"Code available at: https://github.com/MiracleDance/CAR"},{"id":"http://arxiv.org/abs/2410.04659v1","updated":"2024-10-07T00:16:26Z","published":"2024-10-07T00:16:26Z","title":"ActiView: Evaluating Active Perception Ability for Multimodal Large\n  Language Models","summary":"  Active perception, a crucial human capability, involves setting a goal based\non the current understanding of the environment and performing actions to\nachieve that goal. Despite significant efforts in evaluating Multimodal Large\nLanguage Models (MLLMs), active perception has been largely overlooked. To\naddress this gap, we propose a novel benchmark named ActiView to evaluate\nactive perception in MLLMs. Since comprehensively assessing active perception\nis challenging, we focus on a specialized form of Visual Question Answering\n(VQA) that eases the evaluation yet challenging for existing MLLMs. Given an\nimage, we restrict the perceptual field of a model, requiring it to actively\nzoom or shift its perceptual field based on reasoning to answer the question\nsuccessfully. We conduct extensive evaluation over 27 models, including\nproprietary and open-source models, and observe that the ability to read and\ncomprehend multiple images simultaneously plays a significant role in enabling\nactive perception. Results reveal a significant gap in the active perception\ncapability of MLLMs, indicating that this area deserves more attention. We hope\nthat our benchmark could help develop methods for MLLMs to understand\nmultimodal inputs in more natural and holistic ways.\n","authors":["Ziyue Wang","Chi Chen","Fuwen Luo","Yurui Dong","Yuanchi Zhang","Yuzhuang Xu","Xiaolong Wang","Peng Li","Yang Liu"],"pdf_url":"https://arxiv.org/pdf/2410.04659v1.pdf","comment":null}],"Human-Computer Interaction":[{"id":"http://arxiv.org/abs/2405.00099v4","updated":"2024-10-07T16:45:42Z","published":"2024-04-30T18:00:02Z","title":"Creative Beam Search: LLM-as-a-Judge For Improving Response Generation","summary":"  Large language models are revolutionizing several areas, including artificial\ncreativity. However, the process of generation in machines profoundly diverges\nfrom that observed in humans. In particular, machine generation is\ncharacterized by a lack of intentionality and an underlying creative process.\nWe propose a method called Creative Beam Search that uses Diverse Beam Search\nand LLM-as-a-Judge to perform response generation and response validation. The\nresults of a qualitative experiment show how our approach can provide better\noutput than standard sampling techniques. We also show that the response\nvalidation step is a necessary complement to the response generation step.\n","authors":["Giorgio Franceschelli","Mirco Musolesi"],"pdf_url":"https://arxiv.org/pdf/2405.00099v4.pdf","comment":"Presented as a short paper at the 15th International Conference on\n  Computational Creativity (ICCC'24)"},{"id":"http://arxiv.org/abs/2311.10054v2","updated":"2024-10-07T16:26:00Z","published":"2023-11-16T17:48:55Z","title":"When \"A Helpful Assistant\" Is Not Really Helpful: Personas in System\n  Prompts Do Not Improve Performances of Large Language Models","summary":"  Prompting serves as the major way humans interact with Large Language Models\n(LLM). Commercial AI systems commonly define the role of the LLM in system\nprompts. For example, ChatGPT uses \"You are a helpful assistant\" as part of its\ndefault system prompt. Despite current practices of adding personas to system\nprompts, it remains unclear how different personas affect a model's performance\non objective tasks. In this study, we present a systematic evaluation of\npersonas in system prompts. We curate a list of 162 roles covering 6 types of\ninterpersonal relationships and 8 domains of expertise. Through extensive\nanalysis of 4 popular families of LLMs and 2,410 factual questions, we\ndemonstrate that adding personas in system prompts does not improve model\nperformance across a range of questions compared to the control setting where\nno persona is added. Nevertheless, further analysis suggests that the gender,\ntype, and domain of the persona can all influence the resulting prediction\naccuracies. We further experimented with a list of persona search strategies\nand found that, while aggregating results from the best persona for each\nquestion significantly improves prediction accuracy, automatically identifying\nthe best persona is challenging, with predictions often performing no better\nthan random selection. Overall, our findings suggest that while adding a\npersona may lead to performance gains in certain settings, the effect of each\npersona can be largely random. Code and data are available at\nhttps://github.com/Jiaxin-Pei/Prompting-with-Social-Roles.\n","authors":["Mingqian Zheng","Jiaxin Pei","Lajanugen Logeswaran","Moontae Lee","David Jurgens"],"pdf_url":"https://arxiv.org/pdf/2311.10054v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.05131v1","updated":"2024-10-07T15:34:36Z","published":"2024-10-07T15:34:36Z","title":"Enhancing Job Interview Preparation Through Immersive Experiences Using\n  Photorealistic, AI-powered Metahuman Avatars","summary":"  This study will investigate the user experience while interacting with highly\nphotorealistic virtual job interviewer avatars in Virtual Reality (VR),\nAugmented Reality (AR), and on a 2D screen. Having a precise speech recognition\nmechanism, our virtual character performs a mock-up software engineering job\ninterview to adequately immerse the user in a life-like scenario. To evaluate\nthe efficiency of our system, we measure factors such as the provoked level of\nanxiety, social presence, self-esteem, and intrinsic motivation. This research\nis a work in progress with a prospective within-subject user study including\napproximately 40 participants. All users will engage with three job interview\nconditions (VR, AR, and desktop) and provide their feedback. Additionally,\nusers' bio-physical responses will be collected using a biosensor to measure\nthe level of anxiety during the job interview.\n","authors":["Navid Ashrafi","Francesco Vona","Carina Ringsdorf","Christian Hertel","Luca Toni","Sarina Kailer","Alice Bartels","Tanja Kojic","Jan-Niklas Voigt-Antons"],"pdf_url":"https://arxiv.org/pdf/2410.05131v1.pdf","comment":"2-page ISMAR poster paper"},{"id":"http://arxiv.org/abs/2410.05116v1","updated":"2024-10-07T15:12:01Z","published":"2024-10-07T15:12:01Z","title":"Human-Feedback Efficient Reinforcement Learning for Online Diffusion\n  Model Finetuning","summary":"  Controllable generation through Stable Diffusion (SD) fine-tuning aims to\nimprove fidelity, safety, and alignment with human guidance. Existing\nreinforcement learning from human feedback methods usually rely on predefined\nheuristic reward functions or pretrained reward models built on large-scale\ndatasets, limiting their applicability to scenarios where collecting such data\nis costly or difficult. To effectively and efficiently utilize human feedback,\nwe develop a framework, HERO, which leverages online human feedback collected\non the fly during model learning. Specifically, HERO features two key\nmechanisms: (1) Feedback-Aligned Representation Learning, an online training\nmethod that captures human feedback and provides informative learning signals\nfor fine-tuning, and (2) Feedback-Guided Image Generation, which involves\ngenerating images from SD's refined initialization samples, enabling faster\nconvergence towards the evaluator's intent. We demonstrate that HERO is 4x more\nefficient in online feedback for body part anomaly correction compared to the\nbest existing method. Additionally, experiments show that HERO can effectively\nhandle tasks like reasoning, counting, personalization, and reducing NSFW\ncontent with only 0.5K online feedback.\n","authors":["Ayano Hiranaka","Shang-Fu Chen","Chieh-Hsin Lai","Dongjun Kim","Naoki Murata","Takashi Shibuya","Wei-Hsiang Liao","Shao-Hua Sun","Yuki Mitsufuji"],"pdf_url":"https://arxiv.org/pdf/2410.05116v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04931v1","updated":"2024-10-07T11:24:29Z","published":"2024-10-07T11:24:29Z","title":"The Role of Governments in Increasing Interconnected Post-Deployment\n  Monitoring of AI","summary":"  Language-based AI systems are diffusing into society, bringing positive and\nnegative impacts. Mitigating negative impacts depends on accurate impact\nassessments, drawn from an empirical evidence base that makes causal\nconnections between AI usage and impacts. Interconnected post-deployment\nmonitoring combines information about model integration and use, application\nuse, and incidents and impacts. For example, inference time monitoring of\nchain-of-thought reasoning can be combined with long-term monitoring of\nsectoral AI diffusion, impacts and incidents. Drawing on information sharing\nmechanisms in other industries, we highlight example data sources and specific\ndata points that governments could collect to inform AI risk management.\n","authors":["Merlin Stein","Jamie Bernardi","Connor Dunlop"],"pdf_url":"https://arxiv.org/pdf/2410.04931v1.pdf","comment":"7 pages, 2 figures, 1 table"},{"id":"http://arxiv.org/abs/2410.04921v1","updated":"2024-10-07T11:09:45Z","published":"2024-10-07T11:09:45Z","title":"Music-triggered fashion design: from songs to the metaverse","summary":"  The advent of increasingly-growing virtual realities poses unprecedented\nopportunities and challenges to different societies. Artistic collectives are\nnot an exception, and we here aim to put special attention into musicians.\nCompositions, lyrics and even show-advertisements are constituents of a message\nthat artists transmit about their reality. As such, artistic creations are\nultimately linked to feelings and emotions, with aesthetics playing a crucial\nrole when it comes to transmit artist's intentions. In this context, we here\nanalyze how virtual realities can help to broaden the opportunities for\nmusicians to bridge with their audiences, by devising a dynamical\nfashion-design recommendation system inspired by sound stimulus. We present our\nfirst steps towards re-defining musical experiences in the metaverse, opening\nup alternative opportunities for artists to connect both with real and virtual\n(\\textit{e.g.} machine-learning agents operating in the metaverse) in\npotentially broader ways.\n","authors":["Martina Delgado","Marta Llopart","Eva Sarabia","Sandra Taboada","Pol Vierge","Fernando Vilariño","Joan Moya Kohler","Julieta Grimberg Golijov","Matías Bilkis"],"pdf_url":"https://arxiv.org/pdf/2410.04921v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04917v1","updated":"2024-10-07T11:07:04Z","published":"2024-10-07T11:07:04Z","title":"Why am I seeing this: Democratizing End User Auditing for Online Content\n  Recommendations","summary":"  Personalized recommendation systems tailor content based on user attributes,\nwhich are either provided or inferred from private data. Research suggests that\nusers often hypothesize about reasons behind contents they encounter (e.g., \"I\nsee this jewelry ad because I am a woman\"), but they lack the means to confirm\nthese hypotheses due to the opaqueness of these systems. This hinders informed\ndecision-making about privacy and system use and contributes to the lack of\nalgorithmic accountability. To address these challenges, we introduce a new\ninteractive sandbox approach. This approach creates sets of synthetic user\npersonas and corresponding personal data that embody realistic variations in\npersonal attributes, allowing users to test their hypotheses by observing how a\nwebsite's algorithms respond to these personas. We tested the sandbox in the\ncontext of targeted advertisement. Our user study demonstrates its usability,\nusefulness, and effectiveness in empowering end-user auditing in a case study\nof targeting ads.\n","authors":["Chaoran Chen","Leyang Li","Luke Cao","Yanfang Ye","Tianshi Li","Yaxing Yao","Toby Jia-jun Li"],"pdf_url":"https://arxiv.org/pdf/2410.04917v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04899v1","updated":"2024-10-07T10:29:08Z","published":"2024-10-07T10:29:08Z","title":"Working with Mixed Reality in Public: Effects of Virtual Display Layouts\n  on Productivity, Feeling of Safety, and Social Acceptability","summary":"  Nowadays, Mixed Reality (MR) headsets are a game-changer for knowledge work.\nUnlike stationary monitors, MR headsets allow users to work with large virtual\ndisplays anywhere they wear the headset, whether in a professional office, a\npublic setting like a cafe, or a quiet space like a library. This study\ncompares four different layouts (eye level-close, eye level-far, below eye\nlevel-close, below eye level-far) of virtual displays regarding feelings of\nsafety, perceived productivity, and social acceptability when working with MR\nin public. We test which layout is most preferred by users and seek to\nunderstand which factors affect users' layout preferences. The aim is to derive\nuseful insights for designing better MR layouts. A field study in a public\nlibrary was conducted using a within-subject design. While the participants\ninteract with a layout, they are asked to work on a planning task. The results\nfrom a repeated measure ANOVA show a statistically significant effect on\nproductivity but not on safety and social acceptability. Additionally, we\nreport preferences expressed by the users regarding the layouts and using MR in\npublic.\n","authors":["Janne Kaeder","Maurizio Vergari","Verena Biener","Tanja Kojić","Jens Grubert","Sebastian Möller","Jan-Niklas Voigt-Antons"],"pdf_url":"https://arxiv.org/pdf/2410.04899v1.pdf","comment":"Part of the 23rd annual IEEE International Symposium on Mixed and\n  Augmented Reality (ISMAR 2024)"},{"id":"http://arxiv.org/abs/2410.04852v1","updated":"2024-10-07T09:16:23Z","published":"2024-10-07T09:16:23Z","title":"Single Vs Dual: Influence of the Number of Displays on User Experience\n  within Virtually Embodied Conversational Systems","summary":"  The current research evaluates user experience and preference when\ninteracting with a patient-reported outcome measure (PROM) healthcare\napplication displayed on a single tablet in comparison to interaction with the\nsame application distributed across two tablets. We conducted a within-subject\nuser study with 43 participants who engaged with and rated the usability of our\nsystem and participated in a post-experiment interview to collect subjective\ndata. Our findings showed significantly higher usability and higher pragmatic\nquality ratings for the single tablet condition. However, some users attribute\na higher level of presence to the avatar and prefer it to be placed on a second\ntablet.\n","authors":["Navid Ashrafi","Francesco Vona","Philipp Graf","Philipp Harnisch","Sina Hinzmann","Jan-Niklas Voigt-Antons"],"pdf_url":"https://arxiv.org/pdf/2410.04852v1.pdf","comment":"In 30th ACM Symposium on Virtual Reality Software and Technology\n  (VRST 2024)"},{"id":"http://arxiv.org/abs/2405.13753v3","updated":"2024-10-07T08:20:55Z","published":"2024-05-22T15:38:30Z","title":"A Dynamic Model of Performative Human-ML Collaboration: Theory and\n  Empirical Evidence","summary":"  Machine learning (ML) models are increasingly used in various applications,\nfrom recommendation systems in e-commerce to diagnosis prediction in\nhealthcare. In this paper, we present a novel dynamic framework for thinking\nabout the deployment of ML models in a performative, human-ML collaborative\nsystem. In our framework, the introduction of ML recommendations changes the\ndata-generating process of human decisions, which are only a proxy to the\nground truth and which are then used to train future versions of the model. We\nshow that this dynamic process in principle can converge to different stable\npoints, i.e. where the ML model and the Human+ML system have the same\nperformance. Some of these stable points are suboptimal with respect to the\nactual ground truth. As a proof of concept, we conduct an empirical user study\nwith 1,408 participants. In the study, humans solve instances of the knapsack\nproblem with the help of machine learning predictions of varying performance.\nThis is an ideal setting because we can identify the actual ground truth, and\nevaluate the performance of human decisions supported by ML recommendations. We\nfind that for many levels of ML performance, humans can improve upon the ML\npredictions. We also find that the improvement could be even higher if humans\nrationally followed the ML recommendations. Finally, we test whether monetary\nincentives can increase the quality of human decisions, but we fail to find any\npositive effect. Using our empirical data to approximate our collaborative\nsystem suggests that the learning process would dynamically reach an\nequilibrium performance that is around 92% of the maximum knapsack value. Our\nresults have practical implications for the deployment of ML models in contexts\nwhere human decisions may deviate from the indisputable ground truth.\n","authors":["Tom Sühr","Samira Samadi","Chiara Farronato"],"pdf_url":"https://arxiv.org/pdf/2405.13753v3.pdf","comment":"10 Pages and appendix"},{"id":"http://arxiv.org/abs/2410.04768v1","updated":"2024-10-07T06:06:25Z","published":"2024-10-07T06:06:25Z","title":"A Stretchable Electrostatic Tactile Surface","summary":"  Tactile sensation is essential for humans to recognize objects. Various\ndevices have been developed in the past for tactile presentation by\nelectrostatic force, which are easy to configure devices, but there is\ncurrently no such device that features stretchability. Considering that the\ndevice is worn over the joints of a human body or robot, it is extremely\nimportant that the device itself be stretchable. In this study, we propose a\nstretchable electrostatic tactile surface comprising a stretchable transparent\nelectrode and a stretchable insulating film that can be stretched to a maximum\nof 50%. This means that when attached to the human body, this surface can\nrespond to the expansion and contraction that occur due to joint movements.\nThis surface can also provide tactile information in response to deformation\nsuch as pushing and pulling. As a basic investigation, we measured the lower\nlimit of voltage that can be perceived by changing the configuration of the\nsurface and evaluated the states of stretching and contraction. We also\ninvestigated and modeled the relationship between the voltage and the perceived\nintensity.\n","authors":["Naoto Takayanagi","Naoji Matsuhisa","Yuki Hashimoto","Yuta Sugiura"],"pdf_url":"https://arxiv.org/pdf/2410.04768v1.pdf","comment":"7 pages, 9 figures"},{"id":"http://arxiv.org/abs/2210.04483v2","updated":"2024-10-07T05:52:31Z","published":"2022-10-10T08:16:29Z","title":"Auxilio and Beyond: Comparative Evaluation, Usability, and Design\n  Guidelines for Head Movement-based Assistive Mouse Controllers","summary":"  Upper limb disability due to neurological disorders or other factors\nrestricts computer interaction for affected individuals using a generic optical\nmouse. This work reports the findings of a comparative evaluation of Auxilio, a\nsensor-based wireless head-mounted Assistive Mouse Controller (AMC), that\nfacilitates computer interaction for such individuals. Combining commercially\navailable, low-cost motion and infrared sensors, Auxilio utilizes head\nmovements and cheek muscle twitches for mouse control. Its performance in\npointing tasks with subjects without motor impairments has been juxtaposed\nagainst a commercially available and patented vision-based head-tracking AMC\ndeveloped for similar stakeholders. Furthermore, our study evaluates the\nusability of Auxilio using the System Usability Scale, supplemented by a\nqualitative analysis of participant interview transcripts to identify the\nstrengths and weaknesses of both AMCs. Experimental results demonstrate the\nfeasibility and effectiveness of Auxilio, and we summarize our key findings\ninto design guidelines for the development of similar future AMCs.\n","authors":["Mohammad Ridwan Kabir","Mohammad Ishrak Abedin","Rizvi Ahmed","Saad Bin Ashraf","Hasan Mahmud","Md. Kamrul Hasan"],"pdf_url":"https://arxiv.org/pdf/2210.04483v2.pdf","comment":"30 pages, 6 figures, 3 tables"},{"id":"http://arxiv.org/abs/2405.13803v3","updated":"2024-10-07T04:18:40Z","published":"2024-05-22T16:30:24Z","title":"\"I Like Sunnie More Than I Expected!\": Exploring User Expectation and\n  Perception of an Anthropomorphic LLM-based Conversational Agent for\n  Well-Being Support","summary":"  The human-computer interaction (HCI) research community has a longstanding\ninterest in exploring the mismatch between users' actual experiences and\nexpectation toward new technologies, for instance, large language models\n(LLMs). In this study, we compared users' (N = 38) initial expectations against\ntheir post-interaction perceptions of two LLM-powered mental well-being\nintervention activity recommendation systems. Both systems have a built-in LLM\nto recommend a personalized well-being intervention activity, but one system\n(Sunnie) has an anthropomorphic conversational interaction design via elements\nsuch as appearance, persona, and natural conversation. Results showed that user\nengagement was high with both systems, and both systems exceeded users'\nexpectations along the utility dimension, highlighting AI's potential to offer\nuseful intervention activity recommendations. In addition, Sunnie further\noutperformed the non-anthropomorphic baseline system in relational warmth.\nThese findings suggest that anthropomorphic conversational interaction design\nmay be particularly effective in fostering warmth in mental health support\ncontexts.\n","authors":["Siyi Wu","Julie Y. A. Cachia","Feixue Han","Bingsheng Yao","Tianyi Xie","Xuan Zhao","Dakuo Wang"],"pdf_url":"https://arxiv.org/pdf/2405.13803v3.pdf","comment":"In Submission"},{"id":"http://arxiv.org/abs/2410.04732v1","updated":"2024-10-07T03:51:25Z","published":"2024-10-07T03:51:25Z","title":"Guidance of the Center of Pressure Using Haptic Presentation","summary":"  Accurately instructing posture and the position of the body's center of\ngravity is challenging. In this study, we propose a system that utilizes haptic\nfeedback to induce the Center of Pressure (CoP) movement. The Wii Balance Board\nis employed to sense the CoP, and vibration motors are used for haptic\nfeedback. To provide a comparison, inductions were also performed using visual\nand auditory feedback, and the time required for induction was measured.\nAdditionally, after the experiments, a questionnaire survey was conducted.\n","authors":["Yohei Kawasaki","Yuta Sugiura"],"pdf_url":"https://arxiv.org/pdf/2410.04732v1.pdf","comment":"4 pages, 6 figures"},{"id":"http://arxiv.org/abs/2410.04730v1","updated":"2024-10-07T03:46:21Z","published":"2024-10-07T03:46:21Z","title":"Exploring Gestural Interaction with a Cushion Interface for Smart Home\n  Control","summary":"  In this research, we aim to realize cushion interface for operating smart\nhome. We designed user-defined gestures using cushion and developed gesture\nrecognition system. We asked some users to make gestures using cushions for\noperating home appliances and determined user-defined gesture sets. We\ndeveloped two methods for gesture identification. The First, We inserted sensor\nmodules consisting of photo reflective sensors and acceleration sensor inside a\ncushion. The second, we embedded the acceleration sensor arrays in the cushion\ncover. Gesture recognizer was implemented using Convolutional Neural Networks\n(CNN). To evaluate our method, We conducted an experiment to measure\nrecognition accuracy. Results showed that an average accuracy was 94.8% when\ntraining for each user, and an average accuracy of 91.3% when testing with a\nuser that did not exist in the training data set.\n","authors":["Yuri Suzuki","Kaho Kato","Naomi Furui","Daisuke Sakamoto","Yuta Sugiura"],"pdf_url":"https://arxiv.org/pdf/2410.04730v1.pdf","comment":"10 pages"},{"id":"http://arxiv.org/abs/2404.08743v2","updated":"2024-10-07T02:59:58Z","published":"2024-04-12T18:10:40Z","title":"VizGroup: An AI-Assisted Event-Driven System for Real-Time Collaborative\n  Programming Learning Analytics","summary":"  Programming instructors often conduct collaborative learning activities, like\nPeer Instruction, to foster a deeper understanding in students and enhance\ntheir engagement with learning. These activities, however, may not always yield\nproductive outcomes due to the diversity of student mental models and their\nineffective collaboration. In this work, we introduce VizGroup, an AI-assisted\nsystem that enables programming instructors to easily oversee students'\nreal-time collaborative learning behaviors during large programming courses.\nVizGroup leverages Large Language Models (LLMs) to recommend event\nspecifications for instructors so that they can simultaneously track and\nreceive alerts about key correlation patterns between various collaboration\nmetrics and ongoing coding tasks. We evaluated VizGroup with 12 instructors in\na comparison study using a dataset collected from a Peer Instruction activity\nthat was conducted in a large programming lecture. The results showed that\nVizGroup helped instructors effectively overview, narrow down, and track\nnuances throughout students' behaviors.\n","authors":["Xiaohang Tang","Sam Wong","Kevin Pu","Xi Chen","Yalong Yang","Yan Chen"],"pdf_url":"https://arxiv.org/pdf/2404.08743v2.pdf","comment":"Accepted to UIST 2024"},{"id":"http://arxiv.org/abs/2410.04699v1","updated":"2024-10-07T02:30:18Z","published":"2024-10-07T02:30:18Z","title":"The LLM Effect: Are Humans Truly Using LLMs, or Are They Being\n  Influenced By Them Instead?","summary":"  Large Language Models (LLMs) have shown capabilities close to human\nperformance in various analytical tasks, leading researchers to use them for\ntime and labor-intensive analyses. However, their capability to handle highly\nspecialized and open-ended tasks in domains like policy studies remains in\nquestion. This paper investigates the efficiency and accuracy of LLMs in\nspecialized tasks through a structured user study focusing on Human-LLM\npartnership. The study, conducted in two stages-Topic Discovery and Topic\nAssignment-integrates LLMs with expert annotators to observe the impact of LLM\nsuggestions on what is usually human-only analysis. Results indicate that\nLLM-generated topic lists have significant overlap with human generated topic\nlists, with minor hiccups in missing document-specific topics. However, LLM\nsuggestions may significantly improve task completion speed, but at the same\ntime introduce anchoring bias, potentially affecting the depth and nuance of\nthe analysis, raising a critical question about the trade-off between increased\nefficiency and the risk of biased analysis.\n","authors":["Alexander S. Choi","Syeda Sabrina Akter","JP Singh","Antonios Anastasopoulos"],"pdf_url":"https://arxiv.org/pdf/2410.04699v1.pdf","comment":"Accepted to EMNLP Main 2024. First two authors contributed equally"},{"id":"http://arxiv.org/abs/2407.15851v2","updated":"2024-10-07T02:03:30Z","published":"2024-07-03T18:07:57Z","title":"A Survey on Trustworthiness in Foundation Models for Medical Image\n  Analysis","summary":"  The rapid advancement of foundation models in medical imaging represents a\nsignificant leap toward enhancing diagnostic accuracy and personalized\ntreatment. However, the deployment of foundation models in healthcare\nnecessitates a rigorous examination of their trustworthiness, encompassing\nprivacy, robustness, reliability, explainability, and fairness. The current\nbody of survey literature on foundation models in medical imaging reveals\nconsiderable gaps, particularly in the area of trustworthiness. Additionally,\nexisting surveys on the trustworthiness of foundation models do not adequately\naddress their specific variations and applications within the medical imaging\ndomain. This survey aims to fill that gap by presenting a novel taxonomy of\nfoundation models used in medical imaging and analyzing the key motivations for\nensuring their trustworthiness. We review current research on foundation models\nin major medical imaging applications, focusing on segmentation, medical report\ngeneration, medical question and answering (Q\\&A), and disease diagnosis. These\nareas are highlighted because they have seen a relatively mature and\nsubstantial number of foundation models compared to other applications. We\nfocus on literature that discusses trustworthiness in medical image analysis\nmanuscripts. We explore the complex challenges of building trustworthy\nfoundation models for each application, summarizing current concerns and\nstrategies for enhancing trustworthiness. Furthermore, we examine the potential\nof these models to revolutionize patient care. Our analysis underscores the\nimperative for advancing towards trustworthy AI in medical image analysis,\nadvocating for a balanced approach that fosters innovation while ensuring\nethical and equitable healthcare delivery.\n","authors":["Congzhen Shi","Ryan Rezai","Jiaxi Yang","Qi Dou","Xiaoxiao Li"],"pdf_url":"https://arxiv.org/pdf/2407.15851v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04686v1","updated":"2024-10-07T01:46:30Z","published":"2024-10-07T01:46:30Z","title":"Does the Infamous Pie Chart Really Hurt Decision-Making in the Real\n  World? Assessing the Role of Visualization in High-Level Academic Decisions","summary":"  Visualization design influences how people perceive data patterns, yet most\nresearch focuses on low-level analytic tasks, such as finding correlations.\nExisting work has criticized pie charts for their perceptual limitations.\nHowever, simpler visualizations like pie and bar charts are widely used for\nreal-world decision-making, such as choosing schools or advisors. As a case\nstudy, we examine whether pie charts hurt high-level decisions compared to bar\ncharts, using the website that presents academic data, CSRankings.org. By\ncomparing the impact of pie charts versus bar charts on users' impressions of\nfaculty productivity and projected workload, we found no significant\ndifferences in decisions among over 300 participants. Our findings challenge\ntraditional views on visualization design, emphasizing the need for real-world\nuse cases in evaluations.\n","authors":["Yixuan Li","Emery D. Berger","Minsuk Kahng","Cindy Xiong Bearfield"],"pdf_url":"https://arxiv.org/pdf/2410.04686v1.pdf","comment":null}],"Machine Learning":[{"id":"http://arxiv.org/abs/2410.05269v1","updated":"2024-10-07T17:59:58Z","published":"2024-10-07T17:59:58Z","title":"Data Advisor: Dynamic Data Curation for Safety Alignment of Large\n  Language Models","summary":"  Data is a crucial element in large language model (LLM) alignment. Recent\nstudies have explored using LLMs for efficient data collection. However,\nLLM-generated data often suffers from quality issues, with underrepresented or\nabsent aspects and low-quality datapoints. To address these problems, we\npropose Data Advisor, an enhanced LLM-based method for generating data that\ntakes into account the characteristics of the desired dataset. Starting from a\nset of pre-defined principles in hand, Data Advisor monitors the status of the\ngenerated data, identifies weaknesses in the current dataset, and advises the\nnext iteration of data generation accordingly. Data Advisor can be easily\nintegrated into existing data generation methods to enhance data quality and\ncoverage. Experiments on safety alignment of three representative LLMs (i.e.,\nMistral, Llama2, and Falcon) demonstrate the effectiveness of Data Advisor in\nenhancing model safety against various fine-grained safety issues without\nsacrificing model utility.\n","authors":["Fei Wang","Ninareh Mehrabi","Palash Goyal","Rahul Gupta","Kai-Wei Chang","Aram Galstyan"],"pdf_url":"https://arxiv.org/pdf/2410.05269v1.pdf","comment":"Accepted to EMNLP 2024 Main Conference. Project website:\n  https://feiwang96.github.io/DataAdvisor/"},{"id":"http://arxiv.org/abs/2406.11839v2","updated":"2024-10-07T17:59:42Z","published":"2024-06-17T17:59:58Z","title":"mDPO: Conditional Preference Optimization for Multimodal Large Language\n  Models","summary":"  Direct preference optimization (DPO) has shown to be an effective method for\nlarge language model (LLM) alignment. Recent works have attempted to apply DPO\nto multimodal scenarios but have found it challenging to achieve consistent\nimprovement. Through a comparative experiment, we identify the unconditional\npreference problem in multimodal preference optimization, where the model\noverlooks the image condition. To address this problem, we propose mDPO, a\nmultimodal DPO objective that prevents the over-prioritization of language-only\npreferences by also optimizing image preference. Moreover, we introduce a\nreward anchor that forces the reward to be positive for chosen responses,\nthereby avoiding the decrease in their likelihood -- an intrinsic problem of\nrelative preference optimization. Experiments on two multimodal LLMs of\ndifferent sizes and three widely used benchmarks demonstrate that mDPO\neffectively addresses the unconditional preference problem in multimodal\npreference optimization and significantly improves model performance,\nparticularly in reducing hallucination.\n","authors":["Fei Wang","Wenxuan Zhou","James Y. Huang","Nan Xu","Sheng Zhang","Hoifung Poon","Muhao Chen"],"pdf_url":"https://arxiv.org/pdf/2406.11839v2.pdf","comment":"Accepted to EMNLP 2024 Main Conference. Project website:\n  https://feiwang96.github.io/mDPO"},{"id":"http://arxiv.org/abs/2410.05265v1","updated":"2024-10-07T17:59:35Z","published":"2024-10-07T17:59:35Z","title":"PrefixQuant: Static Quantization Beats Dynamic through Prefixed Outliers\n  in LLMs","summary":"  Quantization is essential for deploying Large Language Models (LLMs) by\nenhancing memory efficiency and inference speed. Existing methods for\nactivation quantization mainly address channel-wise outliers, often neglecting\ntoken-wise outliers, leading to reliance on costly per-token dynamic\nquantization. To address this, we introduce PrefixQuant, a novel technique that\nisolates outlier tokens offline without re-training. Specifically, PrefixQuant\nidentifies high-frequency outlier tokens and prefixes them in the KV cache,\npreventing the generation of outlier tokens during inference and simplifying\nquantization. To our knowledge, PrefixQuant is the first to enable efficient\nper-tensor static quantization to outperform expensive per-token dynamic\nquantization. For instance, in W4A4KV4 (4- bit weight, 4-bit activation, and\n4-bit KV cache) Llama-3-8B, PrefixQuant with per-tensor static quantization\nachieves a 7.43 WikiText2 perplexity and 71.08% average accuracy on 5\ncommon-sense reasoning tasks, outperforming previous per-token dynamic\nquantization methods like QuaRot with 0.98 perplexity improvement and +5.98\npoints accuracy. Additionally, the inference speed of W4A4 quantized models\nusing PrefixQuant is 1.60x to 2.81x faster than FP16 models and exceeds QuaRot\nmodels by 1.2x to 1.3x. Our code is available at\n\\url{https://github.com/ChenMnZ/PrefixQuant}.\n","authors":["Mengzhao Chen","Yi Liu","Jiahao Wang","Yi Bin","Wenqi Shao","Ping Luo"],"pdf_url":"https://arxiv.org/pdf/2410.05265v1.pdf","comment":"A PTQ method to significantly boost the performance of static\n  activation quantization"},{"id":"http://arxiv.org/abs/2410.05263v1","updated":"2024-10-07T17:59:09Z","published":"2024-10-07T17:59:09Z","title":"Regression Conformal Prediction under Bias","summary":"  Uncertainty quantification is crucial to account for the imperfect\npredictions of machine learning algorithms for high-impact applications.\nConformal prediction (CP) is a powerful framework for uncertainty\nquantification that generates calibrated prediction intervals with valid\ncoverage. In this work, we study how CP intervals are affected by bias - the\nsystematic deviation of a prediction from ground truth values - a phenomenon\nprevalent in many real-world applications. We investigate the influence of bias\non interval lengths of two different types of adjustments -- symmetric\nadjustments, the conventional method where both sides of the interval are\nadjusted equally, and asymmetric adjustments, a more flexible method where the\ninterval can be adjusted unequally in positive or negative directions. We\npresent theoretical and empirical analyses characterizing how symmetric and\nasymmetric adjustments impact the \"tightness\" of CP intervals for regression\ntasks. Specifically for absolute residual and quantile-based non-conformity\nscores, we prove: 1) the upper bound of symmetrically adjusted interval lengths\nincreases by $2|b|$ where $b$ is a globally applied scalar value representing\nbias, 2) asymmetrically adjusted interval lengths are not affected by bias, and\n3) conditions when asymmetrically adjusted interval lengths are guaranteed to\nbe smaller than symmetric ones. Our analyses suggest that even if predictions\nexhibit significant drift from ground truth values, asymmetrically adjusted\nintervals are still able to maintain the same tightness and validity of\nintervals as if the drift had never happened, while symmetric ones\nsignificantly inflate the lengths. We demonstrate our theoretical results with\ntwo real-world prediction tasks: sparse-view computed tomography (CT)\nreconstruction and time-series weather forecasting. Our work paves the way for\nmore bias-robust machine learning systems.\n","authors":["Matt Y. Cheung","Tucker J. Netherton","Laurence E. Court","Ashok Veeraraghavan","Guha Balakrishnan"],"pdf_url":"https://arxiv.org/pdf/2410.05263v1.pdf","comment":"17 pages, 6 figures, code available at:\n  https://github.com/matthewyccheung/conformal-metric"},{"id":"http://arxiv.org/abs/2410.05258v1","updated":"2024-10-07T17:57:38Z","published":"2024-10-07T17:57:38Z","title":"Differential Transformer","summary":"  Transformer tends to overallocate attention to irrelevant context. In this\nwork, we introduce Diff Transformer, which amplifies attention to the relevant\ncontext while canceling noise. Specifically, the differential attention\nmechanism calculates attention scores as the difference between two separate\nsoftmax attention maps. The subtraction cancels noise, promoting the emergence\nof sparse attention patterns. Experimental results on language modeling show\nthat Diff Transformer outperforms Transformer in various settings of scaling up\nmodel size and training tokens. More intriguingly, it offers notable advantages\nin practical applications, such as long-context modeling, key information\nretrieval, hallucination mitigation, in-context learning, and reduction of\nactivation outliers. By being less distracted by irrelevant context, Diff\nTransformer can mitigate hallucination in question answering and text\nsummarization. For in-context learning, Diff Transformer not only enhances\naccuracy but is also more robust to order permutation, which was considered as\na chronic robustness issue. The results position Diff Transformer as a highly\neffective and promising architecture to advance large language models.\n","authors":["Tianzhu Ye","Li Dong","Yuqing Xia","Yutao Sun","Yi Zhu","Gao Huang","Furu Wei"],"pdf_url":"https://arxiv.org/pdf/2410.05258v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.05255v1","updated":"2024-10-07T17:56:53Z","published":"2024-10-07T17:56:53Z","title":"SePPO: Semi-Policy Preference Optimization for Diffusion Alignment","summary":"  Reinforcement learning from human feedback (RLHF) methods are emerging as a\nway to fine-tune diffusion models (DMs) for visual generation. However,\ncommonly used on-policy strategies are limited by the generalization capability\nof the reward model, while off-policy approaches require large amounts of\ndifficult-to-obtain paired human-annotated data, particularly in visual\ngeneration tasks. To address the limitations of both on- and off-policy RLHF,\nwe propose a preference optimization method that aligns DMs with preferences\nwithout relying on reward models or paired human-annotated data. Specifically,\nwe introduce a Semi-Policy Preference Optimization (SePPO) method. SePPO\nleverages previous checkpoints as reference models while using them to generate\non-policy reference samples, which replace \"losing images\" in preference pairs.\nThis approach allows us to optimize using only off-policy \"winning images.\"\nFurthermore, we design a strategy for reference model selection that expands\nthe exploration in the policy space. Notably, we do not simply treat reference\nsamples as negative examples for learning. Instead, we design an anchor-based\ncriterion to assess whether the reference samples are likely to be winning or\nlosing images, allowing the model to selectively learn from the generated\nreference samples. This approach mitigates performance degradation caused by\nthe uncertainty in reference sample quality. We validate SePPO across both\ntext-to-image and text-to-video benchmarks. SePPO surpasses all previous\napproaches on the text-to-image benchmarks and also demonstrates outstanding\nperformance on the text-to-video benchmarks. Code will be released in\nhttps://github.com/DwanZhang-AI/SePPO.\n","authors":["Daoan Zhang","Guangchen Lan","Dong-Jun Han","Wenlin Yao","Xiaoman Pan","Hongming Zhang","Mingxiao Li","Pengcheng Chen","Yu Dong","Christopher Brinton","Jiebo Luo"],"pdf_url":"https://arxiv.org/pdf/2410.05255v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.05254v1","updated":"2024-10-07T17:55:35Z","published":"2024-10-07T17:55:35Z","title":"GLEE: A Unified Framework and Benchmark for Language-based Economic\n  Environments","summary":"  Large Language Models (LLMs) show significant potential in economic and\nstrategic interactions, where communication via natural language is often\nprevalent. This raises key questions: Do LLMs behave rationally? Can they mimic\nhuman behavior? Do they tend to reach an efficient and fair outcome? What is\nthe role of natural language in the strategic interaction? How do\ncharacteristics of the economic environment influence these dynamics? These\nquestions become crucial concerning the economic and societal implications of\nintegrating LLM-based agents into real-world data-driven systems, such as\nonline retail platforms and recommender systems. While the ML community has\nbeen exploring the potential of LLMs in such multi-agent setups, varying\nassumptions, design choices and evaluation criteria across studies make it\ndifficult to draw robust and meaningful conclusions. To address this, we\nintroduce a benchmark for standardizing research on two-player, sequential,\nlanguage-based games. Inspired by the economic literature, we define three base\nfamilies of games with consistent parameterization, degrees of freedom and\neconomic measures to evaluate agents' performance (self-gain), as well as the\ngame outcome (efficiency and fairness). We develop an open-source framework for\ninteraction simulation and analysis, and utilize it to collect a dataset of LLM\nvs. LLM interactions across numerous game configurations and an additional\ndataset of human vs. LLM interactions. Through extensive experimentation, we\ndemonstrate how our framework and dataset can be used to: (i) compare the\nbehavior of LLM-based agents to human players in various economic contexts;\n(ii) evaluate agents in both individual and collective performance measures;\nand (iii) quantify the effect of the economic characteristics of the\nenvironments on the behavior of agents.\n","authors":["Eilam Shapira","Omer Madmon","Itamar Reinman","Samuel Joseph Amouyal","Roi Reichart","Moshe Tennenholtz"],"pdf_url":"https://arxiv.org/pdf/2410.05254v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.05252v1","updated":"2024-10-07T17:55:10Z","published":"2024-10-07T17:55:10Z","title":"Causal Micro-Narratives","summary":"  We present a novel approach to classify causal micro-narratives from text.\nThese narratives are sentence-level explanations of the cause(s) and/or\neffect(s) of a target subject. The approach requires only a subject-specific\nontology of causes and effects, and we demonstrate it with an application to\ninflation narratives. Using a human-annotated dataset spanning historical and\ncontemporary US news articles for training, we evaluate several large language\nmodels (LLMs) on this multi-label classification task. The best-performing\nmodel--a fine-tuned Llama 3.1 8B--achieves F1 scores of 0.87 on narrative\ndetection and 0.71 on narrative classification. Comprehensive error analysis\nreveals challenges arising from linguistic ambiguity and highlights how model\nerrors often mirror human annotator disagreements. This research establishes a\nframework for extracting causal micro-narratives from real-world data, with\nwide-ranging applications to social science research.\n","authors":["Mourad Heddaya","Qingcheng Zeng","Chenhao Tan","Rob Voigt","Alexander Zentefis"],"pdf_url":"https://arxiv.org/pdf/2410.05252v1.pdf","comment":"Accepted to EMNLP 2024 Workshop on Narrative Understanding"},{"id":"http://arxiv.org/abs/2410.05248v1","updated":"2024-10-07T17:52:21Z","published":"2024-10-07T17:52:21Z","title":"SFTMix: Elevating Language Model Instruction Tuning with Mixup Recipe","summary":"  To induce desired behaviors in large language models (LLMs) for\ninteraction-driven tasks, the instruction-tuning stage typically trains LLMs on\ninstruction-response pairs using the next-token prediction (NTP) loss. Previous\nwork aiming to improve instruction-tuning performance often emphasizes the need\nfor higher-quality supervised fine-tuning (SFT) datasets, which typically\ninvolves expensive data filtering with proprietary LLMs or labor-intensive data\ngeneration by human annotators. However, these approaches do not fully leverage\nthe datasets' intrinsic properties, resulting in high computational and labor\ncosts, thereby limiting scalability and performance gains. In this paper, we\npropose SFTMix, a novel recipe that elevates instruction-tuning performance\nbeyond the conventional NTP paradigm, without the need for well-curated\ndatasets. Observing that LLMs exhibit uneven confidence across the semantic\nrepresentation space, we argue that examples with different confidence levels\nshould play distinct roles during the instruction-tuning process. Based on this\ninsight, SFTMix leverages training dynamics to identify examples with varying\nconfidence levels, then applies a Mixup-based regularization to mitigate\noverfitting on confident examples while propagating supervision signals to\nimprove learning on relatively unconfident ones. This approach enables SFTMix\nto significantly outperform NTP across a wide range of instruction-following\nand healthcare domain-specific SFT tasks, demonstrating its adaptability to\ndiverse LLM families and scalability to datasets of any size. Comprehensive\nablation studies further verify the robustness of SFTMix's design choices,\nunderscoring its versatility in consistently enhancing performance across\ndifferent LLMs and datasets in broader natural language processing\napplications.\n","authors":["Yuxin Xiao","Shujian Zhang","Wenxuan Zhou","Marzyeh Ghassemi","Sanqiang Zhao"],"pdf_url":"https://arxiv.org/pdf/2410.05248v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17975v2","updated":"2024-10-07T17:49:13Z","published":"2024-06-25T23:12:07Z","title":"SoK: Membership Inference Attacks on LLMs are Rushing Nowhere (and How\n  to Fix It)","summary":"  Whether LLMs memorize their training data and what this means, from privacy\nleakage to detecting copyright violations -- has become a rapidly growing area\nof research over the last two years. In recent months, more than 10 new methods\nhave been proposed to perform Membership Inference Attacks (MIAs) against LLMs.\nContrary to traditional MIAs which rely on fixed -- but randomized -- records\nor models, these methods are mostly evaluated on datasets collected post-hoc.\nSets of members and non-members, used to evaluate the MIA, are constructed\nusing informed guesses after the release of a model. This lack of randomization\nraises concerns of a distribution shift between members and non-members. In the\nfirst part, we review the literature on MIAs against LLMs. While most work\nfocuses on sequence-level MIAs evaluated in post-hoc setups, we show that a\nrange of target models, motivations and units of interest have been considered\nin the literature. We then quantify distribution shifts present in the 6\ndatasets used in the literature, ranging from books to papers, using a bag of\nword classifier. Our analysis reveals that all of them suffer from severe\ndistribution shifts. This challenges the validity of using such setups to\nmeasure LLM memorization and may undermine the benchmarking of recently\nproposed methods. Yet, all hope might not be lost. In the second part, we\nintroduce important considerations to properly evaluate MIAs against LLMs and\ndiscuss potential ways forward: randomized test splits, injections of\nrandomized (unique) sequences, randomized finetuning, and post-hoc control\nmethods. While each option comes with its advantages and limitations, we\nbelieve they collectively provide solid grounds to guide the development of MIA\nmethods and study LLM memorization. We conclude by proposing comprehensive,\neasy-to-use benchmarks for sequence- and document-level MIAs against LLMs.\n","authors":["Matthieu Meeus","Igor Shilov","Shubham Jain","Manuel Faysse","Marek Rei","Yves-Alexandre de Montjoye"],"pdf_url":"https://arxiv.org/pdf/2406.17975v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.05233v1","updated":"2024-10-07T17:41:10Z","published":"2024-10-07T17:41:10Z","title":"SimO Loss: Anchor-Free Contrastive Loss for Fine-Grained Supervised\n  Contrastive Learning","summary":"  We introduce a novel anchor-free contrastive learning (AFCL) method\nleveraging our proposed Similarity-Orthogonality (SimO) loss. Our approach\nminimizes a semi-metric discriminative loss function that simultaneously\noptimizes two key objectives: reducing the distance and orthogonality between\nembeddings of similar inputs while maximizing these metrics for dissimilar\ninputs, facilitating more fine-grained contrastive learning. The AFCL method,\npowered by SimO loss, creates a fiber bundle topological structure in the\nembedding space, forming class-specific, internally cohesive yet orthogonal\nneighborhoods. We validate the efficacy of our method on the CIFAR-10 dataset,\nproviding visualizations that demonstrate the impact of SimO loss on the\nembedding space. Our results illustrate the formation of distinct, orthogonal\nclass neighborhoods, showcasing the method's ability to create well-structured\nembeddings that balance class separation with intra-class variability. This\nwork opens new avenues for understanding and leveraging the geometric\nproperties of learned representations in various machine learning tasks.\n","authors":["Taha Bouhsine","Imad El Aaroussi","Atik Faysal","Wang Huaxia"],"pdf_url":"https://arxiv.org/pdf/2410.05233v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.05232v1","updated":"2024-10-07T17:40:51Z","published":"2024-10-07T17:40:51Z","title":"SymmetryLens: A new candidate paradigm for unsupervised symmetry\n  learning via locality and equivariance","summary":"  We develop a new, unsupervised symmetry learning method that starts with raw\ndata, and gives the minimal (discrete) generator of an underlying Lie group of\nsymmetries, together with a symmetry equivariant representation of the data.\nThe method is able to learn the pixel translation operator from a dataset with\nonly an approximate translation symmetry, and can learn quite different types\nof symmetries which are not apparent to the naked eye, equally well. The method\nis based on the formulation of an information-theoretic loss function that\nmeasures both the degree to which the dataset is symmetric under a given\ncandidate symmetry, and also, the degree of locality of the samples in the\ndataset with respect to this symmetry. We demonstrate that this coupling\nbetween symmetry and locality, together with a special optimization technique\ndeveloped for entropy estimation, results in a highly stable system that gives\nreproducible results. The symmetry actions we consider are group\nrepresentations, however, we believe the approach has the potential to be\ngeneralized to more general, nonlinear actions of non-commutative Lie groups.\n","authors":["Onur Efe","Arkadas Ozakin"],"pdf_url":"https://arxiv.org/pdf/2410.05232v1.pdf","comment":"27 pages"},{"id":"http://arxiv.org/abs/2312.00700v4","updated":"2024-10-07T17:40:32Z","published":"2023-12-01T16:33:57Z","title":"Generative Parameter-Efficient Fine-Tuning","summary":"  We present Generative Parameter-Efficient Fine-Tuning (GIFT) for adapting\npretrained Transformer backbones on downstream tasks. GIFT learns to generate\nthe fine-tuned weights for a layer directly from its pretrained weights. The\nGIFT network is parameterized in a minimally-simple way by two linear layers\n(without bias terms), and is shared by different pretrained layers selected for\nfine-tuning (e.g., the Query layers), which result in significantly fewer\ntrainable parameters compared to the layer-specific methods like Low-Rank\nAdapter (LoRA). We also show this formulation bridges parameter-efficient\nfine-tuning and representation fine-tuning. We perform comprehensive\nexperiments on natural language tasks (commonsense and arithmetic reasoning,\ninstruction tuning, and sequence classification) and computer vision tasks\n(fine-grained classification). We obtain the best performance and parameter\nefficiency among baselines on commonsense and arithmetic reasoning, and\ninstruction following using the Llama family of models and on visual\nrecognition benchmarks using Vision Transformers. Notably, compared to LoRA, we\nobtain 5.7% absolute increase in average accuracy with 14 times reduction of\nparameters on Commonsense170k using Llama-3 (8B), and 5.4% absolute increase in\nthe win rate with 4 times reduction of parameters using Llama-2 (7B) during\ninstruction tuning. Our GIFT also obtains a slightly higher win rate on\ninstruction tuning than GPT 3.5 (Turbo 1106).\n","authors":["Chinmay Savadikar","Xi Song","Tianfu Wu"],"pdf_url":"https://arxiv.org/pdf/2312.00700v4.pdf","comment":"Project page and code: https://savadikarc.github.io/gift"},{"id":"http://arxiv.org/abs/2410.05229v1","updated":"2024-10-07T17:36:37Z","published":"2024-10-07T17:36:37Z","title":"GSM-Symbolic: Understanding the Limitations of Mathematical Reasoning in\n  Large Language Models","summary":"  Recent advancements in Large Language Models (LLMs) have sparked interest in\ntheir formal reasoning capabilities, particularly in mathematics. The GSM8K\nbenchmark is widely used to assess the mathematical reasoning of models on\ngrade-school-level questions. While the performance of LLMs on GSM8K has\nsignificantly improved in recent years, it remains unclear whether their\nmathematical reasoning capabilities have genuinely advanced, raising questions\nabout the reliability of the reported metrics. To address these concerns, we\nconduct a large-scale study on several SOTA open and closed models. To overcome\nthe limitations of existing evaluations, we introduce GSM-Symbolic, an improved\nbenchmark created from symbolic templates that allow for the generation of a\ndiverse set of questions. GSM-Symbolic enables more controllable evaluations,\nproviding key insights and more reliable metrics for measuring the reasoning\ncapabilities of models.Our findings reveal that LLMs exhibit noticeable\nvariance when responding to different instantiations of the same question.\nSpecifically, the performance of all models declines when only the numerical\nvalues in the question are altered in the GSM-Symbolic benchmark. Furthermore,\nwe investigate the fragility of mathematical reasoning in these models and show\nthat their performance significantly deteriorates as the number of clauses in a\nquestion increases. We hypothesize that this decline is because current LLMs\ncannot perform genuine logical reasoning; they replicate reasoning steps from\ntheir training data. Adding a single clause that seems relevant to the question\ncauses significant performance drops (up to 65%) across all state-of-the-art\nmodels, even though the clause doesn't contribute to the reasoning chain needed\nfor the final answer. Overall, our work offers a more nuanced understanding of\nLLMs' capabilities and limitations in mathematical reasoning.\n","authors":["Iman Mirzadeh","Keivan Alizadeh","Hooman Shahrokhi","Oncel Tuzel","Samy Bengio","Mehrdad Farajtabar"],"pdf_url":"https://arxiv.org/pdf/2410.05229v1.pdf","comment":"preprint"},{"id":"http://arxiv.org/abs/2410.05225v1","updated":"2024-10-07T17:31:52Z","published":"2024-10-07T17:31:52Z","title":"ETGL-DDPG: A Deep Deterministic Policy Gradient Algorithm for Sparse\n  Reward Continuous Control","summary":"  We consider deep deterministic policy gradient (DDPG) in the context of\nreinforcement learning with sparse rewards. To enhance exploration, we\nintroduce a search procedure, \\emph{${\\epsilon}{t}$-greedy}, which generates\nexploratory options for exploring less-visited states. We prove that search\nusing $\\epsilon t$-greedy has polynomial sample complexity under mild MDP\nassumptions. To more efficiently use the information provided by rewarded\ntransitions, we develop a new dual experience replay buffer framework,\n\\emph{GDRB}, and implement \\emph{longest n-step returns}. The resulting\nalgorithm, \\emph{ETGL-DDPG}, integrates all three techniques: \\bm{$\\epsilon\nt$}-greedy, \\textbf{G}DRB, and \\textbf{L}ongest $n$-step, into DDPG. We\nevaluate ETGL-DDPG on standard benchmarks and demonstrate that it outperforms\nDDPG, as well as other state-of-the-art methods, across all tested\nsparse-reward continuous environments. Ablation studies further highlight how\neach strategy individually enhances the performance of DDPG in this setting.\n","authors":["Ehsan Futuhi","Shayan Karimi","Chao Gao","Martin Müller"],"pdf_url":"https://arxiv.org/pdf/2410.05225v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.05224v1","updated":"2024-10-07T17:29:40Z","published":"2024-10-07T17:29:40Z","title":"Cookbook: A framework for improving LLM generative abilities via\n  programmatic data generating templates","summary":"  Fine-tuning large language models (LLMs) on instruction datasets is a common\nway to improve their generative capabilities. However, instruction datasets can\nbe expensive and time-consuming to manually curate, and while LLM-generated\ndata is less labor-intensive, it may violate user privacy agreements or terms\nof service of LLM providers. Therefore, we seek a way of constructing\ninstruction datasets with samples that are not generated by humans or LLMs but\nstill improve LLM generative capabilities. In this work, we introduce Cookbook,\na framework that programmatically generates training data consisting of simple\npatterns over random tokens, resulting in a scalable, cost-effective approach\nthat avoids legal and privacy issues. First, Cookbook uses a template -- a data\ngenerating Python function -- to produce training data that encourages the\nmodel to learn an explicit pattern-based rule that corresponds to a desired\ntask. We find that fine-tuning on Cookbook-generated data is able to improve\nperformance on its corresponding task by up to 52.7 accuracy points. Second,\nsince instruction datasets improve performance on multiple downstream tasks\nsimultaneously, Cookbook algorithmically learns how to mix data from various\ntemplates to optimize performance on multiple tasks. On the standard multi-task\nGPT4ALL evaluation suite, Mistral-7B fine-tuned using a Cookbook-generated\ndataset attains the best accuracy on average compared to other 7B parameter\ninstruction-tuned models and is the best performing model on 3 out of 8 tasks.\nFinally, we analyze when and why Cookbook improves performance and present a\nmetric that allows us to verify that the improvement is largely explained by\nthe model's generations adhering better to template rules.\n","authors":["Avanika Narayan","Mayee F. Chen","Kush Bhatia","Christopher Ré"],"pdf_url":"https://arxiv.org/pdf/2410.05224v1.pdf","comment":"COLM 2024"},{"id":"http://arxiv.org/abs/2406.13356v2","updated":"2024-10-07T17:27:30Z","published":"2024-06-19T09:03:21Z","title":"Jogging the Memory of Unlearned LLMs Through Targeted Relearning Attack","summary":"  Machine unlearning is a promising approach to mitigate undesirable\nmemorization of training data in LLMs. However, in this work we show that\nexisting approaches for unlearning in LLMs are surprisingly susceptible to a\nsimple set of targeted relearning attacks. With access to only a small and\npotentially loosely related set of data, we find that we can \"jog\" the memory\nof unlearned models to reverse the effects of unlearning. For example, we show\nthat relearning on public medical articles can lead an unlearned LLM to output\nharmful knowledge about bioweapons, and relearning general wiki information\nabout the book series Harry Potter can force the model to output verbatim\nmemorized text. We formalize this unlearning-relearning pipeline, explore the\nattack across three popular unlearning benchmarks, and discuss future\ndirections and guidelines that result from our study.\n","authors":["Shengyuan Hu","Yiwei Fu","Zhiwei Steven Wu","Virginia Smith"],"pdf_url":"https://arxiv.org/pdf/2406.13356v2.pdf","comment":"26 pages, 5 figures, 7 tables"},{"id":"http://arxiv.org/abs/2310.13391v3","updated":"2024-10-07T17:27:21Z","published":"2023-10-20T10:03:14Z","title":"Learning Successor Features with Distributed Hebbian Temporal Memory","summary":"  This paper presents a novel approach to address the challenge of online\ntemporal memory learning for decision-making under uncertainty in\nnon-stationary, partially observable environments. The proposed algorithm,\nDistributed Hebbian Temporal Memory (DHTM), is based on factor graph formalism\nand a multicomponent neuron model. DHTM aims to capture sequential data\nrelationships and make cumulative predictions about future observations,\nforming Successor Features (SF). Inspired by neurophysiological models of the\nneocortex, the algorithm utilizes distributed representations, sparse\ntransition matrices, and local Hebbian-like learning rules to overcome the\ninstability and slow learning process of traditional temporal memory algorithms\nlike RNN and HMM. Experimental results demonstrate that DHTM outperforms LSTM\nand a biologically inspired HMM-like algorithm, CSCG, in the case of\nnon-stationary datasets. Our findings suggest that DHTM is a promising approach\nfor addressing the challenges of online sequence learning and planning in\ndynamic environments.\n","authors":["Evgenii Dzhivelikian","Petr Kuderov","Aleksandr I. Panov"],"pdf_url":"https://arxiv.org/pdf/2310.13391v3.pdf","comment":"20 pages, 7 figures"},{"id":"http://arxiv.org/abs/2410.05222v1","updated":"2024-10-07T17:26:31Z","published":"2024-10-07T17:26:31Z","title":"Precise Model Benchmarking with Only a Few Observations","summary":"  How can we precisely estimate a large language model's (LLM) accuracy on\nquestions belonging to a specific topic within a larger question-answering\ndataset? The standard direct estimator, which averages the model's accuracy on\nthe questions in each subgroup, may exhibit high variance for subgroups\n(topics) with small sample sizes. Synthetic regression modeling, which\nleverages the model's accuracy on questions about other topics, may yield\nbiased estimates that are too unreliable for large subgroups. We prescribe a\nsimple yet effective solution: an empirical Bayes (EB) estimator that balances\ndirect and regression estimates for each subgroup separately, improving the\nprecision of subgroup-level estimates of model performance. Our experiments on\nmultiple datasets show that this approach consistently provides more precise\nestimates of the LLM performance compared to the direct and regression\napproaches, achieving substantial reductions in the mean squared error.\nConfidence intervals for EB estimates also have near-nominal coverage and are\nnarrower compared to those for the direct estimator. Additional experiments on\ntabular and vision data validate the benefits of this EB approach.\n","authors":["Riccardo Fogliato","Pratik Patil","Nil-Jana Akpinar","Mathew Monfort"],"pdf_url":"https://arxiv.org/pdf/2410.05222v1.pdf","comment":"To appear at EMNLP 2024"},{"id":"http://arxiv.org/abs/2405.08704v2","updated":"2024-10-07T17:23:25Z","published":"2024-05-14T15:42:55Z","title":"Full Line Code Completion: Bringing AI to Desktop","summary":"  In recent years, several industrial solutions for the problem of multi-token\ncode completion appeared, each making a great advance in the area but mostly\nfocusing on cloud-based runtime and avoiding working on the end user's device.\n  In this work, we describe our approach for building a multi-token code\ncompletion feature for the JetBrains' IntelliJ Platform, which we call Full\nLine Code Completion. The feature suggests only syntactically correct code and\nworks fully locally, i.e., data querying and the generation of suggestions\nhappens on the end user's machine. We share important time and\nmemory-consumption restrictions, as well as design principles that a code\ncompletion engine should satisfy. Working entirely on the end user's device,\nour code completion engine enriches user experience while being not only fast\nand compact but also secure. We share a number of useful techniques to meet the\nstated development constraints and also describe offline and online evaluation\npipelines that allowed us to make better decisions.\n  Our online evaluation shows that the usage of the tool leads to 1.3 times\nmore Python code in the IDE being produced by code completion. The described\nsolution was initially started with a help of researchers and was then bundled\ninto all JetBrains IDEs where it is now used by millions of users. Thus, we\nbelieve that this work is useful for bridging academia and industry, providing\nresearchers with the knowledge of what happens when complex research-based\nsolutions are integrated into real products.\n","authors":["Anton Semenkin","Vitaliy Bibaev","Yaroslav Sokolov","Kirill Krylov","Alexey Kalina","Anna Khannanova","Danila Savenkov","Darya Rovdo","Igor Davidenko","Kirill Karnaukhov","Maxim Vakhrushev","Mikhail Kostyukov","Mikhail Podvitskii","Petr Surkov","Yaroslav Golubev","Nikita Povarov","Timofey Bryksin"],"pdf_url":"https://arxiv.org/pdf/2405.08704v2.pdf","comment":"12 pages, 4 figures"},{"id":"http://arxiv.org/abs/2410.05218v1","updated":"2024-10-07T17:22:56Z","published":"2024-10-07T17:22:56Z","title":"Density estimation with LLMs: a geometric investigation of in-context\n  learning trajectories","summary":"  Large language models (LLMs) demonstrate remarkable emergent abilities to\nperform in-context learning across various tasks, including time series\nforecasting. This work investigates LLMs' ability to estimate probability\ndensity functions (PDFs) from data observed in-context; such density estimation\n(DE) is a fundamental task underlying many probabilistic modeling problems. We\nleverage the Intensive Principal Component Analysis (InPCA) to visualize and\nanalyze the in-context learning dynamics of LLaMA-2 models. Our main finding is\nthat these LLMs all follow similar learning trajectories in a low-dimensional\nInPCA space, which are distinct from those of traditional density estimation\nmethods like histograms and Gaussian kernel density estimation (KDE). We\ninterpret the LLaMA in-context DE process as a KDE with an adaptive kernel\nwidth and shape. This custom kernel model captures a significant portion of\nLLaMA's behavior despite having only two parameters. We further speculate on\nwhy LLaMA's kernel width and shape differs from classical algorithms, providing\ninsights into the mechanism of in-context probabilistic reasoning in LLMs.\n","authors":["Toni J. B. Liu","Nicolas Boullé","Raphaël Sarfati","Christopher J. Earls"],"pdf_url":"https://arxiv.org/pdf/2410.05218v1.pdf","comment":"Under review as a conference paper at ICLR 2025"},{"id":"http://arxiv.org/abs/2312.05516v3","updated":"2024-10-07T17:21:57Z","published":"2023-12-09T09:55:07Z","title":"Stateful Large Language Model Serving with Pensieve","summary":"  Large Language Models (LLMs) are wildly popular today and it is important to\nserve them efficiently. Existing LLM serving systems are stateless across\nrequests. Consequently, when LLMs are used in the common setting of multi-turn\nconversations, a growing log of the conversation history must be processed\nalongside any request by the serving system at each turn, resulting in repeated\nprocessing.\n  In this paper, we design $Pensieve$, a system optimized for multi-turn\nconversation LLM serving. $Pensieve$ maintains the conversation state across\nrequests by caching previously processed history to avoid duplicate processing.\n$Pensieve$'s multi-tier caching strategy can utilize both GPU and CPU memory to\nefficiently store and retrieve cached data. $Pensieve$ also generalizes the\nrecent PagedAttention kernel to support attention between multiple input tokens\nwith a GPU cache spread over non-contiguous memory. Our evaluation shows that\n$Pensieve$ can achieve $1.14$-$3.0\\times$ the throughput of vLLM and\nTensorRT-LLM and significantly reduce latency.\n","authors":["Lingfan Yu","Jinkun Lin","Jinyang Li"],"pdf_url":"https://arxiv.org/pdf/2312.05516v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.02476v2","updated":"2024-10-07T17:15:37Z","published":"2024-10-03T13:35:08Z","title":"Online Convex Optimization with a Separation Oracle","summary":"  In this paper, we introduce a new projection-free algorithm for Online Convex\nOptimization (OCO) with a state-of-the-art regret guarantee among\nseparation-based algorithms. Existing projection-free methods based on the\nclassical Frank-Wolfe algorithm achieve a suboptimal regret bound of\n$O(T^{3/4})$, while more recent separation-based approaches guarantee a regret\nbound of $O(\\kappa \\sqrt{T})$, where $\\kappa$ denotes the asphericity of the\nfeasible set, defined as the ratio of the radii of the containing and contained\nballs. However, for ill-conditioned sets, $\\kappa$ can be arbitrarily large,\npotentially leading to poor performance. Our algorithm achieves a regret bound\nof $\\widetilde{O}(\\sqrt{dT} + \\kappa d)$, while requiring only\n$\\widetilde{O}(1)$ calls to a separation oracle per round. Crucially, the main\nterm in the bound, $\\widetilde{O}(\\sqrt{d T})$, is independent of $\\kappa$,\naddressing the limitations of previous methods. Additionally, as a by-product\nof our analysis, we recover the $O(\\kappa \\sqrt{T})$ regret bound of existing\nOCO algorithms with a more straightforward analysis and improve the regret\nbound for projection-free online exp-concave optimization. Finally, for\nconstrained stochastic convex optimization, we achieve a state-of-the-art\nconvergence rate of $\\widetilde{O}(\\sigma/\\sqrt{T} + \\kappa d/T)$, where\n$\\sigma$ represents the noise in the stochastic gradients, while requiring only\n$\\widetilde{O}(1)$ calls to a separation oracle per iteration.\n","authors":["Zakaria Mhammedi"],"pdf_url":"https://arxiv.org/pdf/2410.02476v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.02844v2","updated":"2024-10-07T17:12:15Z","published":"2024-10-03T13:57:08Z","title":"CAnDOIT: Causal Discovery with Observational and Interventional Data\n  from Time-Series","summary":"  The study of cause-and-effect is of the utmost importance in many branches of\nscience, but also for many practical applications of intelligent systems. In\nparticular, identifying causal relationships in situations that include hidden\nfactors is a major challenge for methods that rely solely on observational data\nfor building causal models. This paper proposes CAnDOIT, a causal discovery\nmethod to reconstruct causal models using both observational and interventional\ntime-series data. The use of interventional data in the causal analysis is\ncrucial for real-world applications, such as robotics, where the scenario is\nhighly complex and observational data alone are often insufficient to uncover\nthe correct causal structure. Validation of the method is performed initially\non randomly generated synthetic models and subsequently on a well-known\nbenchmark for causal structure learning in a robotic manipulation environment.\nThe experiments demonstrate that the approach can effectively handle data from\ninterventions and exploit them to enhance the accuracy of the causal analysis.\nA Python implementation of CAnDOIT has also been developed and is publicly\navailable on GitHub: https://github.com/lcastri/causalflow.\n","authors":["Luca Castri","Sariah Mghames","Marc Hanheide","Nicola Bellotto"],"pdf_url":"https://arxiv.org/pdf/2410.02844v2.pdf","comment":"Published in Advanced Intelligent Systems"},{"id":"http://arxiv.org/abs/2410.05203v1","updated":"2024-10-07T17:07:21Z","published":"2024-10-07T17:07:21Z","title":"Beyond FVD: Enhanced Evaluation Metrics for Video Generation Quality","summary":"  The Fr\\'echet Video Distance (FVD) is a widely adopted metric for evaluating\nvideo generation distribution quality. However, its effectiveness relies on\ncritical assumptions. Our analysis reveals three significant limitations: (1)\nthe non-Gaussianity of the Inflated 3D Convnet (I3D) feature space; (2) the\ninsensitivity of I3D features to temporal distortions; (3) the impractical\nsample sizes required for reliable estimation. These findings undermine FVD's\nreliability and show that FVD falls short as a standalone metric for video\ngeneration evaluation. After extensive analysis of a wide range of metrics and\nbackbone architectures, we propose JEDi, the JEPA Embedding Distance, based on\nfeatures derived from a Joint Embedding Predictive Architecture, measured using\nMaximum Mean Discrepancy with polynomial kernel. Our experiments on multiple\nopen-source datasets show clear evidence that it is a superior alternative to\nthe widely used FVD metric, requiring only 16% of the samples to reach its\nsteady value, while increasing alignment with human evaluation by 34%, on\naverage.\n","authors":["Ge Ya"," Luo","Gian Favero","Zhi Hao Luo","Alexia Jolicoeur-Martineau","Christopher Pal"],"pdf_url":"https://arxiv.org/pdf/2410.05203v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.10302v2","updated":"2024-10-07T17:07:09Z","published":"2024-05-16T17:55:42Z","title":"Optimal Aggregation of Prediction Intervals under Unsupervised Domain\n  Shift","summary":"  As machine learning models are increasingly deployed in dynamic environments,\nit becomes paramount to assess and quantify uncertainties associated with\ndistribution shifts. A distribution shift occurs when the underlying\ndata-generating process changes, leading to a deviation in the model's\nperformance. The prediction interval, which captures the range of likely\noutcomes for a given prediction, serves as a crucial tool for characterizing\nuncertainties induced by their underlying distribution. In this paper, we\npropose methodologies for aggregating prediction intervals to obtain one with\nminimal width and adequate coverage on the target domain under unsupervised\ndomain shift, under which we have labeled samples from a related source domain\nand unlabeled covariates from the target domain. Our analysis encompasses\nscenarios where the source and the target domain are related via i) a bounded\ndensity ratio, and ii) a measure-preserving transformation. Our proposed\nmethodologies are computationally efficient and easy to implement. Beyond\nillustrating the performance of our method through real-world datasets, we also\ndelve into the theoretical details. This includes establishing rigorous\ntheoretical guarantees, coupled with finite sample bounds, regarding the\ncoverage and width of our prediction intervals. Our approach excels in\npractical applications and is underpinned by a solid theoretical framework,\nensuring its reliability and effectiveness across diverse contexts.\n","authors":["Jiawei Ge","Debarghya Mukherjee","Jianqing Fan"],"pdf_url":"https://arxiv.org/pdf/2405.10302v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.05192v1","updated":"2024-10-07T16:49:39Z","published":"2024-10-07T16:49:39Z","title":"Understanding Warmup-Stable-Decay Learning Rates: A River Valley Loss\n  Landscape Perspective","summary":"  Training language models currently requires pre-determining a fixed compute\nbudget because the typical cosine learning rate schedule depends on the total\nnumber of steps. In contrast, the Warmup-Stable-Decay (WSD) schedule uses a\nconstant learning rate to produce a main branch of iterates that can in\nprinciple continue indefinitely without a pre-specified compute budget. Then,\ngiven any compute budget, one can branch out from the main branch at a proper\nat any time with a rapidly decaying learning rate to produce a strong model.\nEmpirically, WSD generates a non-traditional loss curve: the loss remains\nelevated during the stable phase but sharply declines during the decay phase.\nTowards explaining this phenomenon, we conjecture that pretraining loss\nexhibits a river valley landscape, which resembles a deep valley with a river\nat its bottom. Under this assumption, we show that during the stable phase, the\niterate undergoes large oscillations due to the high learning rate, yet it\nprogresses swiftly along the river. During the decay phase, the rapidly\ndropping learning rate minimizes the iterate's oscillations, moving it closer\nto the river and revealing true optimization progress. Therefore, the sustained\nhigh learning rate phase and fast decaying phase are responsible for progress\nin the river and the mountain directions respectively, and are both critical.\nOur analysis predicts phenomenons consistent with empirical observations and\nshows that this landscape can emerge from pretraining on a simple bi-gram\ndataset. Inspired by the theory, we introduce WSD-S, a variant of WSD that\nreuses previous checkpoints' decay phases and keeps only one main branch, where\nwe resume from a decayed checkpoint. WSD-S empirically outperforms WSD and\nCyclic-Cosine in obtaining multiple language model checkpoints across various\ncompute budgets in a single run for parameters scaling from 0.1B to 1.2B.\n","authors":["Kaiyue Wen","Zhiyuan Li","Jason Wang","David Hall","Percy Liang","Tengyu Ma"],"pdf_url":"https://arxiv.org/pdf/2410.05192v1.pdf","comment":"45 pages,13 figures"},{"id":"http://arxiv.org/abs/2410.05188v1","updated":"2024-10-07T16:47:30Z","published":"2024-10-07T16:47:30Z","title":"Matrix-weighted networks for modeling multidimensional dynamics","summary":"  Networks are powerful tools for modeling interactions in complex systems.\nWhile traditional networks use scalar edge weights, many real-world systems\ninvolve multidimensional interactions. For example, in social networks,\nindividuals often have multiple interconnected opinions that can affect\ndifferent opinions of other individuals, which can be better characterized by\nmatrices. We propose a novel, general framework for modeling such\nmultidimensional interacting dynamics: matrix-weighted networks (MWNs). We\npresent the mathematical foundations of MWNs and examine consensus dynamics and\nrandom walks within this context. Our results reveal that the coherence of MWNs\ngives rise to non-trivial steady states that generalize the notions of\ncommunities and structural balance in traditional networks.\n","authors":["Yu Tian","Sadamori Kojaku","Hiroki Sayama","Renaud Lambiotte"],"pdf_url":"https://arxiv.org/pdf/2410.05188v1.pdf","comment":"14 pages, 8 figures"},{"id":"http://arxiv.org/abs/2407.18074v2","updated":"2024-10-07T16:46:42Z","published":"2024-07-25T14:28:58Z","title":"Principal-Agent Reinforcement Learning: Orchestrating AI Agents with\n  Contracts","summary":"  The increasing deployment of AI is shaping the future landscape of the\ninternet, which is set to become an integrated ecosystem of AI agents.\nOrchestrating the interaction among AI agents necessitates decentralized,\nself-sustaining mechanisms that harmonize the tension between individual\ninterests and social welfare. In this paper we tackle this challenge by\nsynergizing reinforcement learning with principal-agent theory from economics.\nTaken separately, the former allows unrealistic freedom of intervention, while\nthe latter struggles to scale in sequential settings. Combining them achieves\nthe best of both worlds. We propose a framework where a principal guides an\nagent in a Markov Decision Process (MDP) using a series of contracts, which\nspecify payments by the principal based on observable outcomes of the agent's\nactions. We present and analyze a meta-algorithm that iteratively optimizes the\npolicies of the principal and agent, showing its equivalence to a contraction\noperator on the principal's Q-function, and its convergence to subgame-perfect\nequilibrium. We then scale our algorithm with deep Q-learning and analyze its\nconvergence in the presence of approximation error, both theoretically and\nthrough experiments with randomly generated binary game-trees. Extending our\nframework to multiple agents, we apply our methodology to the combinatorial\nCoin Game. Addressing this multi-agent sequential social dilemma is a promising\nfirst step toward scaling our approach to more complex, real-world instances.\n","authors":["Dima Ivanov","Paul Dütting","Inbal Talgam-Cohen","Tonghan Wang","David C. Parkes"],"pdf_url":"https://arxiv.org/pdf/2407.18074v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.00099v4","updated":"2024-10-07T16:45:42Z","published":"2024-04-30T18:00:02Z","title":"Creative Beam Search: LLM-as-a-Judge For Improving Response Generation","summary":"  Large language models are revolutionizing several areas, including artificial\ncreativity. However, the process of generation in machines profoundly diverges\nfrom that observed in humans. In particular, machine generation is\ncharacterized by a lack of intentionality and an underlying creative process.\nWe propose a method called Creative Beam Search that uses Diverse Beam Search\nand LLM-as-a-Judge to perform response generation and response validation. The\nresults of a qualitative experiment show how our approach can provide better\noutput than standard sampling techniques. We also show that the response\nvalidation step is a necessary complement to the response generation step.\n","authors":["Giorgio Franceschelli","Mirco Musolesi"],"pdf_url":"https://arxiv.org/pdf/2405.00099v4.pdf","comment":"Presented as a short paper at the 15th International Conference on\n  Computational Creativity (ICCC'24)"},{"id":"http://arxiv.org/abs/2410.03098v2","updated":"2024-10-07T16:41:49Z","published":"2024-10-04T02:47:49Z","title":"Forest Proximities for Time Series","summary":"  RF-GAP has recently been introduced as an improved random forest proximity\nmeasure. In this paper, we present PF-GAP, an extension of RF-GAP proximities\nto proximity forests, an accurate and efficient time series classification\nmodel. We use the forest proximities in connection with Multi-Dimensional\nScaling to obtain vector embeddings of univariate time series, comparing the\nembeddings to those obtained using various time series distance measures. We\nalso use the forest proximities alongside Local Outlier Factors to investigate\nthe connection between misclassified points and outliers, comparing with\nnearest neighbor classifiers which use time series distance measures. We show\nthat the forest proximities may exhibit a stronger connection between\nmisclassified points and outliers than nearest neighbor classifiers.\n","authors":["Ben Shaw","Jake Rhodes","Soukaina Filali Boubrahimi","Kevin R. Moon"],"pdf_url":"https://arxiv.org/pdf/2410.03098v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.05182v1","updated":"2024-10-07T16:41:45Z","published":"2024-10-07T16:41:45Z","title":"MARs: Multi-view Attention Regularizations for Patch-based Feature\n  Recognition of Space Terrain","summary":"  The visual detection and tracking of surface terrain is required for\nspacecraft to safely land on or navigate within close proximity to celestial\nobjects. Current approaches rely on template matching with pre-gathered\npatch-based features, which are expensive to obtain and a limiting factor in\nperceptual capability. While recent literature has focused on in-situ detection\nmethods to enhance navigation and operational autonomy, robust description is\nstill needed. In this work, we explore metric learning as the lightweight\nfeature description mechanism and find that current solutions fail to address\ninter-class similarity and multi-view observational geometry. We attribute this\nto the view-unaware attention mechanism and introduce Multi-view Attention\nRegularizations (MARs) to constrain the channel and spatial attention across\nmultiple feature views, regularizing the what and where of attention focus. We\nthoroughly analyze many modern metric learning losses with and without MARs and\ndemonstrate improved terrain-feature recognition performance by upwards of 85%.\nWe additionally introduce the Luna-1 dataset, consisting of Moon crater\nlandmarks and reference navigation frames from NASA mission data to support\nfuture research in this difficult task. Luna-1 and source code are publicly\navailable at https://droneslab.github.io/mars/.\n","authors":["Timothy Chase Jr","Karthik Dantu"],"pdf_url":"https://arxiv.org/pdf/2410.05182v1.pdf","comment":"ECCV 2024. Project page available at\n  https://droneslab.github.io/mars/"},{"id":"http://arxiv.org/abs/2407.13493v3","updated":"2024-10-07T16:40:25Z","published":"2024-07-18T13:23:16Z","title":"Training Foundation Models as Data Compression: On Information, Model\n  Weights and Copyright Law","summary":"  The training process of foundation models as for other classes of deep\nlearning systems is based on minimizing the reconstruction error over a\ntraining set. For this reason, they are susceptible to the memorization and\nsubsequent reproduction of training samples. In this paper, we introduce a\ntraining-as-compressing perspective, wherein the model's weights embody a\ncompressed representation of the training data. From a copyright standpoint,\nthis point of view implies that the weights could be considered a reproduction\nor a derivative work of a potentially protected set of works. We investigate\nthe technical and legal challenges that emerge from this framing of the\ncopyright of outputs generated by foundation models, including their\nimplications for practitioners and researchers. We demonstrate that adopting an\ninformation-centric approach to the problem presents a promising pathway for\ntackling these emerging complex legal issues.\n","authors":["Giorgio Franceschelli","Claudia Cevenini","Mirco Musolesi"],"pdf_url":"https://arxiv.org/pdf/2407.13493v3.pdf","comment":"Spotlight presentation at GenLaw'24, see\n  https://www.genlaw.org/2024-icml-papers#training-foundation-models-as-data-compression-on-information-model-weights-and-copyright-law"},{"id":"http://arxiv.org/abs/2410.02381v2","updated":"2024-10-07T16:39:24Z","published":"2024-10-03T11:01:25Z","title":"MetaMetrics: Calibrating Metrics For Generation Tasks Using Human\n  Preferences","summary":"  Understanding the quality of a performance evaluation metric is crucial for\nensuring that model outputs align with human preferences. However, it remains\nunclear how well each metric captures the diverse aspects of these preferences,\nas metrics often excel in one particular area but not across all dimensions. To\naddress this, it is essential to systematically calibrate metrics to specific\naspects of human preference, catering to the unique characteristics of each\naspect. We introduce MetaMetrics, a calibrated meta-metric designed to evaluate\ngeneration tasks across different modalities in a supervised manner.\nMetaMetrics optimizes the combination of existing metrics to enhance their\nalignment with human preferences. Our metric demonstrates flexibility and\neffectiveness in both language and vision downstream tasks, showing significant\nbenefits across various multilingual and multi-domain scenarios. MetaMetrics\naligns closely with human preferences and is highly extendable and easily\nintegrable into any application. This makes MetaMetrics a powerful tool for\nimproving the evaluation of generation tasks, ensuring that metrics are more\nrepresentative of human judgment across diverse contexts.\n","authors":["Genta Indra Winata","David Anugraha","Lucky Susanto","Garry Kuwanto","Derry Tanti Wijaya"],"pdf_url":"https://arxiv.org/pdf/2410.02381v2.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2409.05928v3","updated":"2024-10-07T16:37:56Z","published":"2024-09-09T09:26:48Z","title":"Machine Learning Based Optimal Design of Fibrillar Adhesives","summary":"  Fibrillar adhesion, observed in animals like beetles, spiders, and geckos,\nrelies on nanoscopic or microscopic fibrils to enhance surface adhesion via\n'contact splitting.' This concept has inspired engineering applications across\nrobotics, transportation, and medicine. Recent studies suggest that functional\ngrading of fibril properties can improve adhesion, but this is a complex design\nchallenge that has only been explored in simplified geometries. While machine\nlearning (ML) has gained traction in adhesive design, no previous attempts have\ntargeted fibril-array scale optimization. In this study, we propose an ML-based\ntool that optimizes the distribution of fibril compliance to maximize adhesive\nstrength. Our tool, featuring two deep neural networks (DNNs), recovers\nprevious design results for simple geometries and introduces novel solutions\nfor complex configurations. The Predictor DNN estimates adhesive strength based\non random compliance distributions, while the Designer DNN optimizes compliance\nfor maximum strength using gradient-based optimization. Our method\nsignificantly reduces test error and accelerates the optimization process,\noffering a high-performance solution for designing fibrillar adhesives and\nmicro-architected materials aimed at fracture resistance by achieving equal\nload sharing (ELS).\n","authors":["Mohammad Shojaeifard","Matteo Ferraresso","Alessandro Lucantonio","Mattia Bacca"],"pdf_url":"https://arxiv.org/pdf/2409.05928v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.05177v1","updated":"2024-10-07T16:37:35Z","published":"2024-10-07T16:37:35Z","title":"Are causal effect estimations enough for optimal recommendations under\n  multitreatment scenarios?","summary":"  When making treatment selection decisions, it is essential to include a\ncausal effect estimation analysis to compare potential outcomes under different\ntreatments or controls, assisting in optimal selection. However, merely\nestimating individual treatment effects may not suffice for truly optimal\ndecisions. Our study addressed this issue by incorporating additional criteria,\nsuch as the estimations' uncertainty, measured by the conditional\nvalue-at-risk, commonly used in portfolio and insurance management. For\ncontinuous outcomes observable before and after treatment, we incorporated a\nspecific prediction condition. We prioritized treatments that could yield\noptimal treatment effect results and lead to post-treatment outcomes more\ndesirable than pretreatment levels, with the latter condition being called the\nprediction criterion. With these considerations, we propose a comprehensive\nmethodology for multitreatment selection. Our approach ensures satisfaction of\nthe overlap assumption, crucial for comparing outcomes for treated and control\ngroups, by training propensity score models as a preliminary step before\nemploying traditional causal models. To illustrate a practical application of\nour methodology, we applied it to the credit card limit adjustment problem.\nAnalyzing a fintech company's historical data, we found that relying solely on\ncounterfactual predictions was inadequate for appropriate credit line\nmodifications. Incorporating our proposed additional criteria significantly\nenhanced policy performance.\n","authors":["Sherly Alfonso-Sánchez","Kristina P. Sendova","Cristián Bravo"],"pdf_url":"https://arxiv.org/pdf/2410.05177v1.pdf","comment":"34 pages, 4 figures"},{"id":"http://arxiv.org/abs/2404.02151v3","updated":"2024-10-07T16:35:15Z","published":"2024-04-02T17:58:27Z","title":"Jailbreaking Leading Safety-Aligned LLMs with Simple Adaptive Attacks","summary":"  We show that even the most recent safety-aligned LLMs are not robust to\nsimple adaptive jailbreaking attacks. First, we demonstrate how to successfully\nleverage access to logprobs for jailbreaking: we initially design an\nadversarial prompt template (sometimes adapted to the target LLM), and then we\napply random search on a suffix to maximize a target logprob (e.g., of the\ntoken \"Sure\"), potentially with multiple restarts. In this way, we achieve 100%\nattack success rate -- according to GPT-4 as a judge -- on Vicuna-13B,\nMistral-7B, Phi-3-Mini, Nemotron-4-340B, Llama-2-Chat-7B/13B/70B,\nLlama-3-Instruct-8B, Gemma-7B, GPT-3.5, GPT-4o, and R2D2 from HarmBench that\nwas adversarially trained against the GCG attack. We also show how to jailbreak\nall Claude models -- that do not expose logprobs -- via either a transfer or\nprefilling attack with a 100% success rate. In addition, we show how to use\nrandom search on a restricted set of tokens for finding trojan strings in\npoisoned models -- a task that shares many similarities with jailbreaking --\nwhich is the algorithm that brought us the first place in the SaTML'24 Trojan\nDetection Competition. The common theme behind these attacks is that adaptivity\nis crucial: different models are vulnerable to different prompting templates\n(e.g., R2D2 is very sensitive to in-context learning prompts), some models have\nunique vulnerabilities based on their APIs (e.g., prefilling for Claude), and\nin some settings, it is crucial to restrict the token search space based on\nprior knowledge (e.g., for trojan detection). For reproducibility purposes, we\nprovide the code, logs, and jailbreak artifacts in the JailbreakBench format at\nhttps://github.com/tml-epfl/llm-adaptive-attacks.\n","authors":["Maksym Andriushchenko","Francesco Croce","Nicolas Flammarion"],"pdf_url":"https://arxiv.org/pdf/2404.02151v3.pdf","comment":"Updates in the v3: GPT-4o and Claude 3.5 Sonnet results, improved\n  writing. Updates in the v2: more models (Llama3, Phi-3, Nemotron-4-340B),\n  jailbreak artifacts for all attacks are available, evaluation with different\n  judges (Llama-3-70B and Llama Guard 2), more experiments (convergence plots\n  over iterations, ablation on the suffix length for random search), examples\n  of jailbroken generation"},{"id":"http://arxiv.org/abs/2310.09675v2","updated":"2024-10-07T16:28:52Z","published":"2023-10-14T22:24:26Z","title":"Efficient Model-Agnostic Multi-Group Equivariant Networks","summary":"  Constructing model-agnostic group equivariant networks, such as equitune\n(Basu et al., 2023b) and its generalizations (Kim et al., 2023), can be\ncomputationally expensive for large product groups. We address this problem by\nproviding efficient model-agnostic equivariant designs for two related\nproblems: one where the network has multiple inputs each with potentially\ndifferent groups acting on them, and another where there is a single input but\nthe group acting on it is a large product group. For the first design, we\ninitially consider a linear model and characterize the entire equivariant space\nthat satisfies this constraint. This characterization gives rise to a novel\nfusion layer between different channels that satisfies an invariance-symmetry\n(IS) constraint, which we call an IS layer. We then extend this design beyond\nlinear models, similar to equitune, consisting of equivariant and IS layers. We\nalso show that the IS layer is a universal approximator of invariant-symmetric\nfunctions. Inspired by the first design, we use the notion of the IS property\nto design a second efficient model-agnostic equivariant design for large\nproduct groups acting on a single input. For the first design, we provide\nexperiments on multi-image classification where each view is transformed\nindependently with transformations such as rotations. We find equivariant\nmodels are robust to such transformations and perform competitively otherwise.\nFor the second design, we consider three applications: language\ncompositionality on the SCAN dataset to product groups; fairness in natural\nlanguage generation from GPT-2 to address intersectionality; and robust\nzero-shot image classification with CLIP. Overall, our methods are simple and\ngeneral, competitive with equitune and its variants, while also being\ncomputationally more efficient.\n","authors":["Razan Baltaji","Sourya Basu","Lav R. Varshney"],"pdf_url":"https://arxiv.org/pdf/2310.09675v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10054v2","updated":"2024-10-07T16:26:00Z","published":"2023-11-16T17:48:55Z","title":"When \"A Helpful Assistant\" Is Not Really Helpful: Personas in System\n  Prompts Do Not Improve Performances of Large Language Models","summary":"  Prompting serves as the major way humans interact with Large Language Models\n(LLM). Commercial AI systems commonly define the role of the LLM in system\nprompts. For example, ChatGPT uses \"You are a helpful assistant\" as part of its\ndefault system prompt. Despite current practices of adding personas to system\nprompts, it remains unclear how different personas affect a model's performance\non objective tasks. In this study, we present a systematic evaluation of\npersonas in system prompts. We curate a list of 162 roles covering 6 types of\ninterpersonal relationships and 8 domains of expertise. Through extensive\nanalysis of 4 popular families of LLMs and 2,410 factual questions, we\ndemonstrate that adding personas in system prompts does not improve model\nperformance across a range of questions compared to the control setting where\nno persona is added. Nevertheless, further analysis suggests that the gender,\ntype, and domain of the persona can all influence the resulting prediction\naccuracies. We further experimented with a list of persona search strategies\nand found that, while aggregating results from the best persona for each\nquestion significantly improves prediction accuracy, automatically identifying\nthe best persona is challenging, with predictions often performing no better\nthan random selection. Overall, our findings suggest that while adding a\npersona may lead to performance gains in certain settings, the effect of each\npersona can be largely random. Code and data are available at\nhttps://github.com/Jiaxin-Pei/Prompting-with-Social-Roles.\n","authors":["Mingqian Zheng","Jiaxin Pei","Lajanugen Logeswaran","Moontae Lee","David Jurgens"],"pdf_url":"https://arxiv.org/pdf/2311.10054v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.10207v2","updated":"2024-10-07T16:25:34Z","published":"2024-07-14T14:01:38Z","title":"Learning to Steer Markovian Agents under Model Uncertainty","summary":"  Designing incentives for an adapting population is a ubiquitous problem in a\nwide array of economic applications and beyond. In this work, we study how to\ndesign additional rewards to steer multi-agent systems towards desired policies\n\\emph{without} prior knowledge of the agents' underlying learning dynamics.\nMotivated by the limitation of existing works, we consider a new and general\ncategory of learning dynamics called \\emph{Markovian agents}. We introduce a\nmodel-based non-episodic Reinforcement Learning (RL) formulation for our\nsteering problem. Importantly, we focus on learning a \\emph{history-dependent}\nsteering strategy to handle the inherent model uncertainty about the agents'\nlearning dynamics. We introduce a novel objective function to encode the\ndesiderata of achieving a good steering outcome with reasonable cost.\nTheoretically, we identify conditions for the existence of steering strategies\nto guide agents to the desired policies. Complementing our theoretical\ncontributions, we provide empirical algorithms to approximately solve our\nobjective, which effectively tackles the challenge in learning\nhistory-dependent strategies. We demonstrate the efficacy of our algorithms\nthrough empirical evaluations.\n","authors":["Jiawei Huang","Vinzenz Thoma","Zebang Shen","Heinrich H. Nax","Niao He"],"pdf_url":"https://arxiv.org/pdf/2407.10207v2.pdf","comment":"34 Pages"},{"id":"http://arxiv.org/abs/2403.18681v2","updated":"2024-10-07T16:25:02Z","published":"2024-03-27T15:24:54Z","title":"Deep Fusion: Capturing Dependencies in Contrastive Learning via\n  Transformer Projection Heads","summary":"  Contrastive Learning (CL) has emerged as a powerful method for training\nfeature extraction models using unlabeled data. Recent studies suggest that\nincorporating a linear projection head post-backbone significantly enhances\nmodel performance. In this work, we investigate the use of a transformer model\nas a projection head within the CL framework, aiming to exploit the\ntransformer's capacity for capturing long-range dependencies across embeddings\nto further improve performance. Our key contributions are fourfold: First, we\nintroduce a novel application of transformers in the projection head role for\ncontrastive learning, marking the first endeavor of its kind. Second, our\nexperiments reveal a compelling \"Deep Fusion\" phenomenon where the attention\nmechanism progressively captures the correct relational dependencies among\nsamples from the same class in deeper layers. Third, we provide a theoretical\nframework that explains and supports this \"Deep Fusion\" behavior. Finally, we\ndemonstrate through experimental results that our model achieves superior\nperformance compared to the existing approach of using a feed-forward layer.\n","authors":["Huanran Li","Daniel Pimentel-Alarcón"],"pdf_url":"https://arxiv.org/pdf/2403.18681v2.pdf","comment":"10 pages, 2 figures"},{"id":"http://arxiv.org/abs/2410.05167v1","updated":"2024-10-07T16:24:18Z","published":"2024-10-07T16:24:18Z","title":"Presto! Distilling Steps and Layers for Accelerating Music Generation","summary":"  Despite advances in diffusion-based text-to-music (TTM) methods, efficient,\nhigh-quality generation remains a challenge. We introduce Presto!, an approach\nto inference acceleration for score-based diffusion transformers via reducing\nboth sampling steps and cost per step. To reduce steps, we develop a new\nscore-based distribution matching distillation (DMD) method for the EDM-family\nof diffusion models, the first GAN-based distillation method for TTM. To reduce\nthe cost per step, we develop a simple, but powerful improvement to a recent\nlayer distillation method that improves learning via better preserving hidden\nstate variance. Finally, we combine our step and layer distillation methods\ntogether for a dual-faceted approach. We evaluate our step and layer\ndistillation methods independently and show each yield best-in-class\nperformance. Our combined distillation method can generate high-quality outputs\nwith improved diversity, accelerating our base model by 10-18x (230/435ms\nlatency for 32 second mono/stereo 44.1kHz, 15x faster than comparable SOTA) --\nthe fastest high-quality TTM to our knowledge. Sound examples can be found at\nhttps://presto-music.github.io/web/.\n","authors":["Zachary Novack","Ge Zhu","Jonah Casebeer","Julian McAuley","Taylor Berg-Kirkpatrick","Nicholas J. Bryan"],"pdf_url":"https://arxiv.org/pdf/2410.05167v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.05109v2","updated":"2024-10-07T16:21:29Z","published":"2024-02-07T18:58:50Z","title":"Hydra: Sequentially-Dependent Draft Heads for Medusa Decoding","summary":"  To combat the memory bandwidth-bound nature of autoregressive LLM inference,\nprevious research has proposed the speculative decoding frame-work. To perform\nspeculative decoding, a small draft model proposes candidate continuations of\nthe input sequence that are then verified in parallel by the base model. One\nway to specify the draft model, as used in the recent Medusa decoding\nframework, is as a collection of lightweight heads, called draft heads, that\noperate on the base model's hidden states. To date, all existing draft heads\nhave been sequentially independent, meaning that they speculate tokens in the\ncandidate continuation independently of any preceding tokens in the candidate\ncontinuation. In this work, we propose Hydra heads: a sequentially-dependent\ndrop-in replacement for standard draft heads that significantly improves the\naccuracy of draft head speculation. We further explore the design space of\nHydra head training objectives and architectures, and propose a carefully tuned\nHydra head recipe, which we call Hydra++, that improves decoding throughput by\nup to 1.31x and 2.70x compared to Medusa decoding and autoregressive de-coding\nrespectively. Overall, Hydra heads are a simple and well-motivated intervention\non standard draft heads that significantly improve the end-to-end speed of\ndraft head-based speculative decoding. We make our code publicly available at\nhttps://github.com/zankner/Hydra.\n","authors":["Zachary Ankner","Rishab Parthasarathy","Aniruddha Nrusimha","Christopher Rinard","Jonathan Ragan-Kelley","William Brandon"],"pdf_url":"https://arxiv.org/pdf/2402.05109v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.06357v4","updated":"2024-10-07T16:19:17Z","published":"2024-02-09T12:07:06Z","title":"The SkipSponge Attack: Sponge Weight Poisoning of Deep Neural Networks","summary":"  Sponge attacks aim to increase the energy consumption and computation time of\nneural networks. In this work, we present a novel sponge attack called\nSkipSponge. SkipSponge is the first sponge attack that is performed directly on\nthe parameters of a pre-trained model using only a few data samples. Our\nexperiments show that SkipSponge can successfully increase the energy\nconsumption of image classification models, GANs, and autoencoders requiring\nfewer samples than the state-of-the-art (Sponge Poisoning). We show that\npoisoning defenses are ineffective if not adjusted specifically for the defense\nagainst SkipSponge (i.e., they decrease target layer bias values). Our work\nshows that SkipSponge is more effective on the GANs and the autoencoders than\nSponge Poisoning. Additionally, SkipSponge is stealthier than Sponge Poisoning\nas it does not require significant changes in the victim model's weights. Our\nexperiments indicate that SkipSponge can be performed even when an attacker has\naccess to only 1% of the entire dataset and reaches up to 13% energy increase.\n","authors":["Jona te Lintelo","Stefanos Koffas","Stjepan Picek"],"pdf_url":"https://arxiv.org/pdf/2402.06357v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.05163v1","updated":"2024-10-07T16:16:53Z","published":"2024-10-07T16:16:53Z","title":"A Simulation-Free Deep Learning Approach to Stochastic Optimal Control","summary":"  We propose a simulation-free algorithm for the solution of generic problems\nin stochastic optimal control (SOC). Unlike existing methods, our approach does\nnot require the solution of an adjoint problem, but rather leverages Girsanov\ntheorem to directly calculate the gradient of the SOC objective on-policy. This\nallows us to speed up the optimization of control policies parameterized by\nneural networks since it completely avoids the expensive back-propagation step\nthrough stochastic differential equations (SDEs) used in the Neural SDE\nframework. In particular, it enables us to solve SOC problems in high dimension\nand on long time horizons. We demonstrate the efficiency of our approach in\nvarious domains of applications, including standard stochastic optimal control\nproblems, sampling from unnormalized distributions via construction of a\nSchr\\\"odinger-F\\\"ollmer process, and fine-tuning of pre-trained diffusion\nmodels. In all cases our method is shown to outperform the existing methods in\nboth the computing time and memory efficiency.\n","authors":["Mengjian Hua","Matthieu Laurière","Eric Vanden-Eijnden"],"pdf_url":"https://arxiv.org/pdf/2410.05163v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.03986v6","updated":"2024-10-07T16:15:36Z","published":"2023-10-06T03:04:21Z","title":"Robust Multimodal Learning with Missing Modalities via\n  Parameter-Efficient Adaptation","summary":"  Multimodal learning seeks to utilize data from multiple sources to improve\nthe overall performance of downstream tasks. It is desirable for redundancies\nin the data to make multimodal systems robust to missing or corrupted\nobservations in some correlated modalities. However, we observe that the\nperformance of several existing multimodal networks significantly deteriorates\nif one or multiple modalities are absent at test time. To enable robustness to\nmissing modalities, we propose a simple and parameter-efficient adaptation\nprocedure for pretrained multimodal networks. In particular, we exploit\nmodulation of intermediate features to compensate for the missing modalities.\nWe demonstrate that such adaptation can partially bridge performance drop due\nto missing modalities and outperform independent, dedicated networks trained\nfor the available modality combinations in some cases. The proposed adaptation\nrequires extremely small number of parameters (e.g., fewer than 1% of the total\nparameters) and applicable to a wide range of modality combinations and tasks.\nWe conduct a series of experiments to highlight the missing modality robustness\nof our proposed method on five different multimodal tasks across seven\ndatasets. Our proposed method demonstrates versatility across various tasks and\ndatasets, and outperforms existing methods for robust multimodal learning with\nmissing modalities.\n","authors":["Md Kaykobad Reza","Ashley Prater-Bennette","M. Salman Asif"],"pdf_url":"https://arxiv.org/pdf/2310.03986v6.pdf","comment":"Accepted by IEEE Transactions on Pattern Analysis and Machine\n  Intelligence (TPAMI). 28 pages, 6 figures, 17 tables"},{"id":"http://arxiv.org/abs/2403.18699v2","updated":"2024-10-07T16:07:23Z","published":"2024-03-27T15:48:16Z","title":"Preventing Collapse in Contrastive Learning with Orthonormal Prototypes\n  (CLOP)","summary":"  Contrastive learning has emerged as a powerful method in deep learning,\nexcelling at learning effective representations through contrasting samples\nfrom different distributions. However, neural collapse, where embeddings\nconverge into a lower-dimensional space, poses a significant challenge,\nespecially in semi-supervised and self-supervised setups. In this paper, we\nfirst theoretically analyze the effect of large learning rates on contrastive\nlosses that solely rely on the cosine similarity metric, and derive a\ntheoretical bound to mitigate this collapse. {Building on these insights, we\npropose CLOP, a novel semi-supervised loss function designed to prevent neural\ncollapse by promoting the formation of orthogonal linear subspaces among class\nembeddings.} Unlike prior approaches that enforce a simplex ETF structure, CLOP\nfocuses on subspace separation, leading to more distinguishable embeddings.\nThrough extensive experiments on real and synthetic datasets, we demonstrate\nthat CLOP enhances performance, providing greater stability across different\nlearning rates and batch sizes.\n","authors":["Huanran Li","Manh Nguyen","Daniel Pimentel-Alarcón"],"pdf_url":"https://arxiv.org/pdf/2403.18699v2.pdf","comment":"17 pages, 8 figures"},{"id":"http://arxiv.org/abs/2309.15608v2","updated":"2024-10-07T16:05:53Z","published":"2023-09-27T12:15:05Z","title":"NoSENSE: Learned unrolled cardiac MRI reconstruction without explicit\n  sensitivity maps","summary":"  We present a novel learned image reconstruction method for accelerated\ncardiac MRI with multiple receiver coils based on deep convolutional neural\nnetworks (CNNs) and algorithm unrolling. In contrast to many existing learned\nMR image reconstruction techniques that necessitate coil-sensitivity map (CSM)\nestimation as a distinct network component, our proposed approach avoids\nexplicit CSM estimation. Instead, it implicitly captures and learns to exploit\nthe inter-coil relationships of the images. Our method consists of a series of\nnovel learned image and k-space blocks with shared latent information and\nadaptation to the acquisition parameters by feature-wise modulation (FiLM), as\nwell as coil-wise data-consistency (DC) blocks.\n  Our method achieved PSNR values of 34.89 and 35.56 and SSIM values of 0.920\nand 0.942 in the cine track and mapping track validation leaderboard of the\nMICCAI STACOM CMRxRecon Challenge, respectively, ranking 4th among different\nteams at the time of writing.\n  Code will be made available at https://github.com/fzimmermann89/CMRxRecon\n","authors":["Felix Frederik Zimmermann","Andreas Kofler"],"pdf_url":"https://arxiv.org/pdf/2309.15608v2.pdf","comment":"Accepted at MICCAI STACOM 2023"},{"id":"http://arxiv.org/abs/2405.14577v2","updated":"2024-10-07T16:01:49Z","published":"2024-05-23T13:51:55Z","title":"Representation noising effectively prevents harmful fine-tuning on LLMs","summary":"  Releasing open-source large language models (LLMs) presents a dual-use risk\nsince bad actors can easily fine-tune these models for harmful purposes. Even\nwithout the open release of weights, weight stealing and fine-tuning APIs make\nclosed models vulnerable to harmful fine-tuning attacks (HFAs). While safety\nmeasures like preventing jailbreaks and improving safety guardrails are\nimportant, such measures can easily be reversed through fine-tuning. In this\nwork, we propose Representation Noising (RepNoise), a defence mechanism that is\neffective even when attackers have access to the weights. RepNoise works by\nremoving information about harmful representations such that it is difficult to\nrecover them during fine-tuning. Importantly, our defence is also able to\ngeneralize across different subsets of harm that have not been seen during the\ndefence process as long as they are drawn from the same distribution of the\nattack set. Our method does not degrade the general capability of LLMs and\nretains the ability to train the model on harmless tasks. We provide empirical\nevidence that the effectiveness of our defence lies in its \"depth\": the degree\nto which information about harmful representations is removed across all layers\nof the LLM.\n","authors":["Domenic Rosati","Jan Wehner","Kai Williams","Łukasz Bartoszcze","David Atanasov","Robie Gonzales","Subhabrata Majumdar","Carsten Maple","Hassan Sajjad","Frank Rudzicz"],"pdf_url":"https://arxiv.org/pdf/2405.14577v2.pdf","comment":"Published in NeurIPs 2024"},{"id":"http://arxiv.org/abs/2410.05147v1","updated":"2024-10-07T16:00:27Z","published":"2024-10-07T16:00:27Z","title":"PAMLR: A Passive-Active Multi-Armed Bandit-Based Solution for LoRa\n  Channel Allocation","summary":"  Achieving low duty cycle operation in low-power wireless networks in urban\nenvironments is complicated by the complex and variable dynamics of external\ninterference and fading. We explore the use of reinforcement learning for\nachieving low power consumption for the task of optimal selection of channels.\nThe learning relies on a hybrid of passive channel sampling for dealing with\nexternal interference and active channel sampling for dealing with fading. Our\nsolution, Passive-Active Multi-armed bandit for LoRa (PAMLR, pronounced\n\"Pamela\"), balances the two types of samples to achieve energy-efficient\nchannel selection: active channel measurements are tuned to an appropriately\nlow level to update noise thresholds, and to compensate passive channel\nmeasurements are tuned to an appropriately high level for selecting the\ntop-most channels from channel exploration using the noise thresholds. The\nrates of both types of samples are adapted in response to channel dynamics.\nBased on extensive testing in multiple environments in different cities, we\nvalidate that PAMLR can maintain excellent communication quality, as\ndemonstrated by a low SNR regret compared to the optimal channel allocation\npolicy, while substantially minimizing the energy cost associated with channel\nmeasurements.\n","authors":["Jihoon Yun","Chengzhang Li","Anish Arora"],"pdf_url":"https://arxiv.org/pdf/2410.05147v1.pdf","comment":"10 pages"},{"id":"http://arxiv.org/abs/2406.14995v2","updated":"2024-10-07T15:59:03Z","published":"2024-06-21T09:14:11Z","title":"Differentiable and Learnable Wireless Simulation with Geometric\n  Transformers","summary":"  Modelling the propagation of electromagnetic wireless signals is critical for\ndesigning modern communication systems. Wireless ray tracing simulators model\nsignal propagation based on the 3D geometry and other scene parameters, but\ntheir accuracy is fundamentally limited by underlying modelling assumptions and\ncorrectness of parameters. In this work, we introduce Wi-GATr, a\nfully-learnable neural simulation surrogate designed to predict the channel\nobservations based on scene primitives (e.g., surface mesh, antenna position\nand orientation). Recognizing the inherently geometric nature of these\nprimitives, Wi-GATr leverages an equivariant Geometric Algebra Transformer that\noperates on a tokenizer specifically tailored for wireless simulation. We\nevaluate our approach on a range of tasks (i.e., signal strength and delay\nspread prediction, receiver localization, and geometry reconstruction) and find\nthat Wi-GATr is accurate, fast, sample-efficient, and robust to\nsymmetry-induced transformations. Remarkably, we find our results also\ntranslate well to the real world: Wi-GATr demonstrates more than 35% lower\nerror than hybrid techniques, and 70% lower error than a calibrated wireless\ntracer.\n","authors":["Thomas Hehn","Markus Peschl","Tribhuvanesh Orekondy","Arash Behboodi","Johann Brehmer"],"pdf_url":"https://arxiv.org/pdf/2406.14995v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.05108v2","updated":"2024-10-07T15:57:38Z","published":"2024-04-07T23:34:51Z","title":"Efficient Gradient Estimation of Variational Quantum Circuits with Lie\n  Algebraic Symmetries","summary":"  Hybrid quantum-classical optimization and learning strategies are among the\nmost promising approaches to harnessing quantum information or gaining a\nquantum advantage over classical methods. However, efficient estimation of the\ngradient of the objective function in such models remains a challenge due to\nseveral factors including the exponential dimensionality of the Hilbert spaces,\nand information loss of quantum measurements. In this work, we developed an\nefficient framework that makes the Hadamard test efficiently applicable to\ngradient estimation for a broad range of quantum systems, an advance that had\nbeen wanting from the outset. Under certain mild structural assumptions, the\ngradient is estimated with the measurement shots that scale logarithmically\nwith the number of parameters and with polynomial classical and quantum time.\nThis is an exponential reduction in the measurement cost and polynomial speed\nup in time compared to existing works. The structural assumptions are (1) the\ndimension of the dynamical Lie algebra is polynomial in the number of qubits,\nand (2) the observable has a bounded Hilbert-Schmidt norm.\n","authors":["Mohsen Heidari","Masih Mozakka","Wojciech Szpankowski"],"pdf_url":"https://arxiv.org/pdf/2404.05108v2.pdf","comment":"39 pages"},{"id":"http://arxiv.org/abs/2407.10930v2","updated":"2024-10-07T15:52:48Z","published":"2024-07-15T17:30:31Z","title":"Fine-Tuning and Prompt Optimization: Two Great Steps that Work Better\n  Together","summary":"  Natural Language Processing (NLP) systems are increasingly taking the form of\nsophisticated modular pipelines, e.g., Retrieval Augmented Generation (RAG),\nwhere each module may involve a distinct Language Model (LM) and an associated\nprompt template. These compound systems often lack intermediate labels or\ngradient flow to optimize each module, making their end-to-end optimization\nchallenging. Here we seek strategies to optimize both the module-level LM\nweights and the associated prompt templates of such systems to maximize a\ndownstream task metric. We propose for the first time combining the weight and\nprompt optimization strategies to optimize a modular LM pipeline by alternating\nbetween the two to get the same LM to teach itself. In experiments with\nmulti-hop QA, mathematical reasoning, and feature-based classification using\nmistral-7b, llama-2-7b, and llama-3-8b, these BetterTogether strategies\noptimizing the weights and prompts of a pipeline together outperform directly\noptimizing weights alone and prompts alone by up to 60% and 6%, respectively,\non average across LMs and tasks. BetterTogether optimizer is released in DSPy\nat http://dspy.ai\n","authors":["Dilara Soylu","Christopher Potts","Omar Khattab"],"pdf_url":"https://arxiv.org/pdf/2407.10930v2.pdf","comment":"EMNLP 2024"},{"id":"http://arxiv.org/abs/2410.05140v1","updated":"2024-10-07T15:50:30Z","published":"2024-10-07T15:50:30Z","title":"Tuning-Free Bilevel Optimization: New Algorithms and Convergence\n  Analysis","summary":"  Bilevel optimization has recently attracted considerable attention due to its\nabundant applications in machine learning problems. However, existing methods\nrely on prior knowledge of problem parameters to determine stepsizes, resulting\nin significant effort in tuning stepsizes when these parameters are unknown. In\nthis paper, we propose two novel tuning-free algorithms, D-TFBO and S-TFBO.\nD-TFBO employs a double-loop structure with stepsizes adaptively adjusted by\nthe \"inverse of cumulative gradient norms\" strategy. S-TFBO features a simpler\nfully single-loop structure that updates three variables simultaneously with a\ntheory-motivated joint design of adaptive stepsizes for all variables. We\nprovide a comprehensive convergence analysis for both algorithms and show that\nD-TFBO and S-TFBO respectively require $O(\\frac{1}{\\epsilon})$ and\n$O(\\frac{1}{\\epsilon}\\log^4(\\frac{1}{\\epsilon}))$ iterations to find an\n$\\epsilon$-accurate stationary point, (nearly) matching their well-tuned\ncounterparts using the information of problem parameters. Experiments on\nvarious problems show that our methods achieve performance comparable to\nexisting well-tuned approaches, while being more robust to the selection of\ninitial stepsizes. To the best of our knowledge, our methods are the first to\ncompletely eliminate the need for stepsize tuning, while achieving theoretical\nguarantees.\n","authors":["Yifan Yang","Hao Ban","Minhui Huang","Shiqian Ma","Kaiyi Ji"],"pdf_url":"https://arxiv.org/pdf/2410.05140v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.03853v5","updated":"2024-10-07T15:46:59Z","published":"2023-12-06T19:07:38Z","title":"Dr. Jekyll and Mr. Hyde: Two Faces of LLMs","summary":"  Recently, we have witnessed a rise in the use of Large Language Models\n(LLMs), especially in applications like chatbots. Safety mechanisms are\nimplemented to prevent improper responses from these chatbots. In this work, we\nbypass these measures for ChatGPT and Gemini by making them impersonate complex\npersonas with personality characteristics that are not aligned with a truthful\nassistant. First, we create elaborate biographies of these personas, which we\nthen use in a new session with the same chatbots. Our conversations then follow\na role-play style to elicit prohibited responses. Using personas, we show that\nprohibited responses are provided, making it possible to obtain unauthorized,\nillegal, or harmful information in both ChatGPT and Gemini. We also introduce\nseveral ways of activating such adversarial personas, showing that both\nchatbots are vulnerable to this attack. With the same principle, we introduce\ntwo defenses that push the model to interpret trustworthy personalities and\nmake it more robust against such attacks.\n","authors":["Matteo Gioele Collu","Tom Janssen-Groesbeek","Stefanos Koffas","Mauro Conti","Stjepan Picek"],"pdf_url":"https://arxiv.org/pdf/2312.03853v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.07917v3","updated":"2024-10-07T15:45:38Z","published":"2024-02-27T15:59:15Z","title":"A Neural-Evolutionary Algorithm for Autonomous Transit Network Design","summary":"  Planning a public transit network is a challenging optimization problem, but\nessential in order to realize the benefits of autonomous buses. We propose a\nnovel algorithm for planning networks of routes for autonomous buses. We first\ntrain a graph neural net model as a policy for constructing route networks, and\nthen use the policy as one of several mutation operators in a evolutionary\nalgorithm. We evaluate this algorithm on a standard set of benchmarks for\ntransit network design, and find that it outperforms the learned policy alone\nby up to 20% and a plain evolutionary algorithm approach by up to 53% on\nrealistic benchmark instances.\n","authors":["Andrew Holliday","Gregory Dudek"],"pdf_url":"https://arxiv.org/pdf/2403.07917v3.pdf","comment":"Copyright 2024 IEEE. Personal use of this material is permitted.\n  Permission from IEEE must be obtained for all other uses, in any current or\n  future media, including reprinting/republishing this material for advertising\n  or promotional purposes, creating new collective works, for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component of\n  this work in other works. arXiv admin note: text overlap with\n  arXiv:2306.00720"},{"id":"http://arxiv.org/abs/2410.05136v1","updated":"2024-10-07T15:43:28Z","published":"2024-10-07T15:43:28Z","title":"LOTOS: Layer-wise Orthogonalization for Training Robust Ensembles","summary":"  Transferability of adversarial examples is a well-known property that\nendangers all classification models, even those that are only accessible\nthrough black-box queries. Prior work has shown that an ensemble of models is\nmore resilient to transferability: the probability that an adversarial example\nis effective against most models of the ensemble is low. Thus, most ongoing\nresearch focuses on improving ensemble diversity. Another line of prior work\nhas shown that Lipschitz continuity of the models can make models more robust\nsince it limits how a model's output changes with small input perturbations. In\nthis paper, we study the effect of Lipschitz continuity on transferability\nrates. We show that although a lower Lipschitz constant increases the\nrobustness of a single model, it is not as beneficial in training robust\nensembles as it increases the transferability rate of adversarial examples\nacross models in the ensemble. Therefore, we introduce LOTOS, a new training\nparadigm for ensembles, which counteracts this adverse effect. It does so by\npromoting orthogonality among the top-$k$ sub-spaces of the transformations of\nthe corresponding affine layers of any pair of models in the ensemble. We\ntheoretically show that $k$ does not need to be large for convolutional layers,\nwhich makes the computational overhead negligible. Through various experiments,\nwe show LOTOS increases the robust accuracy of ensembles of ResNet-18 models by\n$6$ percentage points (p.p) against black-box attacks on CIFAR-10. It is also\ncapable of combining with the robustness of prior state-of-the-art methods for\ntraining robust ensembles to enhance their robust accuracy by $10.7$ p.p.\n","authors":["Ali Ebrahimpour-Boroojeny","Hari Sundaram","Varun Chandrasekaran"],"pdf_url":"https://arxiv.org/pdf/2410.05136v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.05133v1","updated":"2024-10-07T15:36:50Z","published":"2024-10-07T15:36:50Z","title":"A Digital Twin Framework for Liquid-cooled Supercomputers as\n  Demonstrated at Exascale","summary":"  We present ExaDigiT, an open-source framework for developing comprehensive\ndigital twins of liquid-cooled supercomputers. It integrates three main\nmodules: (1) a resource allocator and power simulator, (2) a transient\nthermo-fluidic cooling model, and (3) an augmented reality model of the\nsupercomputer and central energy plant. The framework enables the study of\n\"what-if\" scenarios, system optimizations, and virtual prototyping of future\nsystems. Using Frontier as a case study, we demonstrate the framework's\ncapabilities by replaying six months of system telemetry for systematic\nverification and validation. Such a comprehensive analysis of a liquid-cooled\nexascale supercomputer is the first of its kind. ExaDigiT elucidates complex\ntransient cooling system dynamics, runs synthetic or real workloads, and\npredicts energy losses due to rectification and voltage conversion. Throughout\nour paper, we present lessons learned to benefit HPC practitioners developing\nsimilar digital twins. We envision the digital twin will be a key enabler for\nsustainable, energy-efficient supercomputing.\n","authors":["Wesley Brewer","Matthias Maiterth","Vineet Kumar","Rafal Wojda","Sedrick Bouknight","Jesse Hines","Woong Shin","Scott Greenwood","David Grant","Wesley Williams","Feiyi Wang"],"pdf_url":"https://arxiv.org/pdf/2410.05133v1.pdf","comment":"14 pages, 9 figures, To be published in the Proceedings of the\n  International Conference for High Performance Computing, Networking, Storage\n  and Analysis. 2024"},{"id":"http://arxiv.org/abs/2406.16424v2","updated":"2024-10-07T15:33:37Z","published":"2024-06-24T08:18:19Z","title":"Memory-Enhanced Neural Solvers for Efficient Adaptation in Combinatorial\n  Optimization","summary":"  Combinatorial Optimization is crucial to numerous real-world applications,\nyet still presents challenges due to its (NP-)hard nature. Amongst existing\napproaches, heuristics often offer the best trade-off between quality and\nscalability, making them suitable for industrial use. While Reinforcement\nLearning (RL) offers a flexible framework for designing heuristics, its\nadoption over handcrafted heuristics remains incomplete within industrial\nsolvers. Existing learned methods still lack the ability to adapt to specific\ninstances and fully leverage the available computational budget. The current\nbest methods either rely on a collection of pre-trained policies, or on\ndata-inefficient fine-tuning; hence failing to fully utilize newly available\ninformation within the constraints of the budget. In response, we present\nMEMENTO, an approach that leverages memory to improve the adaptation of neural\nsolvers at inference time. MEMENTO enables updating the action distribution\ndynamically based on the outcome of previous decisions. We validate its\neffectiveness on benchmark problems, in particular Traveling Salesman and\nCapacitated Vehicle Routing, demonstrating its superiority over tree-search and\npolicy-gradient fine-tuning; and showing it can be zero-shot combined with\ndiversity-based solvers. We successfully train all RL auto-regressive solvers\non large instances, and show that MEMENTO can scale and is data-efficient.\nOverall, MEMENTO enables to push the state-of-the-art on 11 out of 12 evaluated\ntasks.\n","authors":["Felix Chalumeau","Refiloe Shabe","Noah De Nicola","Arnu Pretorius","Thomas D. Barrett","Nathan Grinsztajn"],"pdf_url":"https://arxiv.org/pdf/2406.16424v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.12282v2","updated":"2024-10-07T15:29:14Z","published":"2024-04-18T15:58:31Z","title":"Investigating Guiding Information for Adaptive Collocation Point\n  Sampling in PINNs","summary":"  Physics-informed neural networks (PINNs) provide a means of obtaining\napproximate solutions of partial differential equations and systems through the\nminimisation of an objective function which includes the evaluation of a\nresidual function at a set of collocation points within the domain. The quality\nof a PINNs solution depends upon numerous parameters, including the number and\ndistribution of these collocation points. In this paper we consider a number of\nstrategies for selecting these points and investigate their impact on the\noverall accuracy of the method. In particular, we suggest that no single\napproach is likely to be \"optimal\" but we show how a number of important\nmetrics can have an impact in improving the quality of the results obtained\nwhen using a fixed number of residual evaluations. We illustrate these\napproaches through the use of two benchmark test problems: Burgers' equation\nand the Allen-Cahn equation.\n","authors":["Jose Florido","He Wang","Amirul Khan","Peter K. Jimack"],"pdf_url":"https://arxiv.org/pdf/2404.12282v2.pdf","comment":"15 pages, 8 figures, 2 tables. Published in the conference\n  proceedings of the International Conference on Computational Science (ICCS)\n  2024. Replacement to correct a typo regarding the value of viscosity listed\n  in the captions"},{"id":"http://arxiv.org/abs/2105.02135v4","updated":"2024-10-07T15:27:58Z","published":"2021-05-05T15:38:36Z","title":"UVIP: Model-Free Approach to Evaluate Reinforcement Learning Algorithms","summary":"  Policy evaluation is an important instrument for the comparison of different\nalgorithms in Reinforcement Learning (RL). Yet even a precise knowledge of the\nvalue function $V^{\\pi}$ corresponding to a policy $\\pi$ does not provide\nreliable information on how far is the policy $\\pi$ from the optimal one. We\npresent a novel model-free upper value iteration procedure $({\\sf UVIP})$ that\nallows us to estimate the suboptimality gap $V^{\\star}(x) - V^{\\pi}(x)$ from\nabove and to construct confidence intervals for $V^\\star$. Our approach relies\non upper bounds to the solution of the Bellman optimality equation via\nmartingale approach. We provide theoretical guarantees for ${\\sf UVIP}$ under\ngeneral assumptions and illustrate its performance on a number of benchmark RL\nproblems.\n","authors":["Ilya Levin","Denis Belomestny","Alexey Naumov","Sergey Samsonov"],"pdf_url":"https://arxiv.org/pdf/2105.02135v4.pdf","comment":"ICOMP-2024 camera-ready version"},{"id":"http://arxiv.org/abs/2410.05124v1","updated":"2024-10-07T15:25:21Z","published":"2024-10-07T15:25:21Z","title":"Agnostic Smoothed Online Learning","summary":"  Classical results in statistical learning typically consider two extreme\ndata-generating models: i.i.d. instances from an unknown distribution, or fully\nadversarial instances, often much more challenging statistically. To bridge the\ngap between these models, recent work introduced the smoothed framework, in\nwhich at each iteration an adversary generates instances from a distribution\nconstrained to have density bounded by $\\sigma^{-1}$ compared to some fixed\nbase measure $\\mu$. This framework interpolates between the i.i.d. and\nadversarial cases, depending on the value of $\\sigma$. For the classical online\nprediction problem, most prior results in smoothed online learning rely on the\narguably strong assumption that the base measure $\\mu$ is known to the learner,\ncontrasting with standard settings in the PAC learning or consistency\nliterature. We consider the general agnostic problem in which the base measure\nis unknown and values are arbitrary. Along this direction, Block et al. showed\nthat empirical risk minimization has sublinear regret under the well-specified\nassumption. We propose an algorithm R-Cover based on recursive coverings which\nis the first to guarantee sublinear regret for agnostic smoothed online\nlearning without prior knowledge of $\\mu$. For classification, we prove that\nR-Cover has adaptive regret $\\tilde O(\\sqrt{dT/\\sigma})$ for function classes\nwith VC dimension $d$, which is optimal up to logarithmic factors. For\nregression, we establish that R-Cover has sublinear oblivious regret for\nfunction classes with polynomial fat-shattering dimension growth.\n","authors":["Moïse Blanchard"],"pdf_url":"https://arxiv.org/pdf/2410.05124v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.00428v2","updated":"2024-10-07T15:24:10Z","published":"2024-10-01T06:23:17Z","title":"LayerKV: Optimizing Large Language Model Serving with Layer-wise KV\n  Cache Management","summary":"  The expanding context windows in large language models (LLMs) have greatly\nenhanced their capabilities in various applications, but they also introduce\nsignificant challenges in maintaining low latency, particularly in Time to\nFirst Token (TTFT). This paper identifies that the sharp rise in TTFT as\ncontext length increases is predominantly driven by queuing delays, which are\ncaused by the growing demands for GPU Key-Value (KV) cache allocation clashing\nwith the limited availability of KV cache blocks. To address this issue, we\npropose LayerKV, a simple yet effective plug-in method that effectively reduces\nTTFT without requiring additional hardware or compromising output performance,\nwhile seamlessly integrating with existing parallelism strategies and\nscheduling techniques. Specifically, LayerKV introduces layer-wise KV block\nallocation, management, and offloading for fine-grained control over system\nmemory, coupled with an SLO-aware scheduler to optimize overall Service Level\nObjectives (SLOs). Comprehensive evaluations on representative models, ranging\nfrom 7B to 70B parameters, across various GPU configurations, demonstrate that\nLayerKV improves TTFT latency up to 69x and reduces SLO violation rates by\n28.7%, significantly enhancing the user experience.\n","authors":["Yi Xiong","Hao Wu","Changxu Shao","Ziqing Wang","Rui Zhang","Yuhong Guo","Junping Zhao","Ke Zhang","Zhenxuan Pan"],"pdf_url":"https://arxiv.org/pdf/2410.00428v2.pdf","comment":"11 pages, 7 figures, 1 table"},{"id":"http://arxiv.org/abs/2401.03192v2","updated":"2024-10-07T15:21:37Z","published":"2024-01-06T11:13:16Z","title":"On the Convergence of Hermitian Dynamic Mode Decomposition","summary":"  We study the convergence of Hermitian Dynamic Mode Decomposition (DMD) to the\nspectral properties of self-adjoint Koopman operators. Hermitian DMD is a\ndata-driven method that approximates the Koopman operator associated with an\nunknown nonlinear dynamical system, using discrete-time snapshots. This\napproach preserves the self-adjointness of the operator in its\nfinite-dimensional approximations. \\rev{We prove that, under suitably broad\nconditions, the spectral measures corresponding to the eigenvalues and\neigenfunctions computed by Hermitian DMD converge to those of the underlying\nKoopman operator}. This result also applies to skew-Hermitian systems (after\nmultiplication by $i$), applicable to generators of continuous-time\nmeasure-preserving systems. Along the way, we establish a general theorem on\nthe convergence of spectral measures for finite sections of self-adjoint\noperators, including those that are unbounded, which is of independent interest\nto the wider spectral community. We numerically demonstrate our results by\napplying them to two-dimensional Schr\\\"odinger equations.\n","authors":["Nicolas Boullé","Matthew J. Colbrook"],"pdf_url":"https://arxiv.org/pdf/2401.03192v2.pdf","comment":"24 pages, 4 figures. arXiv admin note: text overlap with\n  arXiv:2312.00137"},{"id":"http://arxiv.org/abs/2410.05117v1","updated":"2024-10-07T15:14:58Z","published":"2024-10-07T15:14:58Z","title":"Assouad, Fano, and Le Cam with Interaction: A Unifying Lower Bound\n  Framework and Characterization for Bandit Learnability","summary":"  In this paper, we develop a unified framework for lower bound methods in\nstatistical estimation and interactive decision making. Classical lower bound\ntechniques -- such as Fano's inequality, Le Cam's method, and Assouad's lemma\n-- have been central to the study of minimax risk in statistical estimation,\nyet they are insufficient for the analysis of methods that collect data in an\ninteractive manner. The recent minimax lower bounds for interactive decision\nmaking via the Decision-Estimation Coefficient (DEC) appear to be genuinely\ndifferent from the classical methods. We propose a unified view of these\ndistinct methodologies through a general algorithmic lower bound method. We\nfurther introduce a novel complexity measure, decision dimension, which\nfacilitates the derivation of new lower bounds for interactive decision making.\nIn particular, decision dimension provides a characterization of bandit\nlearnability for any structured bandit model class. Further, we characterize\nthe sample complexity of learning convex model class up to a polynomial gap\nwith the decision dimension, addressing the remaining gap between upper and\nlower bounds in Foster et al. (2021, 2023).\n","authors":["Fan Chen","Dylan J. Foster","Yanjun Han","Jian Qian","Alexander Rakhlin","Yunbei Xu"],"pdf_url":"https://arxiv.org/pdf/2410.05117v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.05116v1","updated":"2024-10-07T15:12:01Z","published":"2024-10-07T15:12:01Z","title":"Human-Feedback Efficient Reinforcement Learning for Online Diffusion\n  Model Finetuning","summary":"  Controllable generation through Stable Diffusion (SD) fine-tuning aims to\nimprove fidelity, safety, and alignment with human guidance. Existing\nreinforcement learning from human feedback methods usually rely on predefined\nheuristic reward functions or pretrained reward models built on large-scale\ndatasets, limiting their applicability to scenarios where collecting such data\nis costly or difficult. To effectively and efficiently utilize human feedback,\nwe develop a framework, HERO, which leverages online human feedback collected\non the fly during model learning. Specifically, HERO features two key\nmechanisms: (1) Feedback-Aligned Representation Learning, an online training\nmethod that captures human feedback and provides informative learning signals\nfor fine-tuning, and (2) Feedback-Guided Image Generation, which involves\ngenerating images from SD's refined initialization samples, enabling faster\nconvergence towards the evaluator's intent. We demonstrate that HERO is 4x more\nefficient in online feedback for body part anomaly correction compared to the\nbest existing method. Additionally, experiments show that HERO can effectively\nhandle tasks like reasoning, counting, personalization, and reducing NSFW\ncontent with only 0.5K online feedback.\n","authors":["Ayano Hiranaka","Shang-Fu Chen","Chieh-Hsin Lai","Dongjun Kim","Naoki Murata","Takashi Shibuya","Wei-Hsiang Liao","Shao-Hua Sun","Yuki Mitsufuji"],"pdf_url":"https://arxiv.org/pdf/2410.05116v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.05107v1","updated":"2024-10-07T15:03:00Z","published":"2024-10-07T15:03:00Z","title":"Hyper-Representations: Learning from Populations of Neural Networks","summary":"  This thesis addresses the challenge of understanding Neural Networks through\nthe lens of their most fundamental component: the weights, which encapsulate\nthe learned information and determine the model behavior. At the core of this\nthesis is a fundamental question: Can we learn general, task-agnostic\nrepresentations from populations of Neural Network models? The key contribution\nof this thesis to answer that question are hyper-representations, a\nself-supervised method to learn representations of NN weights. Work in this\nthesis finds that trained NN models indeed occupy meaningful structures in the\nweight space, that can be learned and used. Through extensive experiments, this\nthesis demonstrates that hyper-representations uncover model properties, such\nas their performance, state of training, or hyperparameters. Moreover, the\nidentification of regions with specific properties in hyper-representation\nspace allows to sample and generate model weights with targeted properties.\nThis thesis demonstrates applications for fine-tuning, and transfer learning to\ngreat success. Lastly, it presents methods that allow hyper-representations to\ngeneralize beyond model sizes, architectures, and tasks. The practical\nimplications of that are profound, as it opens the door to foundation models of\nNeural Networks, which aggregate and instantiate their knowledge across models\nand architectures. Ultimately, this thesis contributes to the deeper\nunderstanding of Neural Networks by investigating structures in their weights\nwhich leads to more interpretable, efficient, and adaptable models. By laying\nthe groundwork for representation learning of NN weights, this research\ndemonstrates the potential to change the way Neural Networks are developed,\nanalyzed, and used.\n","authors":["Konstantin Schürholt"],"pdf_url":"https://arxiv.org/pdf/2410.05107v1.pdf","comment":"PhD Dissertation accepted at University of St. Gallen"},{"id":"http://arxiv.org/abs/2410.05106v1","updated":"2024-10-07T15:02:48Z","published":"2024-10-07T15:02:48Z","title":"Nonasymptotic Analysis of Stochastic Gradient Descent with the\n  Richardson-Romberg Extrapolation","summary":"  We address the problem of solving strongly convex and smooth minimization\nproblems using stochastic gradient descent (SGD) algorithm with a constant step\nsize. Previous works suggested to combine the Polyak-Ruppert averaging\nprocedure with the Richardson-Romberg extrapolation technique to reduce the\nasymptotic bias of SGD at the expense of a mild increase of the variance. We\nsignificantly extend previous results by providing an expansion of the\nmean-squared error of the resulting estimator with respect to the number of\niterations $n$. More precisely, we show that the mean-squared error can be\ndecomposed into the sum of two terms: a leading one of order\n$\\mathcal{O}(n^{-1/2})$ with explicit dependence on a minimax-optimal\nasymptotic covariance matrix, and a second-order term of order\n$\\mathcal{O}(n^{-3/4})$ where the power $3/4$ can not be improved in general.\nWe also extend this result to the $p$-th moment bound keeping optimal scaling\nof the remainders with respect to $n$. Our analysis relies on the properties of\nthe SGD iterates viewed as a time-homogeneous Markov chain. In particular, we\nestablish that this chain is geometrically ergodic with respect to a suitably\ndefined weighted Wasserstein semimetric.\n","authors":["Marina Sheshukova","Denis Belomestny","Alain Durmus","Eric Moulines","Alexey Naumov","Sergey Samsonov"],"pdf_url":"https://arxiv.org/pdf/2410.05106v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.15929v2","updated":"2024-10-07T15:01:48Z","published":"2024-02-24T23:16:57Z","title":"Decoding Intelligence: A Framework for Certifying Knowledge\n  Comprehension in LLMs","summary":"  Knowledge comprehension capability is an important aspect of human\nintelligence. As Large Language Models (LLMs) are being envisioned as\nsuperhuman agents, it is crucial for them to be proficient at knowledge\ncomprehension. However, existing benchmarking studies do not provide\nconsistent, generalizable, and formal guarantees on the knowledge comprehension\ncapabilities of LLMs. In this work, we propose the first framework to certify\nknowledge comprehension in LLMs with formal probabilistic guarantees. Our\ncertificates are quantitative -- they consist of high-confidence, tight bounds\non the probability that a target LLM gives the correct answer on any knowledge\ncomprehension prompt sampled from a distribution. We design and certify novel\nspecifications that precisely represent distributions of knowledge\ncomprehension prompts leveraging knowledge graphs. We certify SOTA LLMs for\nspecifications over the Wikidata5m knowledge graph. We find that the knowledge\ncomprehension capability improves significantly with scaling the size of the\nmodels.\n","authors":["Isha Chaudhary","Vedaant V. Jain","Gagandeep Singh"],"pdf_url":"https://arxiv.org/pdf/2402.15929v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.05102v1","updated":"2024-10-07T15:01:29Z","published":"2024-10-07T15:01:29Z","title":"SparsePO: Controlling Preference Alignment of LLMs via Sparse Token\n  Masks","summary":"  Preference Optimization (PO) has proven an effective step for aligning\nlanguage models to human-desired behaviors. Current variants, following the\noffline Direct Preference Optimization objective, have focused on a strict\nsetting where all tokens are contributing signals of KL divergence and rewards\nto the loss function. However, human preference is not affected by each word in\na sequence equally but is often dependent on specific words or phrases, e.g.\nexistence of toxic terms leads to non-preferred responses. Based on this\nobservation, we argue that not all tokens should be weighted equally during PO\nand propose a flexible objective termed SparsePO, that aims to automatically\nlearn to weight the KL divergence and reward corresponding to each token during\nPO training. We propose two different variants of weight-masks that can either\nbe derived from the reference model itself or learned on the fly. Notably, our\nmethod induces sparsity in the learned masks, allowing the model to learn how\nto best weight reward and KL divergence contributions at the token level,\nlearning an optimal level of mask sparsity. Extensive experiments on multiple\ndomains, including sentiment control, dialogue, text summarization and\ntext-to-code generation, illustrate that our approach assigns meaningful\nweights to tokens according to the target task, generates more responses with\nthe desired preference and improves reasoning tasks by up to 2 percentage\npoints compared to other token- and response-level PO methods.\n","authors":["Fenia Christopoulou","Ronald Cardenas","Gerasimos Lampouras","Haitham Bou-Ammar","Jun Wang"],"pdf_url":"https://arxiv.org/pdf/2410.05102v1.pdf","comment":"20 papges, 9 figures, 5 tables. Under Review"},{"id":"http://arxiv.org/abs/2410.05101v1","updated":"2024-10-07T14:56:07Z","published":"2024-10-07T14:56:07Z","title":"CR-CTC: Consistency regularization on CTC for improved speech\n  recognition","summary":"  Connectionist Temporal Classification (CTC) is a widely used method for\nautomatic speech recognition (ASR), renowned for its simplicity and\ncomputational efficiency. However, it often falls short in recognition\nperformance compared to transducer or systems combining CTC and attention-based\nencoder-decoder (CTC/AED). In this work, we propose the Consistency-Regularized\nCTC (CR-CTC), which enforces consistency between two CTC distributions obtained\nfrom different augmented views of the input speech mel-spectrogram. We provide\nin-depth insights into its essential behaviors from three perspectives: 1) it\nconducts self-distillation between random pairs of sub-models that process\ndifferent augmented views; 2) it learns contextual representation through\nmasked prediction for positions within time-masked regions, especially when we\nincrease the amount of time masking; 3) it suppresses the extremely peaky CTC\ndistributions, thereby reducing overfitting and improving the generalization\nability. Extensive experiments on LibriSpeech, Aishell-1, and GigaSpeech\ndatasets demonstrate the effectiveness of our CR-CTC, which achieves\nperformance comparable to, or even slightly better than, that of transducer and\nCTC/AED.\n","authors":["Zengwei Yao","Wei Kang","Xiaoyu Yang","Fangjun Kuang","Liyong Guo","Han Zhu","Zengrui Jin","Zhaoqing Li","Long Lin","Daniel Povey"],"pdf_url":"https://arxiv.org/pdf/2410.05101v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.19961v4","updated":"2024-10-07T14:54:18Z","published":"2024-05-30T11:32:42Z","title":"Transition Path Sampling with Improved Off-Policy Training of Diffusion\n  Path Samplers","summary":"  Understanding transition pathways between meta-stable states in molecular\nsystems is crucial to advance material design and drug discovery. However,\nunbiased molecular dynamics simulations are computationally infeasible due to\nthe high energy barriers separating these states. Although recent machine\nlearning techniques offer potential solutions, they are often limited to simple\nsystems or rely on collective variables (CVs) derived from costly domain\nexpertise. In this paper, we introduce a novel approach that trains diffusion\npath samplers (DPS) for transition path sampling (TPS) without the need for\nCVs. We recast the problem as an amortized sampling of the target path measure,\nminimizing the log-variance divergence between the path measure induced by our\nDPS and the target path measure. To ensure scalability for high-dimensional\ntasks, we introduce (1) a new off-policy training objective based on learning\ncontrol variates with replay buffers and (2) a scale-based equivariant\nparameterization of the bias forces. We evaluate our approach, coined TPS-DPS,\non a synthetic double-well potential and three peptides: Alanine Dipeptide,\nPolyproline Helix, and Chignolin. Results show that our approach produces more\nrealistic and diverse transition pathways compared to existing baselines.\n","authors":["Kiyoung Seong","Seonghyun Park","Seonghwan Kim","Woo Youn Kim","Sungsoo Ahn"],"pdf_url":"https://arxiv.org/pdf/2405.19961v4.pdf","comment":"10 pages, 8 figures, 1 tables"},{"id":"http://arxiv.org/abs/2410.05097v1","updated":"2024-10-07T14:51:54Z","published":"2024-10-07T14:51:54Z","title":"DreamSat: Towards a General 3D Model for Novel View Synthesis of Space\n  Objects","summary":"  Novel view synthesis (NVS) enables to generate new images of a scene or\nconvert a set of 2D images into a comprehensive 3D model. In the context of\nSpace Domain Awareness, since space is becoming increasingly congested, NVS can\naccurately map space objects and debris, improving the safety and efficiency of\nspace operations. Similarly, in Rendezvous and Proximity Operations missions,\n3D models can provide details about a target object's shape, size, and\norientation, allowing for better planning and prediction of the target's\nbehavior. In this work, we explore the generalization abilities of these\nreconstruction techniques, aiming to avoid the necessity of retraining for each\nnew scene, by presenting a novel approach to 3D spacecraft reconstruction from\nsingle-view images, DreamSat, by fine-tuning the Zero123 XL, a state-of-the-art\nsingle-view reconstruction model, on a high-quality dataset of 190 high-quality\nspacecraft models and integrating it into the DreamGaussian framework. We\ndemonstrate consistent improvements in reconstruction quality across multiple\nmetrics, including Contrastive Language-Image Pretraining (CLIP) score\n(+0.33%), Peak Signal-to-Noise Ratio (PSNR) (+2.53%), Structural Similarity\nIndex (SSIM) (+2.38%), and Learned Perceptual Image Patch Similarity (LPIPS)\n(+0.16%) on a test set of 30 previously unseen spacecraft images. Our method\naddresses the lack of domain-specific 3D reconstruction tools in the space\nindustry by leveraging state-of-the-art diffusion models and 3D Gaussian\nsplatting techniques. This approach maintains the efficiency of the\nDreamGaussian framework while enhancing the accuracy and detail of spacecraft\nreconstructions. The code for this work can be accessed on GitHub\n(https://github.com/ARCLab-MIT/space-nvs).\n","authors":["Nidhi Mathihalli","Audrey Wei","Giovanni Lavezzi","Peng Mun Siew","Victor Rodriguez-Fernandez","Hodei Urrutxua","Richard Linares"],"pdf_url":"https://arxiv.org/pdf/2410.05097v1.pdf","comment":"Presented at the 75th International Astronautical Congress, October\n  2024, Milan, Italy"},{"id":"http://arxiv.org/abs/2410.05090v1","updated":"2024-10-07T14:42:45Z","published":"2024-10-07T14:42:45Z","title":"HyperINF: Unleashing the HyperPower of the Schulz's Method for Data\n  Influence Estimation","summary":"  Influence functions provide a principled method to assess the contribution of\nindividual training samples to a specific target. Yet, their high computational\ncosts limit their applications on large-scale models and datasets. Existing\nmethods proposed for influence function approximation have significantly\nreduced the computational overheads. However, they mostly suffer from\ninaccurate estimation due to the lack of strong convergence guarantees from the\nalgorithm. The family of hyperpower methods are well-known for their rigorous\nconvergence guarantees on matrix inverse approximation, while the matrix\nmultiplication operation can involve intractable memory and computation costs\non large-scale models. We propose HyperINF, an efficient and accurate influence\nfunction approximation method which leverages the hyperpower method,\nspecifically Schulz's iterative algorithm.\n  To deal with the computation-intensive matrix multiplication, we incorporate\nthe generalized fisher information (GFIM) as a low-rank approximation of the\nHessian matrix, which reduces the memory and computation overheads to constant\ncosts independent of ranks on LoRA-tuned models.\n  We first demonstrate the superior accuracy and stability of \\method compared\nto other baselines through a synthetic convergence simulation for matrix\ninversion. We further validate the efficacy of \\method through extensive\nreal-world data attribution tasks, including mislabeled data detection and data\nselection for LLM and VLM fine-tuning.\n  On LoRA-tuned models, HyperINF achieves superior downstream performance with\nminimal memory and computational overhead, while other baselines suffer from\nsignificant degradation. Our codebase is available at\nhttps://github.com/Blackzxy/HyperINF.\n","authors":["Xinyu Zhou","Simin Fan","Martin Jaggi"],"pdf_url":"https://arxiv.org/pdf/2410.05090v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.14768v2","updated":"2024-10-07T14:35:14Z","published":"2024-05-23T16:35:52Z","title":"WISE: Rethinking the Knowledge Memory for Lifelong Model Editing of\n  Large Language Models","summary":"  Large language models (LLMs) need knowledge updates to meet the ever-growing\nworld facts and correct the hallucinated responses, facilitating the methods of\nlifelong model editing. Where the updated knowledge resides in memories is a\nfundamental question for model editing. In this paper, we find that editing\neither long-term memory (direct model parameters) or working memory\n(non-parametric knowledge of neural network activations/representations by\nretrieval) will result in an impossible triangle -- reliability,\ngeneralization, and locality can not be realized together in the lifelong\nediting settings. For long-term memory, directly editing the parameters will\ncause conflicts with irrelevant pretrained knowledge or previous edits (poor\nreliability and locality). For working memory, retrieval-based activations can\nhardly make the model understand the edits and generalize (poor\ngeneralization). Therefore, we propose WISE to bridge the gap between memories.\nIn WISE, we design a dual parametric memory scheme, which consists of the main\nmemory for the pretrained knowledge and a side memory for the edited knowledge.\nWe only edit the knowledge in the side memory and train a router to decide\nwhich memory to go through when given a query. For continual editing, we devise\na knowledge-sharding mechanism where different sets of edits reside in distinct\nsubspaces of parameters, and are subsequently merged into a shared memory\nwithout conflicts. Extensive experiments show that WISE can outperform previous\nmodel editing methods and overcome the impossible triangle under lifelong model\nediting of question answering, hallucination, and out-of-distribution settings\nacross trending LLM architectures, e.g., GPT, LLaMA, and Mistral. Code is\navailable at https://github.com/zjunlp/EasyEdit.\n","authors":["Peng Wang","Zexi Li","Ningyu Zhang","Ziwen Xu","Yunzhi Yao","Yong Jiang","Pengjun Xie","Fei Huang","Huajun Chen"],"pdf_url":"https://arxiv.org/pdf/2405.14768v2.pdf","comment":"NeurIPS 2024"},{"id":"http://arxiv.org/abs/2410.05080v1","updated":"2024-10-07T14:33:50Z","published":"2024-10-07T14:33:50Z","title":"ScienceAgentBench: Toward Rigorous Assessment of Language Agents for\n  Data-Driven Scientific Discovery","summary":"  The advancements of language language models (LLMs) have piqued growing\ninterest in developing LLM-based language agents to automate scientific\ndiscovery end-to-end, which has sparked both excitement and skepticism about\nthe true capabilities of such agents. In this work, we argue that for an agent\nto fully automate scientific discovery, it must be able to complete all\nessential tasks in the workflow. Thus, we call for rigorous assessment of\nagents on individual tasks in a scientific workflow before making bold claims\non end-to-end automation. To this end, we present ScienceAgentBench, a new\nbenchmark for evaluating language agents for data-driven scientific discovery.\nTo ensure the scientific authenticity and real-world relevance of our\nbenchmark, we extract 102 tasks from 44 peer-reviewed publications in four\ndisciplines and engage nine subject matter experts to validate them. We unify\nthe target output for every task to a self-contained Python program file and\nemploy an array of evaluation metrics to examine the generated programs,\nexecution results, and costs. Each task goes through multiple rounds of manual\nvalidation by annotators and subject matter experts to ensure its annotation\nquality and scientific plausibility. We also propose two effective strategies\nto mitigate data contamination concerns. Using our benchmark, we evaluate five\nopen-weight and proprietary LLMs, each with three frameworks: direct prompting,\nOpenHands, and self-debug. Given three attempts for each task, the\nbest-performing agent can only solve 32.4% of the tasks independently and 34.3%\nwith expert-provided knowledge. These results underscore the limited capacities\nof current language agents in generating code for data-driven discovery, let\nalone end-to-end automation for scientific research.\n","authors":["Ziru Chen","Shijie Chen","Yuting Ning","Qianheng Zhang","Boshi Wang","Botao Yu","Yifei Li","Zeyi Liao","Chen Wei","Zitong Lu","Vishal Dey","Mingyi Xue","Frazier N. Baker","Benjamin Burns","Daniel Adu-Ampratwum","Xuhui Huang","Xia Ning","Song Gao","Yu Su","Huan Sun"],"pdf_url":"https://arxiv.org/pdf/2410.05080v1.pdf","comment":"55 pages"},{"id":"http://arxiv.org/abs/2410.05078v1","updated":"2024-10-07T14:32:03Z","published":"2024-10-07T14:32:03Z","title":"Compression via Pre-trained Transformers: A Study on Byte-Level\n  Multimodal Data","summary":"  Foundation models have recently been shown to be strong data compressors.\nHowever, when accounting for their excessive parameter count, their compression\nratios are actually inferior to standard compression algorithms. Moreover,\nnaively reducing the number of parameters may not necessarily help as it leads\nto worse predictions and thus weaker compression. In this paper, we conduct a\nlarge-scale empirical study to investigate whether there is a sweet spot where\ncompetitive compression ratios with pre-trained vanilla transformers are\npossible. To this end, we train families of models on 165GB of raw byte\nsequences of either text, image, or audio data (and all possible combinations\nof the three) and then compress 1GB of out-of-distribution (OOD) data from each\nmodality. We find that relatively small models (i.e., millions of parameters)\ncan outperform standard general-purpose compression algorithms (gzip, LZMA2)\nand even domain-specific compressors (PNG, JPEG 2000, FLAC) - even when\nfactoring in parameter count. We achieve, e.g., the lowest compression ratio of\n0.49 on OOD audio data (vs. 0.54 for FLAC). To study the impact of model- and\ndataset scale, we conduct extensive ablations and hyperparameter sweeps, and we\ninvestigate the effect of unimodal versus multimodal training. We find that\neven small models can be trained to perform well on multiple modalities, but,\nin contrast to previously reported results with large-scale foundation models,\ntransfer to unseen modalities is generally weak.\n","authors":["David Heurtel-Depeiges","Anian Ruoss","Joel Veness","Tim Genewein"],"pdf_url":"https://arxiv.org/pdf/2410.05078v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.05076v1","updated":"2024-10-07T14:30:27Z","published":"2024-10-07T14:30:27Z","title":"TidalDecode: Fast and Accurate LLM Decoding with Position Persistent\n  Sparse Attention","summary":"  Large language models (LLMs) have driven significant advancements across\ndiverse NLP tasks, with long-context models gaining prominence for handling\nextended inputs. However, the expanding key-value (KV) cache size required by\nTransformer architectures intensifies the memory constraints, particularly\nduring the decoding phase, creating a significant bottleneck. Existing sparse\nattention mechanisms designed to address this bottleneck have two limitations:\n(1) they often fail to reliably identify the most relevant tokens for\nattention, and (2) they overlook the spatial coherence of token selection\nacross consecutive Transformer layers, which can lead to performance\ndegradation and substantial overhead in token selection. This paper introduces\nTidalDecode, a simple yet effective algorithm and system for fast and accurate\nLLM decoding through position persistent sparse attention. TidalDecode\nleverages the spatial coherence of tokens selected by existing sparse attention\nmethods and introduces a few token selection layers that perform full attention\nto identify the tokens with the highest attention scores, while all other\nlayers perform sparse attention with the pre-selected tokens. This design\nenables TidalDecode to substantially reduce the overhead of token selection for\nsparse attention without sacrificing the quality of the generated results.\nEvaluation on a diverse set of LLMs and tasks shows that TidalDecode closely\nmatches the generative performance of full attention methods while reducing the\nLLM decoding latency by up to 2.1x.\n","authors":["Lijie Yang","Zhihao Zhang","Zhuofu Chen","Zikun Li","Zhihao Jia"],"pdf_url":"https://arxiv.org/pdf/2410.05076v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.12034v2","updated":"2024-10-07T14:27:56Z","published":"2024-06-17T19:06:54Z","title":"Self-MoE: Towards Compositional Large Language Models with\n  Self-Specialized Experts","summary":"  We present Self-MoE, an approach that transforms a monolithic LLM into a\ncompositional, modular system of self-specialized experts, named MiXSE (MiXture\nof Self-specialized Experts). Our approach leverages self-specialization, which\nconstructs expert modules using self-generated synthetic data, each equipping a\nshared base LLM with distinct domain-specific capabilities, activated via\nself-optimized routing. This allows for dynamic and capability-specific\nhandling of various target tasks, enhancing overall capabilities, without\nextensive human-labeled data and added parameters. Our empirical results reveal\nthat specializing LLMs may exhibit potential trade-offs in performances on\nnon-specialized tasks. On the other hand, our Self-MoE demonstrates substantial\nimprovements (6.5%p on average) over the base LLM across diverse benchmarks\nsuch as knowledge, reasoning, math, and coding. It also consistently\noutperforms other methods, including instance merging and weight merging, while\noffering better flexibility and interpretability by design with semantic\nexperts and routing. Our findings highlight the critical role of modularity,\nthe applicability of Self-MoE to multiple base LLMs, and the potential of\nself-improvement in achieving efficient, scalable, and adaptable systems.\n","authors":["Junmo Kang","Leonid Karlinsky","Hongyin Luo","Zhen Wang","Jacob Hansen","James Glass","David Cox","Rameswar Panda","Rogerio Feris","Alan Ritter"],"pdf_url":"https://arxiv.org/pdf/2406.12034v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.11410v2","updated":"2024-10-07T14:26:56Z","published":"2024-02-18T00:53:05Z","title":"An Elementary Predictor Obtaining $2\\sqrt{T}+1$ Distance to Calibration","summary":"  Blasiok et al. [2023] proposed distance to calibration as a natural measure\nof calibration error that unlike expected calibration error (ECE) is\ncontinuous. Recently, Qiao and Zheng [2024] gave a non-constructive argument\nestablishing the existence of an online predictor that can obtain $O(\\sqrt{T})$\ndistance to calibration in the adversarial setting, which is known to be\nimpossible for ECE. They leave as an open problem finding an explicit,\nefficient algorithm. We resolve this problem and give an extremely simple,\nefficient, deterministic algorithm that obtains distance to calibration error\nat most $2\\sqrt{T}+1$.\n","authors":["Eshwar Ram Arunachaleswaran","Natalie Collina","Aaron Roth","Mirah Shi"],"pdf_url":"https://arxiv.org/pdf/2402.11410v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.05071v1","updated":"2024-10-07T14:26:49Z","published":"2024-10-07T14:26:49Z","title":"Function Gradient Approximation with Random Shallow ReLU Networks with\n  Control Applications","summary":"  Neural networks are widely used to approximate unknown functions in control.\nA common neural network architecture uses a single hidden layer (i.e. a shallow\nnetwork), in which the input parameters are fixed in advance and only the\noutput parameters are trained. The typical formal analysis asserts that if\noutput parameters exist to approximate the unknown function with sufficient\naccuracy, then desired control performance can be achieved. A long-standing\ntheoretical gap was that no conditions existed to guarantee that, for the fixed\ninput parameters, required accuracy could be obtained by training the output\nparameters. Our recent work has partially closed this gap by demonstrating that\nif input parameters are chosen randomly, then for any sufficiently smooth\nfunction, with high-probability there are output parameters resulting in\n$O((1/m)^{1/2})$ approximation errors, where $m$ is the number of neurons.\nHowever, some applications, notably continuous-time value function\napproximation, require that the network approximates the both the unknown\nfunction and its gradient with sufficient accuracy. In this paper, we show that\nrandomly generated input parameters and trained output parameters result in\ngradient errors of $O((\\log(m)/m)^{1/2})$, and additionally, improve the\nconstants from our prior work. We show how to apply the result to policy\nevaluation problems.\n","authors":["Andrew Lamperski","Siddharth Salapaka"],"pdf_url":"https://arxiv.org/pdf/2410.05071v1.pdf","comment":"Under Review for American Control Conference, 2025"},{"id":"http://arxiv.org/abs/2408.14325v3","updated":"2024-10-07T14:23:50Z","published":"2024-08-26T14:54:13Z","title":"Function-Space MCMC for Bayesian Wide Neural Networks","summary":"  Bayesian Neural Networks represent a fascinating confluence of deep learning\nand probabilistic reasoning, offering a compelling framework for understanding\nuncertainty in complex predictive models. In this paper, we investigate the use\nof the preconditioned Crank-Nicolson algorithm and its Langevin version to\nsample from the reparametrised posterior distribution of the weights as the\nwidths of Bayesian Neural Networks grow larger. In addition to being robust in\nthe infinite-dimensional setting, we prove that the acceptance probabilities of\nthe proposed methods approach 1 as the width of the network increases,\nindependently of any stepsize tuning. Moreover, we examine and compare how the\nmixing speeds of the underdamped Langevin Monte Carlo, the preconditioned\nCrank-Nicolson and the preconditioned Crank-Nicolson Langevin samplers are\ninfluenced by changes in the network width in some real-world cases. Our\nfindings suggest that, in wide Bayesian Neural Networks configurations, the\npreconditioned Crank-Nicolson method allows for more efficient sampling of the\nreparametrised posterior distribution, as evidenced by a higher effective\nsample size and improved diagnostic results compared with the other analysed\nalgorithms.\n","authors":["Lucia Pezzetti","Stefano Favaro","Stefano Peluchetti"],"pdf_url":"https://arxiv.org/pdf/2408.14325v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.05063v1","updated":"2024-10-07T14:21:51Z","published":"2024-10-07T14:21:51Z","title":"Control-oriented Clustering of Visual Latent Representation","summary":"  We initiate a study of the geometry of the visual representation space -- the\ninformation channel from the vision encoder to the action decoder -- in an\nimage-based control pipeline learned from behavior cloning. Inspired by the\nphenomenon of neural collapse (NC) in image classification, we investigate\nwhether a similar law of clustering emerges in the visual representation space.\nSince image-based control is a regression task without explicitly defined\nclasses, the central piece of the puzzle lies in determining according to what\nimplicit classes the visual features cluster, if such a law exists. Focusing on\nimage-based planar pushing, we posit the most important role of the visual\nrepresentation in a control task is to convey a goal to the action decoder. We\nthen classify training samples of expert demonstrations into eight\n\"control-oriented\" classes based on (a) the relative pose between the object\nand the target in the input or (b) the relative pose of the object induced by\nexpert actions in the output, where one class corresponds to one relative pose\northant (REPO). Across four different instantiations of architecture, we report\nthe prevalent emergence of control-oriented clustering in the visual\nrepresentation space according to the eight REPOs. Beyond empirical\nobservation, we show such a law of clustering can be leveraged as an\nalgorithmic tool to improve test-time performance when training a policy with\nlimited expert demonstrations. Particularly, we pretrain the vision encoder\nusing NC as a regularization to encourage control-oriented clustering of the\nvisual features. Surprisingly, such an NC-pretrained vision encoder, when\nfinetuned end-to-end with the action decoder, boosts the test-time performance\nby 10% to 35% in the low-data regime. Real-world vision-based planar pushing\nexperiments confirmed the surprising advantage of control-oriented visual\nrepresentation pretraining.\n","authors":["Han Qi","Haocheng Yin","Heng Yang"],"pdf_url":"https://arxiv.org/pdf/2410.05063v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.02458v2","updated":"2024-10-07T14:20:42Z","published":"2024-01-04T08:00:32Z","title":"Data-Centric Foundation Models in Computational Healthcare: A Survey","summary":"  The advent of foundation models (FMs) as an emerging suite of AI techniques\nhas struck a wave of opportunities in computational healthcare. The interactive\nnature of these models, guided by pre-training data and human instructions, has\nignited a data-centric AI paradigm that emphasizes better data\ncharacterization, quality, and scale. In healthcare AI, obtaining and\nprocessing high-quality clinical data records has been a longstanding\nchallenge, ranging from data quantity, annotation, patient privacy, and ethics.\nIn this survey, we investigate a wide range of data-centric approaches in the\nFM era (from model pre-training to inference) towards improving the healthcare\nworkflow. We discuss key perspectives in AI security, assessment, and alignment\nwith human values. Finally, we offer a promising outlook of FM-based analytics\nto enhance the performance of patient outcome and clinical workflow in the\nevolving landscape of healthcare and medicine. We provide an up-to-date list of\nhealthcare-related foundation models and datasets at\nhttps://github.com/Yunkun-Zhang/Data-Centric-FM-Healthcare .\n","authors":["Yunkun Zhang","Jin Gao","Zheling Tan","Lingfeng Zhou","Kexin Ding","Mu Zhou","Shaoting Zhang","Dequan Wang"],"pdf_url":"https://arxiv.org/pdf/2401.02458v2.pdf","comment":"Survey content updated to include recent research work and progress"},{"id":"http://arxiv.org/abs/2407.03878v2","updated":"2024-10-07T14:14:54Z","published":"2024-07-04T12:15:42Z","title":"Geodesic Optimization for Predictive Shift Adaptation on EEG data","summary":"  Electroencephalography (EEG) data is often collected from diverse contexts\ninvolving different populations and EEG devices. This variability can induce\ndistribution shifts in the data $X$ and in the biomedical variables of interest\n$y$, thus limiting the application of supervised machine learning (ML)\nalgorithms. While domain adaptation (DA) methods have been developed to\nmitigate the impact of these shifts, such methods struggle when distribution\nshifts occur simultaneously in $X$ and $y$. As state-of-the-art ML models for\nEEG represent the data by spatial covariance matrices, which lie on the\nRiemannian manifold of Symmetric Positive Definite (SPD) matrices, it is\nappealing to study DA techniques operating on the SPD manifold. This paper\nproposes a novel method termed Geodesic Optimization for Predictive Shift\nAdaptation (GOPSA) to address test-time multi-source DA for situations in which\nsource domains have distinct $y$ distributions. GOPSA exploits the geodesic\nstructure of the Riemannian manifold to jointly learn a domain-specific\nre-centering operator representing site-specific intercepts and the regression\nmodel. We performed empirical benchmarks on the cross-site generalization of\nage-prediction models with resting-state EEG data from a large multi-national\ndataset (HarMNqEEG), which included $14$ recording sites and more than $1500$\nhuman participants. Compared to state-of-the-art methods, our results showed\nthat GOPSA achieved significantly higher performance on three regression\nmetrics ($R^2$, MAE, and Spearman's $\\rho$) for several source-target site\ncombinations, highlighting its effectiveness in tackling multi-source DA with\npredictive shifts in EEG data analysis. Our method has the potential to combine\nthe advantages of mixed-effects modeling with machine learning for biomedical\napplications of EEG, such as multicenter clinical trials.\n","authors":["Apolline Mellot","Antoine Collas","Sylvain Chevallier","Alexandre Gramfort","Denis A. Engemann"],"pdf_url":"https://arxiv.org/pdf/2407.03878v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.01386v2","updated":"2024-10-07T14:14:39Z","published":"2024-10-02T09:55:58Z","title":"FLAME: Adaptive and Reactive Concept Drift Mitigation for Federated\n  Learning Deployments","summary":"  This paper presents Federated Learning with Adaptive Monitoring and\nElimination (FLAME), a novel solution capable of detecting and mitigating\nconcept drift in Federated Learning (FL) Internet of Things (IoT) environments.\nConcept drift poses significant challenges for FL models deployed in dynamic\nand real-world settings. FLAME leverages an FL architecture, considers a\nreal-world FL pipeline, and proves capable of maintaining model performance and\naccuracy while addressing bandwidth and privacy constraints. Introducing\nvarious features and extensions on previous works, FLAME offers a robust\nsolution to concept drift, significantly reducing computational load and\ncommunication overhead. Compared to well-known lightweight mitigation methods,\nFLAME demonstrates superior performance in maintaining high F1 scores and\nreducing resource utilisation in large-scale IoT deployments, making it a\npromising approach for real-world applications.\n","authors":["Ioannis Mavromatis","Stefano De Feo","Aftab Khan"],"pdf_url":"https://arxiv.org/pdf/2410.01386v2.pdf","comment":"Accepted for Publication at ACM EWSN 2024 - EMERGE Workshop"},{"id":"http://arxiv.org/abs/2410.05057v1","updated":"2024-10-07T14:14:38Z","published":"2024-10-07T14:14:38Z","title":"SELECT: A Large-Scale Benchmark of Data Curation Strategies for Image\n  Classification","summary":"  Data curation is the problem of how to collect and organize samples into a\ndataset that supports efficient learning. Despite the centrality of the task,\nlittle work has been devoted towards a large-scale, systematic comparison of\nvarious curation methods. In this work, we take steps towards a formal\nevaluation of data curation strategies and introduce SELECT, the first\nlarge-scale benchmark of curation strategies for image classification.\n  In order to generate baseline methods for the SELECT benchmark, we create a\nnew dataset, ImageNet++, which constitutes the largest superset of ImageNet-1K\nto date. Our dataset extends ImageNet with 5 new training-data shifts, each\napproximately the size of ImageNet-1K itself, and each assembled using a\ndistinct curation strategy. We evaluate our data curation baselines in two\nways: (i) using each training-data shift to train identical image\nclassification models from scratch (ii) using the data itself to fit a\npretrained self-supervised representation.\n  Our findings show interesting trends, particularly pertaining to recent\nmethods for data curation such as synthetic data generation and lookup based on\nCLIP embeddings. We show that although these strategies are highly competitive\nfor certain tasks, the curation strategy used to assemble the original\nImageNet-1K dataset remains the gold standard. We anticipate that our benchmark\ncan illuminate the path for new methods to further reduce the gap. We release\nour checkpoints, code, documentation, and a link to our dataset at\nhttps://github.com/jimmyxu123/SELECT.\n","authors":["Benjamin Feuer","Jiawei Xu","Niv Cohen","Patrick Yubeaton","Govind Mittal","Chinmay Hegde"],"pdf_url":"https://arxiv.org/pdf/2410.05057v1.pdf","comment":"NeurIPS 2024, Datasets and Benchmarks Track"},{"id":"http://arxiv.org/abs/2410.05050v1","updated":"2024-10-07T14:05:57Z","published":"2024-10-07T14:05:57Z","title":"FreSh: Frequency Shifting for Accelerated Neural Representation Learning","summary":"  Implicit Neural Representations (INRs) have recently gained attention as a\npowerful approach for continuously representing signals such as images, videos,\nand 3D shapes using multilayer perceptrons (MLPs). However, MLPs are known to\nexhibit a low-frequency bias, limiting their ability to capture high-frequency\ndetails accurately. This limitation is typically addressed by incorporating\nhigh-frequency input embeddings or specialized activation layers. In this work,\nwe demonstrate that these embeddings and activations are often configured with\nhyperparameters that perform well on average but are suboptimal for specific\ninput signals under consideration, necessitating a costly grid search to\nidentify optimal settings. Our key observation is that the initial frequency\nspectrum of an untrained model's output correlates strongly with the model's\neventual performance on a given target signal. Leveraging this insight, we\npropose frequency shifting (or FreSh), a method that selects embedding\nhyperparameters to align the frequency spectrum of the model's initial output\nwith that of the target signal. We show that this simple initialization\ntechnique improves performance across various neural representation methods and\ntasks, achieving results comparable to extensive hyperparameter sweeps but with\nonly marginal computational overhead compared to training a single model with\ndefault hyperparameters.\n","authors":["Adam Kania","Marko Mihajlovic","Sergey Prokudin","Jacek Tabor","Przemysław Spurek"],"pdf_url":"https://arxiv.org/pdf/2410.05050v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.03386v2","updated":"2024-10-07T14:01:11Z","published":"2024-06-05T15:36:57Z","title":"Learning Long Range Dependencies on Graphs via Random Walks","summary":"  Message-passing graph neural networks (GNNs) excel at capturing local\nrelationships but struggle with long-range dependencies in graphs. In contrast,\ngraph transformers (GTs) enable global information exchange but often\noversimplify the graph structure by representing graphs as sets of fixed-length\nvectors. This work introduces a novel architecture that overcomes the\nshortcomings of both approaches by combining the long-range information of\nrandom walks with local message passing. By treating random walks as sequences,\nour architecture leverages recent advances in sequence models to effectively\ncapture long-range dependencies within these walks. Based on this concept, we\npropose a framework that offers (1) more expressive graph representations\nthrough random walk sequences, (2) the ability to utilize any sequence model\nfor capturing long-range dependencies, and (3) the flexibility by integrating\nvarious GNN and GT architectures. Our experimental evaluations demonstrate that\nour approach achieves significant performance improvements on 19 graph and node\nbenchmark datasets, notably outperforming existing methods by up to 13\\% on the\nPascalVoc-SP and COCO-SP datasets. The code is available at\nhttps://github.com/BorgwardtLab/NeuralWalker.\n","authors":["Dexiong Chen","Till Hendrik Schulz","Karsten Borgwardt"],"pdf_url":"https://arxiv.org/pdf/2406.03386v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.13687v4","updated":"2024-10-07T13:59:42Z","published":"2024-07-18T17:42:37Z","title":"Dynamic Pricing in Securities Lending Market: Application in Revenue\n  Optimization for an Agent Lender Portfolio","summary":"  Securities lending is an important part of the financial market structure,\nwhere agent lenders help long term institutional investors to lend out their\nsecurities to short sellers in exchange for a lending fee. Agent lenders within\nthe market seek to optimize revenue by lending out securities at the highest\nrate possible. Typically, this rate is set by hard-coded business rules or\nstandard supervised machine learning models. These approaches are often\ndifficult to scale and are not adaptive to changing market conditions. Unlike a\ntraditional stock exchange with a centralized limit order book, the securities\nlending market is organized similarly to an e-commerce marketplace, where agent\nlenders and borrowers can transact at any agreed price in a bilateral fashion.\nThis similarity suggests that the use of typical methods for addressing dynamic\npricing problems in e-commerce could be effective in the securities lending\nmarket. We show that existing contextual bandit frameworks can be successfully\nutilized in the securities lending market. Using offline evaluation on real\nhistorical data, we show that the contextual bandit approach can consistently\noutperform typical approaches by at least 15% in terms of total revenue\ngenerated.\n","authors":["Jing Xu","Yung-Cheng Hsu","William Biscarri"],"pdf_url":"https://arxiv.org/pdf/2407.13687v4.pdf","comment":"7 pages, 8 figures"},{"id":"http://arxiv.org/abs/2410.05044v1","updated":"2024-10-07T13:58:40Z","published":"2024-10-07T13:58:40Z","title":"PhotoReg: Photometrically Registering 3D Gaussian Splatting Models","summary":"  Building accurate representations of the environment is critical for\nintelligent robots to make decisions during deployment. Advances in\nphotorealistic environment models have enabled robots to develop\nhyper-realistic reconstructions, which can be used to generate images that are\nintuitive for human inspection. In particular, the recently introduced\n\\ac{3DGS}, which describes the scene with up to millions of primitive\nellipsoids, can be rendered in real time. \\ac{3DGS} has rapidly gained\nprominence. However, a critical unsolved problem persists: how can we fuse\nmultiple \\ac{3DGS} into a single coherent model? Solving this problem will\nenable robot teams to jointly build \\ac{3DGS} models of their surroundings. A\nkey insight of this work is to leverage the {duality} between photorealistic\nreconstructions, which render realistic 2D images from 3D structure, and\n\\emph{3D foundation models}, which predict 3D structure from image pairs. To\nthis end, we develop PhotoReg, a framework to register multiple photorealistic\n\\ac{3DGS} models with 3D foundation models. As \\ac{3DGS} models are generally\nbuilt from monocular camera images, they have \\emph{arbitrary scale}. To\nresolve this, PhotoReg actively enforces scale consistency among the different\n\\ac{3DGS} models by considering depth estimates within these models. Then, the\nalignment is iteratively refined with fine-grained photometric losses to\nproduce high-quality fused \\ac{3DGS} models. We rigorously evaluate PhotoReg on\nboth standard benchmark datasets and our custom-collected datasets, including\nwith two quadruped robots. The code is released at\n\\url{ziweny11.github.io/photoreg}.\n","authors":["Ziwen Yuan","Tianyi Zhang","Matthew Johnson-Roberson","Weiming Zhi"],"pdf_url":"https://arxiv.org/pdf/2410.05044v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.05041v1","updated":"2024-10-07T13:53:17Z","published":"2024-10-07T13:53:17Z","title":"Systematic Literature Review of Vision-Based Approaches to Outdoor\n  Livestock Monitoring with Lessons from Wildlife Studies","summary":"  Precision livestock farming (PLF) aims to improve the health and welfare of\nlivestock animals and farming outcomes through the use of advanced\ntechnologies. Computer vision, combined with recent advances in machine\nlearning and deep learning artificial intelligence approaches, offers a\npossible solution to the PLF ideal of 24/7 livestock monitoring that helps\nfacilitate early detection of animal health and welfare issues. However, a\nsignificant number of livestock species are raised in large outdoor habitats\nthat pose technological challenges for computer vision approaches. This review\nprovides a comprehensive overview of computer vision methods and open\nchallenges in outdoor animal monitoring. We include research from both the\nlivestock and wildlife fields in the review because of the similarities in\nappearance, behaviour, and habitat for many livestock and wildlife. We focus on\nlarge terrestrial mammals, such as cattle, horses, deer, goats, sheep, koalas,\ngiraffes, and elephants. We use an image processing pipeline to frame our\ndiscussion and highlight the current capabilities and open technical challenges\nat each stage of the pipeline. The review found a clear trend towards the use\nof deep learning approaches for animal detection, counting, and multi-species\nclassification. We discuss in detail the applicability of current vision-based\nmethods to PLF contexts and promising directions for future research.\n","authors":["Stacey D. Scott","Zayn J. Abbas","Feerass Ellid","Eli-Henry Dykhne","Muhammad Muhaiminul Islam","Weam Ayad","Kristina Kacmorova","Dan Tulpan","Minglun Gong"],"pdf_url":"https://arxiv.org/pdf/2410.05041v1.pdf","comment":"28 pages, 5 figures, 2 tables"},{"id":"http://arxiv.org/abs/2410.05026v1","updated":"2024-10-07T13:26:36Z","published":"2024-10-07T13:26:36Z","title":"Active Fine-Tuning of Generalist Policies","summary":"  Pre-trained generalist policies are rapidly gaining relevance in robot\nlearning due to their promise of fast adaptation to novel, in-domain tasks.\nThis adaptation often relies on collecting new demonstrations for a specific\ntask of interest and applying imitation learning algorithms, such as behavioral\ncloning. However, as soon as several tasks need to be learned, we must decide\nwhich tasks should be demonstrated and how often? We study this multi-task\nproblem and explore an interactive framework in which the agent adaptively\nselects the tasks to be demonstrated. We propose AMF (Active Multi-task\nFine-tuning), an algorithm to maximize multi-task policy performance under a\nlimited demonstration budget by collecting demonstrations yielding the largest\ninformation gain on the expert policy. We derive performance guarantees for AMF\nunder regularity assumptions and demonstrate its empirical effectiveness to\nefficiently fine-tune neural policies in complex and high-dimensional\nenvironments.\n","authors":["Marco Bagatella","Jonas Hübotter","Georg Martius","Andreas Krause"],"pdf_url":"https://arxiv.org/pdf/2410.05026v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.05021v1","updated":"2024-10-07T13:24:24Z","published":"2024-10-07T13:24:24Z","title":"DEPT: Decoupled Embeddings for Pre-training Language Models","summary":"  Language Model pre-training benefits from a broader data mixture to enhance\nperformance across domains and languages. However, training on such\nheterogeneous text corpora is complex, requiring extensive and cost-intensive\nefforts. Since these data sources vary in lexical, syntactic, and semantic\naspects, they cause negative interference or the \"curse of multilinguality\". We\npropose a novel pre-training framework to alleviate this curse. Our method,\nDEPT, decouples the embedding layers from the transformer body while\nsimultaneously training the latter in multiple contexts. DEPT enables the model\nto train without being bound to a shared global vocabulary. DEPT: (1) can train\nrobustly and effectively under significant data heterogeneity, (2) reduces the\nparameter count of the token embeddings by up to 80% and the communication\ncosts by 675x for billion-scale models (3) enhances model generalization and\nplasticity in adapting to new languages and domains, and (4) allows training\nwith custom optimized vocabulary per data source. We prove DEPT's potential by\nperforming the first vocabulary-agnostic federated multilingual pre-training of\na 1.3 billion-parameter model across high and low-resource languages, reducing\nits parameter count by 409 million.\n","authors":["Alex Iacob","Lorenzo Sani","Meghdad Kurmanji","William F. Shen","Xinchi Qiu","Dongqi Cai","Yan Gao","Nicholas D. Lane"],"pdf_url":"https://arxiv.org/pdf/2410.05021v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.19146v2","updated":"2024-10-07T13:21:13Z","published":"2024-05-29T14:51:41Z","title":"I Bet You Did Not Mean That: Testing Semantic Importance via Betting","summary":"  Recent works have extended notions of feature importance to semantic concepts\nthat are inherently interpretable to the users interacting with a black-box\npredictive model. Yet, precise statistical guarantees, such as false positive\nrate and false discovery rate control, are needed to communicate findings\ntransparently and to avoid unintended consequences in real-world scenarios. In\nthis paper, we formalize the global (i.e., over a population) and local (i.e.,\nfor a sample) statistical importance of semantic concepts for the predictions\nof opaque models by means of conditional independence, which allows for\nrigorous testing. We use recent ideas of sequential kernelized independence\ntesting (SKIT) to induce a rank of importance across concepts, and showcase the\neffectiveness and flexibility of our framework on synthetic datasets as well as\non image classification tasks using several and diverse vision-language models.\n","authors":["Jacopo Teneggi","Jeremias Sulam"],"pdf_url":"https://arxiv.org/pdf/2405.19146v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.05020v1","updated":"2024-10-07T13:20:26Z","published":"2024-10-07T13:20:26Z","title":"FRIDA: Free-Rider Detection using Privacy Attacks","summary":"  Federated learning is increasingly popular as it enables multiple parties\nwith limited datasets and resources to train a high-performing machine learning\nmodel collaboratively. However, similarly to other collaborative systems,\nfederated learning is vulnerable to free-riders -- participants who do not\ncontribute to the training but still benefit from the shared model. Free-riders\nnot only compromise the integrity of the learning process but also slow down\nthe convergence of the global model, resulting in increased costs for the\nhonest participants.\n  To address this challenge, we propose FRIDA: free-rider detection using\nprivacy attacks, a framework that leverages inference attacks to detect\nfree-riders. Unlike traditional methods that only capture the implicit effects\nof free-riding, FRIDA directly infers details of the underlying training\ndatasets, revealing characteristics that indicate free-rider behaviour. Through\nextensive experiments, we demonstrate that membership and property inference\nattacks are effective for this purpose. Our evaluation shows that FRIDA\noutperforms state-of-the-art methods, especially in non-IID settings.\n","authors":["Pol G. Recasens","Ádám Horváth","Alberto Gutierrez-Torre","Jordi Torres","Josep Ll. Berral","Balázs Pejó"],"pdf_url":"https://arxiv.org/pdf/2410.05020v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.15160v2","updated":"2024-10-07T13:19:53Z","published":"2024-07-21T13:31:02Z","title":"When Can Transformers Count to n?","summary":"  Large language models based on the transformer architectures can solve highly\ncomplex tasks. But are there simple tasks that such models cannot solve? Here\nwe focus on very simple counting tasks, that involve counting how many times a\ntoken in the vocabulary have appeared in a string. We show that if the\ndimension of the transformer state is linear in the context length, this task\ncan be solved. However, the solution we propose does not scale beyond this\nlimit, and we provide theoretical arguments for why it is likely impossible for\na size limited transformer to implement this task. Our empirical results\ndemonstrate the same phase-transition in performance, as anticipated by the\ntheoretical argument. Our results demonstrate the importance of understanding\nhow transformers can solve simple tasks.\n","authors":["Gilad Yehudai","Haim Kaplan","Asma Ghandeharioun","Mor Geva","Amir Globerson"],"pdf_url":"https://arxiv.org/pdf/2407.15160v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.05019v1","updated":"2024-10-07T13:19:10Z","published":"2024-10-07T13:19:10Z","title":"RelUNet: Relative Channel Fusion U-Net for Multichannel Speech\n  Enhancement","summary":"  Neural multi-channel speech enhancement models, in particular those based on\nthe U-Net architecture, demonstrate promising performance and generalization\npotential. These models typically encode input channels independently, and\nintegrate the channels during later stages of the network. In this paper, we\npropose a novel modification of these models by incorporating relative\ninformation from the outset, where each channel is processed in conjunction\nwith a reference channel through stacking. This input strategy exploits\ncomparative differences to adaptively fuse information between channels,\nthereby capturing crucial spatial information and enhancing the overall\nperformance. The experiments conducted on the CHiME-3 dataset demonstrate\nimprovements in speech enhancement metrics across various architectures.\n","authors":["Ibrahim Aldarmaki","Thamar Solorio","Bhiksha Raj","Hanan Aldarmaki"],"pdf_url":"https://arxiv.org/pdf/2410.05019v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.05016v1","updated":"2024-10-07T13:15:07Z","published":"2024-10-07T13:15:07Z","title":"T-JEPA: Augmentation-Free Self-Supervised Learning for Tabular Data","summary":"  Self-supervision is often used for pre-training to foster performance on a\ndownstream task by constructing meaningful representations of samples.\nSelf-supervised learning (SSL) generally involves generating different views of\nthe same sample and thus requires data augmentations that are challenging to\nconstruct for tabular data. This constitutes one of the main challenges of\nself-supervision for structured data. In the present work, we propose a novel\naugmentation-free SSL method for tabular data. Our approach, T-JEPA, relies on\na Joint Embedding Predictive Architecture (JEPA) and is akin to mask\nreconstruction in the latent space. It involves predicting the latent\nrepresentation of one subset of features from the latent representation of a\ndifferent subset within the same sample, thereby learning rich representations\nwithout augmentations. We use our method as a pre-training technique and train\nseveral deep classifiers on the obtained representation. Our experimental\nresults demonstrate a substantial improvement in both classification and\nregression tasks, outperforming models trained directly on samples in their\noriginal data space. Moreover, T-JEPA enables some methods to consistently\noutperform or match the performance of traditional methods likes Gradient\nBoosted Decision Trees. To understand why, we extensively characterize the\nobtained representations and show that T-JEPA effectively identifies relevant\nfeatures for downstream tasks without access to the labels. Additionally, we\nintroduce regularization tokens, a novel regularization method critical for\ntraining of JEPA-based models on structured data.\n","authors":["Hugo Thimonier","José Lucas De Melo Costa","Fabrice Popineau","Arpad Rimmel","Bich-Liên Doan"],"pdf_url":"https://arxiv.org/pdf/2410.05016v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.01104v2","updated":"2024-10-07T13:13:41Z","published":"2024-10-01T22:22:35Z","title":"softmax is not enough (for sharp out-of-distribution)","summary":"  A key property of reasoning systems is the ability to make sharp decisions on\ntheir input data. For contemporary AI systems, a key carrier of sharp behaviour\nis the softmax function, with its capability to perform differentiable\nquery-key lookups. It is a common belief that the predictive power of networks\nleveraging softmax arises from \"circuits\" which sharply perform certain kinds\nof computations consistently across many diverse inputs. However, for these\ncircuits to be robust, they would need to generalise well to arbitrary valid\ninputs. In this paper, we dispel this myth: even for tasks as simple as finding\nthe maximum key, any learned circuitry must disperse as the number of items\ngrows at test time. We attribute this to a fundamental limitation of the\nsoftmax function to robustly approximate sharp functions, prove this phenomenon\ntheoretically, and propose adaptive temperature as an ad-hoc technique for\nimproving the sharpness of softmax at inference time.\n","authors":["Petar Veličković","Christos Perivolaropoulos","Federico Barbero","Razvan Pascanu"],"pdf_url":"https://arxiv.org/pdf/2410.01104v2.pdf","comment":"Comments welcome. 15 pages, 7 figures"},{"id":"http://arxiv.org/abs/2405.16581v3","updated":"2024-10-07T13:12:20Z","published":"2024-05-26T14:18:38Z","title":"On Bits and Bandits: Quantifying the Regret-Information Trade-off","summary":"  In many sequential decision problems, an agent performs a repeated task. He\nthen suffers regret and obtains information that he may use in the following\nrounds. However, sometimes the agent may also obtain information and avoid\nsuffering regret by querying external sources. We study the trade-off between\nthe information an agent accumulates and the regret it suffers. We invoke\ninformation-theoretic methods for obtaining regret lower bounds, that also\nallow us to easily re-derive several known lower bounds. We introduce the first\nBayesian regret lower bounds that depend on the information an agent\naccumulates. We also prove regret upper bounds using the amount of information\nthe agent accumulates. These bounds show that information measured in bits, can\nbe traded off for regret, measured in reward. Finally, we demonstrate the\nutility of these bounds in improving the performance of a question-answering\ntask with large language models, allowing us to obtain valuable insights.\n","authors":["Itai Shufaro","Nadav Merlis","Nir Weinberger","Shie Mannor"],"pdf_url":"https://arxiv.org/pdf/2405.16581v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.18427v2","updated":"2024-10-07T13:07:11Z","published":"2024-09-27T03:28:11Z","title":"Neural Collaborative Filtering to Detect Anomalies in Human Semantic\n  Trajectories","summary":"  Human trajectory anomaly detection has become increasingly important across a\nwide range of applications, including security surveillance and public health.\nHowever, existing trajectory anomaly detection methods are primarily focused on\nvehicle-level traffic, while human-level trajectory anomaly detection remains\nunder-explored. Since human trajectory data is often very sparse, machine\nlearning methods have become the preferred approach for identifying complex\npatterns. However, concerns regarding potential biases and the robustness of\nthese models have intensified the demand for more transparent and explainable\nalternatives. In response to these challenges, our research focuses on\ndeveloping a lightweight anomaly detection model specifically designed to\ndetect anomalies in human trajectories. We propose a Neural Collaborative\nFiltering approach to model and predict normal mobility. Our method is designed\nto model users' daily patterns of life without requiring prior knowledge,\nthereby enhancing performance in scenarios where data is sparse or incomplete,\nsuch as in cold start situations. Our algorithm consists of two main modules.\nThe first is the collaborative filtering module, which applies collaborative\nfiltering to model normal mobility of individual humans to places of interest.\nThe second is the neural module, responsible for interpreting the complex\nspatio-temporal relationships inherent in human trajectory data. To validate\nour approach, we conducted extensive experiments using simulated and real-world\ndatasets comparing to numerous state-of-the-art trajectory anomaly detection\napproaches.\n","authors":["Yueyang Liu","Lance Kennedy","Hossein Amiri","Andreas Züfle"],"pdf_url":"https://arxiv.org/pdf/2409.18427v2.pdf","comment":"Accepted for publication in the 1st ACM SIGSPATIAL International\n  Workshop on Geospatial Anomaly Detection (GeoAnomalies'24)"},{"id":"http://arxiv.org/abs/2410.04996v1","updated":"2024-10-07T12:52:38Z","published":"2024-10-07T12:52:38Z","title":"Assumption-Lean Post-Integrated Inference with Negative Control Outcomes","summary":"  Data integration has become increasingly common in aligning multiple\nheterogeneous datasets. With high-dimensional outcomes, data integration\nmethods aim to extract low-dimensional embeddings of observations to remove\nunwanted variations, such as batch effects and unmeasured covariates, inherent\nin data collected from different sources. However, multiple hypothesis testing\nafter data integration can be substantially biased due to the data-dependent\nintegration processes. To address this challenge, we introduce a robust\npost-integrated inference (PII) method that adjusts for latent heterogeneity\nusing negative control outcomes. By leveraging causal interpretations, we\nderive nonparametric identification conditions that form the basis of our PII\napproach.\n  Our assumption-lean semiparametric inference method extends robustness and\ngenerality to projected direct effect estimands that account for mediators,\nconfounders, and moderators. These estimands remain statistically meaningful\nunder model misspecifications and with error-prone embeddings. We provide\ndeterministic quantifications of the bias of target estimands induced by\nestimated embeddings and finite-sample linear expansions of the estimators with\nuniform concentration bounds on the residuals for all outcomes.\n  The proposed doubly robust estimators are consistent and efficient under\nminimal assumptions, facilitating data-adaptive estimation with machine\nlearning algorithms. Using random forests, we evaluate empirical statistical\nerrors in simulations and analyze single-cell CRISPR perturbed datasets with\npotential unmeasured confounders.\n","authors":["Jin-Hong Du","Kathryn Roeder","Larry Wasserman"],"pdf_url":"https://arxiv.org/pdf/2410.04996v1.pdf","comment":"29 pages for main text, and 18 pages for appendix, 9 figures for main\n  text, 4 figures for appendix"},{"id":"http://arxiv.org/abs/2402.16017v2","updated":"2024-10-07T12:52:19Z","published":"2024-02-25T07:28:28Z","title":"Spectrum Extraction and Clipping for Implicitly Linear Layers","summary":"  We show the effectiveness of automatic differentiation in efficiently and\ncorrectly computing and controlling the spectrum of implicitly linear\noperators, a rich family of layer types including all standard convolutional\nand dense layers. We provide the first clipping method which is correct for\ngeneral convolution layers, and illuminate the representational limitation that\ncaused correctness issues in prior work. We study the effect of the batch\nnormalization layers when concatenated with convolutional layers and show how\nour clipping method can be applied to their composition. By comparing the\naccuracy and performance of our algorithms to the state-of-the-art methods,\nusing various experiments, we show they are more precise and efficient and lead\nto better generalization and adversarial robustness. We provide the code for\nusing our methods at https://github.com/Ali-E/FastClip.\n","authors":["Ali Ebrahimpour Boroojeny","Matus Telgarsky","Hari Sundaram"],"pdf_url":"https://arxiv.org/pdf/2402.16017v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.15664v2","updated":"2024-10-07T12:52:00Z","published":"2024-06-21T21:44:27Z","title":"Flat Posterior Does Matter For Bayesian Model Averaging","summary":"  Bayesian neural network (BNN) approximates the posterior distribution of\nmodel parameters and utilizes the posterior for prediction via Bayesian Model\nAveraging (BMA). The quality of the posterior approximation is critical for\nachieving accurate and robust predictions. It is known that flatness in the\nloss landscape is strongly associated with generalization performance, and it\nnecessitates consideration to improve the quality of the posterior\napproximation. In this work, we empirically demonstrate that BNNs often\nstruggle to capture the flatness. Moreover, we provide both experimental and\ntheoretical evidence showing that BMA can be ineffective without ensuring\nflatness. To address this, we propose Sharpness-Aware Bayesian Model Averaging\n(SA-BMA), a novel optimizer that seeks flat posteriors by calculating\ndivergence in the parameter space. SA-BMA aligns with the intrinsic nature of\nBNN and the generalized version of existing sharpness-aware optimizers for DNN.\nIn addition, we suggest a Bayesian Transfer Learning scheme to efficiently\nleverage pre-trained DNN. We validate the efficacy of SA-BMA in enhancing\ngeneralization performance in few-shot classification and distribution shift by\nensuring flat posterior.\n","authors":["Sungjun Lim","Jeyoon Yeom","Sooyon Kim","Hoyoon Byun","Jinho Kang","Yohan Jung","Jiyoung Jung","Kyungwoo Song"],"pdf_url":"https://arxiv.org/pdf/2406.15664v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04992v1","updated":"2024-10-07T12:48:03Z","published":"2024-10-07T12:48:03Z","title":"MC-QDSNN: Quantized Deep evolutionary SNN with Multi-Dendritic\n  Compartment Neurons for Stress Detection using Physiological Signals","summary":"  Long short-term memory (LSTM) has emerged as a definitive network for\nanalyzing and inferring time series data. LSTM has the capability to extract\nspectral features and a mixture of temporal features. Due to this benefit, a\nsimilar feature extraction method is explored for the spiking counterparts\ntargeting time-series data. Though LSTMs perform well in their spiking form,\nthey tend to be compute and power intensive. Addressing this issue, this work\nproposes Multi-Compartment Leaky (MCLeaky) neuron as a viable alternative for\nefficient processing of time series data. The MCLeaky neuron, derived from the\nLeaky Integrate and Fire (LIF) neuron model, contains multiple memristive\nsynapses interlinked to form a memory component, which emulates the human\nbrain's Hippocampus region. The proposed MCLeaky neuron based Spiking Neural\nNetwork model and its quantized variant were benchmarked against\nstate-of-the-art (SOTA) Spiking LSTMs to perform human stress detection, by\ncomparing compute requirements, latency and real-world performances on unseen\ndata with models derived through Neural Architecture Search (NAS). Results show\nthat networks with MCLeaky activation neuron managed a superior accuracy of\n98.8% to detect stress based on Electrodermal Activity (EDA) signals, better\nthan any other investigated models, while using 20% less parameters on average.\nMCLeaky neuron was also tested for various signals including EDA Wrist and\nChest, Temperature, ECG, and combinations of them. Quantized MCLeaky model was\nalso derived and validated to forecast their performance on hardware\narchitectures, which resulted in 91.84% accuracy. The neurons were evaluated\nfor multiple modalities of data towards stress detection, which resulted in\nenergy savings of 25.12x to 39.20x and EDP gains of 52.37x to 81.9x over ANNs,\nwhile offering a best accuracy of 98.8% when compared with the rest of the SOTA\nimplementations.\n","authors":["Ajay B. S.","Phani Pavan K","Madhav Rao"],"pdf_url":"https://arxiv.org/pdf/2410.04992v1.pdf","comment":"13 pages, 15 figures. Applied to IEEE Transactions on Computer Aided\n  Design Journal. Awaiting a verdict"},{"id":"http://arxiv.org/abs/2410.04988v1","updated":"2024-10-07T12:42:51Z","published":"2024-10-07T12:42:51Z","title":"Efficient Model-Based Reinforcement Learning Through Optimistic Thompson\n  Sampling","summary":"  Learning complex robot behavior through interactions with the environment\nnecessitates principled exploration. Effective strategies should prioritize\nexploring regions of the state-action space that maximize rewards, with\noptimistic exploration emerging as a promising direction aligned with this idea\nand enabling sample-efficient reinforcement learning. However, existing methods\noverlook a crucial aspect: the need for optimism to be informed by a belief\nconnecting the reward and state. To address this, we propose a practical,\ntheoretically grounded approach to optimistic exploration based on Thompson\nsampling. Our model structure is the first that allows for reasoning about\njoint uncertainty over transitions and rewards. We apply our method on a set of\nMuJoCo and VMAS continuous control tasks. Our experiments demonstrate that\noptimistic exploration significantly accelerates learning in environments with\nsparse rewards, action penalties, and difficult-to-explore regions.\nFurthermore, we provide insights into when optimism is beneficial and emphasize\nthe critical role of model uncertainty in guiding exploration.\n","authors":["Jasmine Bayrooti","Carl Henrik Ek","Amanda Prorok"],"pdf_url":"https://arxiv.org/pdf/2410.04988v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.15421v2","updated":"2024-10-07T12:38:57Z","published":"2022-09-30T12:26:14Z","title":"TabDDPM: Modelling Tabular Data with Diffusion Models","summary":"  Denoising diffusion probabilistic models are currently becoming the leading\nparadigm of generative modeling for many important data modalities. Being the\nmost prevalent in the computer vision community, diffusion models have also\nrecently gained some attention in other domains, including speech, NLP, and\ngraph-like data. In this work, we investigate if the framework of diffusion\nmodels can be advantageous for general tabular problems, where datapoints are\ntypically represented by vectors of heterogeneous features. The inherent\nheterogeneity of tabular data makes it quite challenging for accurate modeling,\nsince the individual features can be of completely different nature, i.e., some\nof them can be continuous and some of them can be discrete. To address such\ndata types, we introduce TabDDPM -- a diffusion model that can be universally\napplied to any tabular dataset and handles any type of feature. We extensively\nevaluate TabDDPM on a wide set of benchmarks and demonstrate its superiority\nover existing GAN/VAE alternatives, which is consistent with the advantage of\ndiffusion models in other fields. Additionally, we show that TabDDPM is\neligible for privacy-oriented setups, where the original datapoints cannot be\npublicly shared.\n","authors":["Akim Kotelnikov","Dmitry Baranchuk","Ivan Rubachev","Artem Babenko"],"pdf_url":"https://arxiv.org/pdf/2209.15421v2.pdf","comment":"code https://github.com/yandex-research/tab-ddpm"},{"id":"http://arxiv.org/abs/2410.04982v1","updated":"2024-10-07T12:23:40Z","published":"2024-10-07T12:23:40Z","title":"Safe Learning-Based Optimization of Model Predictive Control:\n  Application to Battery Fast-Charging","summary":"  Model predictive control (MPC) is a powerful tool for controlling complex\nnonlinear systems under constraints, but often struggles with model\nuncertainties and the design of suitable cost functions. To address these\nchallenges, we discuss an approach that integrates MPC with safe Bayesian\noptimization to optimize long-term closed-loop performance despite significant\nmodel-plant mismatches. By parameterizing the MPC stage cost function using a\nradial basis function network, we employ Bayesian optimization as a\nmulti-episode learning strategy to tune the controller without relying on\nprecise system models. This method mitigates conservativeness introduced by\noverly cautious soft constraints in the MPC cost function and provides\nprobabilistic safety guarantees during learning, ensuring that safety-critical\nconstraints are met with high probability. As a practical application, we apply\nour approach to fast charging of lithium-ion batteries, a challenging task due\nto the complicated battery dynamics and strict safety requirements, subject to\nthe requirement to be implementable in real time. Simulation results\ndemonstrate that, in the context of model-plant mismatch, our method reduces\ncharging times compared to traditional MPC methods while maintaining safety.\nThis work extends previous research by emphasizing closed-loop constraint\nsatisfaction and offers a promising solution for enhancing performance in\nsystems where model uncertainties and safety are critical concerns.\n","authors":["Sebastian Hirt","Andreas Höhl","Johannes Pohlodek","Joachim Schaeffer","Maik Pfefferkorn","Richard D. Braatz","Rolf Findeisen"],"pdf_url":"https://arxiv.org/pdf/2410.04982v1.pdf","comment":"7 pages, 4 figures, submitted to ACC 2025"},{"id":"http://arxiv.org/abs/2410.04968v1","updated":"2024-10-07T12:12:51Z","published":"2024-10-07T12:12:51Z","title":"Collaboration! Towards Robust Neural Methods for Routing Problems","summary":"  Despite enjoying desirable efficiency and reduced reliance on domain\nexpertise, existing neural methods for vehicle routing problems (VRPs) suffer\nfrom severe robustness issues -- their performance significantly deteriorates\non clean instances with crafted perturbations. To enhance robustness, we\npropose an ensemble-based Collaborative Neural Framework (CNF) w.r.t. the\ndefense of neural VRP methods, which is crucial yet underexplored in the\nliterature. Given a neural VRP method, we adversarially train multiple models\nin a collaborative manner to synergistically promote robustness against\nattacks, while boosting standard generalization on clean instances. A neural\nrouter is designed to adeptly distribute training instances among models,\nenhancing overall load balancing and collaborative efficacy. Extensive\nexperiments verify the effectiveness and versatility of CNF in defending\nagainst various attacks across different neural VRP methods. Notably, our\napproach also achieves impressive out-of-distribution generalization on\nbenchmark instances.\n","authors":["Jianan Zhou","Yaoxin Wu","Zhiguang Cao","Wen Song","Jie Zhang","Zhiqi Shen"],"pdf_url":"https://arxiv.org/pdf/2410.04968v1.pdf","comment":"Accepted at NeurIPS 2024"},{"id":"http://arxiv.org/abs/2402.02987v2","updated":"2024-10-07T12:11:58Z","published":"2024-02-05T13:18:42Z","title":"Reconstruct Your Previous Conversations! Comprehensively Investigating\n  Privacy Leakage Risks in Conversations with GPT Models","summary":"  Significant advancements have recently been made in large language models\nrepresented by GPT models. Users frequently have multi-round private\nconversations with cloud-hosted GPT models for task optimization. Yet, this\noperational paradigm introduces additional attack surfaces, particularly in\ncustom GPTs and hijacked chat sessions. In this paper, we introduce a\nstraightforward yet potent Conversation Reconstruction Attack. This attack\ntargets the contents of previous conversations between GPT models and benign\nusers, i.e., the benign users' input contents during their interaction with GPT\nmodels. The adversary could induce GPT models to leak such contents by querying\nthem with designed malicious prompts. Our comprehensive examination of privacy\nrisks during the interactions with GPT models under this attack reveals GPT-4's\nconsiderable resilience. We present two advanced attacks targeting improved\nreconstruction of past conversations, demonstrating significant privacy leakage\nacross all models under these advanced techniques. Evaluating various defense\nmechanisms, we find them ineffective against these attacks. Our findings\nhighlight the ease with which privacy can be compromised in interactions with\nGPT models, urging the community to safeguard against potential abuses of these\nmodels' capabilities.\n","authors":["Junjie Chu","Zeyang Sha","Michael Backes","Yang Zhang"],"pdf_url":"https://arxiv.org/pdf/2402.02987v2.pdf","comment":"Accepted in EMNLP 2024. 14 pages, 10 figures"},{"id":"http://arxiv.org/abs/2409.19339v2","updated":"2024-10-07T12:05:55Z","published":"2024-09-28T12:49:16Z","title":"Visual Question Decomposition on Multimodal Large Language Models","summary":"  Question decomposition has emerged as an effective strategy for prompting\nLarge Language Models (LLMs) to answer complex questions. However, while\nexisting methods primarily focus on unimodal language models, the question\ndecomposition capability of Multimodal Large Language Models (MLLMs) has yet to\nbe explored. To this end, this paper explores visual question decomposition on\nMLLMs. Specifically, we introduce a systematic evaluation framework including a\ndataset and several evaluation criteria to assess the quality of the decomposed\nsub-questions, revealing that existing MLLMs struggle to produce high-quality\nsub-questions. To address this limitation, we propose a specific finetuning\ndataset, DecoVQA+, for enhancing the model's question decomposition capability.\nAiming at enabling models to perform appropriate selective decomposition, we\npropose an efficient finetuning pipeline. The finetuning pipeline consists of\nour proposed dataset and a training objective for selective decomposition.\nFinetuned MLLMs demonstrate significant improvements in the quality of\nsub-questions and the policy of selective question decomposition. Additionally,\nthe models also achieve higher accuracy with selective decomposition on VQA\nbenchmark datasets.\n","authors":["Haowei Zhang","Jianzhe Liu","Zhen Han","Shuo Chen","Bailan He","Volker Tresp","Zhiqiang Xu","Jindong Gu"],"pdf_url":"https://arxiv.org/pdf/2409.19339v2.pdf","comment":"Accepted to EMNLP2024 Findings"},{"id":"http://arxiv.org/abs/2309.16397v3","updated":"2024-10-07T12:05:12Z","published":"2023-09-28T12:44:51Z","title":"Uncertainty-Aware Decision Transformer for Stochastic Driving\n  Environments","summary":"  Offline Reinforcement Learning (RL) enables policy learning without active\ninteractions, making it especially appealing for self-driving tasks. Recent\nsuccesses of Transformers inspire casting offline RL as sequence modeling,\nwhich, however, fails in stochastic environments with incorrect assumptions\nthat identical actions can consistently achieve the same goal. In this paper,\nwe introduce an UNcertainty-awaRE deciSion Transformer (UNREST) for planning in\nstochastic driving environments without introducing additional transition or\ncomplex generative models. Specifically, UNREST estimates uncertainties by\nconditional mutual information between transitions and returns. Discovering\n'uncertainty accumulation' and 'temporal locality' properties of driving\nenvironments, we replace the global returns in decision transformers with\ntruncated returns less affected by environments to learn from actual outcomes\nof actions rather than environment transitions. We also dynamically evaluate\nuncertainty at inference for cautious planning. Extensive experiments\ndemonstrate UNREST's superior performance in various driving scenarios and the\npower of our uncertainty estimation strategy.\n","authors":["Zenan Li","Fan Nie","Qiao Sun","Fang Da","Hang Zhao"],"pdf_url":"https://arxiv.org/pdf/2309.16397v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04959v1","updated":"2024-10-07T11:58:56Z","published":"2024-10-07T11:58:56Z","title":"Failure-Proof Non-Contrastive Self-Supervised Learning","summary":"  We identify sufficient conditions to avoid known failure modes, including\nrepresentation, dimensional, cluster and intracluster collapses, occurring in\nnon-contrastive self-supervised learning. Based on these findings, we propose a\nprincipled design for the projector and loss function. We theoretically\ndemonstrate that this design introduces an inductive bias that promotes\nlearning representations that are both decorrelated and clustered without\nexplicit enforcing these properties and leading to improved generalization. To\nthe best of our knowledge, this is the first solution that achieves robust\ntraining with respect to these failure modes while guaranteeing enhanced\ngeneralization performance in downstream tasks. We validate our theoretical\nfindings on image datasets including SVHN, CIFAR10, CIFAR100 and ImageNet-100,\nand show that our solution, dubbed FALCON, outperforms existing feature\ndecorrelation and cluster-based self-supervised learning methods in terms of\ngeneralization to clustering and linear classification tasks.\n","authors":["Emanuele Sansone","Tim Lebailly","Tinne Tuytelaars"],"pdf_url":"https://arxiv.org/pdf/2410.04959v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.04185v2","updated":"2024-10-07T11:54:11Z","published":"2024-09-06T11:01:55Z","title":"Residual Stream Analysis with Multi-Layer SAEs","summary":"  Sparse autoencoders (SAEs) are a promising approach to interpreting the\ninternal representations of transformer language models. However, SAEs are\nusually trained separately on each transformer layer, making it difficult to\nuse them to study how information flows across layers. To solve this problem,\nwe introduce the multi-layer SAE (MLSAE): a single SAE trained on the residual\nstream activation vectors from every transformer layer. Given that the residual\nstream is understood to preserve information across layers, we expected MLSAE\nlatents to `switch on' at a token position and remain active at later layers.\nInterestingly, we find that individual latents are often active at a single\nlayer for a given token or prompt, but this layer may differ for different\ntokens or prompts. We quantify these phenomena by defining a distribution over\nlayers and considering its variance. We find that the variance of the\ndistributions of latent activations over layers is about two orders of\nmagnitude greater when aggregating over tokens compared with a single token.\nFor larger underlying models, the degree to which latents are active at\nmultiple layers increases, which is consistent with the fact that the residual\nstream activation vectors at adjacent layers become more similar. Finally, we\nrelax the assumption that the residual stream basis is the same at every layer\nby applying pre-trained tuned-lens transformations, but our findings remain\nqualitatively similar. Our results represent a new approach to understanding\nhow representations change as they flow through transformers. We release our\ncode to train and analyze MLSAEs at https://github.com/tim-lawson/mlsae.\n","authors":["Tim Lawson","Lucy Farnik","Conor Houghton","Laurence Aitchison"],"pdf_url":"https://arxiv.org/pdf/2409.04185v2.pdf","comment":"34 pages, 26 figures"},{"id":"http://arxiv.org/abs/2409.11439v2","updated":"2024-10-07T11:44:38Z","published":"2024-09-16T09:19:19Z","title":"Machine listening in a neonatal intensive care unit","summary":"  Oxygenators, alarm devices, and footsteps are some of the most common sound\nsources in a hospital. Detecting them has scientific value for environmental\npsychology but comes with challenges of its own: namely, privacy preservation\nand limited labeled data. In this paper, we address these two challenges via a\ncombination of edge computing and cloud computing. For privacy preservation, we\nhave designed an acoustic sensor which computes third-octave spectrograms on\nthe fly instead of recording audio waveforms. For sample-efficient machine\nlearning, we have repurposed a pretrained audio neural network (PANN) via\nspectral transcoding and label space adaptation. A small-scale study in a\nneonatological intensive care unit (NICU) confirms that the time series of\ndetected events align with another modality of measurement: i.e., electronic\nbadges for parents and healthcare professionals. Hence, this paper demonstrates\nthe feasibility of polyphonic machine listening in a hospital ward while\nguaranteeing privacy by design.\n","authors":["Modan Tailleur","Vincent Lostanlen","Jean-Philippe Rivière","Pierre Aumond"],"pdf_url":"https://arxiv.org/pdf/2409.11439v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04941v1","updated":"2024-10-07T11:35:24Z","published":"2024-10-07T11:35:24Z","title":"Detecting and Approximating Redundant Computational Blocks in Neural\n  Networks","summary":"  Deep neural networks often learn similar internal representations, both\nacross different models and within their own layers. While inter-network\nsimilarities have enabled techniques such as model stitching and merging,\nintra-network similarities present new opportunities for designing more\nefficient architectures. In this paper, we investigate the emergence of these\ninternal similarities across different layers in diverse neural architectures,\nshowing that similarity patterns emerge independently of the datataset used. We\nintroduce a simple metric, Block Redundancy, to detect redundant blocks,\nproviding a foundation for future architectural optimization methods. Building\non this, we propose Redundant Blocks Approximation (RBA), a general framework\nthat identifies and approximates one or more redundant computational blocks\nusing simpler transformations. We show that the transformation $\\mathcal{T}$\nbetween two representations can be efficiently computed in closed-form, and it\nis enough to replace the redundant blocks from the network. RBA reduces model\nparameters and time complexity while maintaining good performance. We validate\nour method on classification tasks in the vision domain using a variety of\npretrained foundational models and datasets.\n","authors":["Irene Cannistraci","Emanuele Rodolà","Bastian Rieck"],"pdf_url":"https://arxiv.org/pdf/2410.04941v1.pdf","comment":"9 pages, 10 figures, 7 tables"},{"id":"http://arxiv.org/abs/2410.04940v1","updated":"2024-10-07T11:32:17Z","published":"2024-10-07T11:32:17Z","title":"Next state prediction gives rise to entangled, yet compositional\n  representations of objects","summary":"  Compositional representations are thought to enable humans to generalize\nacross combinatorially vast state spaces. Models with learnable object slots,\nwhich encode information about objects in separate latent codes, have shown\npromise for this type of generalization but rely on strong architectural\npriors. Models with distributed representations, on the other hand, use\noverlapping, potentially entangled neural codes, and their ability to support\ncompositional generalization remains underexplored. In this paper we examine\nwhether distributed models can develop linearly separable representations of\nobjects, like slotted models, through unsupervised training on videos of object\ninteractions. We show that, surprisingly, models with distributed\nrepresentations often match or outperform models with object slots in\ndownstream prediction tasks. Furthermore, we find that linearly separable\nobject representations can emerge without object-centric priors, with auxiliary\nobjectives like next-state prediction playing a key role. Finally, we observe\nthat distributed models' object representations are never fully disentangled,\neven if they are linearly separable: Multiple objects can be encoded through\npartially overlapping neural populations while still being highly separable\nwith a linear classifier. We hypothesize that maintaining partially shared\ncodes enables distributed models to better compress object dynamics,\npotentially enhancing generalization.\n","authors":["Tankred Saanum","Luca M. Schulze Buschoff","Peter Dayan","Eric Schulz"],"pdf_url":"https://arxiv.org/pdf/2410.04940v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04929v1","updated":"2024-10-07T11:19:23Z","published":"2024-10-07T11:19:23Z","title":"Goal-Conditioned Terminal Value Estimation for Real-time and Multi-task\n  Model Predictive Control","summary":"  While MPC enables nonlinear feedback control by solving an optimal control\nproblem at each timestep, the computational burden tends to be significantly\nlarge, making it difficult to optimize a policy within the control period. To\naddress this issue, one possible approach is to utilize terminal value learning\nto reduce computational costs. However, the learned value cannot be used for\nother tasks in situations where the task dynamically changes in the original\nMPC setup. In this study, we develop an MPC framework with goal-conditioned\nterminal value learning to achieve multitask policy optimization while reducing\ncomputational time. Furthermore, by using a hierarchical control structure that\nallows the upper-level trajectory planner to output appropriate\ngoal-conditioned trajectories, we demonstrate that a robot model is able to\ngenerate diverse motions. We evaluate the proposed method on a bipedal inverted\npendulum robot model and confirm that combining goal-conditioned terminal value\nlearning with an upper-level trajectory planner enables real-time control;\nthus, the robot successfully tracks a target trajectory on sloped terrain.\n","authors":["Mitsuki Morita","Satoshi Yamamori","Satoshi Yagi","Norikazu Sugimoto","Jun Morimoto"],"pdf_url":"https://arxiv.org/pdf/2410.04929v1.pdf","comment":"16 pages, 9 figures"},{"id":"http://arxiv.org/abs/2406.17263v2","updated":"2024-10-07T11:15:41Z","published":"2024-06-25T04:07:22Z","title":"Efficient, Multimodal, and Derivative-Free Bayesian Inference With\n  Fisher-Rao Gradient Flows","summary":"  In this paper, we study efficient approximate sampling for probability\ndistributions known up to normalization constants. We specifically focus on a\nproblem class arising in Bayesian inference for large-scale inverse problems in\nscience and engineering applications. The computational challenges we address\nwith the proposed methodology are: (i) the need for repeated evaluations of\nexpensive forward models; (ii) the potential existence of multiple modes; and\n(iii) the fact that gradient of, or adjoint solver for, the forward model might\nnot be feasible.\n  While existing Bayesian inference methods meet some of these challenges\nindividually, we propose a framework that tackles all three systematically. Our\napproach builds upon the Fisher-Rao gradient flow in probability space,\nyielding a dynamical system for probability densities that converges towards\nthe target distribution at a uniform exponential rate. This rapid convergence\nis advantageous for the computational burden outlined in (i). We apply Gaussian\nmixture approximations with operator splitting techniques to simulate the flow\nnumerically; the resulting approximation can capture multiple modes thus\naddressing (ii). Furthermore, we employ the Kalman methodology to facilitate a\nderivative-free update of these Gaussian components and their respective\nweights, addressing the issue in (iii).\n  The proposed methodology results in an efficient derivative-free sampler\nflexible enough to handle multi-modal distributions: Gaussian Mixture Kalman\nInversion (GMKI). The effectiveness of GMKI is demonstrated both theoretically\nand numerically in several experiments with multimodal target distributions,\nincluding proof-of-concept and two-dimensional examples, as well as a\nlarge-scale application: recovering the Navier-Stokes initial condition from\nsolution data at positive times.\n","authors":["Yifan Chen","Daniel Zhengyu Huang","Jiaoyang Huang","Sebastian Reich","Andrew M. Stuart"],"pdf_url":"https://arxiv.org/pdf/2406.17263v2.pdf","comment":"42 pages, 10 figures"},{"id":"http://arxiv.org/abs/2410.04916v1","updated":"2024-10-07T11:04:38Z","published":"2024-10-07T11:04:38Z","title":"Defense-as-a-Service: Black-box Shielding against Backdoored Graph\n  Models","summary":"  With the trend of large graph learning models, business owners tend to employ\na model provided by a third party to deliver business services to users.\nHowever, these models might be backdoored, and malicious users can submit\ntrigger-embedded inputs to manipulate the model predictions. Current graph\nbackdoor defenses have several limitations: 1) depending on model-related\ndetails, 2) requiring additional model fine-tuning, and 3) relying upon extra\nexplainability tools, all of which are infeasible under stringent privacy\npolicies. To address those limitations, we propose GraphProt, which allows\nresource-constrained business owners to rely on third parties to avoid backdoor\nattacks on GNN-based graph classifiers. Our GraphProt is model-agnostic and\nonly relies on the input graph. The key insight is to leverage subgraph\ninformation for prediction, thereby mitigating backdoor effects induced by\ntriggers. GraphProt comprises two components: clustering-based trigger\nelimination and robust subgraph ensemble. Specifically, we first propose\nfeature-topology clustering that aims to remove most of the anomalous subgraphs\n(triggers). Moreover, we design subgraph sampling strategies based on\nfeature-topology clustering to build a robust classifier via majority vote.\nExperimental results across three backdoor attacks and six benchmark datasets\ndemonstrate that GraphProt significantly reduces the backdoor attack success\nrate while preserving the model accuracy on regular graph classification tasks.\n","authors":["Xiao Yang","Kai Zhou","Yuni Lai","Gaolei Li"],"pdf_url":"https://arxiv.org/pdf/2410.04916v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.12561v5","updated":"2024-10-07T10:52:47Z","published":"2022-12-23T19:37:39Z","title":"An active learning method for solving competitive multi-agent\n  decision-making and control problems","summary":"  To identify a stationary action profile for a population of competitive\nagents, each executing private strategies, we introduce a novel active-learning\nscheme where a centralized external observer (or entity) can probe the agents'\nreactions and recursively update simple local parametric estimates of the\naction-reaction mappings. Under very general working assumptions (not even\nassuming that a stationary profile exists), sufficient conditions are\nestablished to assess the asymptotic properties of the proposed active learning\nmethodology so that, if the parameters characterizing the action-reaction\nmappings converge, a stationary action profile is achieved. Such conditions\nhence act also as certificates for the existence of such a profile. Extensive\nnumerical simulations involving typical competitive multi-agent control and\ndecision-making problems illustrate the practical effectiveness of the proposed\nlearning-based approach.\n","authors":["Filippo Fabiani","Alberto Bemporad"],"pdf_url":"https://arxiv.org/pdf/2212.12561v5.pdf","comment":"Python package available at https://github.com/bemporad/gnep-learn"},{"id":"http://arxiv.org/abs/2410.04907v1","updated":"2024-10-07T10:48:36Z","published":"2024-10-07T10:48:36Z","title":"Decomposition Polyhedra of Piecewise Linear Functions","summary":"  In this paper we contribute to the frequently studied question of how to\ndecompose a continuous piecewise linear (CPWL) function into a difference of\ntwo convex CPWL functions. Every CPWL function has infinitely many such\ndecompositions, but for applications in optimization and neural network theory,\nit is crucial to find decompositions with as few linear pieces as possible.\nThis is a highly challenging problem, as we further demonstrate by disproving a\nrecently proposed approach by Tran and Wang [Minimal representations of\ntropical rational functions. Algebraic Statistics, 15(1):27-59, 2024]. To make\nthe problem more tractable, we propose to fix an underlying polyhedral complex\ndetermining the possible locus of nonlinearity. Under this assumption, we prove\nthat the set of decompositions forms a polyhedron that arises as intersection\nof two translated cones. We prove that irreducible decompositions correspond to\nthe bounded faces of this polyhedron and minimal solutions must be vertices. We\nthen identify cases with a unique minimal decomposition, and illustrate how our\ninsights have consequences in the theory of submodular functions. Finally, we\nimprove upon previous constructions of neural networks for a given convex CPWL\nfunction and apply our framework to obtain results in the nonconvex case.\n","authors":["Marie-Charlotte Brandenburg","Moritz Grillo","Christoph Hertrich"],"pdf_url":"https://arxiv.org/pdf/2410.04907v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.12510v2","updated":"2024-10-07T10:31:58Z","published":"2024-03-19T07:24:54Z","title":"Generalized Consistency Trajectory Models for Image Manipulation","summary":"  Diffusion models (DMs) excel in unconditional generation, as well as on\napplications such as image editing and restoration. The success of DMs lies in\nthe iterative nature of diffusion: diffusion breaks down the complex process of\nmapping noise to data into a sequence of simple denoising tasks. Moreover, we\nare able to exert fine-grained control over the generation process by injecting\nguidance terms into each denoising step. However, the iterative process is also\ncomputationally intensive, often taking from tens up to thousands of function\nevaluations. Although consistency trajectory models (CTMs) enable traversal\nbetween any time points along the probability flow ODE (PFODE) and score\ninference with a single function evaluation, CTMs only allow translation from\nGaussian noise to data. This work aims to unlock the full potential of CTMs by\nproposing generalized CTMs (GCTMs), which translate between arbitrary\ndistributions via ODEs. We discuss the design space of GCTMs and demonstrate\ntheir efficacy in various image manipulation tasks such as image-to-image\ntranslation, restoration, and editing.\n","authors":["Beomsu Kim","Jaemin Kim","Jeongsol Kim","Jong Chul Ye"],"pdf_url":"https://arxiv.org/pdf/2403.12510v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.11834v4","updated":"2024-10-07T10:28:24Z","published":"2023-12-19T04:02:50Z","title":"Multi-agent reinforcement learning using echo-state network and its\n  application to pedestrian dynamics","summary":"  In recent years, simulations of pedestrians using the multi-agent\nreinforcement learning (MARL) have been studied. This study considered the\nroads on a grid-world environment, and implemented pedestrians as MARL agents\nusing an echo-state network and the least squares policy iteration method.\nUnder this environment, the ability of these agents to learn to move forward by\navoiding other agents was investigated. Specifically, we considered two types\nof tasks: the choice between a narrow direct route and a broad detour, and the\nbidirectional pedestrian flow in a corridor. The simulations results indicated\nthat the learning was successful when the density of the agents was not that\nhigh.\n","authors":["Hisato Komatsu"],"pdf_url":"https://arxiv.org/pdf/2312.11834v4.pdf","comment":"25 pages, 19 figures"},{"id":"http://arxiv.org/abs/2410.04891v1","updated":"2024-10-07T10:19:09Z","published":"2024-10-07T10:19:09Z","title":"Low-Rank Continual Personalization of Diffusion Models","summary":"  Recent personalization methods for diffusion models, such as Dreambooth,\nallow fine-tuning pre-trained models to generate new concepts. However,\napplying these techniques across multiple tasks in order to include, e.g.,\nseveral new objects or styles, leads to mutual interference between their\nadapters. While recent studies attempt to mitigate this issue by combining\ntrained adapters across tasks after fine-tuning, we adopt a more rigorous\nregime and investigate the personalization of large diffusion models under a\ncontinual learning scenario, where such interference leads to catastrophic\nforgetting of previous knowledge. To that end, we evaluate the na\\\"ive\ncontinual fine-tuning of customized models and compare this approach with three\nmethods for consecutive adapters' training: sequentially merging new adapters,\nmerging orthogonally initialized adapters, and updating only relevant\nparameters according to the task. In our experiments, we show that the proposed\napproaches mitigate forgetting when compared to the na\\\"ive approach.\n","authors":["Łukasz Staniszewski","Katarzyna Zaleska","Kamil Deja"],"pdf_url":"https://arxiv.org/pdf/2410.04891v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04887v1","updated":"2024-10-07T10:16:40Z","published":"2024-10-07T10:16:40Z","title":"Wide Neural Networks Trained with Weight Decay Provably Exhibit Neural\n  Collapse","summary":"  Deep neural networks (DNNs) at convergence consistently represent the\ntraining data in the last layer via a highly symmetric geometric structure\nreferred to as neural collapse. This empirical evidence has spurred a line of\ntheoretical research aimed at proving the emergence of neural collapse, mostly\nfocusing on the unconstrained features model. Here, the features of the\npenultimate layer are free variables, which makes the model data-agnostic and,\nhence, puts into question its ability to capture DNN training. Our work\naddresses the issue, moving away from unconstrained features and studying DNNs\nthat end with at least two linear layers. We first prove generic guarantees on\nneural collapse that assume (i) low training error and balancedness of the\nlinear layers (for within-class variability collapse), and (ii) bounded\nconditioning of the features before the linear part (for orthogonality of\nclass-means, as well as their alignment with weight matrices). We then show\nthat such assumptions hold for gradient descent training with weight decay: (i)\nfor networks with a wide first layer, we prove low training error and\nbalancedness, and (ii) for solutions that are either nearly optimal or stable\nunder large learning rates, we additionally prove the bounded conditioning.\nTaken together, our results are the first to show neural collapse in the\nend-to-end training of DNNs.\n","authors":["Arthur Jacot","Peter Súkeník","Zihan Wang","Marco Mondelli"],"pdf_url":"https://arxiv.org/pdf/2410.04887v1.pdf","comment":"29 pages, 5 figures"},{"id":"http://arxiv.org/abs/2402.06165v4","updated":"2024-10-07T10:14:00Z","published":"2024-02-09T03:48:20Z","title":"Learning Contrastive Feature Representations for Facial Action Unit\n  Detection","summary":"  Facial action unit (AU) detection has long encountered the challenge of\ndetecting subtle feature differences when AUs activate. Existing methods often\nrely on encoding pixel-level information of AUs, which not only encodes\nadditional redundant information but also leads to increased model complexity\nand limited generalizability. Additionally, the accuracy of AU detection is\nnegatively impacted by the class imbalance issue of each AU type, and the\npresence of noisy and false AU labels. In this paper, we introduce a novel\ncontrastive learning framework aimed for AU detection that incorporates both\nself-supervised and supervised signals, thereby enhancing the learning of\ndiscriminative features for accurate AU detection. To tackle the class\nimbalance issue, we employ a negative sample re-weighting strategy that adjusts\nthe step size of updating parameters for minority and majority class samples.\nMoreover, to address the challenges posed by noisy and false AU labels, we\nemploy a sampling technique that encompasses three distinct types of positive\nsample pairs. This enables us to inject self-supervised signals into the\nsupervised signal, effectively mitigating the adverse effects of noisy labels.\nOur experimental assessments, conducted on four widely-utilized benchmark\ndatasets (BP4D, DISFA, GFT and Aff-Wild2), underscore the superior performance\nof our approach compared to state-of-the-art methods of AU detection. Our code\nis available at \\url{https://github.com/Ziqiao-Shang/AUNCE}.\n","authors":["Ziqiao Shang","Bin Liu","Fengmao Lv","Fei Teng","Tianrui Li"],"pdf_url":"https://arxiv.org/pdf/2402.06165v4.pdf","comment":"13 pages, 17 figures, submitted to IEEE Transactions on Circuits and\n  Systems for Video Technology (TCSVT)"},{"id":"http://arxiv.org/abs/2302.00671v2","updated":"2024-10-07T10:04:28Z","published":"2023-02-01T18:58:20Z","title":"QMP: Q-switch Mixture of Policies for Multi-Task Behavior Sharing","summary":"  Multi-task reinforcement learning (MTRL) aims to learn several tasks\nsimultaneously for better sample efficiency than learning them separately.\nTraditional methods achieve this by sharing parameters or relabeled data\nbetween tasks. In this work, we introduce a new framework for sharing\nbehavioral policies across tasks, which can be used in addition to existing\nMTRL methods. The key idea is to improve each task's off-policy data collection\nby employing behaviors from other task policies. Selectively sharing helpful\nbehaviors acquired in one task to collect training data for another task can\nlead to higher-quality trajectories, leading to more sample-efficient MTRL.\nThus, we introduce a simple and principled framework called Q-switch mixture of\npolicies (QMP) that selectively shares behavior between different task policies\nby using the task's Q-function to evaluate and select useful shareable\nbehaviors. We theoretically analyze how QMP improves the sample efficiency of\nthe underlying RL algorithm. Our experiments show that QMP's behavioral policy\nsharing provides complementary gains over many popular MTRL algorithms and\noutperforms alternative ways to share behaviors in various manipulation,\nlocomotion, and navigation environments. Videos are available at\nhttps://qmp-mtrl.github.io.\n","authors":["Grace Zhang","Ayush Jain","Injune Hwang","Shao-Hua Sun","Joseph J. Lim"],"pdf_url":"https://arxiv.org/pdf/2302.00671v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04883v1","updated":"2024-10-07T10:02:31Z","published":"2024-10-07T10:02:31Z","title":"Improving the Sampling Strategy in KernelSHAP","summary":"  Shapley values are a popular model-agnostic explanation framework for\nexplaining predictions made by complex machine learning models. The framework\nprovides feature contribution scores that sum to the predicted response and\nrepresent each feature's importance. The computation of exact Shapley values is\ncomputationally expensive due to estimating an exponential amount of\nnon-trivial conditional expectations. The KernelSHAP framework enables us to\napproximate the Shapley values using a sampled subset of weighted conditional\nexpectations. We propose three main novel contributions: a stabilizing\ntechnique to reduce the variance of the weights in the current state-of-the-art\nstrategy, a novel weighing scheme that corrects the Shapley kernel weights\nbased on sampled subsets, and a straightforward strategy that includes the\nimportant subsets and integrates them with the corrected Shapley kernel\nweights. We compare these new approximation strategies against existing ones by\nevaluating their Shapley value accuracy as a function of the number of subsets.\nThe results demonstrate that our sampling strategies significantly enhance the\naccuracy of the approximated Shapley value explanations, making them more\nreliable in practical applications. This work provides valuable insights and\npractical recommendations for researchers and practitioners seeking to\nimplement Shapley value-based explainability of their models.\n","authors":["Lars Henry Berge Olsen","Martin Jullum"],"pdf_url":"https://arxiv.org/pdf/2410.04883v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.08227v2","updated":"2024-10-07T09:51:46Z","published":"2024-07-11T07:01:50Z","title":"DALL-M: Context-Aware Clinical Data Augmentation with LLMs","summary":"  X-ray images are vital in medical diagnostics, but their effectiveness is\nlimited without clinical context. Radiologists often find chest X-rays\ninsufficient for diagnosing underlying diseases, necessitating comprehensive\nclinical features and data integration. We present a novel framework to enhance\nthe clinical context through augmentation techniques with clinical tabular\ndata, thereby improving its applicability and reliability in AI medical\ndiagnostics. We introduce a pioneering approach to clinical data augmentation\nthat employs large language models to generate patient contextual synthetic\ndata. This methodology is crucial for training more robust deep learning models\nin healthcare. It preserves the integrity of real patient data while enriching\nthe dataset with contextually relevant synthetic features, significantly\nenhancing model performance. Our methodology, termed DALL-M, uses a three-phase\nfeature generation process: (i)clinical context storage, (ii)expert query\ngeneration, and (iii)context-aware feature augmentation. DALL-M generates new,\nclinically relevant features by synthesizing chest X-ray images and reports.\nApplied to 799 cases using nine features from the MIMIC-IV dataset, it created\nan augmented set of 91 features. This is the first work to generate contextual\nvalues for patients' X-ray reports. Specifically, we provide (i)the capacity of\nLLMs to generate contextual synthetic values for existing clinical features and\n(ii)their ability to create entirely new clinically relevant features.\nEmpirical validation with machine learning models showed significant\nperformance improvements. Incorporating augmented features increased the F1\nscore by 16.5% and Precision and Recall by approximately 25%. DALL-M addresses\na critical gap in clinical data augmentation, offering a robust framework for\ngenerating contextually enriched datasets.\n","authors":["Chihcheng Hsieh","Catarina Moreira","Isabel Blanco Nobre","Sandra Costa Sousa","Chun Ouyang","Margot Brereton","Joaquim Jorge","Jacinto C. Nascimento"],"pdf_url":"https://arxiv.org/pdf/2407.08227v2.pdf","comment":"we introduce a pioneering approach to clinical data augmentation that\n  employs large language models (LLMs) to generate patient contextual synthetic\n  data. It preserves the integrity of real patient data while enriching the\n  dataset with contextually relevant synthetic features, significantly\n  enhancing model performance"},{"id":"http://arxiv.org/abs/2308.06300v3","updated":"2024-10-07T09:48:14Z","published":"2023-08-11T07:57:12Z","title":"Classification of All Blood Cell Images using ML and DL Models","summary":"  Human blood primarily comprises plasma, red blood cells, white blood cells,\nand platelets. It plays a vital role in transporting nutrients to different\norgans, where it stores essential health-related data about the human body.\nBlood cells are utilized to defend the body against diverse infections,\nincluding fungi, viruses, and bacteria. Hence, blood analysis can help\nphysicians assess an individual's physiological condition. Blood cells have\nbeen sub-classified into eight groups: Neutrophils, eosinophils, basophils,\nlymphocytes, monocytes, immature granulocytes (promyelocytes, myelocytes, and\nmetamyelocytes), erythroblasts, and platelets or thrombocytes on the basis of\ntheir nucleus, shape, and cytoplasm. Traditionally, pathologists and\nhematologists in laboratories have examined these blood cells using a\nmicroscope before manually classifying them. The manual approach is slower and\nmore prone to human error. Therefore, it is essential to automate this process.\nIn our paper, transfer learning with CNN pre-trained models. VGG16, VGG19,\nResNet-50, ResNet-101, ResNet-152, InceptionV3, MobileNetV2, and DenseNet-20\napplied to the PBC dataset's normal DIB. The overall accuracy achieved with\nthese models lies between 91.375 and 94.72%. Hence, inspired by these\npre-trained architectures, a model has been proposed to automatically classify\nthe ten types of blood cells with increased accuracy. A novel CNN-based\nframework has been presented to improve accuracy. The proposed CNN model has\nbeen tested on the PBC dataset normal DIB. The outcomes of the experiments\ndemonstrate that our CNN-based framework designed for blood cell classification\nattains an accuracy of 99.91% on the PBC dataset. Our proposed convolutional\nneural network model performs competitively when compared to earlier results\nreported in the literature.\n","authors":["Rabia Asghar","Sanjay Kumar","Paul Hynds","Abeera Mahfooz"],"pdf_url":"https://arxiv.org/pdf/2308.06300v3.pdf","comment":"15"},{"id":"http://arxiv.org/abs/2410.04870v1","updated":"2024-10-07T09:36:43Z","published":"2024-10-07T09:36:43Z","title":"On the Optimization and Generalization of Two-layer Transformers with\n  Sign Gradient Descent","summary":"  The Adam optimizer is widely used for transformer optimization in practice,\nwhich makes understanding the underlying optimization mechanisms an important\nproblem. However, due to the Adam's complexity, theoretical analysis of how it\noptimizes transformers remains a challenging task. Fortunately, Sign Gradient\nDescent (SignGD) serves as an effective surrogate for Adam. Despite its\nsimplicity, theoretical understanding of how SignGD optimizes transformers\nstill lags behind. In this work, we study how SignGD optimizes a two-layer\ntransformer -- consisting of a softmax attention layer with trainable query-key\nparameterization followed by a linear layer -- on a linearly separable noisy\ndataset. We identify four stages in the training dynamics, each exhibiting\nintriguing behaviors. Based on the training dynamics, we prove the fast\nconvergence but poor generalization of the learned transformer on the noisy\ndataset. We also show that Adam behaves similarly to SignGD in terms of both\noptimization and generalization in this setting. Additionally, we find that the\npoor generalization of SignGD is not solely due to data noise, suggesting that\nboth SignGD and Adam requires high-quality data for real-world tasks. Finally,\nexperiments on synthetic and real-world datasets empirically support our\ntheoretical results.\n","authors":["Bingrui Li","Wei Huang","Andi Han","Zhanpeng Zhou","Taiji Suzuki","Jun Zhu","Jianfei Chen"],"pdf_url":"https://arxiv.org/pdf/2410.04870v1.pdf","comment":"preprint"},{"id":"http://arxiv.org/abs/2410.04865v1","updated":"2024-10-07T09:27:51Z","published":"2024-10-07T09:27:51Z","title":"Mastering Chinese Chess AI (Xiangqi) Without Search","summary":"  We have developed a high-performance Chinese Chess AI that operates without\nreliance on search algorithms. This AI has demonstrated the capability to\ncompete at a level commensurate with the top 0.1\\% of human players. By\neliminating the search process typically associated with such systems, this AI\nachieves a Queries Per Second (QPS) rate that exceeds those of systems based on\nthe Monte Carlo Tree Search (MCTS) algorithm by over a thousandfold and\nsurpasses those based on the AlphaBeta pruning algorithm by more than a\nhundredfold. The AI training system consists of two parts: supervised learning\nand reinforcement learning. Supervised learning provides an initial human-like\nChinese chess AI, while reinforcement learning, based on supervised learning,\nelevates the strength of the entire AI to a new level. Based on this training\nsystem, we carried out enough ablation experiments and discovered that 1. The\nsame parameter amount of Transformer architecture has a higher performance than\nCNN on Chinese chess; 2. Possible moves of both sides as features can greatly\nimprove the training process; 3. Selective opponent pool, compared to pure\nself-play training, results in a faster improvement curve and a higher strength\nlimit. 4. Value Estimation with Cutoff(VECT) improves the original PPO\nalgorithm training process and we will give the explanation.\n","authors":["Yu Chen","Juntong Lin","Zhichao Shu"],"pdf_url":"https://arxiv.org/pdf/2410.04865v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.18338v3","updated":"2024-10-07T09:20:59Z","published":"2024-09-26T23:23:27Z","title":"AQMLator -- An Auto Quantum Machine Learning E-Platform","summary":"  A successful Machine Learning (ML) model implementation requires three main\ncomponents: training dataset, suitable model architecture and training\nprocedure. Given dataset and task, finding an appropriate model might be\nchallenging. AutoML, a branch of ML, focuses on automatic architecture search\n-- a meta method that aims at moving human from ML system design process. The\nsuccess of ML and the development of quantum computing (QC) in recent years led\nto a birth of new fascinating field called Quantum Machine Learning (QML) that,\namongst others, incorporates quantum computers into ML models. In this paper we\npresent AQMLator, an Auto Quantum Machine Learning platform that aims to\nautomatically propose and train the quantum layers of an ML model with minimal\ninput from the user. This way, data scientists can bypass the entry barrier for\nQC and use QML. AQMLator uses standard ML libraries, making it easy to\nintroduce into existing ML pipelines.\n","authors":["Tomasz Rybotycki","Piotr Gawron"],"pdf_url":"https://arxiv.org/pdf/2409.18338v3.pdf","comment":"15 pages, 3 figures, links to software in the text"},{"id":"http://arxiv.org/abs/2410.04855v1","updated":"2024-10-07T09:19:13Z","published":"2024-10-07T09:19:13Z","title":"Unsupervised Skill Discovery for Robotic Manipulation through Automatic\n  Task Generation","summary":"  Learning skills that interact with objects is of major importance for robotic\nmanipulation. These skills can indeed serve as an efficient prior for solving\nvarious manipulation tasks. We propose a novel Skill Learning approach that\ndiscovers composable behaviors by solving a large and diverse number of\nautonomously generated tasks. Our method learns skills allowing the robot to\nconsistently and robustly interact with objects in its environment. The\ndiscovered behaviors are embedded in primitives which can be composed with\nHierarchical Reinforcement Learning to solve unseen manipulation tasks. In\nparticular, we leverage Asymmetric Self-Play to discover behaviors and\nMultiplicative Compositional Policies to embed them. We compare our method to\nSkill Learning baselines and find that our skills are more interactive.\nFurthermore, the learned skills can be used to solve a set of unseen\nmanipulation tasks, in simulation as well as on a real robotic platform.\n","authors":["Paul Jansonnie","Bingbing Wu","Julien Perez","Jan Peters"],"pdf_url":"https://arxiv.org/pdf/2410.04855v1.pdf","comment":"Accepted at the 2024 IEEE-RAS International Conference on Humanoid\n  Robots"},{"id":"http://arxiv.org/abs/2410.04853v1","updated":"2024-10-07T09:16:58Z","published":"2024-10-07T09:16:58Z","title":"TimeCNN: Refining Cross-Variable Interaction on Time Point for Time\n  Series Forecasting","summary":"  Time series forecasting is extensively applied across diverse domains.\nTransformer-based models demonstrate significant potential in modeling\ncross-time and cross-variable interaction. However, we notice that the\ncross-variable correlation of multivariate time series demonstrates\nmultifaceted (positive and negative correlations) and dynamic progression over\ntime, which is not well captured by existing Transformer-based models. To\naddress this issue, we propose a TimeCNN model to refine cross-variable\ninteractions to enhance time series forecasting. Its key innovation is\ntimepoint-independent, where each time point has an independent convolution\nkernel, allowing each time point to have its independent model to capture\nrelationships among variables. This approach effectively handles both positive\nand negative correlations and adapts to the evolving nature of variable\nrelationships over time. Extensive experiments conducted on 12 real-world\ndatasets demonstrate that TimeCNN consistently outperforms state-of-the-art\nmodels. Notably, our model achieves significant reductions in computational\nrequirements (approximately 60.46%) and parameter count (about 57.50%), while\ndelivering inference speeds 3 to 4 times faster than the benchmark iTransformer\nmodel\n","authors":["Ao Hu","Dongkai Wang","Yong Dai","Shiyi Qi","Liangjian Wen","Jun Wang","Zhi Chen","Xun Zhou","Zenglin Xu","Jiang Duan"],"pdf_url":"https://arxiv.org/pdf/2410.04853v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.09887v2","updated":"2024-10-07T09:15:07Z","published":"2024-07-13T13:27:57Z","title":"OptiBench Meets ReSocratic: Measure and Improve LLMs for Optimization\n  Modeling","summary":"  Large language models (LLMs) have exhibited their problem-solving abilities\nin mathematical reasoning. Solving realistic optimization (OPT) problems in\napplication scenarios requires advanced and applied mathematics ability.\nHowever, current OPT benchmarks that merely solve linear programming are far\nfrom complex realistic situations. In this work, we propose OptiBench, a\nbenchmark for End-to-end optimization problem-solving with human-readable\ninputs and outputs. OptiBench contains rich optimization problems, including\nlinear and nonlinear programming with or without tabular data, which can\ncomprehensively evaluate LLMs' solving ability. In our benchmark, LLMs are\nrequired to call a code solver to provide precise numerical answers.\nFurthermore, to alleviate the data scarcity for optimization problems, and to\nbridge the gap between open-source LLMs on a small scale (e.g., Llama-3-8b) and\nclosed-source LLMs (e.g., GPT-4), we further propose a data synthesis method\nnamely ReSocratic. Unlike general data synthesis methods that proceed from\nquestions to answers, \\ReSocratic first incrementally synthesizes formatted\noptimization demonstration with mathematical formulations step by step and then\nback-translates the generated demonstrations into questions. Based on this, we\nsynthesize the ReSocratic-29k dataset. We further conduct supervised\nfine-tuning with ReSocratic-29k on multiple open-source models. Experimental\nresults show that ReSocratic-29k significantly improves the performance of\nopen-source models.\n","authors":["Zhicheng Yang","Yiwei Wang","Yinya Huang","Zhijiang Guo","Wei Shi","Xiongwei Han","Liang Feng","Linqi Song","Xiaodan Liang","Jing Tang"],"pdf_url":"https://arxiv.org/pdf/2407.09887v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13538v5","updated":"2024-10-07T09:11:49Z","published":"2023-11-22T17:24:21Z","title":"AlignedCoT: Prompting Large Language Models via Native-Speaking\n  Demonstrations","summary":"  Large Language Models prompting, such as using in-context demonstrations, is\na mainstream technique for invoking LLMs to perform high-performance and solid\ncomplex reasoning (e.g., mathematical reasoning, commonsense reasoning), and\nhas the potential for further human-machine collaborative scientific findings.\nHowever, current LLMs are delicate and elusive in prompt words and styles. And\nthere is an unseen gap between LLM understanding and human-written prompts.\nThis paper introduces Alignedcot, an LLM-acquainted prompting technique that\nincludes proficient ``native-speaking'' in in-context learning for the LLMs.\nSpecifically, it achieves consistent and correct step-wise prompts in zero-shot\nscenarios by progressively probing, refining, and formatting the LLM chain of\nthoughts so that free from handcrafted few-shot demonstrations while\nmaintaining the prompt quality. We conduct experiments on mathematical\nreasoning and commonsense reasoning. We find that LLMs with Alignedcot perform\nsignificantly superior to them with human-crafted demonstrations. We further\napply Alignedcot for rewriting the GSM8K training set, resulting in a\nGSM8K-Align dataset. We observe its benefits for retrieval augmented\ngeneration. The code and data can be found at\nhttps://github.com/yangzhch6/AlignedCoT.\n","authors":["Zhicheng Yang","Yinya Huang","Jing Xiong","Liang Feng","Xiaodan Liang","Yiwei Wang","Jing Tang"],"pdf_url":"https://arxiv.org/pdf/2311.13538v5.pdf","comment":"Findings of EMNLP 2024"},{"id":"http://arxiv.org/abs/2410.04840v1","updated":"2024-10-07T08:54:23Z","published":"2024-10-07T08:54:23Z","title":"Strong Model Collapse","summary":"  Within the scaling laws paradigm, which underpins the training of large\nneural networks like ChatGPT and Llama, we consider a supervised regression\nsetting and establish the existance of a strong form of the model collapse\nphenomenon, a critical performance degradation due to synthetic data in the\ntraining corpus. Our results show that even the smallest fraction of synthetic\ndata (e.g., as little as 1\\% of the total training dataset) can still lead to\nmodel collapse: larger and larger training sets do not enhance performance. We\nfurther investigate whether increasing model size, an approach aligned with\ncurrent trends in training large language models, exacerbates or mitigates\nmodel collapse. In a simplified regime where neural networks are approximated\nvia random projections of tunable size, we both theoretically and empirically\nshow that larger models can amplify model collapse. Interestingly, our theory\nalso indicates that, beyond the interpolation threshold (which can be extremely\nhigh for very large datasets), larger models may mitigate the collapse,\nalthough they do not entirely prevent it. Our theoretical findings are\nempirically verified through experiments on language models and feed-forward\nneural networks for images.\n","authors":["Elvis Dohmatob","Yunzhen Feng","Julia Kempe"],"pdf_url":"https://arxiv.org/pdf/2410.04840v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.14407v3","updated":"2024-10-07T08:45:35Z","published":"2024-02-22T09:48:47Z","title":"Learning an Actionable Discrete Diffusion Policy via Large-Scale\n  Actionless Video Pre-Training","summary":"  Learning a generalist embodied agent capable of completing multiple tasks\nposes challenges, primarily stemming from the scarcity of action-labeled\nrobotic datasets. In contrast, a vast amount of human videos exist, capturing\nintricate tasks and interactions with the physical world. Promising prospects\narise for utilizing actionless human videos for pre-training and transferring\nthe knowledge to facilitate robot policy learning through limited robot\ndemonstrations. However, it remains a challenge due to the domain gap between\nhumans and robots. Moreover, it is difficult to extract useful information\nrepresenting the dynamic world from human videos, because of its noisy and\nmultimodal data structure. In this paper, we introduce a novel framework to\ntackle these challenges, which leverages a unified discrete diffusion to\ncombine generative pre-training on human videos and policy fine-tuning on a\nsmall number of action-labeled robot videos. We start by compressing both human\nand robot videos into unified video tokens. In the pre-training stage, we\nemploy a discrete diffusion model with a mask-and-replace diffusion strategy to\npredict future video tokens in the latent space. In the fine-tuning stage, we\nharness the imagined future videos to guide low-level action learning with a\nlimited set of robot data. Experiments demonstrate that our method generates\nhigh-fidelity future videos for planning and enhances the fine-tuned policies\ncompared to previous state-of-the-art approaches with superior performance. Our\nproject website is available at https://video-diff.github.io/.\n","authors":["Haoran He","Chenjia Bai","Ling Pan","Weinan Zhang","Bin Zhao","Xuelong Li"],"pdf_url":"https://arxiv.org/pdf/2402.14407v3.pdf","comment":"Accepted by NeurIPS 2024. 24 pages"},{"id":"http://arxiv.org/abs/2408.08313v2","updated":"2024-10-07T08:44:35Z","published":"2024-08-15T17:59:57Z","title":"Can Large Language Models Understand Symbolic Graphics Programs?","summary":"  Against the backdrop of enthusiasm for large language models (LLMs), there is\nan urgent need to scientifically assess their capabilities and shortcomings.\nThis is nontrivial in part because it is difficult to find tasks which the\nmodels have not encountered during training. Utilizing symbolic graphics\nprograms, we propose a domain well-suited to test multiple spatial-semantic\nreasoning skills of LLMs. Popular in computer graphics, these programs\nprocedurally generate visual data. While LLMs exhibit impressive skills in\ngeneral program synthesis and analysis, symbolic graphics programs offer a new\nlayer of evaluation: they allow us to test an LLM's ability to answer\ndifferent-grained semantic-level questions of the images or 3D geometries\nwithout a vision encoder. To semantically understand the symbolic programs,\nLLMs would need to possess the ability to \"imagine\" and reason how the\ncorresponding graphics content would look with only the symbolic description.\nWe use this task to evaluate LLMs by creating a large benchmark for the\nsemantic visual understanding of symbolic graphics programs, built procedurally\nwith minimal human effort. Particular emphasis is placed on transformations of\nimages that leave the image level semantics invariant while introducing\nsignificant changes to the underlying program. We evaluate commercial and\nopen-source LLMs on our benchmark to assess their ability to reason about\nvisual output of programs, finding that LLMs considered stronger at reasoning\ngenerally perform better. Lastly, we introduce a novel method to improve this\nability -- Symbolic Instruction Tuning (SIT), in which the LLM is finetuned\nwith pre-collected instruction data on symbolic graphics programs.\nInterestingly, we find that SIT not only improves LLM's understanding on\nsymbolic programs, but it also improves general reasoning ability on various\nother benchmarks.\n","authors":["Zeju Qiu","Weiyang Liu","Haiwen Feng","Zhen Liu","Tim Z. Xiao","Katherine M. Collins","Joshua B. Tenenbaum","Adrian Weller","Michael J. Black","Bernhard Schölkopf"],"pdf_url":"https://arxiv.org/pdf/2408.08313v2.pdf","comment":"Technical Report v2 (46 pages, 24 figures, project page:\n  https://sgp-bench.github.io/, substantial update from v1)"},{"id":"http://arxiv.org/abs/2409.03588v2","updated":"2024-10-07T08:44:08Z","published":"2024-09-05T14:43:11Z","title":"Cost Estimation in Unit Commitment Problems Using Simulation-Based\n  Inference","summary":"  The Unit Commitment (UC) problem is a key optimization task in power systems\nto forecast the generation schedules of power units over a finite time period\nby minimizing costs while meeting demand and technical constraints. However,\nmany parameters required by the UC problem are unknown, such as the costs. In\nthis work, we estimate these unknown costs using simulation-based inference on\nan illustrative UC problem, which provides an approximated posterior\ndistribution of the parameters given observed generation schedules and demands.\nOur results highlight that the learned posterior distribution effectively\ncaptures the underlying distribution of the data, providing a range of possible\nvalues for the unknown parameters given a past observation. This posterior\nallows for the estimation of past costs using observed past generation\nschedules, enabling operators to better forecast future costs and make more\nrobust generation scheduling forecasts. We present avenues for future research\nto address overconfidence in posterior estimation, enhance the scalability of\nthe methodology and apply it to more complex UC problems modeling the network\nconstraints and renewable energy sources.\n","authors":["Matthias Pirlet","Adrien Bolland","Gilles Louppe","Damien Ernst"],"pdf_url":"https://arxiv.org/pdf/2409.03588v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04833v1","updated":"2024-10-07T08:40:29Z","published":"2024-10-07T08:40:29Z","title":"Multimodal Fusion Strategies for Mapping Biophysical Landscape Features","summary":"  Multimodal aerial data are used to monitor natural systems, and machine\nlearning can significantly accelerate the classification of landscape features\nwithin such imagery to benefit ecology and conservation. It remains\nunder-explored, however, how these multiple modalities ought to be fused in a\ndeep learning model. As a step towards filling this gap, we study three\nstrategies (Early fusion, Late fusion, and Mixture of Experts) for fusing\nthermal, RGB, and LiDAR imagery using a dataset of spatially-aligned\northomosaics in these three modalities. In particular, we aim to map three\necologically-relevant biophysical landscape features in African savanna\necosystems: rhino middens, termite mounds, and water. The three fusion\nstrategies differ in whether the modalities are fused early or late, and if\nlate, whether the model learns fixed weights per modality for each class or\ngenerates weights for each class adaptively, based on the input. Overall, the\nthree methods have similar macro-averaged performance with Late fusion\nachieving an AUC of 0.698, but their per-class performance varies strongly,\nwith Early fusion achieving the best recall for middens and water and Mixture\nof Experts achieving the best recall for mounds.\n","authors":["Lucia Gordon","Nico Lang","Catherine Ressijac","Andrew Davies"],"pdf_url":"https://arxiv.org/pdf/2410.04833v1.pdf","comment":"9 pages, 4 figures, ECCV 2024 Workshop in CV for Ecology"},{"id":"http://arxiv.org/abs/2410.04824v1","updated":"2024-10-07T08:22:20Z","published":"2024-10-07T08:22:20Z","title":"Taming Gradient Oversmoothing and Expansion in Graph Neural Networks","summary":"  Oversmoothing has been claimed as a primary bottleneck for multi-layered\ngraph neural networks (GNNs). Multiple analyses have examined how and why\noversmoothing occurs. However, none of the prior work addressed how\noptimization is performed under the oversmoothing regime. In this work, we show\nthe presence of $\\textit{gradient oversmoothing}$ preventing optimization\nduring training. We further analyze that GNNs with residual connections, a\nwell-known solution to help gradient flow in deep architecture, introduce\n$\\textit{gradient expansion}$, a phenomenon of the gradient explosion in\ndiverse directions. Therefore, adding residual connections cannot be a solution\nfor making a GNN deep. Our analysis reveals that constraining the Lipschitz\nbound of each layer can neutralize the gradient expansion. To this end, we\nprovide a simple yet effective normalization method to prevent the gradient\nexpansion. An empirical study shows that the residual GNNs with hundreds of\nlayers can be efficiently trained with the proposed normalization without\ncompromising performance. Additional studies show that the empirical\nobservations corroborate our theoretical analysis.\n","authors":["MoonJeong Park","Dongwoo Kim"],"pdf_url":"https://arxiv.org/pdf/2410.04824v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.13753v3","updated":"2024-10-07T08:20:55Z","published":"2024-05-22T15:38:30Z","title":"A Dynamic Model of Performative Human-ML Collaboration: Theory and\n  Empirical Evidence","summary":"  Machine learning (ML) models are increasingly used in various applications,\nfrom recommendation systems in e-commerce to diagnosis prediction in\nhealthcare. In this paper, we present a novel dynamic framework for thinking\nabout the deployment of ML models in a performative, human-ML collaborative\nsystem. In our framework, the introduction of ML recommendations changes the\ndata-generating process of human decisions, which are only a proxy to the\nground truth and which are then used to train future versions of the model. We\nshow that this dynamic process in principle can converge to different stable\npoints, i.e. where the ML model and the Human+ML system have the same\nperformance. Some of these stable points are suboptimal with respect to the\nactual ground truth. As a proof of concept, we conduct an empirical user study\nwith 1,408 participants. In the study, humans solve instances of the knapsack\nproblem with the help of machine learning predictions of varying performance.\nThis is an ideal setting because we can identify the actual ground truth, and\nevaluate the performance of human decisions supported by ML recommendations. We\nfind that for many levels of ML performance, humans can improve upon the ML\npredictions. We also find that the improvement could be even higher if humans\nrationally followed the ML recommendations. Finally, we test whether monetary\nincentives can increase the quality of human decisions, but we fail to find any\npositive effect. Using our empirical data to approximate our collaborative\nsystem suggests that the learning process would dynamically reach an\nequilibrium performance that is around 92% of the maximum knapsack value. Our\nresults have practical implications for the deployment of ML models in contexts\nwhere human decisions may deviate from the indisputable ground truth.\n","authors":["Tom Sühr","Samira Samadi","Chiara Farronato"],"pdf_url":"https://arxiv.org/pdf/2405.13753v3.pdf","comment":"10 Pages and appendix"},{"id":"http://arxiv.org/abs/2409.06744v2","updated":"2024-10-07T08:20:32Z","published":"2024-09-10T06:52:33Z","title":"ProteinBench: A Holistic Evaluation of Protein Foundation Models","summary":"  Recent years have witnessed a surge in the development of protein foundation\nmodels, significantly improving performance in protein prediction and\ngenerative tasks ranging from 3D structure prediction and protein design to\nconformational dynamics. However, the capabilities and limitations associated\nwith these models remain poorly understood due to the absence of a unified\nevaluation framework. To fill this gap, we introduce ProteinBench, a holistic\nevaluation framework designed to enhance the transparency of protein foundation\nmodels. Our approach consists of three key components: (i) A taxonomic\nclassification of tasks that broadly encompass the main challenges in the\nprotein domain, based on the relationships between different protein\nmodalities; (ii) A multi-metric evaluation approach that assesses performance\nacross four key dimensions: quality, novelty, diversity, and robustness; and\n(iii) In-depth analyses from various user objectives, providing a holistic view\nof model performance. Our comprehensive evaluation of protein foundation models\nreveals several key findings that shed light on their current capabilities and\nlimitations. To promote transparency and facilitate further research, we\nrelease the evaluation dataset, code, and a public leaderboard publicly for\nfurther analysis and a general modular toolkit. We intend for ProteinBench to\nbe a living benchmark for establishing a standardized, in-depth evaluation\nframework for protein foundation models, driving their development and\napplication while fostering collaboration within the field.\n","authors":["Fei Ye","Zaixiang Zheng","Dongyu Xue","Yuning Shen","Lihao Wang","Yiming Ma","Yan Wang","Xinyou Wang","Xiangxin Zhou","Quanquan Gu"],"pdf_url":"https://arxiv.org/pdf/2409.06744v2.pdf","comment":"30 pages, 2 figures and 15 tables"},{"id":"http://arxiv.org/abs/2410.04818v1","updated":"2024-10-07T08:08:36Z","published":"2024-10-07T08:08:36Z","title":"Physics-Informed GNN for non-linear constrained optimization: PINCO a\n  solver for the AC-optimal power flow","summary":"  The energy transition is driving the integration of large shares of\nintermittent power sources in the electric power grid. Therefore, addressing\nthe AC optimal power flow (AC-OPF) effectively becomes increasingly essential.\nThe AC-OPF, which is a fundamental optimization problem in power systems, must\nbe solved more frequently to ensure the safe and cost-effective operation of\npower systems. Due to its non-linear nature, AC-OPF is often solved in its\nlinearized form, despite inherent inaccuracies. Non-linear solvers, such as the\ninterior point method, are typically employed to solve the full OPF problem.\nHowever, these iterative methods may not converge for large systems and do not\nguarantee global optimality. This work explores a physics-informed graph neural\nnetwork, PINCO, to solve the AC-OPF. We demonstrate that this method provides\naccurate solutions in a fraction of the computational time when compared to the\nestablished non-linear programming solvers. Remarkably, PINCO generalizes\neffectively across a diverse set of loading conditions in the power system. We\nshow that our method can solve the AC-OPF without violating inequality\nconstraints. Furthermore, it can function both as a solver and as a hybrid\nuniversal function approximator. Moreover, the approach can be easily adapted\nto different power systems with minimal adjustments to the hyperparameters,\nincluding systems with multiple generators at each bus. Overall, this work\ndemonstrates an advancement in the field of power system optimization to tackle\nthe challenges of the energy transition. The code and data utilized in this\npaper are available at https://anonymous.4open.science/r/opf_pinn_iclr-B83E/.\n","authors":["Anna Varbella","Damien Briens","Blazhe Gjorgiev","Giuseppe Alessio D'Inverno","Giovanni Sansavini"],"pdf_url":"https://arxiv.org/pdf/2410.04818v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04814v1","updated":"2024-10-07T07:54:53Z","published":"2024-10-07T07:54:53Z","title":"Learning Interpretable Hierarchical Dynamical Systems Models from Time\n  Series Data","summary":"  In science, we are often interested in obtaining a generative model of the\nunderlying system dynamics from observed time series. While powerful methods\nfor dynamical systems reconstruction (DSR) exist when data come from a single\ndomain, how to best integrate data from multiple dynamical regimes and leverage\nit for generalization is still an open question. This becomes particularly\nimportant when individual time series are short, and group-level information\nmay help to fill in for gaps in single-domain data. At the same time, averaging\nis not an option in DSR, as it will wipe out crucial dynamical properties\n(e.g., limit cycles in one domain vs. chaos in another). Hence, a framework is\nneeded that enables to efficiently harvest group-level (multi-domain)\ninformation while retaining all single-domain dynamical characteristics. Here\nwe provide such a hierarchical approach and showcase it on popular DSR\nbenchmarks, as well as on neuroscientific and medical time series. In addition\nto faithful reconstruction of all individual dynamical regimes, our\nunsupervised methodology discovers common low-dimensional feature spaces in\nwhich datasets with similar dynamics cluster. The features spanning these\nspaces were further dynamically highly interpretable, surprisingly in often\nlinear relation to control parameters that govern the dynamics of the\nunderlying system. Finally, we illustrate transfer learning and generalization\nto new parameter regimes.\n","authors":["Manuel Brenner","Elias Weber","Georgia Koppe","Daniel Durstewitz"],"pdf_url":"https://arxiv.org/pdf/2410.04814v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2410.04810v1","updated":"2024-10-07T07:45:18Z","published":"2024-10-07T07:45:18Z","title":"FedBiP: Heterogeneous One-Shot Federated Learning with Personalized\n  Latent Diffusion Models","summary":"  One-Shot Federated Learning (OSFL), a special decentralized machine learning\nparadigm, has recently gained significant attention. OSFL requires only a\nsingle round of client data or model upload, which reduces communication costs\nand mitigates privacy threats compared to traditional FL. Despite these\npromising prospects, existing methods face challenges due to client data\nheterogeneity and limited data quantity when applied to real-world OSFL\nsystems. Recently, Latent Diffusion Models (LDM) have shown remarkable\nadvancements in synthesizing high-quality images through pretraining on\nlarge-scale datasets, thereby presenting a potential solution to overcome these\nissues. However, directly applying pretrained LDM to heterogeneous OSFL results\nin significant distribution shifts in synthetic data, leading to performance\ndegradation in classification models trained on such data. This issue is\nparticularly pronounced in rare domains, such as medical imaging, which are\nunderrepresented in LDM's pretraining data. To address this challenge, we\npropose Federated Bi-Level Personalization (FedBiP), which personalizes the\npretrained LDM at both instance-level and concept-level. Hereby, FedBiP\nsynthesizes images following the client's local data distribution without\ncompromising the privacy regulations. FedBiP is also the first approach to\nsimultaneously address feature space heterogeneity and client data scarcity in\nOSFL. Our method is validated through extensive experiments on three OSFL\nbenchmarks with feature space heterogeneity, as well as on challenging medical\nand satellite image datasets with label heterogeneity. The results demonstrate\nthe effectiveness of FedBiP, which substantially outperforms other OSFL\nmethods.\n","authors":["Haokun Chen","Hang Li","Yao Zhang","Gengyuan Zhang","Jinhe Bi","Philip Torr","Jindong Gu","Denis Krompass","Volker Tresp"],"pdf_url":"https://arxiv.org/pdf/2410.04810v1.pdf","comment":null}],"Programming Languages":[{"id":"http://arxiv.org/abs/2304.09697v6","updated":"2024-10-07T13:17:56Z","published":"2023-04-19T14:41:14Z","title":"A Calculus for Scoped Effects & Handlers","summary":"  Algebraic effects & handlers have become a standard approach for side-effects\nin functional programming. Their modular composition with other effects and\nclean separation of syntax and semantics make them attractive to a wide\naudience. However, not all effects can be classified as algebraic; some need a\nmore sophisticated handling. In particular, effects that have or create a\ndelimited scope need special care, as their continuation consists of two\nparts-in and out of the scope-and their modular composition introduces\nadditional complexity. These effects are called scoped and have gained\nattention by their growing applicability and adoption in popular libraries.\nWhile calculi have been designed with algebraic effects & handlers built in to\nfacilitate their use, a calculus that supports scoped effects & handlers in a\nsimilar manner does not yet exist. This work fills this gap: we present\n$\\lambda_{\\mathit{sc}}$, a calculus with native support for both algebraic and\nscoped effects & handlers. It addresses the need for polymorphic handlers and\nexplicit clauses for forwarding unknown scoped operations to other handlers.\nOur calculus is based on Eff, an existing calculus for algebraic effects,\nextended with Koka-style row polymorphism, and consists of a formal grammar,\noperational semantics, a (type-safe) type-and-effect system and type inference.\nWe demonstrate $\\lambda_{\\mathit{sc}}$ on a range of examples.\n","authors":["Roger Bosman","Birthe van den Berg","Wenhao Tang","Tom Schrijvers"],"pdf_url":"https://arxiv.org/pdf/2304.09697v6.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.08617v4","updated":"2024-10-07T07:04:01Z","published":"2023-12-14T02:42:15Z","title":"RTLCoder: Fully Open-Source and Efficient LLM-Assisted RTL Code\n  Generation Technique","summary":"  The automatic generation of RTL code (e.g., Verilog) using natural language\ninstructions and large language models (LLMs) has attracted significant\nresearch interest recently. However, most existing approaches heavily rely on\ncommercial LLMs such as ChatGPT, while open-source LLMs tailored for this\nspecific design generation task exhibit notably inferior performance. The\nabsence of high-quality open-source solutions restricts the flexibility and\ndata privacy of this emerging technique. In this study, we present a new\ncustomized LLM solution with a modest parameter count of only 7B, achieving\nbetter performance than GPT-3.5 on all representative benchmarks for RTL code\ngeneration. Especially, it outperforms GPT-4 in VerilogEval Machine benchmark.\nThis remarkable balance between accuracy and efficiency is made possible by\nleveraging our new RTL code dataset and a customized LLM algorithm, both of\nwhich have been made fully open-source. Furthermore, we have successfully\nquantized our LLM to 4-bit with a total size of 4GB, enabling it to function on\na single laptop with only slight performance degradation. This efficiency\nallows the RTL generator to serve as a local assistant for engineers, ensuring\nall design privacy concerns are addressed.\n","authors":["Shang Liu","Wenji Fang","Yao Lu","Jing Wang","Qijun Zhang","Hongce Zhang","Zhiyao Xie"],"pdf_url":"https://arxiv.org/pdf/2312.08617v4.pdf","comment":"Accepted by IEEE Transactions on Computer-Aided Design of Integrated\n  Circuits and Systems"},{"id":"http://arxiv.org/abs/2410.03120v2","updated":"2024-10-07T00:54:59Z","published":"2024-10-04T03:27:40Z","title":"Solving the Phase Ordering Problem $\\ne$ Generating the Globally Optimal\n  Code","summary":"  Phase ordering problem has been a long-standing challenge in compiler\noptimizations. Over the past four decades, a significant amount of effort has\nbeen devoted, and indeed, substantial progress has been made. However, in this\npaper, we raise questions about the overall significance of solving the phase\nordering problem in the first place, as pursuing a solution to this problem may\nnot align with the fundamental goal of compiler optimizations, i.e., generating\nthe globally optimal code among all programs that compilers deem semantically\nequivalent to an input program.\n  Our findings, supported by both theoretical and empirical evidence, show that\nsolving the phase ordering problem is not equivalent to generating such\nglobally optimal code. The fundamental reason that applying the optimal phase\nordering may still result in suboptimal code is the exclusion of programs of\nless efficiency during the optimization process. Motivated by this insight, we\npropose a theoretical approach, called \\textit{infinitive iterative\nbi-directional optimizations} (\\textit{IIBO}), which is guaranteed to converge\nto the globally optimal code for any input program. We realize IIBO into a\npractical algorithm and apply it to optimize real-world programs. Results show\nthat IIBO frequently generates more efficient code than GCC/LLVM, two\nstate-of-the-art industry compilers, as well as exhaustive search, which can be\ndeemed the solution to the phasing ordering problem.% input programs.\n  Given the significance and impact of our results, we are currently in active\ndiscussions with LLVM engineers on the possible incorporation of our findings\ninto their next release. In general, we expect our work to inspire new design\nprinciples for compiler development in the pursuit of generating the globally\noptimal code.\n","authors":["Yu Wang","Hongyu Chen","Ke Wang"],"pdf_url":"https://arxiv.org/pdf/2410.03120v2.pdf","comment":null}],"Networking and Internet Architecture":[{"id":"http://arxiv.org/abs/2410.05153v1","updated":"2024-10-07T16:09:53Z","published":"2024-10-07T16:09:53Z","title":"Smart Jamming Attack and Mitigation on Deep Transfer Reinforcement\n  Learning Enabled Resource Allocation for Network Slicing","summary":"  Network slicing is a pivotal paradigm in wireless networks enabling\ncustomized services to users and applications. Yet, intelligent jamming attacks\nthreaten the performance of network slicing. In this paper, we focus on the\nsecurity aspect of network slicing over a deep transfer reinforcement learning\n(DTRL) enabled scenario. We first demonstrate how a deep reinforcement learning\n(DRL)-enabled jamming attack exposes potential risks. In particular, the\nattacker can intelligently jam resource blocks (RBs) reserved for slices by\nmonitoring transmission signals and perturbing the assigned resources. Then, we\npropose a DRL-driven mitigation model to mitigate the intelligent attacker.\nSpecifically, the defense mechanism generates interference on unallocated RBs\nwhere another antenna is used for transmitting powerful signals. This causes\nthe jammer to consider these RBs as allocated RBs and generate interference for\nthose instead of the allocated RBs. The analysis revealed that the intelligent\nDRL-enabled jamming attack caused a significant 50% degradation in network\nthroughput and 60% increase in latency in comparison with the no-attack\nscenario. However, with the implemented mitigation measures, we observed 80%\nimprovement in network throughput and 70% reduction in latency in comparison to\nthe under-attack scenario.\n","authors":["Shavbo Salehi","Hao Zhou","Medhat Elsayed","Majid Bavand","Raimundas Gaigalas","Yigit Ozcan","Melike Erol-Kantarci"],"pdf_url":"https://arxiv.org/pdf/2410.05153v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.05147v1","updated":"2024-10-07T16:00:27Z","published":"2024-10-07T16:00:27Z","title":"PAMLR: A Passive-Active Multi-Armed Bandit-Based Solution for LoRa\n  Channel Allocation","summary":"  Achieving low duty cycle operation in low-power wireless networks in urban\nenvironments is complicated by the complex and variable dynamics of external\ninterference and fading. We explore the use of reinforcement learning for\nachieving low power consumption for the task of optimal selection of channels.\nThe learning relies on a hybrid of passive channel sampling for dealing with\nexternal interference and active channel sampling for dealing with fading. Our\nsolution, Passive-Active Multi-armed bandit for LoRa (PAMLR, pronounced\n\"Pamela\"), balances the two types of samples to achieve energy-efficient\nchannel selection: active channel measurements are tuned to an appropriately\nlow level to update noise thresholds, and to compensate passive channel\nmeasurements are tuned to an appropriately high level for selecting the\ntop-most channels from channel exploration using the noise thresholds. The\nrates of both types of samples are adapted in response to channel dynamics.\nBased on extensive testing in multiple environments in different cities, we\nvalidate that PAMLR can maintain excellent communication quality, as\ndemonstrated by a low SNR regret compared to the optimal channel allocation\npolicy, while substantially minimizing the energy cost associated with channel\nmeasurements.\n","authors":["Jihoon Yun","Chengzhang Li","Anish Arora"],"pdf_url":"https://arxiv.org/pdf/2410.05147v1.pdf","comment":"10 pages"},{"id":"http://arxiv.org/abs/2406.14995v2","updated":"2024-10-07T15:59:03Z","published":"2024-06-21T09:14:11Z","title":"Differentiable and Learnable Wireless Simulation with Geometric\n  Transformers","summary":"  Modelling the propagation of electromagnetic wireless signals is critical for\ndesigning modern communication systems. Wireless ray tracing simulators model\nsignal propagation based on the 3D geometry and other scene parameters, but\ntheir accuracy is fundamentally limited by underlying modelling assumptions and\ncorrectness of parameters. In this work, we introduce Wi-GATr, a\nfully-learnable neural simulation surrogate designed to predict the channel\nobservations based on scene primitives (e.g., surface mesh, antenna position\nand orientation). Recognizing the inherently geometric nature of these\nprimitives, Wi-GATr leverages an equivariant Geometric Algebra Transformer that\noperates on a tokenizer specifically tailored for wireless simulation. We\nevaluate our approach on a range of tasks (i.e., signal strength and delay\nspread prediction, receiver localization, and geometry reconstruction) and find\nthat Wi-GATr is accurate, fast, sample-efficient, and robust to\nsymmetry-induced transformations. Remarkably, we find our results also\ntranslate well to the real world: Wi-GATr demonstrates more than 35% lower\nerror than hybrid techniques, and 70% lower error than a calibrated wireless\ntracer.\n","authors":["Thomas Hehn","Markus Peschl","Tribhuvanesh Orekondy","Arash Behboodi","Johann Brehmer"],"pdf_url":"https://arxiv.org/pdf/2406.14995v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.15432v2","updated":"2024-10-07T14:53:57Z","published":"2024-05-24T10:58:20Z","title":"Throughput Requirements for RAN Functional Splits in 3D-Networks","summary":"  The rapid growth of non-terrestrial communication necessitates its\nintegration with existing terrestrial networks, as highlighted in 3GPP Releases\n16 and 17. This paper analyses the concept of functional splits in 3D-Networks.\nTo manage this complex structure effectively, the adoption of a Radio Access\nNetwork (RAN) architecture with Functional Split (FS) offers advantages in\nflexibility, scalability, and cost-efficiency. RAN achieves this by\ndisaggregating functionalities into three separate units. Analogous to the\nterrestrial network approach, 3GPP is extending this concept to non-terrestrial\nplatforms as well. This work presents a general analysis of the requested\nFronthaul (FH) data rate on feeder link between a non-terrestrial platform and\nthe ground-station. Each split option is a trade-of between FH data rate and\nthe respected complexity. Since flying nodes face more limitations regarding\npower consumption and complexity on board in comparison to terrestrial ones, we\nare investigating the split options between lower and higher physical layer.\n","authors":["MohammadAmin Vakilifard","Tim Düe","Mohammad Rihan","Maik Röper","Dirk Wübben","Carsten Bockelmann","Armin Dekorsy"],"pdf_url":"https://arxiv.org/pdf/2405.15432v2.pdf","comment":"14th International ITG Conference on Systems, Communications and\n  Coding (SCC)"},{"id":"http://arxiv.org/abs/2410.03383v2","updated":"2024-10-07T12:36:49Z","published":"2024-10-04T12:51:42Z","title":"Performance Analysis of 6TiSCH Networks Using Discrete Events Simulator","summary":"  The Internet of Things (IoT) empowers small devices to sense, react, and\ncommunicate, with applications ranging from smart ordinary household objects to\ncomplex industrial processes. To provide access to an increasing number of IoT\ndevices, particularly in long-distance communication scenarios, a robust\nlow-power wide area network (LPWAN) protocol becomes essential. A widely\nadopted protocol for this purpose is 6TiSCH, which builds upon the IEEE\n802.15.4 standard. It introduces time-slotted channel hopping (TSCH) mode as a\nnew medium access control (MAC) layer operating mode, in conjunction with IEEE\n802.15.4g, which also defines both MAC and physical layer (PHY) layers and\nprovides IPv6 connectivity for LPWAN. Notably, 6TiSCH has gained adoption in\nsignificant standards such as Wireless Intelligent Ubiquitous Networks\n(Wi-SUN). This study evaluates the scalability of 6TiSCH, with a focus on key\nparameters such as queue size, the maximum number of single-hop retries, and\nthe slotframe length. Computational simulations were performed using an\nopen-source simulator and obtained the following results: increasing the\ntransmission queue size, along with adjusting the number of retries and\nslotframe length, leads to a reduction in the packet error rate (PER). Notably,\nthe impact of the number of retries is particularly pronounced. Furthermore,\nthe effect on latency varies based on the specific combination of these\nparameters as the network scales.\n","authors":["Guilherme de Santi Peron","Marcos Eduardo Pivaro Monteiro","João Luís Verdegay de Barros","Jamil Farhat","Glauber Brante"],"pdf_url":"https://arxiv.org/pdf/2410.03383v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.03392v2","updated":"2024-10-07T12:33:49Z","published":"2024-10-04T12:56:34Z","title":"Probabilistic Allocation of Payload Code Rate and Header Copies in\n  LR-FHSS Networks","summary":"  We evaluate the performance of the LoRaWAN Long-Range Frequency Hopping\nSpread Spectrum (LR-FHSS) technique using a device-level probabilistic strategy\nfor code rate and header replica allocation. Specifically, we investigate the\neffects of different header replica and code rate allocations at each\nend-device, guided by a probability distribution provided by the network\nserver. As a benchmark, we compare the proposed strategy with the standardized\nLR-FHSS data rates DR8 and DR9. Our numerical results demonstrate that the\nproposed strategy consistently outperforms the DR8 and DR9 standard data rates\nacross all considered scenarios. Notably, our findings reveal that the optimal\ndistribution rarely includes data rate DR9, while data rate DR8 significantly\ncontributes to the goodput and energy efficiency optimizations.\n","authors":["Jamil de Araujo Farhat","Jean Michel de Souza Sant'Ana","João Luiz Rebelatto","Nurul Huda Mahmood","Gianni Pasolini","Richard Demo Souza"],"pdf_url":"https://arxiv.org/pdf/2410.03392v2.pdf","comment":null}],"Distributed, Parallel, and Cluster Computing":[{"id":"http://arxiv.org/abs/2312.05516v3","updated":"2024-10-07T17:21:57Z","published":"2023-12-09T09:55:07Z","title":"Stateful Large Language Model Serving with Pensieve","summary":"  Large Language Models (LLMs) are wildly popular today and it is important to\nserve them efficiently. Existing LLM serving systems are stateless across\nrequests. Consequently, when LLMs are used in the common setting of multi-turn\nconversations, a growing log of the conversation history must be processed\nalongside any request by the serving system at each turn, resulting in repeated\nprocessing.\n  In this paper, we design $Pensieve$, a system optimized for multi-turn\nconversation LLM serving. $Pensieve$ maintains the conversation state across\nrequests by caching previously processed history to avoid duplicate processing.\n$Pensieve$'s multi-tier caching strategy can utilize both GPU and CPU memory to\nefficiently store and retrieve cached data. $Pensieve$ also generalizes the\nrecent PagedAttention kernel to support attention between multiple input tokens\nwith a GPU cache spread over non-contiguous memory. Our evaluation shows that\n$Pensieve$ can achieve $1.14$-$3.0\\times$ the throughput of vLLM and\nTensorRT-LLM and significantly reduce latency.\n","authors":["Lingfan Yu","Jinkun Lin","Jinyang Li"],"pdf_url":"https://arxiv.org/pdf/2312.05516v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.03480v2","updated":"2024-10-07T16:28:39Z","published":"2024-10-04T14:52:18Z","title":"SeBS-Flow: Benchmarking Serverless Cloud Function Workflows","summary":"  Serverless computing has emerged as a prominent paradigm, with a significant\nadoption rate among cloud customers. While this model offers advantages such as\nabstraction from the deployment and resource scheduling, it also poses\nlimitations in handling complex use cases due to the restricted nature of\nindividual functions. Serverless workflows address this limitation by\norchestrating multiple functions into a cohesive application. However, existing\nserverless workflow platforms exhibit significant differences in their\nprogramming models and infrastructure, making fair and consistent performance\nevaluations difficult in practice. To address this gap, we propose the first\nserverless workflow benchmarking suite SeBS-Flow, providing a platform-agnostic\nworkflow model that enables consistent benchmarking across various platforms.\nSeBS-Flow includes six real-world application benchmarks and four\nmicrobenchmarks representing different computational patterns. We conduct\ncomprehensive evaluations on three major cloud platforms, assessing\nperformance, cost, scalability, and runtime deviations. We make our benchmark\nsuite open-source, enabling rigorous and comparable evaluations of serverless\nworkflows over time.\n","authors":["Larissa Schmid","Marcin Copik","Alexandru Calotoiu","Laurin Brandner","Anne Koziolek","Torsten Hoefler"],"pdf_url":"https://arxiv.org/pdf/2410.03480v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.05161v1","updated":"2024-10-07T16:14:32Z","published":"2024-10-07T16:14:32Z","title":"A Seesaw Model Attack Algorithm for Distributed Learning","summary":"  We investigate the Byzantine attack problem within the context of model\ntraining in distributed learning systems. While ensuring the convergence of\ncurrent model training processes, common solvers (e.g. SGD, Adam, RMSProp,\netc.) can be easily compromised by malicious nodes in these systems.\nConsequently, the training process may either converge slowly or even diverge.\nTo develop effective secure distributed learning solvers, it is crucial to\nfirst examine attack methods to assess the robustness of these solvers. In this\nwork, we contribute to the design of attack strategies by initially\nhighlighting the limitations of finite-norm attacks. We then introduce the\nseesaw attack, which has been demonstrated to be more effective than the\nfinite-norm attack. Through numerical experiments, we evaluate the efficacy of\nthe seesaw attack across various gradient aggregation rules.\n","authors":["Kun Yang","Tianyi Luo","Yanjie Dong","Aohan Li"],"pdf_url":"https://arxiv.org/pdf/2410.05161v1.pdf","comment":"Accepted for presentation at IEEE SmartIoT 2024"},{"id":"http://arxiv.org/abs/2410.05133v1","updated":"2024-10-07T15:36:50Z","published":"2024-10-07T15:36:50Z","title":"A Digital Twin Framework for Liquid-cooled Supercomputers as\n  Demonstrated at Exascale","summary":"  We present ExaDigiT, an open-source framework for developing comprehensive\ndigital twins of liquid-cooled supercomputers. It integrates three main\nmodules: (1) a resource allocator and power simulator, (2) a transient\nthermo-fluidic cooling model, and (3) an augmented reality model of the\nsupercomputer and central energy plant. The framework enables the study of\n\"what-if\" scenarios, system optimizations, and virtual prototyping of future\nsystems. Using Frontier as a case study, we demonstrate the framework's\ncapabilities by replaying six months of system telemetry for systematic\nverification and validation. Such a comprehensive analysis of a liquid-cooled\nexascale supercomputer is the first of its kind. ExaDigiT elucidates complex\ntransient cooling system dynamics, runs synthetic or real workloads, and\npredicts energy losses due to rectification and voltage conversion. Throughout\nour paper, we present lessons learned to benefit HPC practitioners developing\nsimilar digital twins. We envision the digital twin will be a key enabler for\nsustainable, energy-efficient supercomputing.\n","authors":["Wesley Brewer","Matthias Maiterth","Vineet Kumar","Rafal Wojda","Sedrick Bouknight","Jesse Hines","Woong Shin","Scott Greenwood","David Grant","Wesley Williams","Feiyi Wang"],"pdf_url":"https://arxiv.org/pdf/2410.05133v1.pdf","comment":"14 pages, 9 figures, To be published in the Proceedings of the\n  International Conference for High Performance Computing, Networking, Storage\n  and Analysis. 2024"},{"id":"http://arxiv.org/abs/2410.00428v2","updated":"2024-10-07T15:24:10Z","published":"2024-10-01T06:23:17Z","title":"LayerKV: Optimizing Large Language Model Serving with Layer-wise KV\n  Cache Management","summary":"  The expanding context windows in large language models (LLMs) have greatly\nenhanced their capabilities in various applications, but they also introduce\nsignificant challenges in maintaining low latency, particularly in Time to\nFirst Token (TTFT). This paper identifies that the sharp rise in TTFT as\ncontext length increases is predominantly driven by queuing delays, which are\ncaused by the growing demands for GPU Key-Value (KV) cache allocation clashing\nwith the limited availability of KV cache blocks. To address this issue, we\npropose LayerKV, a simple yet effective plug-in method that effectively reduces\nTTFT without requiring additional hardware or compromising output performance,\nwhile seamlessly integrating with existing parallelism strategies and\nscheduling techniques. Specifically, LayerKV introduces layer-wise KV block\nallocation, management, and offloading for fine-grained control over system\nmemory, coupled with an SLO-aware scheduler to optimize overall Service Level\nObjectives (SLOs). Comprehensive evaluations on representative models, ranging\nfrom 7B to 70B parameters, across various GPU configurations, demonstrate that\nLayerKV improves TTFT latency up to 69x and reduces SLO violation rates by\n28.7%, significantly enhancing the user experience.\n","authors":["Yi Xiong","Hao Wu","Changxu Shao","Ziqing Wang","Rui Zhang","Yuhong Guo","Junping Zhao","Ke Zhang","Zhenxuan Pan"],"pdf_url":"https://arxiv.org/pdf/2410.00428v2.pdf","comment":"11 pages, 7 figures, 1 table"},{"id":"http://arxiv.org/abs/2410.05091v1","updated":"2024-10-07T14:43:51Z","published":"2024-10-07T14:43:51Z","title":"DIMS: Distributed Index for Similarity Search in Metric Spaces","summary":"  Similarity search finds objects that are similar to a given query object\nbased on a similarity metric. As the amount and variety of data continue to\ngrow, similarity search in metric spaces has gained significant attention.\nMetric spaces can accommodate any type of data and support flexible distance\nmetrics, making similarity search in metric spaces beneficial for many\nreal-world applications, such as multimedia retrieval, personalized\nrecommendation, trajectory analytics, data mining, decision planning, and\ndistributed servers. However, existing studies mostly focus on indexing metric\nspaces on a single machine, which faces efficiency and scalability limitations\nwith increasing data volume and query amount. Recent advancements in similarity\nsearch turn towards distributed methods, while they face challenges including\ninefficient local data management, unbalanced workload, and low concurrent\nsearch efficiency. To this end, we propose DIMS, an efficient Distributed Index\nfor similarity search in Metric Spaces. First, we design a novel three-stage\nheterogeneous partition to achieve workload balance. Then, we present an\neffective three-stage indexing structure to efficiently manage objects. We also\ndevelop concurrent search methods with filtering and validation techniques that\nsupport efficient distributed similarity search. Additionally, we devise a\ncost-based optimization model to balance communication and computation cost.\nExtensive experiments demonstrate that DIMS significantly outperforms existing\ndistributed similarity search approaches.\n","authors":["Yifan Zhu","Chengyang Luo","Tang Qian","Lu Chen","Yunjun Gao","Baihua Zheng"],"pdf_url":"https://arxiv.org/pdf/2410.05091v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.05004v1","updated":"2024-10-07T13:03:45Z","published":"2024-10-07T13:03:45Z","title":"Fast State Restoration in LLM Serving with HCache","summary":"  The growing complexity of LLM usage today, e.g., multi-round conversation and\nretrieval-augmented generation (RAG), makes contextual states (i.e., KV cache)\nreusable across user requests. Given the capacity constraints of GPU memory,\nonly a limited number of contexts can be cached on GPU for reusing. Existing\ninference systems typically evict part of the KV cache and restore it by\nrecomputing it from the original tokens or offloading it to host storage for\nlater retrieval, both of which introduce substantial computational or I/O\noverheads. We propose HCache, a novel LLM state restoration method. Its key\nidea is to restore LLM states from intermediate activations and thus utilize\ncomputational and I/O resources with low overhead. We enhance HCache with two\ntechniques, including i) a bubble-free restoration scheduler that integrates\nresource-complementary methods to optimize the balance between computation and\nIO tasks; and ii) a chunk-based storage manager to address the layout mismatch\nissue (i.e., layer-before-token saving versus token-before-layer restoration).\nOur evaluations, conducted using real-world tasks, show that HCache reduces the\nTTFT by up to 1.93X compared to KV offload while consuming 1.92-2.40X less\nstorage space; compared to token recomputation, HCache achieves up to 5.73X\nreduction in TTFT.\n","authors":["Shiwei Gao","Youmin Chen","Jiwu Shu"],"pdf_url":"https://arxiv.org/pdf/2410.05004v1.pdf","comment":"EuroSys 2025"},{"id":"http://arxiv.org/abs/2410.04920v1","updated":"2024-10-07T11:09:30Z","published":"2024-10-07T11:09:30Z","title":"Cloud-Based Scheduling Mechanism for Scalable and Resource-Efficient\n  Centralized Controllers","summary":"  This paper proposes a novel approach to address the challenges of deploying\ncomplex robotic software in large-scale systems, i.e., Centralized Nonlinear\nModel Predictive Controllers (CNMPCs) for multi-agent systems. The proposed\napproach is based on a Kubernetes-based scheduling mechanism designed to\nmonitor and optimize the operation of CNMPCs, while addressing the scalability\nlimitation of centralized control schemes. By leveraging a cluster in a\nreal-time cloud environment, the proposed mechanism effectively offloads the\ncomputational burden of CNMPCs. Through experiments, we have demonstrated the\neffectiveness and performance of our system, especially in scenarios where the\nnumber of robots is subject to change. Our work contributes to the advancement\nof cloud-based control strategies and lays the foundation for enhanced\nperformance in cloud-controlled robotic systems.\n","authors":["Achilleas Santi Seisa","Sumeet Gajanan Satpute","George Nikolakopoulos"],"pdf_url":"https://arxiv.org/pdf/2410.04920v1.pdf","comment":"7 pages, 6 figures, IECON 2024"},{"id":"http://arxiv.org/abs/2404.05838v2","updated":"2024-10-07T09:35:59Z","published":"2024-04-08T20:03:50Z","title":"Space-time deterministic graph rewriting","summary":"  We study non-terminating graph rewriting models, whose local rules are\napplied non-deterministically -- and yet enjoy a strong form of determinism,\nnamely space-time determinism. Of course in the case of terminating computation\nit is well-known that the mess introduced by asynchronous rule applications may\nnot matter to the end result, as confluence conspires to produce a unique\nnormal form. In the context of non-terminating computation however, confluence\nis a very weak property, and (almost) synchronous rule applications is always\npreferred e.g. when it comes to simulating dynamical systems. Here we provide\nsufficient conditions so that asynchronous local rule applications conspire to\nproduce well-determined events in the space-time unfolding of the graph,\nregardless of their application orders. Our first example is an asynchronous\nsimulation of a dynamical system. Our second example features time dilation, in\nthe spirit of general relativity.\n","authors":["Pablo Arrighi","Marin Costes","Gilles Dowek","Luidnel Maignan"],"pdf_url":"https://arxiv.org/pdf/2404.05838v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04810v1","updated":"2024-10-07T07:45:18Z","published":"2024-10-07T07:45:18Z","title":"FedBiP: Heterogeneous One-Shot Federated Learning with Personalized\n  Latent Diffusion Models","summary":"  One-Shot Federated Learning (OSFL), a special decentralized machine learning\nparadigm, has recently gained significant attention. OSFL requires only a\nsingle round of client data or model upload, which reduces communication costs\nand mitigates privacy threats compared to traditional FL. Despite these\npromising prospects, existing methods face challenges due to client data\nheterogeneity and limited data quantity when applied to real-world OSFL\nsystems. Recently, Latent Diffusion Models (LDM) have shown remarkable\nadvancements in synthesizing high-quality images through pretraining on\nlarge-scale datasets, thereby presenting a potential solution to overcome these\nissues. However, directly applying pretrained LDM to heterogeneous OSFL results\nin significant distribution shifts in synthetic data, leading to performance\ndegradation in classification models trained on such data. This issue is\nparticularly pronounced in rare domains, such as medical imaging, which are\nunderrepresented in LDM's pretraining data. To address this challenge, we\npropose Federated Bi-Level Personalization (FedBiP), which personalizes the\npretrained LDM at both instance-level and concept-level. Hereby, FedBiP\nsynthesizes images following the client's local data distribution without\ncompromising the privacy regulations. FedBiP is also the first approach to\nsimultaneously address feature space heterogeneity and client data scarcity in\nOSFL. Our method is validated through extensive experiments on three OSFL\nbenchmarks with feature space heterogeneity, as well as on challenging medical\nand satellite image datasets with label heterogeneity. The results demonstrate\nthe effectiveness of FedBiP, which substantially outperforms other OSFL\nmethods.\n","authors":["Haokun Chen","Hang Li","Yao Zhang","Gengyuan Zhang","Jinhe Bi","Philip Torr","Jindong Gu","Denis Krompass","Volker Tresp"],"pdf_url":"https://arxiv.org/pdf/2410.04810v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.09592v4","updated":"2024-10-07T06:20:17Z","published":"2023-11-16T06:05:01Z","title":"Scalable and Adaptively Secure Any-Trust Distributed Key Generation and\n  All-hands Checkpointing","summary":"  The classical distributed key generation protocols (DKG) are resurging due to\ntheir widespread applications in blockchain. While efforts have been made to\nimprove DKG communication, practical large-scale deployments are still yet to\ncome due to various challenges, including the heavy computation and\ncommunication (particularly broadcast) overhead in their adversarial cases. In\nthis paper, we propose a practical DKG for DLog-based cryptosystems, which\nachieves (quasi-)linear computation and communication per-node cost with the\nhelp of a common coin, even in the face of the maximal amount of Byzantine\nnodes. Moreover, our protocol is secure against adaptive adversaries, which can\ncorrupt less than half of all nodes. The key to our improvements lies in\ndelegating the most costly operations to an Any-Trust group together with a set\nof techniques for adaptive security. This group is randomly sampled and\nconsists of a small number of individuals. The population only trusts that at\nleast one member in the group is honest, without knowing which one. Moreover,\nwe present a generic transformer that enables us to efficiently deploy a\nconventional distributed protocol like our DKG, even when the participants have\ndifferent weights. Additionally, we introduce an extended broadcast channel\nbased on a blockchain and data dispersal network (such as IPFS), enabling\nreliable broadcasting of arbitrary-size messages at the cost of constant-size\nblockchain storage.\n","authors":["Hanwen Feng","Tiancheng Mai","Qiang Tang"],"pdf_url":"https://arxiv.org/pdf/2311.09592v4.pdf","comment":"22 pages, 5 figures"}]},"2024-10-06T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2211.11548v2","updated":"2024-10-06T23:54:24Z","published":"2022-09-17T05:34:32Z","title":"Survey of Query-based Text Summarization","summary":"  Query-based text summarization is an important real world problem that\nrequires to condense the prolix text data into a summary under the guidance of\nthe query information provided by users. The topic has been studied for a long\ntime and there are many existing interesting research related to query-based\ntext summarization. Yet much of the work is not systematically surveyed. This\nsurvey aims at summarizing some interesting work in query-based text\nsummarization methods as well as related generic text summarization methods.\nNot all taxonomies in this paper exist the related work to the best of our\nknowledge and some analysis will be presented.\n","authors":["Hang Yu","Jiawei Han"],"pdf_url":"https://arxiv.org/pdf/2211.11548v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.07064v3","updated":"2024-10-06T23:53:34Z","published":"2023-11-13T04:08:49Z","title":"Prompts have evil twins","summary":"  We discover that many natural-language prompts can be replaced by\ncorresponding prompts that are unintelligible to humans but that provably\nelicit similar behavior in language models. We call these prompts \"evil twins\"\nbecause they are obfuscated and uninterpretable (evil), but at the same time\nmimic the functionality of the original natural-language prompts (twins).\nRemarkably, evil twins transfer between models. We find these prompts by\nsolving a maximum-likelihood problem which has applications of independent\ninterest.\n","authors":["Rimon Melamed","Lucas H. McCabe","Tanay Wakhare","Yejin Kim","H. Howie Huang","Enric Boix-Adsera"],"pdf_url":"https://arxiv.org/pdf/2311.07064v3.pdf","comment":"EMNLP 2024 Main, camera-ready"},{"id":"http://arxiv.org/abs/2409.18025v2","updated":"2024-10-06T23:30:44Z","published":"2024-09-26T16:32:19Z","title":"An Adversarial Perspective on Machine Unlearning for AI Safety","summary":"  Large language models are finetuned to refuse questions about hazardous\nknowledge, but these protections can often be bypassed. Unlearning methods aim\nat completely removing hazardous capabilities from models and make them\ninaccessible to adversaries. This work challenges the fundamental differences\nbetween unlearning and traditional safety post-training from an adversarial\nperspective. We demonstrate that existing jailbreak methods, previously\nreported as ineffective against unlearning, can be successful when applied\ncarefully. Furthermore, we develop a variety of adaptive methods that recover\nmost supposedly unlearned capabilities. For instance, we show that finetuning\non 10 unrelated examples or removing specific directions in the activation\nspace can recover most hazardous capabilities for models edited with RMU, a\nstate-of-the-art unlearning method. Our findings challenge the robustness of\ncurrent unlearning approaches and question their advantages over safety\ntraining.\n","authors":["Jakub Łucki","Boyi Wei","Yangsibo Huang","Peter Henderson","Florian Tramèr","Javier Rando"],"pdf_url":"https://arxiv.org/pdf/2409.18025v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.11823v2","updated":"2024-10-06T22:42:47Z","published":"2024-06-17T17:57:30Z","title":"On Efficient Language and Vision Assistants for Visually-Situated\n  Natural Language Understanding: What Matters in Reading and Reasoning","summary":"  Recent advancements in language and vision assistants have showcased\nimpressive capabilities but suffer from a lack of transparency, limiting\nbroader research and reproducibility. While open-source models handle general\nimage tasks effectively, they face challenges with the high computational\ndemands of complex visually-situated text understanding. Such tasks often\nrequire increased token inputs and large vision modules to harness\nhigh-resolution information. Striking a balance between model size and data\nimportance remains an open question. This study aims to redefine the design of\nvision-language models by identifying key components and creating efficient\nmodels with constrained inference costs. By strategically formulating datasets,\noptimizing vision modules, and enhancing supervision techniques, we achieve\nsignificant improvements in inference throughput while maintaining high\nperformance. Extensive experiments across models ranging from 160M to 13B\nparameters offer insights into model optimization. We will fully open-source\nour codebase, models, and datasets at https://github.com/naver-ai/elva.\n","authors":["Geewook Kim","Minjoon Seo"],"pdf_url":"https://arxiv.org/pdf/2406.11823v2.pdf","comment":"EMNLP 2024 Main"},{"id":"http://arxiv.org/abs/2408.08926v2","updated":"2024-10-06T22:19:54Z","published":"2024-08-15T17:23:10Z","title":"Cybench: A Framework for Evaluating Cybersecurity Capabilities and Risks\n  of Language Models","summary":"  Language Model (LM) agents for cybersecurity that are capable of autonomously\nidentifying vulnerabilities and executing exploits have the potential to cause\nreal-world impact. Policymakers, model providers, and other researchers in the\nAI and cybersecurity communities are interested in quantifying the capabilities\nof such agents to help mitigate cyberrisk and investigate opportunities for\npenetration testing. Toward that end, we introduce Cybench, a framework for\nspecifying cybersecurity tasks and evaluating agents on those tasks. We include\n40 professional-level Capture the Flag (CTF) tasks from 4 distinct CTF\ncompetitions, chosen to be recent, meaningful, and spanning a wide range of\ndifficulties. Each task includes its own description, starter files, and is\ninitialized in an environment where an agent can execute bash commands and\nobserve outputs. Since many tasks are beyond the capabilities of existing LM\nagents, we introduce subtasks for each task, which break down a task into\nintermediary steps for a more detailed evaluation. To evaluate agent\ncapabilities, we construct a cybersecurity agent and evaluate 8 models: GPT-4o,\nOpenAI o1-preview, Claude 3 Opus, Claude 3.5 Sonnet, Mixtral 8x22b Instruct,\nGemini 1.5 Pro, Llama 3 70B Chat, and Llama 3.1 405B Instruct. Without subtask\nguidance, agents leveraging Claude 3.5 Sonnet, GPT-4o, OpenAI o1-preview, and\nClaude 3 Opus successfully solved complete tasks that took human teams up to 11\nminutes to solve. In comparison, the most difficult task took human teams 24\nhours and 54 minutes to solve. All code and data are publicly available at\nhttps://cybench.github.io\n","authors":["Andy K. Zhang","Neil Perry","Riya Dulepet","Joey Ji","Justin W. Lin","Eliot Jones","Celeste Menders","Gashon Hussein","Samantha Liu","Donovan Jasper","Pura Peetathawatchai","Ari Glenn","Vikram Sivashankar","Daniel Zamoshchin","Leo Glikbarg","Derek Askaryar","Mike Yang","Teddy Zhang","Rishi Alluri","Nathan Tran","Rinnara Sangpisit","Polycarpos Yiorkadjis","Kenny Osele","Gautham Raghupathi","Dan Boneh","Daniel E. Ho","Percy Liang"],"pdf_url":"https://arxiv.org/pdf/2408.08926v2.pdf","comment":"78 pages, 6 figures"},{"id":"http://arxiv.org/abs/2406.12074v2","updated":"2024-10-06T22:17:03Z","published":"2024-06-17T20:20:47Z","title":"COMMUNITY-CROSS-INSTRUCT: Unsupervised Instruction Generation for\n  Aligning Large Language Models to Online Communities","summary":"  Social scientists use surveys to probe the opinions and beliefs of\npopulations, but these methods are slow, costly, and prone to biases. Recent\nadvances in large language models (LLMs) enable the creating of computational\nrepresentations or \"digital twins\" of populations that generate human-like\nresponses mimicking the population's language, styles, and attitudes. We\nintroduce Community-Cross-Instruct, an unsupervised framework for aligning LLMs\nto online communities to elicit their beliefs. Given a corpus of a community's\nonline discussions, Community-Cross-Instruct automatically generates\ninstruction-output pairs by an advanced LLM to (1) finetune a foundational LLM\nto faithfully represent that community, and (2) evaluate the alignment of the\nfinetuned model to the community. We demonstrate the method's utility in\naccurately representing political and diet communities on Reddit. Unlike prior\nmethods requiring human-authored instructions, Community-Cross-Instruct\ngenerates instructions in a fully unsupervised manner, enhancing scalability\nand generalization across domains. This work enables cost-effective and\nautomated surveying of diverse online communities.\n","authors":["Zihao He","Minh Duc Chu","Rebecca Dorn","Siyi Guo","Kristina Lerman"],"pdf_url":"https://arxiv.org/pdf/2406.12074v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.18400v4","updated":"2024-10-06T22:13:16Z","published":"2024-05-28T17:40:48Z","title":"Superposed Decoding: Multiple Generations from a Single Autoregressive\n  Inference Pass","summary":"  Many applications today provide users with multiple auto-complete drafts as\nthey type, including GitHub's code completion, Gmail's smart compose, and\nApple's messaging auto-suggestions. Under the hood, language models support\nthis by running an autoregressive inference pass to provide a draft.\nConsequently, providing $k$ drafts to the user requires running an expensive\nlanguage model $k$ times. To alleviate the computation cost of running $k$\ninference passes, we propose Superposed Decoding, a new decoding algorithm that\ngenerates $k$ drafts at the computation cost of one autoregressive inference\npass. We achieve this by feeding a superposition of the most recent token\nembeddings from the $k$ drafts as input to the next decoding step of the\nlanguage model. At every inference step we combine the $k$ drafts with the\ntop-$k$ tokens to get $k^2$ new drafts and cache the $k$ most likely options,\nusing an n-gram interpolation with minimal compute overhead to filter out\nincoherent generations. Our experiments show that $k$ drafts from Superposed\nDecoding are at least as coherent and factual as Nucleus Sampling and Greedy\nDecoding respectively, while being at least $2.44\\times$ faster for $k\\ge3$. In\na compute-normalized setting, user evaluations demonstrably favor text\ngenerated by Superposed Decoding over Nucleus Sampling. Superposed Decoding can\nalso be combined with other decoding strategies, resulting in universal\ncoverage gains when scaling inference time compute. Code and more examples\nopen-sourced at https://github.com/RAIVNLab/SuperposedDecoding.\n","authors":["Ethan Shen","Alan Fan","Sarah M. Pratt","Jae Sung Park","Matthew Wallingford","Sham M. Kakade","Ari Holtzman","Ranjay Krishna","Ali Farhadi","Aditya Kusupati"],"pdf_url":"https://arxiv.org/pdf/2405.18400v4.pdf","comment":"23 pages, 16 figures"},{"id":"http://arxiv.org/abs/2410.04633v1","updated":"2024-10-06T21:33:51Z","published":"2024-10-06T21:33:51Z","title":"A Cross-Lingual Meta-Learning Method Based on Domain Adaptation for\n  Speech Emotion Recognition","summary":"  Best-performing speech models are trained on large amounts of data in the\nlanguage they are meant to work for. However, most languages have sparse data,\nmaking training models challenging. This shortage of data is even more\nprevalent in speech emotion recognition. Our work explores the model's\nperformance in limited data, specifically for speech emotion recognition.\nMeta-learning specializes in improving the few-shot learning. As a result, we\nemploy meta-learning techniques on speech emotion recognition tasks, accent\nrecognition, and person identification. To this end, we propose a series of\nimprovements over the multistage meta-learning method. Unlike other works\nfocusing on smaller models due to the high computational cost of meta-learning\nalgorithms, we take a more practical approach. We incorporate a large\npre-trained backbone and a prototypical network, making our methods more\nfeasible and applicable. Our most notable contribution is an improved\nfine-tuning technique during meta-testing that significantly boosts the\nperformance on out-of-distribution datasets. This result, together with\nincremental improvements from several other works, helped us achieve accuracy\nscores of 83.78% and 56.30% for Greek and Romanian speech emotion recognition\ndatasets not included in the training or validation splits in the context of\n4-way 5-shot learning.\n","authors":["David-Gabriel Ion","Răzvan-Alexandru Smădu","Dumitru-Clementin Cercel","Florin Pop","Mihaela-Claudia Cercel"],"pdf_url":"https://arxiv.org/pdf/2410.04633v1.pdf","comment":"16 pages, 1 figure, Accepted by WISE 2024"}],"Software Engineering":[{"id":"http://arxiv.org/abs/2410.04617v1","updated":"2024-10-06T20:34:03Z","published":"2024-10-06T20:34:03Z","title":"Evaluation of Code LLMs on Geospatial Code Generation","summary":"  Software development support tools have been studied for a long time, with\nrecent approaches using Large Language Models (LLMs) for code generation. These\nmodels can generate Python code for data science and machine learning\napplications. LLMs are helpful for software engineers because they increase\nproductivity in daily work. An LLM can also serve as a \"mentor\" for\ninexperienced software developers, and be a viable learning support.\nHigh-quality code generation with LLMs can also be beneficial in geospatial\ndata science. However, this domain poses different challenges, and code\ngeneration LLMs are typically not evaluated on geospatial tasks. Here, we show\nhow we constructed an evaluation benchmark for code generation models, based on\na selection of geospatial tasks. We categorised geospatial tasks based on their\ncomplexity and required tools. Then, we created a dataset with tasks that test\nmodel capabilities in spatial reasoning, spatial data processing, and\ngeospatial tools usage. The dataset consists of specific coding problems that\nwere manually created for high quality. For every problem, we proposed a set of\ntest scenarios that make it possible to automatically check the generated code\nfor correctness. In addition, we tested a selection of existing code generation\nLLMs for code generation in the geospatial domain. We share our dataset and\nreproducible evaluation code on a public GitHub repository, arguing that this\ncan serve as an evaluation benchmark for new LLMs in the future. Our dataset\nwill hopefully contribute to the development new models capable of solving\ngeospatial coding tasks with high accuracy. These models will enable the\ncreation of coding assistants tailored for geospatial applications.\n","authors":["Piotr Gramacki","Bruno Martins","Piotr Szymański"],"pdf_url":"https://arxiv.org/pdf/2410.04617v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04587v1","updated":"2024-10-06T18:57:46Z","published":"2024-10-06T18:57:46Z","title":"Hammer: Robust Function-Calling for On-Device Language Models via\n  Function Masking","summary":"  Large language models have demonstrated impressive value in performing as\nautonomous agents when equipped with external tools and API calls. Nonetheless,\neffectively harnessing their potential for executing complex tasks crucially\nrelies on enhancements in their function calling capabilities. This paper\nidentifies a critical gap in existing function calling models, where\nperformance varies significantly across benchmarks, often due to being misled\nby specific naming conventions. To address such an issue, we introduce Hammer,\na novel family of foundation models specifically engineered for on-device\nfunction calling. Hammer employs an augmented dataset that enhances models'\nsensitivity to irrelevant functions and incorporates function masking\ntechniques to minimize misleading. Our empirical evaluations reveal that Hammer\nnot only outperforms larger models but also demonstrates robust generalization\nacross diverse benchmarks, achieving sota results. Our open source\ncontributions include a specialized dataset for irrelevance detection, a tuning\nframework for enhanced generalization, and the Hammer models, establishing a\nnew standard for function calling performance.\n","authors":["Qiqiang Lin","Muning Wen","Qiuying Peng","Guanyu Nie","Junwei Liao","Jun Wang","Xiaoyun Mo","Jiamu Zhou","Cheng Cheng","Yin Zhao","Jun Wang","Weinan Zhang"],"pdf_url":"https://arxiv.org/pdf/2410.04587v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.00145v3","updated":"2024-10-06T15:59:06Z","published":"2024-04-30T18:42:18Z","title":"GUing: A Mobile GUI Search Engine using a Vision-Language Model","summary":"  Graphical User Interfaces (GUIs) are central to app development projects. App\ndevelopers may use the GUIs of other apps as a means of requirements refinement\nand rapid prototyping or as a source of inspiration for designing and improving\ntheir own apps. Recent research has thus suggested retrieving relevant GUI\ndesigns that match a certain text query from screenshot datasets acquired\nthrough crowdsourced or automated exploration of GUIs. However, such\ntext-to-GUI retrieval approaches only leverage the textual information of the\nGUI elements, neglecting visual information such as icons or background images.\nIn addition, retrieved screenshots are not steered by app developers and lack\napp features that require particular input data.\n  To overcome these limitations, this paper proposes GUing, a GUI search engine\nbased on a vision-language model called GUIClip, which we trained specifically\nfor the problem of designing app GUIs. For this, we first collected from Google\nPlay app introduction images which display the most representative screenshots\nand are often captioned (i.e.~labelled) by app vendors. Then, we developed an\nautomated pipeline to classify, crop, and extract the captions from these\nimages. This resulted in a large dataset which we share with this paper:\nincluding 303k app screenshots, out of which 135k have captions. We used this\ndataset to train a novel vision-language model, which is, to the best of our\nknowledge, the first of its kind for GUI retrieval. We evaluated our approach\non various datasets from related work and in a manual experiment. The results\ndemonstrate that our model outperforms previous approaches in text-to-GUI\nretrieval achieving a Recall@10 of up to 0.69 and a HIT@10 of 0.91. We also\nexplored the performance of GUIClip for other GUI tasks including GUI\nclassification and sketch-to-GUI retrieval with encouraging results.\n","authors":["Jialiang Wei","Anne-Lise Courbis","Thomas Lambolais","Binbin Xu","Pierre Louis Bernard","Gérard Dray","Walid Maalej"],"pdf_url":"https://arxiv.org/pdf/2405.00145v3.pdf","comment":"Accepted to ACM Transactions on Software Engineering and Methodology\n  (TOSEM)"},{"id":"http://arxiv.org/abs/2402.02037v5","updated":"2024-10-06T14:30:36Z","published":"2024-02-03T05:24:39Z","title":"EffiBench: Benchmarking the Efficiency of Automatically Generated Code","summary":"  Code generation models have increasingly become integral to aiding software\ndevelopment. Although current research has thoroughly examined the correctness\nof the code produced by code generation models, a vital aspect that plays a\npivotal role in green computing and sustainability efforts has often been\nneglected. This paper presents EffiBench, a benchmark with 1,000\nefficiency-critical coding problems to assess the efficiency of code generated\nby code generation models. EffiBench contains a diverse set of LeetCode coding\nproblems. Each problem is paired with an executable human-written canonical\nsolution, which obtains the SOTA efficiency on the LeetCode solution\nleaderboard. With EffiBench, we empirically examine the ability of 42 large\nlanguage models (35 open-source and 7 closed-source) to generate efficient\ncode. Our evaluation results demonstrate that the efficiency of the code\ngenerated by LLMs is generally worse than the efficiency of human-written\ncanonical solutions. For example, GPT-4 generated code has an average\n\\textbf{3.12} times execution time that of the human-written canonical\nsolutions. In the most extreme cases, the execution time and total memory usage\nof GPT-4 generated code are \\textbf{13.89} and \\textbf{43.92} times that of the\ncanonical solutions. The source code of EffiBench is released on\nhttps://github.com/huangd1999/EffiBench. We also provide the LeaderBoard at\nhttps://huggingface.co/spaces/EffiBench/effibench-leaderboard.\n","authors":["Dong Huang","Yuhao Qing","Weiyi Shang","Heming Cui","Jie M. Zhang"],"pdf_url":"https://arxiv.org/pdf/2402.02037v5.pdf","comment":"Camera Ready for NeurIPS 2024"},{"id":"http://arxiv.org/abs/2410.04490v1","updated":"2024-10-06T14:09:54Z","published":"2024-10-06T14:09:54Z","title":"A Large-Scale Exploit Instrumentation Study of AI/ML Supply Chain\n  Attacks in Hugging Face Models","summary":"  The development of machine learning (ML) techniques has led to ample\nopportunities for developers to develop and deploy their own models. Hugging\nFace serves as an open source platform where developers can share and download\nother models in an effort to make ML development more collaborative. In order\nfor models to be shared, they first need to be serialized. Certain Python\nserialization methods are considered unsafe, as they are vulnerable to object\ninjection. This paper investigates the pervasiveness of these unsafe\nserialization methods across Hugging Face, and demonstrates through an\nexploitation approach, that models using unsafe serialization methods can be\nexploited and shared, creating an unsafe environment for ML developers. We\ninvestigate to what extent Hugging Face is able to flag repositories and files\nusing unsafe serialization methods, and develop a technique to detect malicious\nmodels. Our results show that Hugging Face is home to a wide range of\npotentially vulnerable models.\n","authors":["Beatrice Casey","Joanna C. S. Santos","Mehdi Mirakhorli"],"pdf_url":"https://arxiv.org/pdf/2410.04490v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04485v1","updated":"2024-10-06T13:55:33Z","published":"2024-10-06T13:55:33Z","title":"Exploring the Potential of Conversational Test Suite Based Program\n  Repair on SWE-bench","summary":"  Automatic program repair at project level may open yet to be seen\nopportunities in various fields of human activity. Since the SWE-Bench\nchallenge was presented, we have seen numerous of solutions. Patch generation\nis a part of program repair, and test suite-based conversational patch\ngeneration has proven its effectiveness. However, the potential of\nconversational patch generation has not yet specifically estimated on\nSWE-Bench. This study reports experimental results aimed at evaluating the\nindividual effectiveness of conversational patch generation on problems from\nSWE-Bench. The experiments show that a simple conversational pipeline based on\nLLaMA 3.1 70B can generate valid patches in 47\\% of cases, which is comparable\nto the state-of-the-art in program repair on SWE-Bench.\n","authors":["Anton Cheshkov","Pavel Zadorozhny","Rodion Levichev","Evgeny Maslov","Ronaldo Franco Jaldin"],"pdf_url":"https://arxiv.org/pdf/2410.04485v1.pdf","comment":"3 pages, 2 figures, 1 algorithm, appendix"},{"id":"http://arxiv.org/abs/2410.02307v2","updated":"2024-10-06T10:55:33Z","published":"2024-10-03T08:42:18Z","title":"Model-guided Fuzzing of Distributed Systems","summary":"  We present a coverage-guided testing algorithm for distributed systems\nimplementations. Our main innovation is the use of an abstract formal model of\nthe system that is used to define coverage. Such abstract models are frequently\ndeveloped in early phases of protocol design and verification but are\ninfrequently used at testing time. We show that guiding random test generation\nusing model coverage can be effective in covering interesting points in the\nimplementation state space. We have implemented a fuzzer for distributed system\nimplementations and abstract models written in TLA+. Our algorithm shows better\ncoverage over purely random exploration as well as random exploration guided by\ndifferent notions of scheduler coverage and mutation. In particular, we show\nconsistently higher coverage and detect bugs faster on implementations of\ndistributed consensus protocols such as those in Etcd-raft and RedisRaft.\nMoreover, we discovered 13 previously unknown bugs in their implementations,\nfour of which could only be detected by model-guided fuzzing.\n","authors":["Ege Berkay Gulcan","Burcu Kulahcioglu Ozkan","Rupak Majumdar","Srinidhi Nagendra"],"pdf_url":"https://arxiv.org/pdf/2410.02307v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.18816v2","updated":"2024-10-06T09:22:07Z","published":"2024-04-29T15:52:45Z","title":"AppPoet: Large Language Model based Android malware detection via\n  multi-view prompt engineering","summary":"  Due to the vast array of Android applications, their multifarious functions\nand intricate behavioral semantics, attackers can adopt various tactics to\nconceal their genuine attack intentions within legitimate functions. However,\nnumerous learning-based methods suffer from a limitation in mining behavioral\nsemantic information, thus impeding the accuracy and efficiency of Android\nmalware detection. Besides, the majority of existing learning-based methods are\nweakly interpretive and fail to furnish researchers with effective and readable\ndetection reports. Inspired by the success of the Large Language Models (LLMs)\nin natural language understanding, we propose AppPoet, a LLM-assisted\nmulti-view system for Android malware detection. Firstly, AppPoet employs a\nstatic method to comprehensively collect application features and formulate\nvarious observation views. Then, using our carefully crafted multi-view prompt\ntemplates, it guides the LLM to generate function descriptions and behavioral\nsummaries for each view, enabling deep semantic analysis of the views. Finally,\nwe collaboratively fuse the multi-view information to efficiently and\naccurately detect malware through a deep neural network (DNN) classifier and\nthen generate the human-readable diagnostic reports. Experimental results\ndemonstrate that our method achieves a detection accuracy of 97.15% and an F1\nscore of 97.21%, which is superior to the baseline methods. Furthermore, the\ncase study evaluates the effectiveness of our generated diagnostic reports.\n","authors":["Wenxiang Zhao","Juntao Wu","Zhaoyi Meng"],"pdf_url":"https://arxiv.org/pdf/2404.18816v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.03653v6","updated":"2024-10-06T08:46:52Z","published":"2024-01-08T03:50:03Z","title":"An Exploratory Study on Automatic Identification of Assumptions in the\n  Development of Deep Learning Frameworks","summary":"  Stakeholders constantly make assumptions in the development of deep learning\n(DL) frameworks. These assumptions are related to various types of software\nartifacts (e.g., requirements, design decisions, and technical debt) and can\nturn out to be invalid, leading to system failures. Existing approaches and\ntools for assumption management usually depend on manual identification of\nassumptions. However, assumptions are scattered in various sources (e.g., code\ncomments, commits, pull requests, and issues) of DL framework development, and\nmanually identifying assumptions has high costs. This study intends to evaluate\ndifferent classification models for the purpose of identification with respect\nto assumptions from the point of view of developers and users in the context of\nDL framework projects (i.e., issues, pull requests, and commits) on GitHub.\nFirst, we constructed a new and largest dataset (i.e., the AssuEval dataset) of\nassumptions collected from the TensorFlow and Keras repositories on GitHub.\nThen we explored the performance of seven non-transformers based models (e.g.,\nSupport Vector Machine, Classification and Regression Trees), the ALBERT model,\nand three decoder-only models (i.e., ChatGPT, Claude, and Gemini) for\nidentifying assumptions on the AssuEval dataset. The study results show that\nALBERT achieves the best performance (f1-score: 0.9584) for identifying\nassumptions on the AssuEval dataset, which is much better than the other models\n(the 2nd best f1-score is 0.8858, achieved by the Claude 3.5 Sonnet model).\nThough ChatGPT, Claude, and Gemini are popular models, we do not recommend\nusing them to identify assumptions in DL framework development because of their\nlow performance. Fine-tuning ChatGPT, Claude, Gemini, or other language models\n(e.g., Llama3, Falcon, and BLOOM) specifically for assumptions might improve\ntheir performance for assumption identification.\n","authors":["Chen Yang","Peng Liang","Zinan Ma"],"pdf_url":"https://arxiv.org/pdf/2401.03653v6.pdf","comment":"Preprint accepted for publication in Science of Computer Programming,\n  2024"},{"id":"http://arxiv.org/abs/2312.00324v2","updated":"2024-10-06T08:27:32Z","published":"2023-12-01T03:38:21Z","title":"Machine Learning for Actionable Warning Identification: A Comprehensive\n  Survey","summary":"  Actionable Warning Identification (AWI) plays a crucial role in improving the\nusability of static code analyzers. With recent advances in Machine Learning\n(ML), various approaches have been proposed to incorporate ML techniques into\nAWI. These ML-based AWI approaches, benefiting from ML's strong ability to\nlearn subtle and previously unseen patterns from historical data, have\ndemonstrated superior performance. However, a comprehensive overview of these\napproaches is missing, which could hinder researchers/practitioners from\nunderstanding the current process and discovering potential for future\nimprovement in the ML-based AWI community. In this paper, we systematically\nreview the state-of-the-art ML-based AWI approaches. First, we employ a\nmeticulous survey methodology and gather 51 primary studies from 2000/01/01 to\n2023/09/01. Then, we outline the typical ML-based AWI workflow, including\nwarning dataset preparation, preprocessing, AWI model construction, and\nevaluation stages. In such a workflow, we categorize ML-based AWI approaches\nbased on the warning output format. Besides, we analyze the techniques used in\neach stage, along with their strengths, weaknesses, and distribution. Finally,\nwe provide practical research directions for future ML-based AWI approaches,\nfocusing on aspects like data improvement (e.g., enhancing the warning labeling\nstrategy) and model exploration (e.g., exploring large language models for\nAWI).\n","authors":["Xiuting Ge","Chunrong Fang","Xuanye Li","Weisong Sun","Daoyuan Wu","Juan Zhai","Shangwei Lin","Zhihong Zhao","Yang Liu","Zhenyu Chen"],"pdf_url":"https://arxiv.org/pdf/2312.00324v2.pdf","comment":"Accepted by CSUR"},{"id":"http://arxiv.org/abs/2410.04387v1","updated":"2024-10-06T07:57:08Z","published":"2024-10-06T07:57:08Z","title":"WISE: Unraveling Business Process Metrics with Domain Knowledge","summary":"  Anomalies in complex industrial processes are often obscured by high\nvariability and complexity of event data, which hinders their identification\nand interpretation using process mining. To address this problem, we introduce\nWISE (Weighted Insights for Evaluating Efficiency), a novel method for\nanalyzing business process metrics through the integration of domain knowledge,\nprocess mining, and machine learning.\n  The methodology involves defining business goals and establishing Process\nNorms with weighted constraints at the activity level, incorporating input from\ndomain experts and process analysts. Individual process instances are scored\nbased on these constraints, and the scores are normalized to identify features\nimpacting process goals.\n  Evaluation using the BPIC 2019 dataset and real industrial contexts\ndemonstrates that WISE enhances automation in business process analysis and\neffectively detects deviations from desired process flows. While LLMs support\nthe analysis, the inclusion of domain experts ensures the accuracy and\nrelevance of the findings.\n","authors":["Urszula Jessen","Dirk Fahland"],"pdf_url":"https://arxiv.org/pdf/2410.04387v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04352v1","updated":"2024-10-06T04:16:54Z","published":"2024-10-06T04:16:54Z","title":"Enhancing Android Malware Detection: The Influence of ChatGPT on\n  Decision-centric Task","summary":"  With the rise of large language models, such as ChatGPT, non-decisional\nmodels have been applied to various tasks. Moreover, ChatGPT has drawn\nattention to the traditional decision-centric task of Android malware\ndetection. Despite effective detection methods proposed by scholars, they face\nlow interpretability issues. Specifically, while these methods excel in\nclassifying applications as benign or malicious and can detect malicious\nbehavior, they often fail to provide detailed explanations for the decisions\nthey make. This challenge raises concerns about the reliability of existing\ndetection schemes and questions their true ability to understand complex data.\nIn this study, we investigate the influence of the non-decisional model,\nChatGPT, on the traditional decision-centric task of Android malware detection.\nWe choose three state-of-the-art solutions, Drebin, XMAL, and MaMaDroid,\nconduct a series of experiments on publicly available datasets, and carry out a\ncomprehensive comparison and analysis. Our findings indicate that these\ndecision-driven solutions primarily rely on statistical patterns within\ndatasets to make decisions, rather than genuinely understanding the underlying\ndata. In contrast, ChatGPT, as a non-decisional model, excels in providing\ncomprehensive analysis reports, substantially enhancing interpretability.\nFurthermore, we conduct surveys among experienced developers. The result\nhighlights developers' preference for ChatGPT, as it offers in-depth insights\nand enhances efficiency and understanding of challenges. Meanwhile, these\nstudies and analyses offer profound insights, presenting developers with a\nnovel perspective on Android malware detection--enhancing the reliability of\ndetection results from a non-decisional perspective.\n","authors":["Yao Li","Sen Fang","Tao Zhang","Haipeng Cai"],"pdf_url":"https://arxiv.org/pdf/2410.04352v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04334v1","updated":"2024-10-06T02:58:41Z","published":"2024-10-06T02:58:41Z","title":"AI Assistants for Incident Lifecycle in a Microservice Environment: A\n  Systematic Literature Review","summary":"  Incidents in microservice environments can be costly and challenging to\nrecover from due to their complexity and distributed nature. Recent\nadvancements in artificial intelligence (AI) offer promising solutions for\nimproving incident management. This paper systematically reviews primary\nstudies on AI assistants designed to support different phases of the incident\nlifecycle. It highlights successful applications of AI, identifies gaps in\ncurrent research, and suggests future opportunities for enhancing incident\nmanagement through AI. By examining these studies, the paper aims to provide\ninsights into the effectiveness of AI tools and their potential to address\nongoing challenges in incident recovery.\n","authors":["Dahlia Ziqi Zhou","Marios Fokaefs"],"pdf_url":"https://arxiv.org/pdf/2410.04334v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04322v1","updated":"2024-10-06T01:01:21Z","published":"2024-10-06T01:01:21Z","title":"Toward Debugging Deep Reinforcement Learning Programs with RLExplorer","summary":"  Deep reinforcement learning (DRL) has shown success in diverse domains such\nas robotics, computer games, and recommendation systems. However, like any\nother software system, DRL-based software systems are susceptible to faults\nthat pose unique challenges for debugging and diagnosing. These faults often\nresult in unexpected behavior without explicit failures and error messages,\nmaking debugging difficult and time-consuming. Therefore, automating the\nmonitoring and diagnosis of DRL systems is crucial to alleviate the burden on\ndevelopers. In this paper, we propose RLExplorer, the first fault diagnosis\napproach for DRL-based software systems. RLExplorer automatically monitors\ntraining traces and runs diagnosis routines based on properties of the DRL\nlearning dynamics to detect the occurrence of DRL-specific faults. It then logs\nthe results of these diagnoses as warnings that cover theoretical concepts,\nrecommended practices, and potential solutions to the identified faults. We\nconducted two sets of evaluations to assess RLExplorer. Our first evaluation of\nfaulty DRL samples from Stack Overflow revealed that our approach can\neffectively diagnose real faults in 83% of the cases. Our second evaluation of\nRLExplorer with 15 DRL experts/developers showed that (1) RLExplorer could\nidentify 3.6 times more defects than manual debugging and (2) RLExplorer is\neasily integrated into DRL applications.\n","authors":["Rached Bouchoucha","Ahmed Haj Yahmed","Darshan Patil","Janarthanan Rajendran","Amin Nikanjam","Sarath Chandar","Foutse Khomh"],"pdf_url":"https://arxiv.org/pdf/2410.04322v1.pdf","comment":"Accepted for publication in The International Conference on Software\n  Maintenance and Evolution (ICSME 2024)"}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2410.04652v1","updated":"2024-10-06T23:25:21Z","published":"2024-10-06T23:25:21Z","title":"Multimodal 3D Fusion and In-Situ Learning for Spatially Aware AI","summary":"  Seamless integration of virtual and physical worlds in augmented reality\nbenefits from the system semantically \"understanding\" the physical environment.\nAR research has long focused on the potential of context awareness,\ndemonstrating novel capabilities that leverage the semantics in the 3D\nenvironment for various object-level interactions. Meanwhile, the computer\nvision community has made leaps in neural vision-language understanding to\nenhance environment perception for autonomous tasks. In this work, we introduce\na multimodal 3D object representation that unifies both semantic and linguistic\nknowledge with the geometric representation, enabling user-guided machine\nlearning involving physical objects. We first present a fast multimodal 3D\nreconstruction pipeline that brings linguistic understanding to AR by fusing\nCLIP vision-language features into the environment and object models. We then\npropose \"in-situ\" machine learning, which, in conjunction with the multimodal\nrepresentation, enables new tools and interfaces for users to interact with\nphysical spaces and objects in a spatially and linguistically meaningful\nmanner. We demonstrate the usefulness of the proposed system through two\nreal-world AR applications on Magic Leap 2: a) spatial search in physical\nenvironments with natural language and b) an intelligent inventory system that\ntracks object changes over time. We also make our full implementation and demo\ndata available at (https://github.com/cy-xu/spatially_aware_AI) to encourage\nfurther exploration and research in spatially aware AI.\n","authors":["Chengyuan Xu","Radha Kumaran","Noah Stier","Kangyou Yu","Tobias Höllerer"],"pdf_url":"https://arxiv.org/pdf/2410.04652v1.pdf","comment":"10 pages, 6 figures, accepted to IEEE ISMAR 2024"},{"id":"http://arxiv.org/abs/2410.04648v1","updated":"2024-10-06T23:04:29Z","published":"2024-10-06T23:04:29Z","title":"AdaptDiff: Cross-Modality Domain Adaptation via Weak Conditional\n  Semantic Diffusion for Retinal Vessel Segmentation","summary":"  Deep learning has shown remarkable performance in medical image segmentation.\nHowever, despite its promise, deep learning has many challenges in practice due\nto its inability to effectively transition to unseen domains, caused by the\ninherent data distribution shift and the lack of manual annotations to guide\ndomain adaptation. To tackle this problem, we present an unsupervised domain\nadaptation (UDA) method named AdaptDiff that enables a retinal vessel\nsegmentation network trained on fundus photography (FP) to produce satisfactory\nresults on unseen modalities (e.g., OCT-A) without any manual labels. For all\nour target domains, we first adopt a segmentation model trained on the source\ndomain to create pseudo-labels. With these pseudo-labels, we train a\nconditional semantic diffusion probabilistic model to represent the target\ndomain distribution. Experimentally, we show that even with low quality\npseudo-labels, the diffusion model can still capture the conditional semantic\ninformation. Subsequently, we sample on the target domain with binary vessel\nmasks from the source domain to get paired data, i.e., target domain synthetic\nimages conditioned on the binary vessel map. Finally, we fine-tune the\npre-trained segmentation network using the synthetic paired data to mitigate\nthe domain gap. We assess the effectiveness of AdaptDiff on seven publicly\navailable datasets across three distinct modalities. Our results demonstrate a\nsignificant improvement in segmentation performance across all unseen datasets.\nOur code is publicly available at https://github.com/DeweiHu/AdaptDiff.\n","authors":["Dewei Hu","Hao Li","Han Liu","Jiacheng Wang","Xing Yao","Daiwei Lu","Ipek Oguz"],"pdf_url":"https://arxiv.org/pdf/2410.04648v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04646v1","updated":"2024-10-06T23:01:57Z","published":"2024-10-06T23:01:57Z","title":"Mode-GS: Monocular Depth Guided Anchored 3D Gaussian Splatting for\n  Robust Ground-View Scene Rendering","summary":"  We present a novel-view rendering algorithm, Mode-GS, for ground-robot\ntrajectory datasets. Our approach is based on using anchored Gaussian splats,\nwhich are designed to overcome the limitations of existing 3D Gaussian\nsplatting algorithms. Prior neural rendering methods suffer from severe splat\ndrift due to scene complexity and insufficient multi-view observation, and can\nfail to fix splats on the true geometry in ground-robot datasets. Our method\nintegrates pixel-aligned anchors from monocular depths and generates Gaussian\nsplats around these anchors using residual-form Gaussian decoders. To address\nthe inherent scale ambiguity of monocular depth, we parameterize anchors with\nper-view depth-scales and employ scale-consistent depth loss for online scale\ncalibration. Our method results in improved rendering performance, based on\nPSNR, SSIM, and LPIPS metrics, in ground scenes with free trajectory patterns,\nand achieves state-of-the-art rendering performance on the R3LIVE odometry\ndataset and the Tanks and Temples dataset.\n","authors":["Yonghan Lee","Jaehoon Choi","Dongki Jung","Jaeseong Yun","Soohyun Ryu","Dinesh Manocha","Suyong Yeon"],"pdf_url":"https://arxiv.org/pdf/2410.04646v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.11823v2","updated":"2024-10-06T22:42:47Z","published":"2024-06-17T17:57:30Z","title":"On Efficient Language and Vision Assistants for Visually-Situated\n  Natural Language Understanding: What Matters in Reading and Reasoning","summary":"  Recent advancements in language and vision assistants have showcased\nimpressive capabilities but suffer from a lack of transparency, limiting\nbroader research and reproducibility. While open-source models handle general\nimage tasks effectively, they face challenges with the high computational\ndemands of complex visually-situated text understanding. Such tasks often\nrequire increased token inputs and large vision modules to harness\nhigh-resolution information. Striking a balance between model size and data\nimportance remains an open question. This study aims to redefine the design of\nvision-language models by identifying key components and creating efficient\nmodels with constrained inference costs. By strategically formulating datasets,\noptimizing vision modules, and enhancing supervision techniques, we achieve\nsignificant improvements in inference throughput while maintaining high\nperformance. Extensive experiments across models ranging from 160M to 13B\nparameters offer insights into model optimization. We will fully open-source\nour codebase, models, and datasets at https://github.com/naver-ai/elva.\n","authors":["Geewook Kim","Minjoon Seo"],"pdf_url":"https://arxiv.org/pdf/2406.11823v2.pdf","comment":"EMNLP 2024 Main"},{"id":"http://arxiv.org/abs/2410.01665v2","updated":"2024-10-06T22:28:20Z","published":"2024-10-02T15:32:01Z","title":"Towards a vision foundation model for comprehensive assessment of\n  Cardiac MRI","summary":"  Cardiac magnetic resonance imaging (CMR), considered the gold standard for\nnoninvasive cardiac assessment, is a diverse and complex modality requiring a\nwide variety of image processing tasks for comprehensive assessment of cardiac\nmorphology and function. Advances in deep learning have enabled the development\nof state-of-the-art (SoTA) models for these tasks. However, model training is\nchallenging due to data and label scarcity, especially in the less common\nimaging sequences. Moreover, each model is often trained for a specific task,\nwith no connection between related tasks. In this work, we introduce a vision\nfoundation model trained for CMR assessment, that is trained in a\nself-supervised fashion on 36 million CMR images. We then finetune the model in\nsupervised way for 9 clinical tasks typical to a CMR workflow, across\nclassification, segmentation, landmark localization, and pathology detection.\nWe demonstrate improved accuracy and robustness across all tasks, over a range\nof available labeled dataset sizes. We also demonstrate improved few-shot\nlearning with fewer labeled samples, a common challenge in medical image\nanalyses. We achieve an out-of-box performance comparable to SoTA for most\nclinical tasks. The proposed method thus presents a resource-efficient, unified\nframework for CMR assessment, with the potential to accelerate the development\nof deep learning-based solutions for image analysis tasks, even with few\nannotated data available.\n","authors":["Athira J Jacob","Indraneel Borgohain","Teodora Chitiboi","Puneet Sharma","Dorin Comaniciu","Daniel Rueckert"],"pdf_url":"https://arxiv.org/pdf/2410.01665v2.pdf","comment":"11 pages, 3 figures, 4 tables"},{"id":"http://arxiv.org/abs/2410.04636v1","updated":"2024-10-06T21:51:02Z","published":"2024-10-06T21:51:02Z","title":"Multi-Tiered Self-Contrastive Learning for Medical Microwave Radiometry\n  (MWR) Breast Cancer Detection","summary":"  The pursuit of enhanced breast cancer detection and monitoring techniques is\na paramount healthcare objective, driving the need for innovative imaging\ntechnologies and diagnostic approaches. This study introduces a novel\nmulti-tiered self-contrastive model tailored for the application of microwave\nradiometry (MWR) breast cancer detection. Our approach encompasses three\ndistinct models: Local-MWR (L-MWR), Regional-MWR (R-MWR), and Global-MWR\n(G-MWR), each engineered to analyze varying sub-regional comparisons within the\nbreasts. These models are cohesively integrated through the Joint-MWR (J-MWR)\nnetwork, which leverages the self-contrastive data generated at each analytical\nlevel to enhance detection capabilities. Employing a dataset comprising 4,932\ncases of female patients, our research showcases the effectiveness of our\nproposed models. Notably, the J-MWR model distinguishes itself by achieving a\nMatthews correlation coefficient of 0.74 $\\pm$ 0.018, surpassing existing MWR\nneural networks and contrastive methods. These results highlight the\nsignificant potential of self-contrastive learning techniques in improving both\nthe diagnostic accuracy and generalizability of MWR-based breast cancer\ndetection processes. Such advancements hold considerable promise for further\ninvestigative and clinical endeavors. The source code is available at:\nhttps://github.com/cgalaz01/self_contrastive_mwr\n","authors":["Christoforos Galazis","Huiyi Wu","Igor Goryanin"],"pdf_url":"https://arxiv.org/pdf/2410.04636v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04634v1","updated":"2024-10-06T21:42:53Z","published":"2024-10-06T21:42:53Z","title":"Is What You Ask For What You Get? Investigating Concept Associations in\n  Text-to-Image Models","summary":"  Text-to-image (T2I) models are increasingly used in impactful real-life\napplications. As such, there is a growing need to audit these models to ensure\nthat they generate desirable, task-appropriate images. However, systematically\ninspecting the associations between prompts and generated content in a\nhuman-understandable way remains challenging. To address this, we propose\n\\emph{Concept2Concept}, a framework where we characterize conditional\ndistributions of vision language models using interpretable concepts and\nmetrics that can be defined in terms of these concepts. This characterization\nallows us to use our framework to audit models and prompt-datasets. To\ndemonstrate, we investigate several case studies of conditional distributions\nof prompts, such as user defined distributions or empirical, real world\ndistributions. Lastly, we implement Concept2Concept as an open-source\ninteractive visualization tool facilitating use by non-technical end-users.\n  Warning: This paper contains discussions of harmful content, including CSAM\nand NSFW material, which may be disturbing to some readers.\n","authors":["Salma Abdel Magid","Weiwei Pan","Simon Warchol","Grace Guo","Junsik Kim","Mahia Rahman","Hanspeter Pfister"],"pdf_url":"https://arxiv.org/pdf/2410.04634v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.00321v2","updated":"2024-10-06T21:29:57Z","published":"2024-10-01T01:41:23Z","title":"A Cat Is A Cat (Not A Dog!): Unraveling Information Mix-ups in\n  Text-to-Image Encoders through Causal Analysis and Embedding Optimization","summary":"  This paper analyzes the impact of causal manner in the text encoder of\ntext-to-image (T2I) diffusion models, which can lead to information bias and\nloss. Previous works have focused on addressing the issues through the\ndenoising process. However, there is no research discussing how text embedding\ncontributes to T2I models, especially when generating more than one object. In\nthis paper, we share a comprehensive analysis of text embedding: i) how text\nembedding contributes to the generated images and ii) why information gets lost\nand biases towards the first-mentioned object. Accordingly, we propose a simple\nbut effective text embedding balance optimization method, which is\ntraining-free, with an improvement of 90.05% on information balance in stable\ndiffusion. Furthermore, we propose a new automatic evaluation metric that\nquantifies information loss more accurately than existing methods, achieving\n81% concordance with human assessments. This metric effectively measures the\npresence and accuracy of objects, addressing the limitations of current\ndistribution scores like CLIP's text-image similarities.\n","authors":["Chieh-Yun Chen","Li-Wu Tsao","Chiang Tseng","Hong-Han Shuai"],"pdf_url":"https://arxiv.org/pdf/2410.00321v2.pdf","comment":"Accepted to NeurIPS 2024"},{"id":"http://arxiv.org/abs/2409.15615v2","updated":"2024-10-06T21:08:01Z","published":"2024-09-23T23:39:03Z","title":"KISS-Matcher: Fast and Robust Point Cloud Registration Revisited","summary":"  While global point cloud registration systems have advanced significantly in\nall aspects, many studies have focused on specific components, such as feature\nextraction, graph-theoretic pruning, or pose solvers. In this paper, we take a\nholistic view on the registration problem and develop an open-source and\nversatile C++ library for point cloud registration, called\n\\textit{KISS-Matcher}. KISS-Matcher combines a novel feature detector,\n\\textit{Faster-PFH}, that improves over the classical fast point feature\nhistogram (FPFH). Moreover, it adopts a $k$-core-based graph-theoretic pruning\nto reduce the time complexity of rejecting outlier correspondences. Finally, it\ncombines these modules in a complete, user-friendly, and ready-to-use pipeline.\nAs verified by extensive experiments, KISS-Matcher has superior scalability and\nbroad applicability, achieving a substantial speed-up compared to\nstate-of-the-art outlier-robust registration pipelines while preserving\naccuracy. Our code will be available at\n\\href{https://github.com/MIT-SPARK/KISS-Matcher}{\\texttt{https://github.com/MIT-SPARK/KISS-Matcher}}.\n","authors":["Hyungtae Lim","Daebeom Kim","Gunhee Shin","Jingnan Shi","Ignacio Vizzo","Hyun Myung","Jaesik Park","Luca Carlone"],"pdf_url":"https://arxiv.org/pdf/2409.15615v2.pdf","comment":"9 pages, 9 figures"},{"id":"http://arxiv.org/abs/2410.04618v1","updated":"2024-10-06T20:38:14Z","published":"2024-10-06T20:38:14Z","title":"Towards Unsupervised Blind Face Restoration using Diffusion Prior","summary":"  Blind face restoration methods have shown remarkable performance,\nparticularly when trained on large-scale synthetic datasets with supervised\nlearning. These datasets are often generated by simulating low-quality face\nimages with a handcrafted image degradation pipeline. The models trained on\nsuch synthetic degradations, however, cannot deal with inputs of unseen\ndegradations. In this paper, we address this issue by using only a set of input\nimages, with unknown degradations and without ground truth targets, to\nfine-tune a restoration model that learns to map them to clean and contextually\nconsistent outputs. We utilize a pre-trained diffusion model as a generative\nprior through which we generate high quality images from the natural image\ndistribution while maintaining the input image content through consistency\nconstraints. These generated images are then used as pseudo targets to\nfine-tune a pre-trained restoration model. Unlike many recent approaches that\nemploy diffusion models at test time, we only do so during training and thus\nmaintain an efficient inference-time performance. Extensive experiments show\nthat the proposed approach can consistently improve the perceptual quality of\npre-trained blind face restoration models while maintaining great consistency\nwith the input contents. Our best model also achieves the state-of-the-art\nresults on both synthetic and real-world datasets.\n","authors":["Tianshu Kuai","Sina Honari","Igor Gilitschenski","Alex Levinshtein"],"pdf_url":"https://arxiv.org/pdf/2410.04618v1.pdf","comment":"Project page: https://dt-bfr.github.io/"},{"id":"http://arxiv.org/abs/2410.04609v1","updated":"2024-10-06T20:11:53Z","published":"2024-10-06T20:11:53Z","title":"VISTA: A Visual and Textual Attention Dataset for Interpreting\n  Multimodal Models","summary":"  The recent developments in deep learning led to the integration of natural\nlanguage processing (NLP) with computer vision, resulting in powerful\nintegrated Vision and Language Models (VLMs). Despite their remarkable\ncapabilities, these models are frequently regarded as black boxes within the\nmachine learning research community. This raises a critical question: which\nparts of an image correspond to specific segments of text, and how can we\ndecipher these associations? Understanding these connections is essential for\nenhancing model transparency, interpretability, and trustworthiness. To answer\nthis question, we present an image-text aligned human visual attention dataset\nthat maps specific associations between image regions and corresponding text\nsegments. We then compare the internal heatmaps generated by VL models with\nthis dataset, allowing us to analyze and better understand the model's\ndecision-making process. This approach aims to enhance model transparency,\ninterpretability, and trustworthiness by providing insights into how these\nmodels align visual and linguistic information. We conducted a comprehensive\nstudy on text-guided visual saliency detection in these VL models. This study\naims to understand how different models prioritize and focus on specific visual\nelements in response to corresponding text segments, providing deeper insights\ninto their internal mechanisms and improving our ability to interpret their\noutputs.\n","authors":[" Harshit","Tolga Tasdizen"],"pdf_url":"https://arxiv.org/pdf/2410.04609v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.02401v2","updated":"2024-10-06T19:01:06Z","published":"2024-10-03T11:29:09Z","title":"SynCo: Synthetic Hard Negatives in Contrastive Learning for Better\n  Unsupervised Visual Representations","summary":"  Contrastive learning has become a dominant approach in self-supervised visual\nrepresentation learning. Hard negatives - samples closely resembling the anchor\n- are key to enhancing learned representations' discriminative power. However,\nefficiently leveraging hard negatives remains challenging. We introduce SynCo\n(sYnthetic Negatives in Contrastive learning), a novel approach that improves\nmodel performance by generating synthetic hard negatives on the representation\nspace. Building on the MoCo framework, SynCo introduces six strategies for\ncreating diverse synthetic hard negatives on-the-fly with minimal computational\noverhead. SynCo achieves faster training and better representation learning,\nreaching 67.9% top-1 accuracy on ImageNet ILSVRC-201 linear evaluation after\n200 pretraining epochs, surpassing MoCo's 67.5% using the same ResNet-50\nencoder. It also transfers more effectively to detection tasks: on PASCAL VOC,\nit outperforms both the supervised baseline and MoCo with 82.6% AP; on COCO, it\nsets new benchmarks with 41.0% AP for bounding box detection and 35.7% AP for\ninstance segmentation. Our synthetic hard negative generation approach\nsignificantly enhances visual representations learned through self-supervised\ncontrastive learning. Code is available at\nhttps://github.com/giakoumoglou/synco.\n","authors":["Nikolaos Giakoumoglou","Tania Stathaki"],"pdf_url":"https://arxiv.org/pdf/2410.02401v2.pdf","comment":"10 pages, 6 figures, 4 tables"},{"id":"http://arxiv.org/abs/2410.04574v1","updated":"2024-10-06T18:15:27Z","published":"2024-10-06T18:15:27Z","title":"Enhancing 3D Human Pose Estimation Amidst Severe Occlusion with Dual\n  Transformer Fusion","summary":"  In the field of 3D Human Pose Estimation from monocular videos, the presence\nof diverse occlusion types presents a formidable challenge. Prior research has\nmade progress by harnessing spatial and temporal cues to infer 3D poses from 2D\njoint observations. This paper introduces a Dual Transformer Fusion (DTF)\nalgorithm, a novel approach to obtain a holistic 3D pose estimation, even in\nthe presence of severe occlusions. Confronting the issue of occlusion-induced\nmissing joint data, we propose a temporal interpolation-based occlusion\nguidance mechanism. To enable precise 3D Human Pose Estimation, our approach\nleverages the innovative DTF architecture, which first generates a pair of\nintermediate views. Each intermediate-view undergoes spatial refinement through\na self-refinement schema. Subsequently, these intermediate-views are fused to\nyield the final 3D human pose estimation. The entire system is end-to-end\ntrainable. Through extensive experiments conducted on the Human3.6M and\nMPI-INF-3DHP datasets, our method's performance is rigorously evaluated.\nNotably, our approach outperforms existing state-of-the-art methods on both\ndatasets, yielding substantial improvements. The code is available here:\nhttps://github.com/MehwishG/DTF.\n","authors":["Mehwish Ghafoor","Arif Mahmood","Muhammad Bilal"],"pdf_url":"https://arxiv.org/pdf/2410.04574v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.09240v2","updated":"2024-10-06T17:44:46Z","published":"2024-02-14T15:28:42Z","title":"Switch EMA: A Free Lunch for Better Flatness and Sharpness","summary":"  Exponential Moving Average (EMA) is a widely used weight averaging (WA)\nregularization to learn flat optima for better generalizations without extra\ncost in deep neural network (DNN) optimization. Despite achieving better\nflatness, existing WA methods might fall into worse final performances or\nrequire extra test-time computations. This work unveils the full potential of\nEMA with a single line of modification, i.e., switching the EMA parameters to\nthe original model after each epoch, dubbed as Switch EMA (SEMA). From both\ntheoretical and empirical aspects, we demonstrate that SEMA can help DNNs to\nreach generalization optima that better trade-off between flatness and\nsharpness. To verify the effectiveness of SEMA, we conduct comparison\nexperiments with discriminative, generative, and regression tasks on vision and\nlanguage datasets, including image classification, self-supervised learning,\nobject detection and segmentation, image generation, video prediction,\nattribute regression, and language modeling. Comprehensive results with popular\noptimizers and networks show that SEMA is a free lunch for DNN training by\nimproving performances and boosting convergence speeds.\n","authors":["Siyuan Li","Zicheng Liu","Juanxi Tian","Ge Wang","Zedong Wang","Weiyang Jin","Di Wu","Cheng Tan","Tao Lin","Yang Liu","Baigui Sun","Stan Z. Li"],"pdf_url":"https://arxiv.org/pdf/2402.09240v2.pdf","comment":"Preprint V2. Source code and models at\n  https://github.com/Westlake-AI/SEMA"},{"id":"http://arxiv.org/abs/2409.18974v2","updated":"2024-10-06T17:40:40Z","published":"2024-09-12T15:38:21Z","title":"Neural Product Importance Sampling via Warp Composition","summary":"  Achieving high efficiency in modern photorealistic rendering hinges on using\nMonte Carlo sampling distributions that closely approximate the illumination\nintegral estimated for every pixel. Samples are typically generated from a set\nof simple distributions, each targeting a different factor in the integrand,\nwhich are combined via multiple importance sampling. The resulting mixture\ndistribution can be far from the actual product of all factors, leading to\nsub-optimal variance even for direct-illumination estimation. We present a\nlearning-based method that uses normalizing flows to efficiently importance\nsample illumination product integrals, e.g., the product of environment\nlighting and material terms. Our sampler composes a flow head warp with an\nemitter tail warp. The small conditional head warp is represented by a neural\nspline flow, while the large unconditional tail is discretized per environment\nmap and its evaluation is instant. If the conditioning is low-dimensional, the\nhead warp can be also discretized to achieve even better performance. We\ndemonstrate variance reduction over prior methods on a range of applications\ncomprising complex geometry, materials and illumination.\n","authors":["Joey Litalien","Miloš Hašan","Fujun Luan","Krishna Mullia","Iliyan Georgiev"],"pdf_url":"https://arxiv.org/pdf/2409.18974v2.pdf","comment":"Published in ACM SIGGRAPH Asia 2024 Conference Papers. Project page:\n  https://joeylitalien.github.io/publications/warp"},{"id":"http://arxiv.org/abs/2410.04546v1","updated":"2024-10-06T16:47:30Z","published":"2024-10-06T16:47:30Z","title":"Learning De-Biased Representations for Remote-Sensing Imagery","summary":"  Remote sensing (RS) imagery, requiring specialized satellites to collect and\nbeing difficult to annotate, suffers from data scarcity and class imbalance in\ncertain spectrums. Due to data scarcity, training any large-scale RS models\nfrom scratch is unrealistic, and the alternative is to transfer pre-trained\nmodels by fine-tuning or a more data-efficient method LoRA. Due to class\nimbalance, transferred models exhibit strong bias, where features of the major\nclass dominate over those of the minor class. In this paper, we propose\ndebLoRA, a generic training approach that works with any LoRA variants to yield\ndebiased features. It is an unsupervised learning approach that can diversify\nminor class features based on the shared attributes with major classes, where\nthe attributes are obtained by a simple step of clustering. To evaluate it, we\nconduct extensive experiments in two transfer learning scenarios in the RS\ndomain: from natural to optical RS images, and from optical RS to\nmulti-spectrum RS images. We perform object classification and oriented object\ndetection tasks on the optical RS dataset DOTA and the SAR dataset FUSRS.\nResults show that our debLoRA consistently surpasses prior arts across these RS\nadaptation settings, yielding up to 3.3 and 4.7 percentage points gains on the\ntail classes for natural to optical RS and optical RS to multi-spectrum RS\nadaptations, respectively, while preserving the performance on head classes,\nsubstantiating its efficacy and adaptability.\n","authors":["Zichen Tian","Zhaozheng Chen","Qianru Sun"],"pdf_url":"https://arxiv.org/pdf/2410.04546v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.15125v3","updated":"2024-10-06T16:45:08Z","published":"2024-05-24T00:46:58Z","title":"HDR-GS: Efficient High Dynamic Range Novel View Synthesis at 1000x Speed\n  via Gaussian Splatting","summary":"  High dynamic range (HDR) novel view synthesis (NVS) aims to create\nphotorealistic images from novel viewpoints using HDR imaging techniques. The\nrendered HDR images capture a wider range of brightness levels containing more\ndetails of the scene than normal low dynamic range (LDR) images. Existing HDR\nNVS methods are mainly based on NeRF. They suffer from long training time and\nslow inference speed. In this paper, we propose a new framework, High Dynamic\nRange Gaussian Splatting (HDR-GS), which can efficiently render novel HDR views\nand reconstruct LDR images with a user input exposure time. Specifically, we\ndesign a Dual Dynamic Range (DDR) Gaussian point cloud model that uses\nspherical harmonics to fit HDR color and employs an MLP-based tone-mapper to\nrender LDR color. The HDR and LDR colors are then fed into two Parallel\nDifferentiable Rasterization (PDR) processes to reconstruct HDR and LDR views.\nTo establish the data foundation for the research of 3D Gaussian\nsplatting-based methods in HDR NVS, we recalibrate the camera parameters and\ncompute the initial positions for Gaussian point clouds. Experiments\ndemonstrate that our HDR-GS surpasses the state-of-the-art NeRF-based method by\n3.84 and 1.91 dB on LDR and HDR NVS while enjoying 1000x inference speed and\nonly requiring 6.3% training time. Code, models, and recalibrated data will be\npublicly available at https://github.com/caiyuanhao1998/HDR-GS\n","authors":["Yuanhao Cai","Zihao Xiao","Yixun Liang","Minghan Qin","Yulun Zhang","Xiaokang Yang","Yaoyao Liu","Alan Yuille"],"pdf_url":"https://arxiv.org/pdf/2405.15125v3.pdf","comment":"NeurIPS 2024; The first 3D Gaussian Splatting-based method for HDR\n  imaging"},{"id":"http://arxiv.org/abs/2409.09808v3","updated":"2024-10-06T16:34:48Z","published":"2024-09-15T18:02:26Z","title":"Famba-V: Fast Vision Mamba with Cross-Layer Token Fusion","summary":"  Mamba and Vision Mamba (Vim) models have shown their potential as an\nalternative to methods based on Transformer architecture. This work introduces\nFast Mamba for Vision (Famba-V), a cross-layer token fusion technique to\nenhance the training efficiency of Vim models. The key idea of Famba-V is to\nidentify and fuse similar tokens across different Vim layers based on a suit of\ncross-layer strategies instead of simply applying token fusion uniformly across\nall the layers that existing works propose. We evaluate the performance of\nFamba-V on CIFAR-100. Our results show that Famba-V is able to enhance the\ntraining efficiency of Vim models by reducing both training time and peak\nmemory usage during training. Moreover, the proposed cross-layer strategies\nallow Famba-V to deliver superior accuracy-efficiency trade-offs. These results\nall together demonstrate Famba-V as a promising efficiency enhancement\ntechnique for Vim models.\n","authors":["Hui Shen","Zhongwei Wan","Xin Wang","Mi Zhang"],"pdf_url":"https://arxiv.org/pdf/2409.09808v3.pdf","comment":"Camera ready version of ECCV 2024 Workshop on Computational Aspects\n  of Deep Learning (Best Paper Award)"},{"id":"http://arxiv.org/abs/2405.19224v3","updated":"2024-10-06T16:06:54Z","published":"2024-05-29T16:04:03Z","title":"A study on the adequacy of common IQA measures for medical images","summary":"  Image quality assessment (IQA) is standard practice in the development stage\nof novel machine learning algorithms that operate on images. The most commonly\nused IQA measures have been developed and tested for natural images, but not in\nthe medical setting. Reported inconsistencies arising in medical images are not\nsurprising, as they have different properties than natural images. In this\nstudy, we test the applicability of common IQA measures for medical image data\nby comparing their assessment to manually rated chest X-ray (5 experts) and\nphotoacoustic image data (2 experts). Moreover, we include supplementary\nstudies on grayscale natural images and accelerated brain MRI data. The results\nof all experiments show a similar outcome in line with previous findings for\nmedical images: PSNR and SSIM in the default setting are in the lower range of\nthe result list and HaarPSI outperforms the other tested measures in the\noverall performance. Also among the top performers in our medical experiments\nare the full reference measures FSIM, LPIPS and MS-SSIM. Generally, the results\non natural images yield considerably higher correlations, suggesting that\nadditional employment of tailored IQA measures for medical imaging algorithms\nis needed.\n","authors":["Anna Breger","Clemens Karner","Ian Selby","Janek Gröhl","Sören Dittmer","Edward Lilley","Judith Babar","Jake Beckford","Thomas R Else","Timothy J Sadler","Shahab Shahipasand","Arthikkaa Thavakumar","Michael Roberts","Carola-Bibiane Schönlieb"],"pdf_url":"https://arxiv.org/pdf/2405.19224v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04534v1","updated":"2024-10-06T16:04:05Z","published":"2024-10-06T16:04:05Z","title":"UniMuMo: Unified Text, Music and Motion Generation","summary":"  We introduce UniMuMo, a unified multimodal model capable of taking arbitrary\ntext, music, and motion data as input conditions to generate outputs across all\nthree modalities. To address the lack of time-synchronized data, we align\nunpaired music and motion data based on rhythmic patterns to leverage existing\nlarge-scale music-only and motion-only datasets. By converting music, motion,\nand text into token-based representation, our model bridges these modalities\nthrough a unified encoder-decoder transformer architecture. To support multiple\ngeneration tasks within a single framework, we introduce several architectural\nimprovements. We propose encoding motion with a music codebook, mapping motion\ninto the same feature space as music. We introduce a music-motion parallel\ngeneration scheme that unifies all music and motion generation tasks into a\nsingle transformer decoder architecture with a single training task of\nmusic-motion joint generation. Moreover, the model is designed by fine-tuning\nexisting pre-trained single-modality models, significantly reducing\ncomputational demands. Extensive experiments demonstrate that UniMuMo achieves\ncompetitive results on all unidirectional generation benchmarks across music,\nmotion, and text modalities. Quantitative results are available in the\n\\href{https://hanyangclarence.github.io/unimumo_demo/}{project page}.\n","authors":["Han Yang","Kun Su","Yutong Zhang","Jiaben Chen","Kaizhi Qian","Gaowen Liu","Chuang Gan"],"pdf_url":"https://arxiv.org/pdf/2410.04534v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.13640v3","updated":"2024-10-06T16:02:15Z","published":"2024-06-19T15:39:27Z","title":"Transferable Tactile Transformers for Representation Learning Across\n  Diverse Sensors and Tasks","summary":"  This paper presents T3: Transferable Tactile Transformers, a framework for\ntactile representation learning that scales across multi-sensors and\nmulti-tasks. T3 is designed to overcome the contemporary issue that\ncamera-based tactile sensing is extremely heterogeneous, i.e. sensors are built\ninto different form factors, and existing datasets were collected for disparate\ntasks. T3 captures the shared latent information across different sensor-task\npairings by constructing a shared trunk transformer with sensor-specific\nencoders and task-specific decoders. The pre-training of T3 utilizes a novel\nFoundation Tactile (FoTa) dataset, which is aggregated from several\nopen-sourced datasets and it contains over 3 million data points gathered from\n13 sensors and 11 tasks. FoTa is the largest and most diverse dataset in\ntactile sensing to date and it is made publicly available in a unified format.\nAcross various sensors and tasks, experiments show that T3 pre-trained with\nFoTa achieved zero-shot transferability in certain sensor-task pairings, can be\nfurther fine-tuned with small amounts of domain-specific data, and its\nperformance scales with bigger network sizes. T3 is also effective as a tactile\nencoder for long horizon contact-rich manipulation. Results from sub-millimeter\nmulti-pin electronics insertion tasks show that T3 achieved a task success rate\n25% higher than that of policies trained with tactile encoders trained from\nscratch, or 53% higher than without tactile sensing. Data, code, and model\ncheckpoints are open-sourced at https://t3.alanz.info\n","authors":["Jialiang Zhao","Yuxiang Ma","Lirui Wang","Edward H. Adelson"],"pdf_url":"https://arxiv.org/pdf/2406.13640v3.pdf","comment":"Accepted to 2024 Conference on Robot Learning (CoRL)"},{"id":"http://arxiv.org/abs/2405.00145v3","updated":"2024-10-06T15:59:06Z","published":"2024-04-30T18:42:18Z","title":"GUing: A Mobile GUI Search Engine using a Vision-Language Model","summary":"  Graphical User Interfaces (GUIs) are central to app development projects. App\ndevelopers may use the GUIs of other apps as a means of requirements refinement\nand rapid prototyping or as a source of inspiration for designing and improving\ntheir own apps. Recent research has thus suggested retrieving relevant GUI\ndesigns that match a certain text query from screenshot datasets acquired\nthrough crowdsourced or automated exploration of GUIs. However, such\ntext-to-GUI retrieval approaches only leverage the textual information of the\nGUI elements, neglecting visual information such as icons or background images.\nIn addition, retrieved screenshots are not steered by app developers and lack\napp features that require particular input data.\n  To overcome these limitations, this paper proposes GUing, a GUI search engine\nbased on a vision-language model called GUIClip, which we trained specifically\nfor the problem of designing app GUIs. For this, we first collected from Google\nPlay app introduction images which display the most representative screenshots\nand are often captioned (i.e.~labelled) by app vendors. Then, we developed an\nautomated pipeline to classify, crop, and extract the captions from these\nimages. This resulted in a large dataset which we share with this paper:\nincluding 303k app screenshots, out of which 135k have captions. We used this\ndataset to train a novel vision-language model, which is, to the best of our\nknowledge, the first of its kind for GUI retrieval. We evaluated our approach\non various datasets from related work and in a manual experiment. The results\ndemonstrate that our model outperforms previous approaches in text-to-GUI\nretrieval achieving a Recall@10 of up to 0.69 and a HIT@10 of 0.91. We also\nexplored the performance of GUIClip for other GUI tasks including GUI\nclassification and sketch-to-GUI retrieval with encouraging results.\n","authors":["Jialiang Wei","Anne-Lise Courbis","Thomas Lambolais","Binbin Xu","Pierre Louis Bernard","Gérard Dray","Walid Maalej"],"pdf_url":"https://arxiv.org/pdf/2405.00145v3.pdf","comment":"Accepted to ACM Transactions on Software Engineering and Methodology\n  (TOSEM)"},{"id":"http://arxiv.org/abs/2410.04529v1","updated":"2024-10-06T15:49:58Z","published":"2024-10-06T15:49:58Z","title":"In-Place Panoptic Radiance Field Segmentation with Perceptual Prior for\n  3D Scene Understanding","summary":"  Accurate 3D scene representation and panoptic understanding are essential for\napplications such as virtual reality, robotics, and autonomous driving.\nHowever, challenges persist with existing methods, including precise 2D-to-3D\nmapping, handling complex scene characteristics like boundary ambiguity and\nvarying scales, and mitigating noise in panoptic pseudo-labels. This paper\nintroduces a novel perceptual-prior-guided 3D scene representation and panoptic\nunderstanding method, which reformulates panoptic understanding within neural\nradiance fields as a linear assignment problem involving 2D semantics and\ninstance recognition. Perceptual information from pre-trained 2D panoptic\nsegmentation models is incorporated as prior guidance, thereby synchronizing\nthe learning processes of appearance, geometry, and panoptic understanding\nwithin neural radiance fields. An implicit scene representation and\nunderstanding model is developed to enhance generalization across indoor and\noutdoor scenes by extending the scale-encoded cascaded grids within a\nreparameterized domain distillation framework. This model effectively manages\ncomplex scene attributes and generates 3D-consistent scene representations and\npanoptic understanding outcomes for various scenes. Experiments and ablation\nstudies under challenging conditions, including synthetic and real-world\nscenes, demonstrate the proposed method's effectiveness in enhancing 3D scene\nrepresentation and panoptic segmentation accuracy.\n","authors":["Shenghao Li"],"pdf_url":"https://arxiv.org/pdf/2410.04529v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.01920v2","updated":"2024-10-06T15:49:20Z","published":"2024-07-02T03:34:16Z","title":"To Forget or Not? Towards Practical Knowledge Unlearning for Large\n  Language Models","summary":"  Large Language Models (LLMs) trained on extensive corpora inevitably retain\nsensitive data, such as personal privacy information and copyrighted material.\nRecent advancements in knowledge unlearning involve updating LLM parameters to\nerase specific knowledge. However, current unlearning paradigms are mired in\nvague forgetting boundaries, often erasing knowledge indiscriminately. In this\nwork, we introduce KnowUnDo, a benchmark containing copyrighted content and\nuser privacy domains to evaluate if the unlearning process inadvertently erases\nessential knowledge. Our findings indicate that existing unlearning methods\noften suffer from excessive unlearning. To address this, we propose a simple\nyet effective method, MemFlex, which utilizes gradient information to precisely\ntarget and unlearn sensitive parameters. Experimental results show that MemFlex\nis superior to existing methods in both precise knowledge unlearning and\ngeneral knowledge retaining of LLMs. Code and dataset are released at\nhttps://github.com/zjunlp/KnowUnDo.\n","authors":["Bozhong Tian","Xiaozhuan Liang","Siyuan Cheng","Qingbin Liu","Mengru Wang","Dianbo Sui","Xi Chen","Huajun Chen","Ningyu Zhang"],"pdf_url":"https://arxiv.org/pdf/2407.01920v2.pdf","comment":"EMNLP 2024 Findings; Code and dataset are released at\n  https://github.com/zjunlp/KnowUnDo"},{"id":"http://arxiv.org/abs/2407.15017v3","updated":"2024-10-06T15:42:55Z","published":"2024-07-22T06:15:59Z","title":"Knowledge Mechanisms in Large Language Models: A Survey and Perspective","summary":"  Understanding knowledge mechanisms in Large Language Models (LLMs) is crucial\nfor advancing towards trustworthy AGI. This paper reviews knowledge mechanism\nanalysis from a novel taxonomy including knowledge utilization and evolution.\nKnowledge utilization delves into the mechanism of memorization, comprehension\nand application, and creation. Knowledge evolution focuses on the dynamic\nprogression of knowledge within individual and group LLMs. Moreover, we discuss\nwhat knowledge LLMs have learned, the reasons for the fragility of parametric\nknowledge, and the potential dark knowledge (hypothesis) that will be\nchallenging to address. We hope this work can help understand knowledge in LLMs\nand provide insights for future research.\n","authors":["Mengru Wang","Yunzhi Yao","Ziwen Xu","Shuofei Qiao","Shumin Deng","Peng Wang","Xiang Chen","Jia-Chen Gu","Yong Jiang","Pengjun Xie","Fei Huang","Huajun Chen","Ningyu Zhang"],"pdf_url":"https://arxiv.org/pdf/2407.15017v3.pdf","comment":"EMNLP 2024 Findings; 39 pages (v3)"},{"id":"http://arxiv.org/abs/2410.04525v1","updated":"2024-10-06T15:36:07Z","published":"2024-10-06T15:36:07Z","title":"Look Around and Find Out: OOD Detection with Relative Angles","summary":"  Deep learning systems deployed in real-world applications often encounter\ndata that is different from their in-distribution (ID). A reliable system\nshould ideally abstain from making decisions in this out-of-distribution (OOD)\nsetting. Existing state-of-the-art methods primarily focus on feature\ndistances, such as k-th nearest neighbors and distances to decision boundaries,\neither overlooking or ineffectively using in-distribution statistics. In this\nwork, we propose a novel angle-based metric for OOD detection that is computed\nrelative to the in-distribution structure. We demonstrate that the angles\nbetween feature representations and decision boundaries, viewed from the mean\nof in-distribution features, serve as an effective discriminative factor\nbetween ID and OOD data. Our method achieves state-of-the-art performance on\nCIFAR-10 and ImageNet benchmarks, reducing FPR95 by 0.88% and 7.74%\nrespectively. Our score function is compatible with existing feature space\nregularization techniques, enhancing performance. Additionally, its\nscale-invariance property enables creating an ensemble of models for OOD\ndetection via simple score summation.\n","authors":["Berker Demirel","Marco Fumero","Francesco Locatello"],"pdf_url":"https://arxiv.org/pdf/2410.04525v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04521v1","updated":"2024-10-06T15:28:48Z","published":"2024-10-06T15:28:48Z","title":"MC-CoT: A Modular Collaborative CoT Framework for Zero-shot Medical-VQA\n  with LLM and MLLM Integration","summary":"  In recent advancements, multimodal large language models (MLLMs) have been\nfine-tuned on specific medical image datasets to address medical visual\nquestion answering (Med-VQA) tasks. However, this common approach of\ntask-specific fine-tuning is costly and necessitates separate models for each\ndownstream task, limiting the exploration of zero-shot capabilities. In this\npaper, we introduce MC-CoT, a modular cross-modal collaboration\nChain-of-Thought (CoT) framework designed to enhance the zero-shot performance\nof MLLMs in Med-VQA by leveraging large language models (LLMs). MC-CoT improves\nreasoning and information extraction by integrating medical knowledge and\ntask-specific guidance, where LLM provides various complex medical reasoning\nchains and MLLM provides various observations of medical images based on\ninstructions of the LLM. Our experiments on datasets such as SLAKE, VQA-RAD,\nand PATH-VQA show that MC-CoT surpasses standalone MLLMs and various\nmultimodality CoT frameworks in recall rate and accuracy. These findings\nhighlight the importance of incorporating background information and detailed\nguidance in addressing complex zero-shot Med-VQA tasks.\n","authors":["Lai Wei","Wenkai Wang","Xiaoyu Shen","Yu Xie","Zhihao Fan","Xiaojin Zhang","Zhongyu Wei","Wei Chen"],"pdf_url":"https://arxiv.org/pdf/2410.04521v1.pdf","comment":"21 pages, 14 figures, 6 tables"},{"id":"http://arxiv.org/abs/2410.04514v1","updated":"2024-10-06T15:12:09Z","published":"2024-10-06T15:12:09Z","title":"DAMRO: Dive into the Attention Mechanism of LVLM to Reduce Object\n  Hallucination","summary":"  Despite the great success of Large Vision-Language Models (LVLMs), they\ninevitably suffer from hallucination. As we know, both the visual encoder and\nthe Large Language Model (LLM) decoder in LVLMs are Transformer-based, allowing\nthe model to extract visual information and generate text outputs via attention\nmechanisms. We find that the attention distribution of LLM decoder on image\ntokens is highly consistent with the visual encoder and both distributions tend\nto focus on particular background tokens rather than the referred objects in\nthe image. We attribute to the unexpected attention distribution to an inherent\nflaw in the visual encoder itself, which misguides LLMs to over emphasize the\nredundant information and generate object hallucination. To address the issue,\nwe propose DAMRO, a novel training-free strategy that $D$ive into $A$ttention\n$M$echanism of LVLM to $R$educe $O$bject Hallucination. Specifically, our\napproach employs classification token (CLS) of ViT to filter out high-attention\noutlier tokens scattered in the background and then eliminate their influence\nduring decoding stage. We evaluate our method on LVLMs including LLaVA-1.5,\nLLaVA-NeXT and InstructBLIP, using various benchmarks such as POPE, CHAIR, MME\nand GPT-4V Aided Evaluation. The results demonstrate that our approach\nsignificantly reduces the impact of these outlier tokens, thus effectively\nalleviating the hallucination of LVLMs. The code of our method will be released\nsoon.\n","authors":["Xuan Gong","Tianshi Ming","Xinpeng Wang","Zhihua Wei"],"pdf_url":"https://arxiv.org/pdf/2410.04514v1.pdf","comment":"Accepted by EMNLP2024 (Main Conference)"},{"id":"http://arxiv.org/abs/2410.04511v1","updated":"2024-10-06T15:03:22Z","published":"2024-10-06T15:03:22Z","title":"Realizing Video Summarization from the Path of Language-based Semantic\n  Understanding","summary":"  The recent development of Video-based Large Language Models (VideoLLMs), has\nsignificantly advanced video summarization by aligning video features and, in\nsome cases, audio features with Large Language Models (LLMs). Each of these\nVideoLLMs possesses unique strengths and weaknesses. Many recent methods have\nrequired extensive fine-tuning to overcome the limitations of these models,\nwhich can be resource-intensive. In this work, we observe that the strengths of\none VideoLLM can complement the weaknesses of another. Leveraging this insight,\nwe propose a novel video summarization framework inspired by the Mixture of\nExperts (MoE) paradigm, which operates as an inference-time algorithm without\nrequiring any form of fine-tuning. Our approach integrates multiple VideoLLMs\nto generate comprehensive and coherent textual summaries. It effectively\ncombines visual and audio content, provides detailed background descriptions,\nand excels at identifying keyframes, which enables more semantically meaningful\nretrieval compared to traditional computer vision approaches that rely solely\non visual information, all without the need for additional fine-tuning.\nMoreover, the resulting summaries enhance performance in downstream tasks such\nas summary video generation, either through keyframe selection or in\ncombination with text-to-image models. Our language-driven approach offers a\nsemantically rich alternative to conventional methods and provides flexibility\nto incorporate newer VideoLLMs, enhancing adaptability and performance in video\nsummarization tasks.\n","authors":["Kuan-Chen Mu","Zhi-Yi Chin","Wei-Chen Chiu"],"pdf_url":"https://arxiv.org/pdf/2410.04511v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04507v1","updated":"2024-10-06T14:56:23Z","published":"2024-10-06T14:56:23Z","title":"MECFormer: Multi-task Whole Slide Image Classification with Expert\n  Consultation Network","summary":"  Whole slide image (WSI) classification is a crucial problem for cancer\ndiagnostics in clinics and hospitals. A WSI, acquired at gigapixel size, is\ncommonly tiled into patches and processed by multiple-instance learning (MIL)\nmodels. Previous MIL-based models designed for this problem have only been\nevaluated on individual tasks for specific organs, and the ability to handle\nmultiple tasks within a single model has not been investigated. In this study,\nwe propose MECFormer, a generative Transformer-based model designed to handle\nmultiple tasks within one model. To leverage the power of learning multiple\ntasks simultaneously and to enhance the model's effectiveness in focusing on\neach individual task, we introduce an Expert Consultation Network, a projection\nlayer placed at the beginning of the Transformer-based model. Additionally, to\nenable flexible classification, autoregressive decoding is incorporated by a\nlanguage decoder for WSI classification. Through extensive experiments on five\ndatasets involving four different organs, one cancer classification task, and\nfour cancer subtyping tasks, MECFormer demonstrates superior performance\ncompared to individual state-of-the-art multiple-instance learning models.\n","authors":["Doanh C. Bui","Jin Tae Kwak"],"pdf_url":"https://arxiv.org/pdf/2410.04507v1.pdf","comment":"Accepted for presentation at ACCV2024"},{"id":"http://arxiv.org/abs/2410.04497v1","updated":"2024-10-06T14:29:02Z","published":"2024-10-06T14:29:02Z","title":"Generalizability analysis of deep learning predictions of human brain\n  responses to augmented and semantically novel visual stimuli","summary":"  The purpose of this work is to investigate the soundness and utility of a\nneural network-based approach as a framework for exploring the impact of image\nenhancement techniques on visual cortex activation. In a preliminary study, we\nprepare a set of state-of-the-art brain encoding models, selected among the top\n10 methods that participated in The Algonauts Project 2023 Challenge [16]. We\nanalyze their ability to make valid predictions about the effects of various\nimage enhancement techniques on neural responses. Given the impossibility of\nacquiring the actual data due to the high costs associated with brain imaging\nprocedures, our investigation builds up on a series of experiments.\nSpecifically, we analyze the ability of brain encoders to estimate the cerebral\nreaction to various augmentations by evaluating the response to augmentations\ntargeting objects (i.e., faces and words) with known impact on specific areas.\nMoreover, we study the predicted activation in response to objects unseen\nduring training, exploring the impact of semantically out-of-distribution\nstimuli. We provide relevant evidence for the generalization ability of the\nmodels forming the proposed framework, which appears to be promising for the\nidentification of the optimal visual augmentation filter for a given task,\nmodel-driven design strategies as well as for AR and VR applications.\n","authors":["Valentyn Piskovskyi","Riccardo Chimisso","Sabrina Patania","Tom Foulsham","Giuseppe Vizzari","Dimitri Ognibene"],"pdf_url":"https://arxiv.org/pdf/2410.04497v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.04851v3","updated":"2024-10-06T14:25:21Z","published":"2022-09-11T12:46:01Z","title":"OpenMixup: Open Mixup Toolbox and Benchmark for Visual Representation\n  Learning","summary":"  Mixup augmentation has emerged as a widely used technique for improving the\ngeneralization ability of deep neural networks (DNNs). However, the lack of\nstandardized implementations and benchmarks has impeded recent progress,\nresulting in poor reproducibility, unfair comparisons, and conflicting\ninsights. In this paper, we introduce OpenMixup, the first mixup augmentation\ncodebase, and benchmark for visual representation learning. Specifically, we\ntrain 18 representative mixup baselines from scratch and rigorously evaluate\nthem across 11 image datasets of varying scales and granularity, ranging from\nfine-grained scenarios to complex non-iconic scenes. We also open-source our\nmodular codebase, including a collection of popular vision backbones,\noptimization strategies, and analysis toolkits, which not only supports the\nbenchmarking but enables broader mixup applications beyond classification, such\nas self-supervised learning and regression tasks. Through experiments and\nempirical analysis, we gain observations and insights on mixup\nperformance-efficiency trade-offs, generalization, and optimization behaviors,\nand thereby identify preferred choices for different needs. To the best of our\nknowledge, OpenMixup has facilitated several recent studies. We believe this\nwork can further advance reproducible mixup augmentation research and thereby\nlay a solid ground for future progress in the community. The source code and\nuser documents are available at \\url{https://github.com/Westlake-AI/openmixup}.\n","authors":["Siyuan Li","Zedong Wang","Zicheng Liu","Juanxi Tian","Di Wu","Cheng Tan","Weiyang Jin","Stan Z. Li"],"pdf_url":"https://arxiv.org/pdf/2209.04851v3.pdf","comment":"Preprint V3. The source code is available at\n  https://github.com/Westlake-AI/openmixup"},{"id":"http://arxiv.org/abs/2408.13036v2","updated":"2024-10-06T14:17:11Z","published":"2024-08-23T12:51:49Z","title":"S4D: Streaming 4D Real-World Reconstruction with Gaussians and 3D\n  Control Points","summary":"  Dynamic scene reconstruction using Gaussians has recently attracted increased\ninterest. Mainstream approaches typically employ a global deformation field to\nwarp a 3D scene in canonical space. However, the inherent low-frequency nature\nof implicit neural fields often leads to ineffective representations of complex\nmotions. Moreover, their structural rigidity can hinder adaptation to scenes\nwith varying resolutions and durations. To address these challenges, we\nintroduce a novel approach for streaming 4D real-world reconstruction utilizing\ndiscrete 3D control points. This method physically models local rays and\nestablishes a motion-decoupling coordinate system. By effectively merging\ntraditional graphics with learnable pipelines, it provides a robust and\nefficient local 6-degrees-of-freedom (6-DoF) motion representation.\nAdditionally, we have developed a generalized framework that integrates our\ncontrol points with Gaussians. Starting from an initial 3D reconstruction, our\nworkflow decomposes the streaming 4D reconstruction into four independent\nsubmodules: 3D segmentation, 3D control point generation, object-wise motion\nmanipulation, and residual compensation. Experimental results demonstrate that\nour method outperforms existing state-of-the-art 4D Gaussian splatting\ntechniques on both the Neu3DV and CMU-Panoptic datasets. Notably, the\noptimization of our 3D control points is achievable in 100 iterations and\nwithin just 2 seconds per frame on a single NVIDIA 4070 GPU.\n","authors":["Bing He","Yunuo Chen","Guo Lu","Qi Wang","Qunshan Gu","Rong Xie","Li Song","Wenjun Zhang"],"pdf_url":"https://arxiv.org/pdf/2408.13036v2.pdf","comment":"20 pages, 9 figures, 5 tables"},{"id":"http://arxiv.org/abs/2410.04492v1","updated":"2024-10-06T14:11:39Z","published":"2024-10-06T14:11:39Z","title":"Interpret Your Decision: Logical Reasoning Regularization for\n  Generalization in Visual Classification","summary":"  Vision models excel in image classification but struggle to generalize to\nunseen data, such as classifying images from unseen domains or discovering\nnovel categories. In this paper, we explore the relationship between logical\nreasoning and deep learning generalization in visual classification. A logical\nregularization termed L-Reg is derived which bridges a logical analysis\nframework to image classification. Our work reveals that L-Reg reduces the\ncomplexity of the model in terms of the feature distribution and classifier\nweights. Specifically, we unveil the interpretability brought by L-Reg, as it\nenables the model to extract the salient features, such as faces to persons,\nfor classification. Theoretical analysis and experiments demonstrate that L-Reg\nenhances generalization across various scenarios, including multi-domain\ngeneralization and generalized category discovery. In complex real-world\nscenarios where images span unknown classes and unseen domains, L-Reg\nconsistently improves generalization, highlighting its practical efficacy.\n","authors":["Zhaorui Tan","Xi Yang","Qiufeng Wang","Anh Nguyen","Kaizhu Huang"],"pdf_url":"https://arxiv.org/pdf/2410.04492v1.pdf","comment":"Accepted by NeurIPS2024 as Spotlight"},{"id":"http://arxiv.org/abs/2405.17013v3","updated":"2024-10-06T13:46:47Z","published":"2024-05-27T09:57:51Z","title":"Motion-Agent: A Conversational Framework for Human Motion Generation\n  with LLMs","summary":"  While previous approaches to 3D human motion generation have achieved notable\nsuccess, they often rely on extensive training and are limited to specific\ntasks. To address these challenges, we introduce Motion-Agent, an efficient\nconversational framework designed for general human motion generation, editing,\nand understanding. Motion-Agent employs an open-source pre-trained language\nmodel to develop a generative agent, MotionLLM, that bridges the gap between\nmotion and text. This is accomplished by encoding and quantizing motions into\ndiscrete tokens that align with the language model's vocabulary. With only\n1--3\\% of the model's parameters fine-tuned using adapters, MotionLLM delivers\nperformance on par with diffusion models and other transformer-based methods\ntrained from scratch. By integrating MotionLLM with GPT-4 without additional\ntraining, Motion-Agent is able to generate highly complex motion sequences\nthrough multi-turn conversations, a capability that previous models have\nstruggled to achieve. Motion-Agent supports a wide range of motion-language\ntasks, offering versatile capabilities for generating and customizing human\nmotion through interactive conversational exchanges. Project page:\nhttps://knoxzhao.github.io/Motion-Agent\n","authors":["Qi Wu","Yubo Zhao","Yifan Wang","Xinhang Liu","Yu-Wing Tai","Chi-Keung Tang"],"pdf_url":"https://arxiv.org/pdf/2405.17013v3.pdf","comment":"Project page: https://knoxzhao.github.io/Motion-Agent"},{"id":"http://arxiv.org/abs/2406.03293v3","updated":"2024-10-06T13:39:53Z","published":"2024-06-05T14:02:31Z","title":"Text-to-Image Rectified Flow as Plug-and-Play Priors","summary":"  Large-scale diffusion models have achieved remarkable performance in\ngenerative tasks. Beyond their initial training applications, these models have\nproven their ability to function as versatile plug-and-play priors. For\ninstance, 2D diffusion models can serve as loss functions to optimize 3D\nimplicit models. Rectified flow, a novel class of generative models, enforces a\nlinear progression from the source to the target distribution and has\ndemonstrated superior performance across various domains. Compared to\ndiffusion-based methods, rectified flow approaches surpass in terms of\ngeneration quality and efficiency, requiring fewer inference steps. In this\nwork, we present theoretical and experimental evidence demonstrating that\nrectified flow based methods offer similar functionalities to diffusion models\n- they can also serve as effective priors. Besides the generative capabilities\nof diffusion priors, motivated by the unique time-symmetry properties of\nrectified flow models, a variant of our method can additionally perform image\ninversion. Experimentally, our rectified flow-based priors outperform their\ndiffusion counterparts - the SDS and VSD losses - in text-to-3D generation. Our\nmethod also displays competitive performance in image inversion and editing.\n","authors":["Xiaofeng Yang","Cheng Chen","Xulei Yang","Fayao Liu","Guosheng Lin"],"pdf_url":"https://arxiv.org/pdf/2406.03293v3.pdf","comment":"Extended with Stochastic Interpolants. Code:\n  https://github.com/yangxiaofeng/rectified_flow_prior"},{"id":"http://arxiv.org/abs/2410.04479v1","updated":"2024-10-06T13:39:36Z","published":"2024-10-06T13:39:36Z","title":"SITCOM: Step-wise Triple-Consistent Diffusion Sampling for Inverse\n  Problems","summary":"  Diffusion models (DMs) are a class of generative models that allow sampling\nfrom a distribution learned over a training set. When applied to solving\ninverse imaging problems (IPs), the reverse sampling steps of DMs are typically\nmodified to approximately sample from a measurement-conditioned distribution in\nthe image space. However, these modifications may be unsuitable for certain\nsettings (such as in the presence of measurement noise) and non-linear tasks,\nas they often struggle to correct errors from earlier sampling steps and\ngenerally require a large number of optimization and/or sampling steps. To\naddress these challenges, we state three conditions for achieving\nmeasurement-consistent diffusion trajectories. Building on these conditions, we\npropose a new optimization-based sampling method that not only enforces the\nstandard data manifold measurement consistency and forward diffusion\nconsistency, as seen in previous studies, but also incorporates backward\ndiffusion consistency that maintains a diffusion trajectory by optimizing over\nthe input of the pre-trained model at every sampling step. By enforcing these\nconditions, either implicitly or explicitly, our sampler requires significantly\nfewer reverse steps. Therefore, we refer to our accelerated method as Step-wise\nTriple-Consistent Sampling (SITCOM). Compared to existing state-of-the-art\nbaseline methods, under different levels of measurement noise, our extensive\nexperiments across five linear and three non-linear image restoration tasks\ndemonstrate that SITCOM achieves competitive or superior results in terms of\nstandard image similarity metrics while requiring a significantly reduced\nrun-time across all considered tasks.\n","authors":["Ismail Alkhouri","Shijun Liang","Cheng-Han Huang","Jimmy Dai","Qing Qu","Saiprasad Ravishankar","Rongrong Wang"],"pdf_url":"https://arxiv.org/pdf/2410.04479v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.04398v2","updated":"2024-10-06T13:30:17Z","published":"2024-03-07T10:44:47Z","title":"MAGR: Manifold-Aligned Graph Regularization for Continual Action Quality\n  Assessment","summary":"  Action Quality Assessment (AQA) evaluates diverse skills but models struggle\nwith non-stationary data. We propose Continual AQA (CAQA) to refine models\nusing sparse new data. Feature replay preserves memory without storing raw\ninputs. However, the misalignment between static old features and the\ndynamically changing feature manifold causes severe catastrophic forgetting. To\naddress this novel problem, we propose Manifold-Aligned Graph Regularization\n(MAGR), which first aligns deviated old features to the current feature\nmanifold, ensuring representation consistency. It then constructs a graph\njointly arranging old and new features aligned with quality scores. Experiments\nshow MAGR outperforms recent strong baselines with up to 6.56%, 5.66%, 15.64%,\nand 9.05% correlation gains on the MTL-AQA, FineDiving, UNLV-Dive, and JDM-MSA\nsplit datasets, respectively. This validates MAGR for continual assessment\nchallenges arising from non-stationary skill variations. Code is available at\nhttps://github.com/ZhouKanglei/MAGR_CAQA}{https://github.com/ZhouKanglei/MAGR_CAQA.\n","authors":["Kanglei Zhou","Liyuan Wang","Xingxing Zhang","Hubert P. H. Shum","Frederick W. B. Li","Jianguo Li","Xiaohui Liang"],"pdf_url":"https://arxiv.org/pdf/2403.04398v2.pdf","comment":"Accepted by ECCV 2024 as an oral paper"},{"id":"http://arxiv.org/abs/2405.17720v2","updated":"2024-10-06T13:27:37Z","published":"2024-05-28T00:36:25Z","title":"MindFormer: Semantic Alignment of Multi-Subject fMRI for Brain Decoding","summary":"  Research efforts for visual decoding from fMRI signals have attracted\nconsiderable attention in research community. Still multi-subject fMRI decoding\nwith one model has been considered intractable due to the drastic variations in\nfMRI signals between subjects and even within the same subject across different\ntrials. To address current limitations in multi-subject brain decoding, here we\nintroduce a novel semantic alignment method of multi-subject fMRI signals using\nso-called MindFormer. This model is specifically designed to generate\nfMRI-conditioned feature vectors that can be used for conditioning Stable\nDiffusion model for fMRI- to-image generation or large language model (LLM) for\nfMRI-to-text generation. More specifically, MindFormer incorporates two key\ninnovations: 1) a subject specific token that effectively capture individual\ndifferences in fMRI signals while synergistically combines multi subject fMRI\ndata for training, and 2) a novel feature embedding and training scheme based\non the IP-Adapter to extract semantically meaningful features from fMRI\nsignals. Our experimental results demonstrate that MindFormer generates\nsemantically consistent images and text across different subjects. Since our\nMindFormer maintains semantic fidelity by fully utilizing the training data\nacross different subjects by significantly surpassing existing models in\nmulti-subject brain decoding, this may help deepening our understanding of\nneural processing variations among individuals.\n","authors":["Inhwa Han","Jaayeon Lee","Jong Chul Ye"],"pdf_url":"https://arxiv.org/pdf/2405.17720v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04462v1","updated":"2024-10-06T12:25:41Z","published":"2024-10-06T12:25:41Z","title":"Tensor-Train Point Cloud Compression and Efficient Approximate\n  Nearest-Neighbor Search","summary":"  Nearest-neighbor search in large vector databases is crucial for various\nmachine learning applications. This paper introduces a novel method using\ntensor-train (TT) low-rank tensor decomposition to efficiently represent point\nclouds and enable fast approximate nearest-neighbor searches. We propose a\nprobabilistic interpretation and utilize density estimation losses like Sliced\nWasserstein to train TT decompositions, resulting in robust point cloud\ncompression. We reveal an inherent hierarchical structure within TT point\nclouds, facilitating efficient approximate nearest-neighbor searches. In our\npaper, we provide detailed insights into the methodology and conduct\ncomprehensive comparisons with existing methods. We demonstrate its\neffectiveness in various scenarios, including out-of-distribution (OOD)\ndetection problems and approximate nearest-neighbor (ANN) search tasks.\n","authors":["Georgii Novikov","Alexander Gneushev","Alexey Kadeishvili","Ivan Oseledets"],"pdf_url":"https://arxiv.org/pdf/2410.04462v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04460v1","updated":"2024-10-06T12:17:42Z","published":"2024-10-06T12:17:42Z","title":"U-net based prediction of cerebrospinal fluid distribution and\n  ventricular reflux grading","summary":"  Previous work shows evidence that cerebrospinal fluid (CSF) plays a crucial\nrole in brain waste clearance processes, and that altered flow patterns are\nassociated with various diseases of the central nervous system. In this study,\nwe investigate the potential of deep learning to predict the distribution in\nhuman brain of a gadolinium-based CSF contrast agent (tracer) administered\nintrathecal. For this, T1-weighted magnetic resonance imaging (MRI) scans taken\nat multiple time points before and after intrathecal injection were utilized.\nWe propose a U-net-based supervised learning model to predict pixel-wise signal\nincreases at their peak after 24 hours. Its performance is evaluated based on\ndifferent tracer distribution stages provided during training, including\npredictions from baseline scans taken before injection. Our findings indicate\nthat using imaging data from just the first two hours post-injection for\ntraining yields tracer flow predictions comparable to those trained with\nadditional later-stage scans. The model was further validated by comparing\nventricular reflux gradings provided by neuroradiologists, and inter-rater\ngrading among medical experts and the model showed excellent agreement. Our\nresults demonstrate the potential of deep learning-based methods for CSF flow\nprediction, suggesting that fewer MRI scans could be sufficient for clinical\nanalysis, which might significantly improve clinical efficiency, patient\nwell-being, and lower healthcare costs.\n","authors":["Melanie Rieff","Fabian Holzberger","Oksana Lapina","Geir Ringstad","Lars Magnus Valnes","Bogna Warsza","Kent-Andre Mardal","Per Kristian Eide","Barbara Wohlmuth"],"pdf_url":"https://arxiv.org/pdf/2410.04460v1.pdf","comment":"13 pages, 7 figures"},{"id":"http://arxiv.org/abs/2404.16818v2","updated":"2024-10-06T11:52:56Z","published":"2024-04-25T17:58:09Z","title":"Boosting Unsupervised Semantic Segmentation with Principal Mask\n  Proposals","summary":"  Unsupervised semantic segmentation aims to automatically partition images\ninto semantically meaningful regions by identifying global semantic categories\nwithin an image corpus without any form of annotation. Building upon recent\nadvances in self-supervised representation learning, we focus on how to\nleverage these large pre-trained models for the downstream task of unsupervised\nsegmentation. We present PriMaPs - Principal Mask Proposals - decomposing\nimages into semantically meaningful masks based on their feature\nrepresentation. This allows us to realize unsupervised semantic segmentation by\nfitting class prototypes to PriMaPs with a stochastic expectation-maximization\nalgorithm, PriMaPs-EM. Despite its conceptual simplicity, PriMaPs-EM leads to\ncompetitive results across various pre-trained backbone models, including DINO\nand DINOv2, and across different datasets, such as Cityscapes, COCO-Stuff, and\nPotsdam-3. Importantly, PriMaPs-EM is able to boost results when applied\northogonally to current state-of-the-art unsupervised semantic segmentation\npipelines. Code is available at https://github.com/visinf/primaps.\n","authors":["Oliver Hahn","Nikita Araslanov","Simone Schaub-Meyer","Stefan Roth"],"pdf_url":"https://arxiv.org/pdf/2404.16818v2.pdf","comment":"Published in TMLR (September 2024) | OpenReview: see\n  https://openreview.net/forum?id=UawaTQzfwy | Project Page: see\n  https://visinf.github.io/primaps/ | Code: see\n  https://github.com/visinf/primaps"},{"id":"http://arxiv.org/abs/2409.13609v2","updated":"2024-10-06T11:46:51Z","published":"2024-09-20T16:12:26Z","title":"MaPPER: Multimodal Prior-guided Parameter Efficient Tuning for Referring\n  Expression Comprehension","summary":"  Referring Expression Comprehension (REC), which aims to ground a local visual\nregion via natural language, is a task that heavily relies on multimodal\nalignment. Most existing methods utilize powerful pre-trained models to\ntransfer visual/linguistic knowledge by full fine-tuning. However, full\nfine-tuning the entire backbone not only breaks the rich prior knowledge\nembedded in the pre-training, but also incurs significant computational costs.\nMotivated by the recent emergence of Parameter-Efficient Transfer Learning\n(PETL) methods, we aim to solve the REC task in an effective and efficient\nmanner. Directly applying these PETL methods to the REC task is inappropriate,\nas they lack the specific-domain abilities for precise local visual perception\nand visual-language alignment. Therefore, we propose a novel framework of\nMultimodal Prior-guided Parameter Efficient Tuning, namely MaPPER.\nSpecifically, MaPPER comprises Dynamic Prior Adapters guided by an aligned\nprior, and Local Convolution Adapters to extract precise local semantics for\nbetter visual perception. Moreover, the Prior-Guided Text module is proposed to\nfurther utilize the prior for facilitating the cross-modal alignment.\nExperimental results on three widely-used benchmarks demonstrate that MaPPER\nachieves the best accuracy compared to the full fine-tuning and other PETL\nmethods with only 1.41% tunable backbone parameters. Our code is available at\nhttps://github.com/liuting20/MaPPER.\n","authors":["Ting Liu","Zunnan Xu","Yue Hu","Liangtao Shi","Zhiqiang Wang","Quanjun Yin"],"pdf_url":"https://arxiv.org/pdf/2409.13609v2.pdf","comment":"EMNLP 2024"},{"id":"http://arxiv.org/abs/2410.04449v1","updated":"2024-10-06T11:17:54Z","published":"2024-10-06T11:17:54Z","title":"Video Summarization Techniques: A Comprehensive Review","summary":"  The rapid expansion of video content across a variety of industries,\nincluding social media, education, entertainment, and surveillance, has made\nvideo summarization an essential field of study. The current work is a survey\nthat explores the various approaches and methods created for video summarizing,\nemphasizing both abstractive and extractive strategies. The process of\nextractive summarization involves the identification of key frames or segments\nfrom the source video, utilizing methods such as shot boundary recognition, and\nclustering. On the other hand, abstractive summarization creates new content by\ngetting the essential content from the video, using machine learning models\nlike deep neural networks and natural language processing, reinforcement\nlearning, attention mechanisms, generative adversarial networks, and\nmulti-modal learning. We also include approaches that incorporate the two\nmethodologies, along with discussing the uses and difficulties encountered in\nreal-world implementations. The paper also covers the datasets used to\nbenchmark these techniques. This review attempts to provide a state-of-the-art\nthorough knowledge of the current state and future directions of video\nsummarization research.\n","authors":["Toqa Alaa","Ahmad Mongy","Assem Bakr","Mariam Diab","Walid Gomaa"],"pdf_url":"https://arxiv.org/pdf/2410.04449v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04447v1","updated":"2024-10-06T11:16:54Z","published":"2024-10-06T11:16:54Z","title":"Attention Shift: Steering AI Away from Unsafe Content","summary":"  This study investigates the generation of unsafe or harmful content in\nstate-of-the-art generative models, focusing on methods for restricting such\ngenerations. We introduce a novel training-free approach using attention\nreweighing to remove unsafe concepts without additional training during\ninference. We compare our method against existing ablation methods, evaluating\nthe performance on both, direct and adversarial jailbreak prompts, using\nqualitative and quantitative metrics. We hypothesize potential reasons for the\nobserved results and discuss the limitations and broader implications of\ncontent restriction.\n","authors":["Shivank Garg","Manyana Tiwari"],"pdf_url":"https://arxiv.org/pdf/2410.04447v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04445v1","updated":"2024-10-06T10:54:56Z","published":"2024-10-06T10:54:56Z","title":"Optimising for the Unknown: Domain Alignment for Cephalometric Landmark\n  Detection","summary":"  Cephalometric Landmark Detection is the process of identifying key areas for\ncephalometry. Each landmark is a single GT point labelled by a clinician. A\nmachine learning model predicts the probability locus of a landmark represented\nby a heatmap. This work, for the 2024 CL-Detection MICCAI Challenge, proposes a\ndomain alignment strategy with a regional facial extraction module and an X-ray\nartefact augmentation procedure. The challenge ranks our method's results as\nthe best in MRE of 1.186mm and third in the 2mm SDR of 82.04% on the online\nvalidation leaderboard. The code is available at\nhttps://github.com/Julian-Wyatt/OptimisingfortheUnknown.\n","authors":["Julian Wyatt","Irina Voiculescu"],"pdf_url":"https://arxiv.org/pdf/2410.04445v1.pdf","comment":"MICCAI CL-Detection2024: Cephalometric Landmark Detection in Lateral\n  X-ray Images"},{"id":"http://arxiv.org/abs/2410.04440v1","updated":"2024-10-06T10:29:45Z","published":"2024-10-06T10:29:45Z","title":"Automated Detection of Defects on Metal Surfaces using Vision\n  Transformers","summary":"  Metal manufacturing often results in the production of defective products,\nleading to operational challenges. Since traditional manual inspection is\ntime-consuming and resource-intensive, automatic solutions are needed. The\nstudy utilizes deep learning techniques to develop a model for detecting metal\nsurface defects using Vision Transformers (ViTs). The proposed model focuses on\nthe classification and localization of defects using a ViT for feature\nextraction. The architecture branches into two paths: classification and\nlocalization. The model must approach high classification accuracy while\nkeeping the Mean Square Error (MSE) and Mean Absolute Error (MAE) as low as\npossible in the localization process. Experimental results show that it can be\nutilized in the process of automated defects detection, improve operational\nefficiency, and reduce errors in metal manufacturing.\n","authors":["Toqa Alaa","Mostafa Kotb","Arwa Zakaria","Mariam Diab","Walid Gomaa"],"pdf_url":"https://arxiv.org/pdf/2410.04440v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04439v1","updated":"2024-10-06T10:25:39Z","published":"2024-10-06T10:25:39Z","title":"Empowering Backbone Models for Visual Text Generation with Input\n  Granularity Control and Glyph-Aware Training","summary":"  Diffusion-based text-to-image models have demonstrated impressive\nachievements in diversity and aesthetics but struggle to generate images with\nlegible visual texts. Existing backbone models have limitations such as\nmisspelling, failing to generate texts, and lack of support for Chinese text,\nbut their development shows promising potential. In this paper, we propose a\nseries of methods, aiming to empower backbone models to generate visual texts\nin English and Chinese. We first conduct a preliminary study revealing that\nByte Pair Encoding (BPE) tokenization and the insufficient learning of\ncross-attention modules restrict the performance of the backbone models. Based\non these observations, we make the following improvements: (1) We design a\nmixed granularity input strategy to provide more suitable text representations;\n(2) We propose to augment the conventional training objective with three\nglyph-aware training losses, which enhance the learning of cross-attention\nmodules and encourage the model to focus on visual texts. Through experiments,\nwe demonstrate that our methods can effectively empower backbone models to\ngenerate semantic relevant, aesthetically appealing, and accurate visual text\nimages, while maintaining their fundamental image generation quality.\n","authors":["Wenbo Li","Guohao Li","Zhibin Lan","Xue Xu","Wanru Zhuang","Jiachen Liu","Xinyan Xiao","Jinsong Su"],"pdf_url":"https://arxiv.org/pdf/2410.04439v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04434v1","updated":"2024-10-06T10:07:52Z","published":"2024-10-06T10:07:52Z","title":"A Mathematical Explanation of UNet","summary":"  The UNet architecture has transformed image segmentation. UNet's versatility\nand accuracy have driven its widespread adoption, significantly advancing\nfields reliant on machine learning problems with images. In this work, we give\na clear and concise mathematical explanation of UNet. We explain what is the\nmeaning and function of each of the components of UNet. We will show that UNet\nis solving a control problem. We decompose the control variables using\nmultigrid methods. Then, operator-splitting techniques is used to solve the\nproblem, whose architecture exactly recovers the UNet architecture. Our result\nshows that UNet is a one-step operator-splitting algorithm for the control\nproblem.\n","authors":["Xue-Cheng Tai","Hao Liu","Raymond H. Chan","Lingfeng Li"],"pdf_url":"https://arxiv.org/pdf/2410.04434v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.18299v3","updated":"2024-10-06T10:07:08Z","published":"2024-05-28T15:51:18Z","title":"Deep Learning Innovations for Underwater Waste Detection: An In-Depth\n  Analysis","summary":"  Addressing the issue of submerged underwater trash is crucial for\nsafeguarding aquatic ecosystems and preserving marine life. While identifying\ndebris present on the surface of water bodies is straightforward, assessing the\nunderwater submerged waste is a challenge due to the image distortions caused\nby factors such as light refraction, absorption, suspended particles, color\nshifts, and occlusion. This paper conducts a comprehensive review of\nstate-of-the-art architectures and on the existing datasets to establish a\nbaseline for submerged waste and trash detection. The primary goal remains to\nestablish the benchmark of the object localization techniques to be leveraged\nby advanced underwater sensors and autonomous underwater vehicles. The ultimate\nobjective is to explore the underwater environment, to identify, and remove\nunderwater debris. The absence of benchmarks (dataset or algorithm) in many\nresearches emphasizes the need for a more robust algorithmic solution. Through\nthis research, we aim to give performance comparative analysis of various\nunderwater trash detection algorithms.\n","authors":["Jaskaran Singh Walia","Pavithra L K","Kesar Mehta","Shivram Harshavardhana","Nandini Tyagi"],"pdf_url":"https://arxiv.org/pdf/2405.18299v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04433v1","updated":"2024-10-06T10:05:01Z","published":"2024-10-06T10:05:01Z","title":"CAPEEN: Image Captioning with Early Exits and Knowledge Distillation","summary":"  Deep neural networks (DNNs) have made significant progress in recognizing\nvisual elements and generating descriptive text in image-captioning tasks.\nHowever, their improved performance comes from increased computational burden\nand inference latency. Early Exit (EE) strategies can be used to enhance their\nefficiency, but their adaptation presents challenges in image captioning as it\nrequires varying levels of semantic information for accurate predictions. To\novercome this, we introduce CAPEEN to improve the performance of EE strategies\nusing knowledge distillation. Inference in CAPEEN is completed at intermediary\nlayers if prediction confidence exceeds a predefined value learned from the\ntraining data. To account for real-world deployments, where target\ndistributions could drift from that of training samples, we introduce a variant\nA-CAPEEN to adapt the thresholds on the fly using Multiarmed bandits framework.\nExperiments on the MS COCO and Flickr30k datasets show that CAPEEN gains\nspeedup of 1.77x while maintaining competitive performance compared to the\nfinal layer, and A-CAPEEN additionally offers robustness against distortions.\nThe source code is available at https://github.com/Div290/CapEEN\n","authors":["Divya Jyoti Bajpai","Manjesh Kumar Hanawal"],"pdf_url":"https://arxiv.org/pdf/2410.04433v1.pdf","comment":"To appear in EMNLP (finding) 2024"},{"id":"http://arxiv.org/abs/2405.14156v4","updated":"2024-10-06T09:51:25Z","published":"2024-05-23T04:08:23Z","title":"Unveiling the Tapestry of Consistency in Large Vision-Language Models","summary":"  Large vision-language models (LVLMs) have recently achieved rapid progress,\nexhibiting great perception and reasoning abilities concerning visual\ninformation. However, when faced with prompts in different sizes of solution\nspaces, LVLMs fail to always give consistent answers regarding the same\nknowledge point. This inconsistency of answers between different solution\nspaces is prevalent in LVLMs and erodes trust. To this end, we provide a\nmulti-modal benchmark ConBench, to intuitively analyze how LVLMs perform when\nthe solution space of a prompt revolves around a knowledge point. Based on the\nConBench tool, we are the first to reveal the tapestry and get the following\nfindings: (1) In the discriminate realm, the larger the solution space of the\nprompt, the lower the accuracy of the answers. (2) Establish the relationship\nbetween the discriminative and generative realms: the accuracy of the\ndiscriminative question type exhibits a strong positive correlation with its\nConsistency with the caption. (3) Compared to open-source models, closed-source\nmodels exhibit a pronounced bias advantage in terms of Consistency. Eventually,\nwe ameliorate the consistency of LVLMs by trigger-based diagnostic refinement,\nindirectly improving the performance of their caption. We hope this paper will\naccelerate the research community in better evaluating their models and\nencourage future advancements in the consistency domain. The project is\navailable at https://github.com/foundation-multimodal-models/ConBench.\n","authors":["Yuan Zhang","Fei Xiao","Tao Huang","Chun-Kai Fan","Hongyuan Dong","Jiawen Li","Jiacong Wang","Kuan Cheng","Shanghang Zhang","Haoyuan Guo"],"pdf_url":"https://arxiv.org/pdf/2405.14156v4.pdf","comment":"Accepted by NeurIPS 2024"},{"id":"http://arxiv.org/abs/2410.04426v1","updated":"2024-10-06T09:45:20Z","published":"2024-10-06T09:45:20Z","title":"CoVLM: Leveraging Consensus from Vision-Language Models for\n  Semi-supervised Multi-modal Fake News Detection","summary":"  In this work, we address the real-world, challenging task of out-of-context\nmisinformation detection, where a real image is paired with an incorrect\ncaption for creating fake news. Existing approaches for this task assume the\navailability of large amounts of labeled data, which is often impractical in\nreal-world, since it requires extensive manual intervention and domain\nexpertise. In contrast, since obtaining a large corpus of unlabeled image-text\npairs is much easier, here, we propose a semi-supervised protocol, where the\nmodel has access to a limited number of labeled image-text pairs and a large\ncorpus of unlabeled pairs. Additionally, the occurrence of fake news being much\nlesser compared to the real ones, the datasets tend to be highly imbalanced,\nthus making the task even more challenging. Towards this goal, we propose a\nnovel framework, Consensus from Vision-Language Models (CoVLM), which generates\nrobust pseudo-labels for unlabeled pairs using thresholds derived from the\nlabeled data. This approach can automatically determine the right threshold\nparameters of the model for selecting the confident pseudo-labels. Experimental\nresults on benchmark datasets across challenging conditions and comparisons\nwith state-of-the-art approaches demonstrate the effectiveness of our\nframework.\n","authors":[" Devank","Jayateja Kalla","Soma Biswas"],"pdf_url":"https://arxiv.org/pdf/2410.04426v1.pdf","comment":"Accepted in ACCV 2024"},{"id":"http://arxiv.org/abs/2410.04421v1","updated":"2024-10-06T09:27:45Z","published":"2024-10-06T09:27:45Z","title":"Disentangling Regional Primitives for Image Generation","summary":"  This paper presents a method to explain the internal representation structure\nof a neural network for image generation. Specifically, our method disentangles\nprimitive feature components from the intermediate-layer feature of the neural\nnetwork, which ensures that each feature component is exclusively used to\ngenerate a specific set of image regions. In this way, the generation of the\nentire image can be considered as the superposition of different pre-encoded\nprimitive regional patterns, each being generated by a feature component. We\nfind that the feature component can be represented as an OR relationship\nbetween the demands for generating different image regions, which is encoded by\nthe neural network. Therefore, we extend the Harsanyi interaction to represent\nsuch an OR interaction to disentangle the feature component. Experiments show a\nclear correspondence between each feature component and the generation of\nspecific image regions.\n","authors":["Zhengting Chen","Lei Cheng","Lianghui Ding","Quanshi Zhang"],"pdf_url":"https://arxiv.org/pdf/2410.04421v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04419v1","updated":"2024-10-06T09:26:07Z","published":"2024-10-06T09:26:07Z","title":"LiteVLoc: Map-Lite Visual Localization for Image Goal Navigation","summary":"  This paper presents LiteVLoc, a hierarchical visual localization framework\nthat uses a lightweight topo-metric map to represent the environment. The\nmethod consists of three sequential modules that estimate camera poses in a\ncoarse-to-fine manner. Unlike mainstream approaches relying on detailed 3D\nrepresentations, LiteVLoc reduces storage overhead by leveraging learning-based\nfeature matching and geometric solvers for metric pose estimation. A novel\ndataset for the map-free relocalization task is also introduced. Extensive\nexperiments including localization and navigation in both simulated and\nreal-world scenarios have validate the system's performance and demonstrated\nits precision and efficiency for large-scale deployment. Code and data will be\nmade publicly available.\n","authors":["Jianhao Jiao","Jinhao He","Changkun Liu","Sebastian Aegidius","Xiangcheng Hu","Tristan Braud","Dimitrios Kanoulas"],"pdf_url":"https://arxiv.org/pdf/2410.04419v1.pdf","comment":"8 pages, 4 figures"},{"id":"http://arxiv.org/abs/2410.04417v1","updated":"2024-10-06T09:18:04Z","published":"2024-10-06T09:18:04Z","title":"SparseVLM: Visual Token Sparsification for Efficient Vision-Language\n  Model Inference","summary":"  In vision-language models (VLMs), visual tokens usually consume a significant\namount of computational overhead, despite their sparser information density\ncompared to text tokens. To address this, most existing methods learn a network\nto prune redundant visual tokens and require additional training data.\nDifferently, we propose an efficient training-free token optimization mechanism\ndubbed SparseVLM without extra parameters or fine-tuning costs. Concretely,\ngiven that visual tokens complement text tokens in VLMs for linguistic\nreasoning, we select visual-relevant text tokens to rate the significance of\nvision tokens within the self-attention matrix extracted from the VLMs. Then we\nprogressively prune irrelevant tokens. To maximize sparsity while retaining\nessential information, we introduce a rank-based strategy to adaptively\ndetermine the sparsification ratio for each layer, alongside a token recycling\nmethod that compresses pruned tokens into more compact representations.\nExperimental results show that our SparseVLM improves the efficiency of various\nVLMs across a range of image and video understanding tasks. In particular,\nLLaVA equipped with SparseVLM reduces 61% to 67% FLOPs with a compression ratio\nof 78% while maintaining 93% of the accuracy. Our code is available at\nhttps://github.com/Gumpest/SparseVLMs.\n","authors":["Yuan Zhang","Chun-Kai Fan","Junpeng Ma","Wenzhao Zheng","Tao Huang","Kuan Cheng","Denis Gudovskiy","Tomoyuki Okuno","Yohei Nakata","Kurt Keutzer","Shanghang Zhang"],"pdf_url":"https://arxiv.org/pdf/2410.04417v1.pdf","comment":"17 pages"},{"id":"http://arxiv.org/abs/2410.01535v2","updated":"2024-10-06T08:58:10Z","published":"2024-10-02T13:26:28Z","title":"GaussianBlock: Building Part-Aware Compositional and Editable 3D Scene\n  by Primitives and Gaussians","summary":"  Recently, with the development of Neural Radiance Fields and Gaussian\nSplatting, 3D reconstruction techniques have achieved remarkably high fidelity.\nHowever, the latent representations learnt by these methods are highly\nentangled and lack interpretability. In this paper, we propose a novel\npart-aware compositional reconstruction method, called GaussianBlock, that\nenables semantically coherent and disentangled representations, allowing for\nprecise and physical editing akin to building blocks, while simultaneously\nmaintaining high fidelity. Our GaussianBlock introduces a hybrid representation\nthat leverages the advantages of both primitives, known for their flexible\nactionability and editability, and 3D Gaussians, which excel in reconstruction\nquality. Specifically, we achieve semantically coherent primitives through a\nnovel attention-guided centering loss derived from 2D semantic priors,\ncomplemented by a dynamic splitting and fusion strategy. Furthermore, we\nutilize 3D Gaussians that hybridize with primitives to refine structural\ndetails and enhance fidelity. Additionally, a binding inheritance strategy is\nemployed to strengthen and maintain the connection between the two. Our\nreconstructed scenes are evidenced to be disentangled, compositional, and\ncompact across diverse benchmarks, enabling seamless, direct and precise\nediting while maintaining high quality.\n","authors":["Shuyi Jiang","Qihao Zhao","Hossein Rahmani","De Wen Soh","Jun Liu","Na Zhao"],"pdf_url":"https://arxiv.org/pdf/2410.01535v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.03916v2","updated":"2024-10-06T08:35:10Z","published":"2024-06-06T09:56:49Z","title":"ArMeme: Propagandistic Content in Arabic Memes","summary":"  With the rise of digital communication, memes have become a significant\nmedium for cultural and political expression that is often used to mislead\naudiences. Identification of such misleading and persuasive multimodal content\nhas become more important among various stakeholders, including social media\nplatforms, policymakers, and the broader society as they often cause harm to\nindividuals, organizations, and/or society. While there has been effort to\ndevelop AI-based automatic systems for resource-rich languages (e.g., English),\nit is relatively little to none for medium to low resource languages. In this\nstudy, we focused on developing an Arabic memes dataset with manual annotations\nof propagandistic content. We annotated ~6K Arabic memes collected from various\nsocial media platforms, which is a first resource for Arabic multimodal\nresearch. We provide a comprehensive analysis aiming to develop computational\ntools for their detection. We will make them publicly available for the\ncommunity.\n","authors":["Firoj Alam","Abul Hasnat","Fatema Ahmed","Md Arid Hasan","Maram Hasanain"],"pdf_url":"https://arxiv.org/pdf/2406.03916v2.pdf","comment":"disinformation, misinformation, factuality, harmfulness, fake news,\n  propaganda, multimodality, text, images"},{"id":"http://arxiv.org/abs/2410.04402v1","updated":"2024-10-06T08:35:01Z","published":"2024-10-06T08:35:01Z","title":"Deformable NeRF using Recursively Subdivided Tetrahedra","summary":"  While neural radiance fields (NeRF) have shown promise in novel view\nsynthesis, their implicit representation limits explicit control over object\nmanipulation. Existing research has proposed the integration of explicit\ngeometric proxies to enable deformation. However, these methods face two\nprimary challenges: firstly, the time-consuming and computationally demanding\ntetrahedralization process; and secondly, handling complex or thin structures\noften leads to either excessive, storage-intensive tetrahedral meshes or\npoor-quality ones that impair deformation capabilities. To address these\nchallenges, we propose DeformRF, a method that seamlessly integrates the\nmanipulability of tetrahedral meshes with the high-quality rendering\ncapabilities of feature grid representations. To avoid ill-shaped tetrahedra\nand tetrahedralization for each object, we propose a two-stage training\nstrategy. Starting with an almost-regular tetrahedral grid, our model initially\nretains key tetrahedra surrounding the object and subsequently refines object\ndetails using finer-granularity mesh in the second stage. We also present the\nconcept of recursively subdivided tetrahedra to create higher-resolution meshes\nimplicitly. This enables multi-resolution encoding while only necessitating the\nstorage of the coarse tetrahedral mesh generated in the first training stage.\nWe conduct a comprehensive evaluation of our DeformRF on both synthetic and\nreal-captured datasets. Both quantitative and qualitative results demonstrate\nthe effectiveness of our method for novel view synthesis and deformation tasks.\nProject page: https://ustc3dv.github.io/DeformRF/\n","authors":["Zherui Qiu","Chenqu Ren","Kaiwen Song","Xiaoyi Zeng","Leyuan Yang","Juyong Zhang"],"pdf_url":"https://arxiv.org/pdf/2410.04402v1.pdf","comment":"Accepted by ACM Multimedia 2024. Project Page:\n  https://ustc3dv.github.io/DeformRF/"},{"id":"http://arxiv.org/abs/2410.00503v2","updated":"2024-10-06T07:34:52Z","published":"2024-10-01T08:34:00Z","title":"Drone Stereo Vision for Radiata Pine Branch Detection and Distance\n  Measurement: Utilizing Deep Learning and YOLO Integration","summary":"  This research focuses on the development of a drone equipped with pruning\ntools and a stereo vision camera to accurately detect and measure the spatial\npositions of tree branches. YOLO is employed for branch segmentation, while two\ndepth estimation approaches, monocular and stereo, are investigated. In\ncomparison to SGBM, deep learning techniques produce more refined and accurate\ndepth maps. In the absence of ground-truth data, a fine-tuning process using\ndeep neural networks is applied to approximate optimal depth values. This\nmethodology facilitates precise branch detection and distance measurement,\naddressing critical challenges in the automation of pruning operations. The\nresults demonstrate notable advancements in both accuracy and efficiency,\nunderscoring the potential of deep learning to drive innovation and enhance\nautomation in the agricultural sector.\n","authors":["Yida Lin","Bing Xue","Mengjie Zhang","Sam Schofield","Richard Green"],"pdf_url":"https://arxiv.org/pdf/2410.00503v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04372v1","updated":"2024-10-06T06:22:43Z","published":"2024-10-06T06:22:43Z","title":"DiffusionFake: Enhancing Generalization in Deepfake Detection via Guided\n  Stable Diffusion","summary":"  The rapid progress of Deepfake technology has made face swapping highly\nrealistic, raising concerns about the malicious use of fabricated facial\ncontent. Existing methods often struggle to generalize to unseen domains due to\nthe diverse nature of facial manipulations. In this paper, we revisit the\ngeneration process and identify a universal principle: Deepfake images\ninherently contain information from both source and target identities, while\ngenuine faces maintain a consistent identity. Building upon this insight, we\nintroduce DiffusionFake, a novel plug-and-play framework that reverses the\ngenerative process of face forgeries to enhance the generalization of detection\nmodels. DiffusionFake achieves this by injecting the features extracted by the\ndetection model into a frozen pre-trained Stable Diffusion model, compelling it\nto reconstruct the corresponding target and source images. This guided\nreconstruction process constrains the detection network to capture the source\nand target related features to facilitate the reconstruction, thereby learning\nrich and disentangled representations that are more resilient to unseen\nforgeries. Extensive experiments demonstrate that DiffusionFake significantly\nimproves cross-domain generalization of various detector architectures without\nintroducing additional parameters during inference. Our Codes are available in\nhttps://github.com/skJack/DiffusionFake.git.\n","authors":["Ke Sun","Shen Chen","Taiping Yao","Hong Liu","Xiaoshuai Sun","Shouhong Ding","Rongrong Ji"],"pdf_url":"https://arxiv.org/pdf/2410.04372v1.pdf","comment":"Accepted by NeurIPS 2024"}],"Human-Computer Interaction":[{"id":"http://arxiv.org/abs/2410.04652v1","updated":"2024-10-06T23:25:21Z","published":"2024-10-06T23:25:21Z","title":"Multimodal 3D Fusion and In-Situ Learning for Spatially Aware AI","summary":"  Seamless integration of virtual and physical worlds in augmented reality\nbenefits from the system semantically \"understanding\" the physical environment.\nAR research has long focused on the potential of context awareness,\ndemonstrating novel capabilities that leverage the semantics in the 3D\nenvironment for various object-level interactions. Meanwhile, the computer\nvision community has made leaps in neural vision-language understanding to\nenhance environment perception for autonomous tasks. In this work, we introduce\na multimodal 3D object representation that unifies both semantic and linguistic\nknowledge with the geometric representation, enabling user-guided machine\nlearning involving physical objects. We first present a fast multimodal 3D\nreconstruction pipeline that brings linguistic understanding to AR by fusing\nCLIP vision-language features into the environment and object models. We then\npropose \"in-situ\" machine learning, which, in conjunction with the multimodal\nrepresentation, enables new tools and interfaces for users to interact with\nphysical spaces and objects in a spatially and linguistically meaningful\nmanner. We demonstrate the usefulness of the proposed system through two\nreal-world AR applications on Magic Leap 2: a) spatial search in physical\nenvironments with natural language and b) an intelligent inventory system that\ntracks object changes over time. We also make our full implementation and demo\ndata available at (https://github.com/cy-xu/spatially_aware_AI) to encourage\nfurther exploration and research in spatially aware AI.\n","authors":["Chengyuan Xu","Radha Kumaran","Noah Stier","Kangyou Yu","Tobias Höllerer"],"pdf_url":"https://arxiv.org/pdf/2410.04652v1.pdf","comment":"10 pages, 6 figures, accepted to IEEE ISMAR 2024"},{"id":"http://arxiv.org/abs/2410.04614v1","updated":"2024-10-06T20:25:44Z","published":"2024-10-06T20:25:44Z","title":"Building Solidarity Amid Hostility: Experiences of Fat People in Online\n  Communities","summary":"  Online communities are important spaces for members of marginalized groups to\norganize and support one another. To better understand the experiences of fat\npeople -- a group whose marginalization often goes unrecognized -- in online\ncommunities, we conducted 12 semi-structured interviews with fat people. Our\nparticipants leveraged online communities to engage in consciousness raising\naround fat identity, learning to locate \"the problem of being fat\" not within\nthemselves or their own bodies but rather in the oppressive design of the\nsociety around them. Participants were then able to use these communities to\nmitigate everyday experiences of anti-fatness, such as navigating hostile\nhealthcare systems. However, to access these benefits, our participants had to\nnavigate myriad sociotechnical harms, ranging from harassment to discriminatory\nalgorithms. In light of these findings, we suggest that researchers and\ndesigners of online communities support selective fat visibility, consider fat\npeople in the design of content moderation systems, and investigate algorithmic\ndiscrimination toward fat people. More broadly, we call on researchers and\ndesigners to contend with the social and material realities of fat experience,\nas opposed to the prevailing paradigm of treating fat people as problems to be\nsolved in-and-of-themselves. This requires recognizing fat people as a\nmarginalized social group and actively confronting anti-fatness as it is\nembedded in the design of technology.\n","authors":["Blakeley H. Payne","Jordan Taylor","Katta Spiel","Casey Fiesler"],"pdf_url":"https://arxiv.org/pdf/2410.04614v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04596v1","updated":"2024-10-06T19:11:55Z","published":"2024-10-06T19:11:55Z","title":"Need Help? Designing Proactive AI Assistants for Programming","summary":"  While current chat-based AI assistants primarily operate reactively,\nresponding only when prompted by users, there is significant potential for\nthese systems to proactively assist in tasks without explicit invocation,\nenabling a mixed-initiative interaction. This work explores the design and\nimplementation of proactive AI assistants powered by large language models. We\nfirst outline the key design considerations for building effective proactive\nassistants. As a case study, we propose a proactive chat-based programming\nassistant that automatically provides suggestions and facilitates their\nintegration into the programmer's code. The programming context provides a\nshared workspace enabling the assistant to offer more relevant suggestions. We\nconducted a randomized experimental study examining the impact of various\ndesign elements of the proactive assistant on programmer productivity and user\nexperience. Our findings reveal significant benefits of incorporating proactive\nchat assistants into coding environments and uncover important nuances that\ninfluence their usage and effectiveness.\n","authors":["Valerie Chen","Alan Zhu","Sebastian Zhao","Hussein Mozannar","David Sontag","Ameet Talwalkar"],"pdf_url":"https://arxiv.org/pdf/2410.04596v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04592v1","updated":"2024-10-06T19:02:22Z","published":"2024-10-06T19:02:22Z","title":"CardioAI: A Multimodal AI-based System to Support Symptom Monitoring and\n  Risk Detection of Cancer Treatment-Induced Cardiotoxicity","summary":"  Despite recent advances in cancer treatments that prolong patients' lives,\ntreatment-induced cardiotoxicity remains one severe side effect. The clinical\ndecision-making of cardiotoxicity is challenging, as non-clinical symptoms can\nbe missed until life-threatening events occur at a later stage, and clinicians\nalready have a high workload centered on the treatment, not the side effects.\nOur project starts with a participatory design study with 11 clinicians to\nunderstand their practices and needs; then we build a multimodal AI system,\nCardioAI, that integrates wearables and LLM-powered voice assistants to monitor\nmultimodal non-clinical symptoms. Also, the system includes an explainable risk\nprediction module that can generate cardiotoxicity risk scores and summaries as\nexplanations to support clinicians' decision-making. We conducted a heuristic\nevaluation with four clinical experts and found that they all believe CardioAI\nintegrates well into their workflow, reduces their information overload, and\nenables them to make more informed decisions.\n","authors":["Siyi Wu","Weidan Cao","Shihan Fu","Bingsheng Yao","Ziqi Yang","Changchang Yin","Varun Mishra","Daniel Addison","Ping Zhang","Dakuo Wang"],"pdf_url":"https://arxiv.org/pdf/2410.04592v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.10250v2","updated":"2024-10-06T17:04:23Z","published":"2024-05-16T16:55:06Z","title":"IntelliExplain: Enhancing Interactive Code Generation through Natural\n  Language Explanations for Non-Professional Programmers","summary":"  Chat LLMs such as GPT-3.5-turbo and GPT-4 have shown promise in assisting\nhumans in coding, particularly by enabling them to conversationally provide\nfeedback. However, current approaches assume users have expert debugging\nskills, limiting accessibility for non-professional programmers. In this paper,\nwe first explore Chat LLMs' limitations in assisting non-professional\nprogrammers with coding. Through a formative study, we identify two key\nelements affecting their experience: the way a Chat LLM explains its generated\ncode and the structure of human-LLM interaction. We then propose\nIntelliExplain, a new conversational code generation framework with enhanced\ncode explanations and a structured interaction paradigm, which enforces both\nbetter code understanding and a more effective feedback loop. In two\nprogramming tasks (SQL and Python), IntelliExplain yields significantly higher\nsuccess rates and reduces task time compared to the vanilla Chat LLM. We also\nidentify several opportunities that remain in effectively offering a chat-based\nprogramming experience for non-professional programmers.\n","authors":["Hao Yan","Thomas D. Latoza","Ziyu Yao"],"pdf_url":"https://arxiv.org/pdf/2405.10250v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.15017v3","updated":"2024-10-06T15:42:55Z","published":"2024-07-22T06:15:59Z","title":"Knowledge Mechanisms in Large Language Models: A Survey and Perspective","summary":"  Understanding knowledge mechanisms in Large Language Models (LLMs) is crucial\nfor advancing towards trustworthy AGI. This paper reviews knowledge mechanism\nanalysis from a novel taxonomy including knowledge utilization and evolution.\nKnowledge utilization delves into the mechanism of memorization, comprehension\nand application, and creation. Knowledge evolution focuses on the dynamic\nprogression of knowledge within individual and group LLMs. Moreover, we discuss\nwhat knowledge LLMs have learned, the reasons for the fragility of parametric\nknowledge, and the potential dark knowledge (hypothesis) that will be\nchallenging to address. We hope this work can help understand knowledge in LLMs\nand provide insights for future research.\n","authors":["Mengru Wang","Yunzhi Yao","Ziwen Xu","Shuofei Qiao","Shumin Deng","Peng Wang","Xiang Chen","Jia-Chen Gu","Yong Jiang","Pengjun Xie","Fei Huang","Huajun Chen","Ningyu Zhang"],"pdf_url":"https://arxiv.org/pdf/2407.15017v3.pdf","comment":"EMNLP 2024 Findings; 39 pages (v3)"},{"id":"http://arxiv.org/abs/2410.04497v1","updated":"2024-10-06T14:29:02Z","published":"2024-10-06T14:29:02Z","title":"Generalizability analysis of deep learning predictions of human brain\n  responses to augmented and semantically novel visual stimuli","summary":"  The purpose of this work is to investigate the soundness and utility of a\nneural network-based approach as a framework for exploring the impact of image\nenhancement techniques on visual cortex activation. In a preliminary study, we\nprepare a set of state-of-the-art brain encoding models, selected among the top\n10 methods that participated in The Algonauts Project 2023 Challenge [16]. We\nanalyze their ability to make valid predictions about the effects of various\nimage enhancement techniques on neural responses. Given the impossibility of\nacquiring the actual data due to the high costs associated with brain imaging\nprocedures, our investigation builds up on a series of experiments.\nSpecifically, we analyze the ability of brain encoders to estimate the cerebral\nreaction to various augmentations by evaluating the response to augmentations\ntargeting objects (i.e., faces and words) with known impact on specific areas.\nMoreover, we study the predicted activation in response to objects unseen\nduring training, exploring the impact of semantically out-of-distribution\nstimuli. We provide relevant evidence for the generalization ability of the\nmodels forming the proposed framework, which appears to be promising for the\nidentification of the optimal visual augmentation filter for a given task,\nmodel-driven design strategies as well as for AR and VR applications.\n","authors":["Valentyn Piskovskyi","Riccardo Chimisso","Sabrina Patania","Tom Foulsham","Giuseppe Vizzari","Dimitri Ognibene"],"pdf_url":"https://arxiv.org/pdf/2410.04497v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04366v1","updated":"2024-10-06T05:54:49Z","published":"2024-10-06T05:54:49Z","title":"RespDiff: An End-to-End Multi-scale RNN Diffusion Model for Respiratory\n  Waveform Estimation from PPG Signals","summary":"  Respiratory rate (RR) is a critical health indicator often monitored under\ninconvenient scenarios, limiting its practicality for continuous monitoring.\nPhotoplethysmography (PPG) sensors, increasingly integrated into wearable\ndevices, offer a chance to continuously estimate RR in a portable manner. In\nthis paper, we propose RespDiff, an end-to-end multi-scale RNN diffusion model\nfor respiratory waveform estimation from PPG signals. RespDiff does not require\nhand-crafted features or the exclusion of low-quality signal segments, making\nit suitable for real-world scenarios. The model employs multi-scale encoders,\nto extract features at different resolutions, and a bidirectional RNN to\nprocess PPG signals and extract respiratory waveform. Additionally, a spectral\nloss term is introduced to optimize the model further. Experiments conducted on\nthe BIDMC dataset demonstrate that RespDiff outperforms notable previous works,\nachieving a mean absolute error (MAE) of 1.18 bpm for RR estimation while\nothers range from 1.66 to 2.15 bpm, showing its potential for robust and\naccurate respiratory monitoring in real-world applications.\n","authors":["Yuyang Miao","Zehua Chen","Chang Li","Danilo Mandic"],"pdf_url":"https://arxiv.org/pdf/2410.04366v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04365v1","updated":"2024-10-06T05:52:20Z","published":"2024-10-06T05:52:20Z","title":"Generative Co-Learners: Enhancing Cognitive and Social Presence of\n  Students in Asynchronous Learning with Generative AI","summary":"  Cognitive presence and social presence are crucial for a comprehensive\nlearning experience. Despite the flexibility of asynchronous learning\nenvironments to accommodate individual schedules, the inherent constraints of\nasynchronous environments make augmenting cognitive and social presence\nparticularly challenging. Students often face challenges such as a lack of\ntimely feedback and support, a lack of non-verbal cues in communication, and a\nsense of isolation. To address this challenge, this paper introduces Generative\nCo-Learners, a system designed to leverage generative AI-powered agents,\nsimulating co-learners supporting multimodal interactions, to improve cognitive\nand social presence in asynchronous learning environments. We conducted a study\ninvolving 12 student participants who used our system to engage with online\nprogramming tutorials to assess the system's effectiveness. The results show\nthat by implementing features to support textual and visual communication and\nsimulate an interactive learning environment with generative agents, our system\nenhances the cognitive and social presence in the asynchronous learning\nenvironment. These results suggest the potential to use generative AI to\nsupport students learning at scale and transform asynchronous learning into a\nmore inclusive, engaging, and efficacious educational approach.\n","authors":["Tianjia Wang","Tong Wu","Huayi Liu","Chris Brown","Yan Chen"],"pdf_url":"https://arxiv.org/pdf/2410.04365v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.15003v2","updated":"2024-10-06T04:06:44Z","published":"2024-06-21T09:30:59Z","title":"Real-Time Hand Gesture Recognition: Integrating Skeleton-Based Data\n  Fusion and Multi-Stream CNN","summary":"  Hand Gesture Recognition (HGR) enables intuitive human-computer interactions\nin various real-world contexts. However, existing frameworks often struggle to\nmeet the real-time requirements essential for practical HGR applications. This\nstudy introduces a robust, skeleton-based framework for dynamic HGR that\nsimplifies the recognition of dynamic hand gestures into a static image\nclassification task, effectively reducing both hardware and computational\ndemands. Our framework utilizes a data-level fusion technique to encode 3D\nskeleton data from dynamic gestures into static RGB spatiotemporal images. It\nincorporates a specialized end-to-end Ensemble Tuner (e2eET) Multi-Stream CNN\narchitecture that optimizes the semantic connections between data\nrepresentations while minimizing computational needs. Tested across five\nbenchmark datasets (SHREC'17, DHG-14/28, FPHA, LMDHG, and CNR), the framework\nshowed competitive performance with the state-of-the-art. Its capability to\nsupport real-time HGR applications was also demonstrated through deployment on\nstandard consumer PC hardware, showcasing low latency and minimal resource\nusage in real-world settings. The successful deployment of this framework\nunderscores its potential to enhance real-time applications in fields such as\nvirtual/augmented reality, ambient intelligence, and assistive technologies,\nproviding a scalable and efficient solution for dynamic gesture recognition.\n","authors":["Oluwaleke Yusuf","Maki Habib","Mohamed Moustafa"],"pdf_url":"https://arxiv.org/pdf/2406.15003v2.pdf","comment":"14 pages. 7 figures. Code available at\n  https://github.com/Outsiders17711/e2eET-Skeleton-Based-HGR-Using-Data-Level-Fusion"},{"id":"http://arxiv.org/abs/2310.01774v2","updated":"2024-10-06T01:17:01Z","published":"2023-10-03T03:52:04Z","title":"A mobile digital device proficiency performance test for cognitive\n  clinical research","summary":"  Mobile device proficiency is increasingly important for everyday living,\nincluding to deliver healthcare services. Human-device interactions represent a\npotential in cognitive neurology and aging research. Although traditional\npen-and-paper evaluations serve as valuable tools within public health\nstrategies for population-scale cognitive assessments, digital devices could\namplify cognitive assessment. However, even person-centered studies often fail\nto incorporate measures of mobile device proficiency and research with digital\nmobile technology frequently neglects these evaluations. Besides that,\ncognitive screening, a fundamental part of brain health evaluation and a widely\naccepted strategy to identify high-risk individuals vulnerable to cognitive\nimpairment and dementia, has research using digital devices for older adults in\nneed for standardization. To address this shortfall, the DigiTAU collaborative\nand interdisciplinary project is creating refined methodological parameters for\nthe investigation of digital biomarkers. With careful consideration of\ncognitive design elements, here we describe the open-source and\nperformance-based Mobile Device Abilities Test (MDAT), a simple, low-cost, and\nreproductible open-sourced test framework. This result was achieved with a\ncross-sectional study population sample of 101 low and middle-income subjects\naged 20 to 79 years old. Partial least squares structural equation modeling\n(PLS-SEM) was used to assess the measurement of the construct. It was possible\nto achieve a reliable method with internal consistency, good content validity\nrelated to digital competences, and that does not have much interference with\nauto-perceived global functional disability, health self-perception, and motor\ndexterity. Limitations for this method are discussed and paths to improve and\nestablish better standards are highlighted.\n","authors":["Alan Cronemberger Andrade","Diógenes de Souza Bido","Ana Carolina Bottura de Barros","Walter Richard Boot","Paulo Henrique Ferreira Bertolucci"],"pdf_url":"https://arxiv.org/pdf/2310.01774v2.pdf","comment":"3 figures, 5 tables"},{"id":"http://arxiv.org/abs/2410.04318v1","updated":"2024-10-06T00:32:03Z","published":"2024-10-06T00:32:03Z","title":"Urban Computing for Climate and Environmental Justice: Early\n  Perspectives From Two Research Initiatives","summary":"  The impacts of climate change are intensifying existing vulnerabilities and\ndisparities within urban communities around the globe, as extreme weather\nevents, including floods and heatwaves, are becoming more frequent and severe,\ndisproportionately affecting low-income and underrepresented groups. Tackling\nthese increasing challenges requires novel approaches that integrate expertise\nacross multiple domains, including computer science, engineering, climate\nscience, and public health. Urban computing can play a pivotal role in these\nefforts by integrating data from multiple sources to support decision-making\nand provide actionable insights into weather patterns, infrastructure\nweaknesses, and population vulnerabilities. However, the capacity to leverage\ntechnological advancements varies significantly between the Global South and\nGlobal North. In this paper, we present two multiyear, multidisciplinary\nprojects situated in Chicago, USA and Niter\\'oi, Brazil, highlighting the\nopportunities and limitations of urban computing in these diverse contexts.\nReflecting on our experiences, we then discuss the essential requirements, as\nwell as existing gaps, for visual analytics tools that facilitate the\nunderstanding and mitigation of climate-related risks in urban environments.\n","authors":["Carolina Veiga","Ashish Sharma","Daniel de Oliveira","Marcos Lage","Fabio Miranda"],"pdf_url":"https://arxiv.org/pdf/2410.04318v1.pdf","comment":"Accepted at the Viz4Climate + Sustainability: IEEE VIS 2024 Workshop\n  on Visualization for Climate Action and Sustainability\n  (https://svs.gsfc.nasa.gov/events/2024/Viz4ClimateAndSustainability/)"}],"Programming Languages":[{"id":"http://arxiv.org/abs/2410.04581v1","updated":"2024-10-06T18:35:51Z","published":"2024-10-06T18:35:51Z","title":"Efficient Linearizability Monitoring for Sets, Stacks, Queues and\n  Priority Queues","summary":"  In this paper, we consider the problem of automatically monitoring\nlinearizability. Here, one observes an execution of a concurrent program that\ninteracts with a concurrent object and determines if the execution witnesses\nthe violation of linearizability with respect to the sequential specification\nof the underlying data structure of the concurrent object. This problem has\nbeen extensively studied in the past for read-write registers, and both tight\nupper and lower bounds have been proposed in this case. While this problem has\nalso been studied for the case of other prominent data structures such as\nstacks and queues, we find that these results are either not extensive or in\nsome cases incorrect. In this paper, we study the problem under the restriction\nwhere values inserted in the data types are distinct (in the execution\nobserved). We then show that under such a restriction, the linearizability\nproblem is solvable in polynomial time for these data types. Beyond theoretical\nsoundness and completeness, the algorithms proposed are empirically proven to\noutperform all state-of-the-art linearizability monitors.\n","authors":["Lee Zheng Han","Umang Mathur"],"pdf_url":"https://arxiv.org/pdf/2410.04581v1.pdf","comment":null}],"Networking and Internet Architecture":[{"id":"http://arxiv.org/abs/2410.00012v2","updated":"2024-10-06T23:45:06Z","published":"2024-09-14T00:40:30Z","title":"Research on Enhancing C-V2X Communication via Danger-Aware Vehicular\n  Networking","summary":"  This paper presents a protocol that optimizes message dissemination in C-V2X\ntechnology, crucial for advancing intelligent transportation systems (ITS)\naimed at enhancing road safety. As vehicle density and velocity rise, the\nvolume of data requiring communication significantly increases. By considering\nthe risk levels that vehicles encounter and using inter-vehicle proximity as a\nkey indicator of potential hazards, the proposed protocol prioritizes\ncommunication, allowing vehicles facing higher risks to transmit their messages\nfirst. Our results show that this prioritization effectively reduces the number\nof concurrent transmissions, leading to improved performance metrics such as\npacket delivery ratio, throughput, latency, and lower probabilities of channel\ncongestion and collision.\n","authors":["Lanre Sadeeq","Qasim Ajao"],"pdf_url":"https://arxiv.org/pdf/2410.00012v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04427v1","updated":"2024-10-06T09:45:24Z","published":"2024-10-06T09:45:24Z","title":"Consistent and Repeatable Testing of mMIMO O-RU across labs: A\n  Japan-Singapore Experience","summary":"  Open Radio Access Networks (RAN) aim to bring a paradigm shift to\ntelecommunications industry, by enabling an open, intelligent, virtualized, and\nmulti-vendor interoperable RAN ecosystem. At the center of this movement, O-RAN\nALLIANCE defines the O-RAN architecture and standards, so that companies around\nthe globe can use these specifications to create innovative and interoperable\nsolutions. To accelerate the adoption of O-RAN products, rigorous testing of\nO-RAN Radio Unit (O-RU) and other O-RAN products plays a key role. O-RAN\nALLIANCE has approved around 20 Open Testing and Integration Centres (OTICs)\nglobally. OTICs serve as vendor-neutral platforms for providing the testing and\nintegration services, with the vision that an O-RAN product certified in any\nOTIC is accepted in other parts of the world. To demonstrate the viability of\nsuch a certified-once-and-use-everywhere approach, one theme in the O-RAN\nGlobal PlugFest Spring 2024 is to demonstrate consistent and repeatable testing\nfor the open fronthaul interface across multiple labs. Towards this, Japan OTIC\nand Asia Pacific OTIC in Singapore have teamed up together with an O-RU vendor\nand Keysight Technology. Our international team successfully completed all test\ncases defined by O-RAN ALLIANCE for O-RU conformance testing. In this paper, we\nshare our journey in achieving this outcome, focusing on the challenges we have\novercome and the lessons we have learned through this process.\n","authors":["Thanh-Tam Nguyen","Mao V. Ngo","Binbin Chen","Mitsuhiro Kuchitsu","Serena Wai","Seitaro Kawai","Kenya Suzuki","Eng Wei Koo","Tony Quek"],"pdf_url":"https://arxiv.org/pdf/2410.04427v1.pdf","comment":"Published version at RitiRAN Workshop - co-located with IEEE VTC Fall\n  2024"},{"id":"http://arxiv.org/abs/2410.04416v1","updated":"2024-10-06T09:12:43Z","published":"2024-10-06T09:12:43Z","title":"Consistent and Repeatable Testing of O-RAN Distributed Unit (O-DU)\n  across Continents","summary":"  Open Radio Access Networks (O-RAN) are expected to revolutionize the\ntelecommunications industry with benefits like cost reduction, vendor\ndiversity, and improved network performance through AI optimization. Supporting\nthe O-RAN ALLIANCE's mission to achieve more intelligent, open, virtualized and\nfully interoperable mobile networks, O-RAN Open Testing and Integration Centers\n(OTICs) play a key role in accelerating the adoption of O-RAN specifications\nbased on rigorous testing and validation. One theme in the recent O-RAN Global\nPlugFest Spring 2024 focused on demonstrating consistent and repeatable Open\nFronthaul testing in multiple labs. To respond to this topic, in this paper, we\npresent a detailed analysis of the testing methodologies and results for O-RAN\nDistributed Unit (O-DU) in O-RAN across two OTICs. We identify key differences\nin testing setups, share challenges encountered, and propose best practices for\nachieving repeatable and consistent testing results. Our findings highlight the\nimpact of different deployment technologies and testing environments on\nperformance and conformance testing outcomes, providing valuable insights for\nfuture O-RAN implementations.\n","authors":["Tuan V. Ngo","Mao V. Ngo","Binbin Chen","Gabriele Gemmi","Eduardo Baena","Michele Polese","Tommaso Melodia","William Chien","Tony Quek"],"pdf_url":"https://arxiv.org/pdf/2410.04416v1.pdf","comment":"Published version at RitiRAN Workshop - co-located with IEEE VTC Fall\n  2024"}],"Distributed, Parallel, and Cluster Computing":[{"id":"http://arxiv.org/abs/2410.04453v1","updated":"2024-10-06T11:38:30Z","published":"2024-10-06T11:38:30Z","title":"CONFINE: Preserving Data Secrecy in Decentralized Process Mining","summary":"  In the contemporary business landscape, collaboration across multiple\norganizations offers a multitude of opportunities, including reduced\noperational costs, enhanced performance, and accelerated technological\nadvancement. The application of process mining techniques in an\ninter-organizational setting, exploiting the recorded process event data,\nenables the coordination of joint effort and allows for a deeper understanding\nof the business. Nevertheless, considerable concerns pertaining to data\nconfidentiality emerge, as organizations frequently demonstrate a reluctance to\nexpose sensitive data demanded for process mining, due to concerns related to\nprivacy and security risks. The presence of conflicting interests among the\nparties involved can impede the practice of open data sharing. To address these\nchallenges, we propose our approach and toolset named CONFINE, which we\ndeveloped with the intent of enabling process mining on process event data from\nmultiple providers while preserving the confidentiality and integrity of the\noriginal records. To ensure that the presented interaction protocol steps are\nsecure and that the processed information is hidden from both involved and\nexternal actors, our approach is based on a decentralized architecture and\nconsists of trusted applications running in Trusted Execution Environments\n(TEE). In this demo paper, we provide an overview of the core components and\nfunctionalities as well as the specific details of its application.\n","authors":["Valerio Goretti","Davide Basile","Luca Barbaro","Claudio Di Ciccio"],"pdf_url":"https://arxiv.org/pdf/2410.04453v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.02307v2","updated":"2024-10-06T10:55:33Z","published":"2024-10-03T08:42:18Z","title":"Model-guided Fuzzing of Distributed Systems","summary":"  We present a coverage-guided testing algorithm for distributed systems\nimplementations. Our main innovation is the use of an abstract formal model of\nthe system that is used to define coverage. Such abstract models are frequently\ndeveloped in early phases of protocol design and verification but are\ninfrequently used at testing time. We show that guiding random test generation\nusing model coverage can be effective in covering interesting points in the\nimplementation state space. We have implemented a fuzzer for distributed system\nimplementations and abstract models written in TLA+. Our algorithm shows better\ncoverage over purely random exploration as well as random exploration guided by\ndifferent notions of scheduler coverage and mutation. In particular, we show\nconsistently higher coverage and detect bugs faster on implementations of\ndistributed consensus protocols such as those in Etcd-raft and RedisRaft.\nMoreover, we discovered 13 previously unknown bugs in their implementations,\nfour of which could only be detected by model-guided fuzzing.\n","authors":["Ege Berkay Gulcan","Burcu Kulahcioglu Ozkan","Rupak Majumdar","Srinidhi Nagendra"],"pdf_url":"https://arxiv.org/pdf/2410.02307v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04363v1","updated":"2024-10-06T05:43:00Z","published":"2024-10-06T05:43:00Z","title":"Multi Armed Bandit Algorithms Based Virtual Machine Allocation Policy\n  for Security in Multi-Tenant Distributed Systems","summary":"  This work proposes a secure and dynamic VM allocation strategy for\nmulti-tenant distributed systems using the Thompson sampling approach. The\nmethod proves more effective and secure compared to epsilon-greedy and upper\nconfidence bound methods, showing lower regret levels.,Initially, VM allocation\nwas static, but the unpredictable nature of attacks necessitated a dynamic\napproach. Historical VM data was analyzed to understand attack responses, with\nrewards granted for unsuccessful attacks and reduced for successful ones,\ninfluencing regret levels.,The paper introduces a Multi Arm Bandit-based VM\nallocation policy, utilizing a Weighted Average Ensemble Learning algorithm\ntrained on known attacks and non-attacks. This ensemble approach outperforms\ntraditional algorithms like Logistic Regression, SVM, K Nearest Neighbors, and\nXGBoost.,For suspicious activity detection, a Stacked Anomaly Detector\nalgorithm is proposed, trained on known non-attacks. This method surpasses\nexisting techniques such as Isolation Forest and PCA-based approaches.,Overall,\nthis paper presents an advanced solution for VM allocation policies, enhancing\ncloud-based system security through a combination of dynamic allocation,\nensemble learning, and anomaly detection techniques.\n","authors":["Pravin Patil","Geetanjali Kale","Tanmay Karmarkar","Ruturaj Ghatage"],"pdf_url":"https://arxiv.org/pdf/2410.04363v1.pdf","comment":null}]},"2024-10-05T00:00:00Z":{"Software Engineering":[{"id":"http://arxiv.org/abs/2410.04304v1","updated":"2024-10-05T23:03:56Z","published":"2024-10-05T23:03:56Z","title":"Robotics Meets Software Engineering: A First Look at the Robotics\n  Discussions on Stackoverflow","summary":"  Robots can greatly enhance human capabilities, yet their development presents\na range of challenges. This collaborative study, conducted by a team of\nsoftware engineering and robotics researchers, seeks to identify the challenges\nencountered by robot developers by analyzing questions posted on StackOverflow.\nWe created a filtered dataset of 500 robotics-related questions and examined\ntheir characteristics, comparing them with randomly selected questions from the\nplatform. Our findings indicate that the small size of the robotics community\nlimits the visibility of these questions, resulting in fewer responses. While\nthe number of robotics questions has been steadily increasing, they remain less\npopular than the average question and answer on StackOverflow. This underscores\nthe importance of research that focuses on the challenges faced by robotics\npractitioners.\n  Consequently, we conducted a thematic analysis of the 500 robotics questions\nto uncover common inquiry patterns. We identified 11 major themes, with\nquestions about robot movement being the most frequent. Our analysis of yearly\ntrends revealed that certain themes, such as Specifications, were prominent\nfrom 2009 to 2014 but have since diminished in relevance. In contrast, themes\nlike Moving, Actuator, and Remote have consistently dominated discussions over\nthe years. These findings suggest that challenges in robotics may vary over\ntime.\n  Notably, the majority of robotics questions are framed as How questions,\nrather than Why or What questions, revealing the lack of enough resources for\nthe practitioners. These insights can help guide researchers and educators in\ndeveloping effective and timely educational materials for robotics\npractitioners.\n","authors":["Hisham Kidwai","Danika Passler Bates","Sujana Islam Suhi","James Young","Shaiful Chowdhury"],"pdf_url":"https://arxiv.org/pdf/2410.04304v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04249v1","updated":"2024-10-05T18:11:14Z","published":"2024-10-05T18:11:14Z","title":"DiffSpec: Differential Testing with LLMs using Natural Language\n  Specifications and Code Artifacts","summary":"  Differential testing can be an effective way to find bugs in software systems\nwith multiple implementations that conform to the same specification, like\ncompilers, network protocol parsers, and language runtimes. Specifications for\nsuch systems are often standardized in natural language documents, like\nInstruction Set Architecture (ISA) specifications, Wasm specifications or IETF\nRFC's. Large Language Models (LLMs) have demonstrated potential in both\ngenerating tests and handling large volumes of natural language text, making\nthem well-suited for utilizing artifacts like specification documents, bug\nreports, and code implementations. In this work, we leverage natural language\nand code artifacts to guide LLMs to generate targeted, meaningful tests that\nhighlight meaningful behavioral differences between implementations, including\nthose corresponding to bugs. We introduce DiffSpec, a framework for generating\ndifferential tests with LLMs using prompt chaining. We demonstrate the efficacy\nof DiffSpec on two different systems, namely, eBPF runtimes and Wasm\nvalidators. Using DiffSpec, we generated 359 differentiating tests, uncovering\nat least four distinct and confirmed bugs in eBPF, including a kernel memory\nleak, inconsistent behavior in jump instructions, and undefined behavior when\nusing the stack pointer. We also found 279 differentiating tests in Wasm\nvalidators, that point to at least 2 confirmed and fixed bugs.\n","authors":["Nikitha Rao","Elizabeth Gilbert","Tahina Ramananandro","Nikhil Swamy","Claire Le Goues","Sarah Fakhoury"],"pdf_url":"https://arxiv.org/pdf/2410.04249v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.12736v2","updated":"2024-10-05T09:07:44Z","published":"2024-04-19T09:29:53Z","title":"Large Language Model Supply Chain: A Research Agenda","summary":"  The rapid advancement of Large Language Models (LLMs) has revolutionized\nartificial intelligence, introducing unprecedented capabilities in natural\nlanguage processing and multimodal content generation. However, the increasing\ncomplexity and scale of these models have given rise to a multifaceted supply\nchain that presents unique challenges across infrastructure, foundation models,\nand downstream applications. This paper provides a comprehensive research\nagenda of the LLM supply chain, offering a structured approach to identify\ncritical challenges and opportunities through the dual lenses of Software\nEngineering (SE) and Security & Privacy (S&P). We begin by establishing a clear\ndefinition of the LLM supply chain, encompassing its components and\ndependencies. We then analyze each layer of the supply chain, presenting a\nvision for robust and secure LLM development, reviewing the current state of\npractices and technologies, and identifying key challenges and research\nopportunities. This work aims to bridge the existing research gap in\nsystematically understanding the multifaceted issues within the LLM supply\nchain, offering valuable insights to guide future efforts in this rapidly\nevolving domain.\n","authors":["Shenao Wang","Yanjie Zhao","Xinyi Hou","Haoyu Wang"],"pdf_url":"https://arxiv.org/pdf/2404.12736v2.pdf","comment":"Accepted by 2030 Software Engineering Workshop, co-located with\n  FSE'24. This is an extended and revised version of our paper submitted to the\n  TOSEM Special Issue: 2030 Software Engineering Roadmap"},{"id":"http://arxiv.org/abs/2410.01215v2","updated":"2024-10-05T04:37:06Z","published":"2024-10-02T03:57:21Z","title":"From Code to Correctness: Closing the Last Mile of Code Generation with\n  Hierarchical Debugging","summary":"  While large language models have made significant strides in code generation,\nthe pass rate of the generated code is bottlenecked on subtle errors, often\nrequiring human intervention to pass tests, especially for complex problems.\nExisting LLM-based debugging systems treat generated programs as monolithic\nunits, failing to address bugs at multiple levels of granularity, from\nlow-level syntax errors to high-level algorithmic flaws. In this paper, we\nintroduce Multi-Granularity Debugger (MGDebugger), a hierarchical code debugger\nby isolating, identifying, and resolving bugs at various levels of granularity.\nMGDebugger decomposes problematic code into a hierarchical tree structure of\nsubfunctions, with each level representing a particular granularity of error.\nDuring debugging, it analyzes each subfunction and iteratively resolves bugs in\na bottom-up manner. To effectively test each subfunction, we propose an\nLLM-simulated Python executor, which traces code execution and tracks important\nvariable states to pinpoint errors accurately. Extensive experiments\ndemonstrate that MGDebugger outperforms existing debugging systems, achieving\nan 18.9% improvement in accuracy over seed generations in HumanEval and a 97.6%\nrepair success rate in HumanEvalFix. Furthermore, MGDebugger effectively fixes\nbugs across different categories and difficulty levels, demonstrating its\nrobustness and effectiveness.\n","authors":["Yuling Shi","Songsong Wang","Chengcheng Wan","Xiaodong Gu"],"pdf_url":"https://arxiv.org/pdf/2410.01215v2.pdf","comment":"Code and data available at https://github.com/YerbaPage/MGDebugger"},{"id":"http://arxiv.org/abs/2403.00894v2","updated":"2024-10-05T00:34:44Z","published":"2024-03-01T14:43:06Z","title":"Comparing large language models and human programmers for generating\n  programming code","summary":"  We systematically evaluated the performance of seven large language models in\ngenerating programming code using various prompt strategies, programming\nlanguages, and task difficulties. GPT-4 substantially outperforms other large\nlanguage models, including Gemini Ultra and Claude 2. The coding performance of\nGPT-4 varies considerably with different prompt strategies. In most LeetCode\nand GeeksforGeeks coding contests evaluated in this study, GPT-4 employing the\noptimal prompt strategy outperforms 85 percent of human participants.\nAdditionally, GPT-4 demonstrates strong capabilities in translating code\nbetween different programming languages and in learning from past errors. The\ncomputational efficiency of the code generated by GPT-4 is comparable to that\nof human programmers. These results suggest that GPT-4 has the potential to\nserve as a reliable assistant in programming code generation and software\ndevelopment.\n","authors":["Wenpin Hou","Zhicheng Ji"],"pdf_url":"https://arxiv.org/pdf/2403.00894v2.pdf","comment":null}],"Human-Computer Interaction":[{"id":"http://arxiv.org/abs/2410.04286v1","updated":"2024-10-05T21:15:09Z","published":"2024-10-05T21:15:09Z","title":"Open Science Practices by Early Career HCI Researchers: Perceptions,\n  Challenges, and Benefits","summary":"  Many fields of science, including Human-Computer Interaction (HCI), have\nheightened introspection in the wake of concerns around reproducibility and\nreplicability of published findings. Notably, in recent years the HCI community\nhas worked to implement policy changes and mainstream open science practices.\nOur work investigates early-career HCI researchers' perceptions of open science\nand engagement with best practices through 18 semi-structured interviews. Our\nfindings highlight key barriers to the widespread adoption of data and\nmaterials sharing, and preregistration, namely: lack of clear incentives;\ncultural resistance; limited training; time constraints; concerns about\nintellectual property; and data privacy issues. We observe that small changes\nat major conferences like CHI could meaningfully impact community norms. We\noffer recommendations to address these barriers and to promote transparency and\nopenness in HCI.\n","authors":["Tatiana Chakravorti","Sanjana Gautam","Priya Silverstein","Sarah M. Rajtmajer"],"pdf_url":"https://arxiv.org/pdf/2410.04286v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04280v1","updated":"2024-10-05T20:30:55Z","published":"2024-10-05T20:30:55Z","title":"The Visualization JUDGE : Can Multimodal Foundation Models Guide\n  Visualization Design Through Visual Perception?","summary":"  Foundation models for vision and language are the basis of AI applications\nacross numerous sectors of society. The success of these models stems from\ntheir ability to mimic human capabilities, namely visual perception in vision\nmodels, and analytical reasoning in large language models. As visual perception\nand analysis are fundamental to data visualization, in this position paper we\nask: how can we harness foundation models to advance progress in visualization\ndesign? Specifically, how can multimodal foundation models (MFMs) guide\nvisualization design through visual perception? We approach these questions by\ninvestigating the effectiveness of MFMs for perceiving visualization, and\nformalizing the overall visualization design and optimization space.\nSpecifically, we think that MFMs can best be viewed as judges, equipped with\nthe ability to criticize visualizations, and provide us with actions on how to\nimprove a visualization. We provide a deeper characterization for text-to-image\ngenerative models, and multi-modal large language models, organized by what\nthese models provide as output, and how to utilize the output for guiding\ndesign decisions. We hope that our perspective can inspire researchers in\nvisualization on how to approach MFMs for visualization design.\n","authors":["Matthew Berger","Shusen Liu"],"pdf_url":"https://arxiv.org/pdf/2410.04280v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04253v1","updated":"2024-10-05T18:21:04Z","published":"2024-10-05T18:21:04Z","title":"Contrastive Explanations That Anticipate Human Misconceptions Can\n  Improve Human Decision-Making Skills","summary":"  People's decision-making abilities often fail to improve or may even erode\nwhen they rely on AI for decision-support, even when the AI provides\ninformative explanations. We argue this is partly because people intuitively\nseek contrastive explanations, which clarify the difference between the AI's\ndecision and their own reasoning, while most AI systems offer \"unilateral\"\nexplanations that justify the AI's decision but do not account for users'\nthinking. To align human-AI knowledge on decision tasks, we introduce a\nframework for generating human-centered contrastive explanations that explain\nthe difference between AI's choice and a predicted, likely human choice about\nthe same task. Results from a large-scale experiment (N = 628) demonstrate that\ncontrastive explanations significantly enhance users' independent\ndecision-making skills compared to unilateral explanations, without sacrificing\ndecision accuracy. Amid rising deskilling concerns, our research demonstrates\nthat incorporating human reasoning into AI design can foster human skill\ndevelopment.\n","authors":["Zana Buçinca","Siddharth Swaroop","Amanda E. Paluch","Finale Doshi-Velez","Krzysztof Z. Gajos"],"pdf_url":"https://arxiv.org/pdf/2410.04253v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.06499v2","updated":"2024-10-05T17:59:12Z","published":"2024-06-10T17:34:24Z","title":"NarrativeBridge: Enhancing Video Captioning with Causal-Temporal\n  Narrative","summary":"  Existing video captioning benchmarks and models lack coherent representations\nof causal-temporal narrative, which is sequences of events linked through cause\nand effect, unfolding over time and driven by characters or agents. This lack\nof narrative restricts models' ability to generate text descriptions that\ncapture the causal and temporal dynamics inherent in video content. To address\nthis gap, we propose NarrativeBridge, an approach comprising of: (1) a novel\nCausal-Temporal Narrative (CTN) captions benchmark generated using a large\nlanguage model and few-shot prompting, explicitly encoding cause-effect\ntemporal relationships in video descriptions, evaluated automatically to ensure\ncaption quality and relevance and validated through human evaluation; and (2) a\ndedicated Cause-Effect Network (CEN) architecture with separate encoders for\ncapturing cause and effect dynamics independently, enabling effective learning\nand generation of captions with causal-temporal narrative. Extensive\nexperiments demonstrate that CEN significantly outperforms state-of-the-art\nmodels, including fine-tuned vision-language models, and is more accurate in\narticulating the causal and temporal aspects of video content than the second\nbest model (GIT): 17.88 and 17.44 CIDEr on the MSVD and MSR-VTT datasets,\nrespectively. Cross-dataset evaluations further showcase CEN's strong\ngeneralization capabilities. The proposed framework understands and generates\nnuanced text descriptions with intricate causal-temporal narrative structures\npresent in videos, addressing a critical limitation in video captioning.\n","authors":["Asmar Nadeem","Faegheh Sardari","Robert Dawes","Syed Sameed Husain","Adrian Hilton","Armin Mustafa"],"pdf_url":"https://arxiv.org/pdf/2406.06499v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04232v1","updated":"2024-10-05T17:12:19Z","published":"2024-10-05T17:12:19Z","title":"Be There, Be Together, Be Streamed! AR Scenic Live-Streaming for an\n  Interactive and Collective Experience","summary":"  Scenic Live-Streaming (SLS), capturing real-world scenic sites from fixed\ncameras without streamers, combines scene immersion and the social and\nreal-time characteristics of live-streaming into a unique experience. However,\nexisting SLS affords limited audience interactions to engage them in a\ncollective experience compared to many other live-streaming genres. It is also\ndifficult for SLS to recreate important but intangible constituents of\nin-person trip experiences, such as cultural activities. To offer a more\ninteractive, engaging, and meaningful experience, we propose ARSLS (Augmented\nReality Scenic Live-Streaming). Culturally grounded AR objects with awareness\nof the live-streamed environment can be overlaid over camera views to provide\nadditional interactive features while maintaining consistency with the\nlive-streamed scene. To explore the design space of this new medium, we\ndeveloped an ARSLS prototype for a famous landscape in China. A preliminary\nstudy (N=15) provided initial insights for ARSLS design.\n","authors":["Zeyu Huang","Zuyu Xu","Yuanhao Zhang","Chengzhong Liu","Yanwei Zhao","Chuhan Shi","Jason Chen Zhao","Xiaojuan Ma"],"pdf_url":"https://arxiv.org/pdf/2410.04232v1.pdf","comment":"4 pages, 2 figures, to appear in the adjunct proceedings of ISMAR\n  2024 and the ISMAR 2024 conference"},{"id":"http://arxiv.org/abs/2309.09828v2","updated":"2024-10-05T16:56:57Z","published":"2023-09-18T14:49:49Z","title":"Twenty-Four Years of Empirical Research on Trust in AI: A Bibliometric\n  Review of Trends, Overlooked Issues, and Future Directions","summary":"  Trust is widely regarded as a critical component to building artificial\nintelligence (AI) systems that people will use and safely rely upon. As\nresearch in this area continues to evolve, it becomes imperative that the\nresearch community synchronizes its empirical efforts and aligns on the path\ntoward effective knowledge creation. To lay the groundwork toward achieving\nthis objective, we performed a comprehensive bibliometric analysis,\nsupplemented with a qualitative content analysis of over two decades of\nempirical research measuring trust in AI, comprising 1'156 core articles and\n36'306 cited articles across multiple disciplines. Our analysis reveals several\n\"elephants in the room\" pertaining to missing perspectives in global\ndiscussions on trust in AI, a lack of contextualized theoretical models and a\nreliance on exploratory methodologies. We highlight strategies for the\nempirical research community that are aimed at fostering an in-depth\nunderstanding of trust in AI.\n","authors":["Michaela Benk","Sophie Kerstan","Florian v. Wangenheim","Andrea Ferrario"],"pdf_url":"https://arxiv.org/pdf/2309.09828v2.pdf","comment":"Revised version"},{"id":"http://arxiv.org/abs/2401.05376v2","updated":"2024-10-05T16:41:35Z","published":"2023-12-15T20:21:57Z","title":"Eating Speed Measurement Using Wrist-Worn IMU Sensors Towards\n  Free-Living Environments","summary":"  Eating speed is an important indicator that has been widely investigated in\nnutritional studies. The relationship between eating speed and several\nintake-related problems such as obesity, diabetes, and oral health has received\nincreased attention from researchers. However, existing studies mainly use\nself-reported questionnaires to obtain participants' eating speed, where they\nchoose options from slow, medium, and fast. Such a non-quantitative method is\nhighly subjective and coarse at the individual level. This study integrates two\nclassical tasks in automated food intake monitoring domain: bite detection and\neating episode detection, to advance eating speed measurement in\nnear-free-living environments automatically and objectively. Specifically, a\ntemporal convolutional network combined with a multi-head attention module\n(TCN-MHA) is developed to detect bites (including eating and drinking gestures)\nfrom IMU data. The predicted bite sequences are then clustered into eating\nepisodes. Eating speed is calculated by using the time taken to finish the\neating episode to divide the number of bites. To validate the proposed approach\non eating speed measurement, a 7-fold cross validation is applied to the\nself-collected fine-annotated full-day-I (FD-I) dataset, and a holdout\nexperiment is conducted on the full-day-II (FD-II) dataset. The two datasets\nare collected from 61 participants with a total duration of 513 h, which are\npublicly available. Experimental results show that the proposed approach\nachieves a mean absolute percentage error (MAPE) of 0.110 and 0.146 in the FD-I\nand FD-II datasets, respectively, showcasing the feasibility of automated\neating speed measurement in near-free-living environments.\n","authors":["Chunzhuo Wang","T. Sunil Kumar","Walter De Raedt","Guido Camps","Hans Hallez","Bart Vanrumste"],"pdf_url":"https://arxiv.org/pdf/2401.05376v2.pdf","comment":"The manuscript has been accepted in IEEE Journal of Biomedical and\n  Health Informatics"},{"id":"http://arxiv.org/abs/2410.04214v1","updated":"2024-10-05T16:13:10Z","published":"2024-10-05T16:13:10Z","title":"Boosting Visual Fidelity in Driving Simulations through Diffusion Models","summary":"  Diffusion models have made substantial progress in facilitating image\ngeneration and editing. As the technology matures, we see its potential in the\ncontext of driving simulations to enhance the simulated experience. In this\npaper, we explore this potential through the introduction of a novel system\ndesigned to boost visual fidelity. Our system, DRIVE (Diffusion-based Realism\nImprovement for Virtual Environments), leverages a diffusion model pipeline to\ngive a simulated environment a photorealistic view, with the flexibility to be\nadapted for other applications. We conducted a preliminary user study to assess\nthe system's effectiveness in rendering realistic visuals and supporting\nparticipants in performing driving tasks. Our work not only lays the groundwork\nfor future research on the integration of diffusion models in driving\nsimulations but also provides practical guidelines and best practices for their\napplication in this context.\n","authors":["Fanjun Bu","Hiroshi Yasuda"],"pdf_url":"https://arxiv.org/pdf/2410.04214v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04177v1","updated":"2024-10-05T14:48:05Z","published":"2024-10-05T14:48:05Z","title":"The Impact of Surface Co-location and Eye-tracking on Mixed Reality\n  Typing","summary":"  Accuracy and speed are pivotal when typing. We hypothesized that the lack of\ntactile feedback on midair mixed reality keyboards may adversely impact\nperformance. Our first experiment assessed the potential to provide tactile\nfeedback to users typing in mixed reality by co-locating the virtual keyboard\non a table or a wall. The keyboard was deterministic (without auto-correct),\nrelied only on the headset's egocentric cameras for sensing, and included\nsymbol keys. Users preferred and had the highest entry rate of 12\nwords-per-minute using a midair keyboard. Error rates were similar in all\nconditions. Based on user feedback, our second experiment explored ten-finger\ntyping. We used a novel eye-tracking technique to mitigate accidental key\npresses. The technique halved the number of times backspace was pressed and was\npreferred by users. However, participants were faster using only their index\nfingers without eye-tracking at 11 words-per-minute.\n","authors":["Cecilia Schmitz","Joshua Reynolds","Scott Kuhl","Keith Vertanen"],"pdf_url":"https://arxiv.org/pdf/2410.04177v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04078v1","updated":"2024-10-05T08:15:45Z","published":"2024-10-05T08:15:45Z","title":"TeachTune: Reviewing Pedagogical Agents Against Diverse Student Profiles\n  with Simulated Students","summary":"  Large language models (LLMs) can empower educators to build pedagogical\nconversational agents (PCAs) customized for their students. As students have\ndifferent prior knowledge and motivation levels, educators must evaluate the\nadaptivity of their PCAs to diverse students. Existing chatbot evaluation\nmethods (e.g., direct chat and benchmarks) are either manually intensive for\nmultiple iterations or limited to testing only single-turn interactions. We\npresent TeachTune, where educators can create simulated students and review\nPCAs by observing automated chats between PCAs and simulated students. Our\ntechnical pipeline instructs an LLM-based student to simulate prescribed\nknowledge levels and characteristics, helping educators explore diverse\nconversation patterns. Our pipeline could produce simulated students whose\nbehaviors correlate highly to their input knowledge and motivation levels\nwithin 5% and 10% accuracy gaps. Thirty science teachers designed PCAs in a\nbetween-subjects study, and using TeachTune resulted in a lower task load and\nhigher student profile coverage over a baseline.\n","authors":["Hyoungwook Jin","Minju Yoo","Jeongeon Park","Yokyung Lee","Xu Wang","Juho Kim"],"pdf_url":"https://arxiv.org/pdf/2410.04078v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2308.05822v2","updated":"2024-10-05T06:13:08Z","published":"2023-08-10T18:43:44Z","title":"Encode-Store-Retrieve: Augmenting Human Memory through Language-Encoded\n  Egocentric Perception","summary":"  We depend on our own memory to encode, store, and retrieve our experiences.\nHowever, memory lapses can occur. One promising avenue for achieving memory\naugmentation is through the use of augmented reality head-mounted displays to\ncapture and preserve egocentric videos, a practice commonly referred to as\nlifelogging. However, a significant challenge arises from the sheer volume of\nvideo data generated through lifelogging, as the current technology lacks the\ncapability to encode and store such large amounts of data efficiently. Further,\nretrieving specific information from extensive video archives requires\nsubstantial computational power, further complicating the task of quickly\naccessing desired content. To address these challenges, we propose a memory\naugmentation agent that involves leveraging natural language encoding for video\ndata and storing them in a vector database. This approach harnesses the power\nof large vision language models to perform the language encoding process.\nAdditionally, we propose using large language models to facilitate natural\nlanguage querying. Our agent underwent extensive evaluation using the QA-Ego4D\ndataset and achieved state-of-the-art results with a BLEU score of 8.3,\noutperforming conventional machine learning models that scored between 3.4 and\n5.8. Additionally, we conducted a user study in which participants interacted\nwith the human memory augmentation agent through episodic memory and open-ended\nquestions. The results of this study show that the agent results in\nsignificantly better recall performance on episodic memory tasks compared to\nhuman participants. The results also highlight the agent's practical\napplicability and user acceptance.\n","authors":["Junxiao Shen","John Dudley","Per Ola Kristensson"],"pdf_url":"https://arxiv.org/pdf/2308.05822v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13656v2","updated":"2024-10-05T05:48:53Z","published":"2023-11-22T19:14:25Z","title":"Panda or not Panda? Understanding Adversarial Attacks with Interactive\n  Visualization","summary":"  Adversarial machine learning (AML) studies attacks that can fool machine\nlearning algorithms into generating incorrect outcomes as well as the defenses\nagainst worst-case attacks to strengthen model robustness. Specifically for\nimage classification, it is challenging to understand adversarial attacks due\nto their use of subtle perturbations that are not human-interpretable, as well\nas the variability of attack impacts influenced by diverse methodologies,\ninstance differences, and model architectures. Through a design study with AML\nlearners and teachers, we introduce AdvEx, a multi-level interactive\nvisualization system that comprehensively presents the properties and impacts\nof evasion attacks on different image classifiers for novice AML learners. We\nquantitatively and qualitatively assessed AdvEx in a two-part evaluation\nincluding user studies and expert interviews. Our results show that AdvEx is\nnot only highly effective as a visualization tool for understanding AML\nmechanisms, but also provides an engaging and enjoyable learning experience,\nthus demonstrating its overall benefits for AML learners.\n","authors":["Yuzhe You","Jarvis Tse","Jian Zhao"],"pdf_url":"https://arxiv.org/pdf/2311.13656v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04035v1","updated":"2024-10-05T05:08:36Z","published":"2024-10-05T05:08:36Z","title":"Gamifying XAI: Enhancing AI Explainability for Non-technical Users\n  through LLM-Powered Narrative Gamifications","summary":"  Artificial intelligence (AI) has become tightly integrated into modern\ntechnology, yet existing exploratory visualizations for explainable AI (XAI)\nare primarily designed for users with technical expertise. This leaves everyday\nusers, who also regularly interact with AI systems, with limited resources to\nexplore or understand AI technologies they use. We propose a novel framework\nthat enables non-technical users to collect insights by conversing directly\nwith visualization elements via LLM-powered narrative gamifications. We\nimplemented a prototype that utilizes such gamification to facilitate\nnon-technical users' exploration of AI embedding projections. We conducted a\ncomparative study with 10 participants to assess our prototype quantitatively\nand qualitatively. Our study results indicate that although our prototype\neffectively enhances non-technical users' AI/XAI knowledge, and users believe\nthey learn more through the gamification feature, it remains inconclusive\nwhether the gamification itself leads to further improvements in understanding.\nIn addition, opinions among participants regarding the framework's engagement\nare mixed: some believe it enhances their exploration of the visualizations,\nwhile others feel it disrupts their workflow.\n","authors":["Yuzhe You","Jian Zhao"],"pdf_url":"https://arxiv.org/pdf/2410.04035v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04025v1","updated":"2024-10-05T04:06:07Z","published":"2024-10-05T04:06:07Z","title":"IdeaSynth: Iterative Research Idea Development Through Evolving and\n  Composing Idea Facets with Literature-Grounded Feedback","summary":"  Research ideation involves broad exploring and deep refining ideas. Both\nrequire deep engagement with literature. Existing tools focus primarily on idea\nbroad generation, yet offer little support for iterative specification,\nrefinement, and evaluation needed to further develop initial ideas. To bridge\nthis gap, we introduce IdeaSynth, a research idea development system that uses\nLLMs to provide literature-grounded feedback for articulating research\nproblems, solutions, evaluations, and contributions. IdeaSynth represents these\nidea facets as nodes on a canvas, and allow researchers to iteratively refine\nthem by creating and exploring variations and composing them. Our lab study\n(N=20) showed that participants, while using IdeaSynth, explored more\nalternative ideas and expanded initial ideas with more details compared to a\nstrong LLM-based baseline. Our deployment study (N=7) demonstrated that\nparticipants effectively used IdeaSynth for real-world research projects at\nvarious ideation stages from developing initial ideas to revising framings of\nmature manuscripts, highlighting the possibilities to adopt IdeaSynth in\nresearcher's workflows.\n","authors":["Kevin Pu","K. J. Kevin Feng","Tovi Grossman","Tom Hope","Bhavana Dalvi Mishra","Matt Latzke","Jonathan Bragg","Joseph Chee Chang","Pao Siangliulue"],"pdf_url":"https://arxiv.org/pdf/2410.04025v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04016v1","updated":"2024-10-05T03:19:42Z","published":"2024-10-05T03:19:42Z","title":"Development of a Mouse for Individuals Without Upper Limbs Using Arduino\n  Technology","summary":"  This project focuses on the design and construction of a prototype mouse\nbased on the Arduino platform, intended for individuals without upper limbs to\nuse computers more effectively. The prototype comprises a microcontroller\nresponsible for processing signals from the MPU-6050 sensor, used as a\nreference for cursor position, and foot-operated buttons for right and\nleft-click functions. Its design enables cursor control through head movements,\nproviding users with an easy and intuitive way to interact with the computer's\ngraphical interface. Feasibility testing was conducted through experimental\ntrials, resulting in ideal accuracy and precision. These trials indicate that\nthe device is viable for use in individuals without upper limbs.\n","authors":["Alfonso Gunsha","Luis Chuquimarca","Pedro Pardo","David Herrera"],"pdf_url":"https://arxiv.org/pdf/2410.04016v1.pdf","comment":"6 pages, 9 figures"},{"id":"http://arxiv.org/abs/2410.04005v1","updated":"2024-10-05T02:39:48Z","published":"2024-10-05T02:39:48Z","title":"Enhancing the Travel Experience for People with Visual Impairments\n  through Multimodal Interaction: NaviGPT, A Real-Time AI-Driven Mobile\n  Navigation System","summary":"  Assistive technologies for people with visual impairments (PVI) have made\nsignificant advancements, particularly with the integration of artificial\nintelligence (AI) and real-time sensor technologies. However, current solutions\noften require PVI to switch between multiple apps and tools for tasks like\nimage recognition, navigation, and obstacle detection, which can hinder a\nseamless and efficient user experience. In this paper, we present NaviGPT, a\nhigh-fidelity prototype that integrates LiDAR-based obstacle detection,\nvibration feedback, and large language model (LLM) responses to provide a\ncomprehensive and real-time navigation aid for PVI. Unlike existing\napplications such as Be My AI and Seeing AI, NaviGPT combines image recognition\nand contextual navigation guidance into a single system, offering continuous\nfeedback on the user's surroundings without the need for app-switching.\nMeanwhile, NaviGPT compensates for the response delays of LLM by using location\nand sensor data, aiming to provide practical and efficient navigation support\nfor PVI in dynamic environments.\n","authors":["He Zhang","Nicholas J. Falletta","Jingyi Xie","Rui Yu","Sooyeon Lee","Syed Masum Billah","John M. Carroll"],"pdf_url":"https://arxiv.org/pdf/2410.04005v1.pdf","comment":"7 pages, 3 figures, this work has been accepted by the 2025 ACM\n  International Conference on Supporting Group Work (GROUP '25)"},{"id":"http://arxiv.org/abs/2402.16973v2","updated":"2024-10-05T01:21:14Z","published":"2024-02-26T19:16:04Z","title":"Successfully Guiding Humans with Imperfect Instructions by Highlighting\n  Potential Errors and Suggesting Corrections","summary":"  Language models will inevitably err in situations with which they are\nunfamiliar. However, by effectively communicating uncertainties, they can still\nguide humans toward making sound decisions in those contexts. We demonstrate\nthis idea by developing HEAR, a system that can successfully guide humans in\nsimulated residential environments despite generating potentially inaccurate\ninstructions. Diverging from systems that provide users with only the\ninstructions they generate, HEAR warns users of potential errors in its\ninstructions and suggests corrections. This rich uncertainty information\neffectively prevents misguidance and reduces the search space for users.\nEvaluation with 80 users shows that HEAR achieves a 13% increase in success\nrate and a 29% reduction in final location error distance compared to only\npresenting instructions to users. Interestingly, we find that offering users\npossibilities to explore, HEAR motivates them to make more attempts at the\ntask, ultimately leading to a higher success rate. To our best knowledge, this\nwork is the first to show the practical benefits of uncertainty communication\nin a long-horizon sequential decision-making problem.\n","authors":["Lingjun Zhao","Khanh Nguyen","Hal Daumé III"],"pdf_url":"https://arxiv.org/pdf/2402.16973v2.pdf","comment":"EMNLP 2024"},{"id":"http://arxiv.org/abs/2410.03993v1","updated":"2024-10-05T01:18:26Z","published":"2024-10-05T01:18:26Z","title":"TR-LLM: Integrating Trajectory Data for Scene-Aware LLM-Based Human\n  Action Prediction","summary":"  Accurate prediction of human behavior is crucial for AI systems to\neffectively support real-world applications, such as autonomous robots\nanticipating and assisting with human tasks. Real-world scenarios frequently\npresent challenges such as occlusions and incomplete scene observations, which\ncan compromise predictive accuracy. Thus, traditional video-based methods often\nstruggle due to limited temporal and spatial perspectives. Large Language\nModels (LLMs) offer a promising alternative. Having been trained on a large\ntext corpus describing human behaviors, LLMs likely encode plausible sequences\nof human actions in a home environment. However, LLMs, trained primarily on\ntext data, lack inherent spatial awareness and real-time environmental\nperception. They struggle with understanding physical constraints and spatial\ngeometry. Therefore, to be effective in a real-world spatial scenario, we\npropose a multimodal prediction framework that enhances LLM-based action\nprediction by integrating physical constraints derived from human trajectories.\nOur experiments demonstrate that combining LLM predictions with trajectory data\nsignificantly improves overall prediction performance. This enhancement is\nparticularly notable in situations where the LLM receives limited scene\ninformation, highlighting the complementary nature of linguistic knowledge and\nphysical constraints in understanding and anticipating human behavior.\n","authors":["Kojiro Takeyama","Yimeng Liu","Misha Sra"],"pdf_url":"https://arxiv.org/pdf/2410.03993v1.pdf","comment":null}],"Programming Languages":[{"id":"http://arxiv.org/abs/2410.01215v2","updated":"2024-10-05T04:37:06Z","published":"2024-10-02T03:57:21Z","title":"From Code to Correctness: Closing the Last Mile of Code Generation with\n  Hierarchical Debugging","summary":"  While large language models have made significant strides in code generation,\nthe pass rate of the generated code is bottlenecked on subtle errors, often\nrequiring human intervention to pass tests, especially for complex problems.\nExisting LLM-based debugging systems treat generated programs as monolithic\nunits, failing to address bugs at multiple levels of granularity, from\nlow-level syntax errors to high-level algorithmic flaws. In this paper, we\nintroduce Multi-Granularity Debugger (MGDebugger), a hierarchical code debugger\nby isolating, identifying, and resolving bugs at various levels of granularity.\nMGDebugger decomposes problematic code into a hierarchical tree structure of\nsubfunctions, with each level representing a particular granularity of error.\nDuring debugging, it analyzes each subfunction and iteratively resolves bugs in\na bottom-up manner. To effectively test each subfunction, we propose an\nLLM-simulated Python executor, which traces code execution and tracks important\nvariable states to pinpoint errors accurately. Extensive experiments\ndemonstrate that MGDebugger outperforms existing debugging systems, achieving\nan 18.9% improvement in accuracy over seed generations in HumanEval and a 97.6%\nrepair success rate in HumanEvalFix. Furthermore, MGDebugger effectively fixes\nbugs across different categories and difficulty levels, demonstrating its\nrobustness and effectiveness.\n","authors":["Yuling Shi","Songsong Wang","Chengcheng Wan","Xiaodong Gu"],"pdf_url":"https://arxiv.org/pdf/2410.01215v2.pdf","comment":"Code and data available at https://github.com/YerbaPage/MGDebugger"},{"id":"http://arxiv.org/abs/2403.00894v2","updated":"2024-10-05T00:34:44Z","published":"2024-03-01T14:43:06Z","title":"Comparing large language models and human programmers for generating\n  programming code","summary":"  We systematically evaluated the performance of seven large language models in\ngenerating programming code using various prompt strategies, programming\nlanguages, and task difficulties. GPT-4 substantially outperforms other large\nlanguage models, including Gemini Ultra and Claude 2. The coding performance of\nGPT-4 varies considerably with different prompt strategies. In most LeetCode\nand GeeksforGeeks coding contests evaluated in this study, GPT-4 employing the\noptimal prompt strategy outperforms 85 percent of human participants.\nAdditionally, GPT-4 demonstrates strong capabilities in translating code\nbetween different programming languages and in learning from past errors. The\ncomputational efficiency of the code generated by GPT-4 is comparable to that\nof human programmers. These results suggest that GPT-4 has the potential to\nserve as a reliable assistant in programming code generation and software\ndevelopment.\n","authors":["Wenpin Hou","Zhicheng Ji"],"pdf_url":"https://arxiv.org/pdf/2403.00894v2.pdf","comment":null}],"Networking and Internet Architecture":[{"id":"http://arxiv.org/abs/2409.09602v2","updated":"2024-10-05T23:54:13Z","published":"2024-09-15T03:42:47Z","title":"Security Testbed for Preempting Attacks against Supercomputing\n  Infrastructure","summary":"  Securing HPC has a unique threat model. Untrusted, malicious code exploiting\nthe concentrated computing power may exert an outsized impact on the shared,\nopen-networked environment in HPC, unlike well-isolated VM tenants in public\nclouds. Therefore, preempting attacks targeting supercomputing systems before\ndamage remains the top security priority. The main challenge is that noisy\nattack attempts and unreliable alerts often mask \\emph{real attacks}, causing\npermanent damages such as system integrity violations and data breaches. This\npaper describes a security testbed embedded in live traffic of a supercomputer\nat the National Center for Supercomputing Applications (NCSA). The objective is\nto demonstrate attack \\textit{preemption}, i.e., stopping system compromise and\ndata breaches at petascale supercomputers. Deployment of our testbed at NCSA\nenables the following key contributions:\n  1) Insights from characterizing unique \\textit{attack patterns} found in real\nsecurity logs of more than 200 security incidents curated in the past two\ndecades at NCSA.\n  2) Deployment of an attack visualization tool to illustrate the challenges of\nidentifying real attacks in HPC environments and to support security operators\nin interactive attack analyses.\n  3) Demonstrate the utility of the testbed by running novel models, such as\nFactor-Graph-based models, to preempt a real-world ransomware family.\n","authors":["Phuong Cao","Zbigniew Kalbarczyk","Ravishankar Iyer"],"pdf_url":"https://arxiv.org/pdf/2409.09602v2.pdf","comment":"Accepted to the Third Annual Workshop on Cyber Security in\n  High-Performance Computing (S-HPC 24)"},{"id":"http://arxiv.org/abs/2410.04168v1","updated":"2024-10-05T14:14:08Z","published":"2024-10-05T14:14:08Z","title":"Robust Task-Oriented Communication Framework for Real-Time Collaborative\n  Vision Perception","summary":"  Cooperative perception enhances sensing in multi-robot and vehicular networks\nby aggregating information from multiple agents, improving perception accuracy\nand range. However, mobility and non-rigid sensor mounts introduce extrinsic\ncalibration errors, necessitating online calibration, which is complicated by\nlimited overlap in sensing regions. Maintaining fresh information is crucial\nfor timely and accurate sensing. To address calibration errors and ensure both\nperception accuracy and transmission timeliness, we propose a Robust\nTask-Oriented Communication framework (R-TOCOM) that optimizes calibration and\nfeature transmission in both deployment and streaming phases. First, we\nformulate an Age of Perceived Targets (AoPT) minimization problem to capture\ninformation freshness. Then, in the deployment phase, we introduce a\nchannel-aware self-calibration technique based on re-identification (Re-ID).\nThis technique adaptively compresses key-point features according to channel\ncapacities, effectively addressing calibration issues via spatial and temporal\ncross-camera correlations. In the streaming phase, we tackle the trade-off\nbetween bandwidth and inference accuracy by integrating an Information\nBottleneck (IB)-based encoding method that adjusts video compression rates\nbased on task relevance, thereby reducing communication overhead and latency.\nTo mitigate performance degradation from packet loss, we introduce a priority\nnetwork that filters corrupted features. Extensive studies demonstrate our\nframework outperforms five baselines, improving multiple object detection\naccuracy (MODA) by 25.49% and reducing communication costs by 51.36% under\nsevere channel condition.\n","authors":["Zhengru Fang","Jingjing Wang","Yanan Ma","Yihang Tao","Yiqin Deng","Xianhao Chen","Yuguang Fang"],"pdf_url":"https://arxiv.org/pdf/2410.04168v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.20778v2","updated":"2024-10-05T12:00:03Z","published":"2024-07-30T12:26:46Z","title":"Bayesian Optimization Framework for Channel Simulation-Based Base\n  Station Placement and Transmission Power Design","summary":"  This study proposes an adaptive experimental design framework for a\nchannel-simulation-based base station (BS) design that supports the joint\noptimization of transmission power and placement. We consider a system in which\nmultiple transmitters provide wireless services over a shared frequency band.\nOur objective is to maximize the average throughput within an area of interest.\nSystem operators can design the system configurations prior to deployment by\niterating them through channel simulations and updating the parameters.\nHowever, accurate channel simulations are computationally expensive; therefore,\nit is preferable to configure the system using a limited number of simulation\niterations. We develop a solver for the problem based on Bayesian optimization\n(BO), a black-box optimization method. The numerical results demonstrate that\nour proposed framework can achieve 18-22% higher throughput performance than\nconventional placement and power optimization strategies.\n","authors":["Koya Sato","Katsuya Suto"],"pdf_url":"https://arxiv.org/pdf/2407.20778v2.pdf","comment":"5 pages, 7 figures, 1 table. This work has been published in IEEE\n  Networking Letters under CC BY-NC-ND 4.0 (DOI: 10.1109/LNET.2024.3469175)"},{"id":"http://arxiv.org/abs/2410.04066v1","updated":"2024-10-05T07:31:05Z","published":"2024-10-05T07:31:05Z","title":"Exploring 5G Network Performance: Comparison of Inner and Outer City\n  Areas in Phetchaburi Province","summary":"  The advancement of 5G technology has transformed various aspects of life,\nincluding tourism, by enabling people worldwide to communicate and travel with\nease. Traveling to different places and countries is now seamless, removing\nlanguage barriers and facilitating easy access to information on culture,\naccommodation, and tourist attractions. Additionally, access to applications\nthat facilitate quicker language translation further enhances the travel\nexperience. Phetchaburi Province holds significant importance as a global\ntourist destination. UNESCO has recognized Phetchaburi as a member of the\nUNESCO Creative Cities Network (UCCN), comprising one of 49 cities worldwide\nacknowledged for their creative city initiatives. Phetchaburi Province stands\nas the 5th city in Thailand to receive this designation. This research\ninvestigated 5G performance in Phetchaburi Province, both the inner and outer\ncity, focusing on download and upload speeds. The results indicate that there\nis widespread 5G coverage throughout Phetchaburi Province, including urban and\nrural areas, especially for the 5G network with a good performance provided by\none of the mobile network operators. In addition, the statistical analysis\nreveals differences in 5G performances between the inner city and the outer\ncity of Phetchaburi Province, particularly for download speeds (p-value <\n0.001).\n","authors":["Phisit Pornpongtechavanich","Therdpong Daengsi"],"pdf_url":"https://arxiv.org/pdf/2410.04066v1.pdf","comment":null}],"Distributed, Parallel, and Cluster Computing":[{"id":"http://arxiv.org/abs/2405.11658v3","updated":"2024-10-05T21:25:58Z","published":"2024-05-19T20:10:55Z","title":"A Starting Point for Dynamic Community Detection with Leiden Algorithm","summary":"  Real-world graphs often evolve over time, making community or cluster\ndetection a crucial task. In this technical report, we extend three dynamic\napproaches - Naive-dynamic (ND), Delta-screening (DS), and Dynamic Frontier\n(DF) - to our multicore implementation of the Leiden algorithm, known for its\nhigh-quality community detection. Our experiments, conducted on a server with a\n64-core AMD EPYC-7742 processor, show that ND, DS, and DF Leiden achieve\naverage speedups of 1.37x, 1.47x, and 1.98x on large graphs with random batch\nupdates, compared to the Static Leiden algorithm - while scaling at a rate of\n1.6x for every doubling of threads. To our knowledge, this is the first attempt\nto apply dynamic approaches to the Leiden algorithm. We hope these early\nresults pave the way for further development of dynamic approaches for evolving\ngraphs.\n","authors":["Subhajit Sahu"],"pdf_url":"https://arxiv.org/pdf/2405.11658v3.pdf","comment":"17 pages, 10 figures, 2 tables. arXiv admin note: substantial text\n  overlap with arXiv:2404.19634"},{"id":"http://arxiv.org/abs/2410.04285v1","updated":"2024-10-05T21:11:32Z","published":"2024-10-05T21:11:32Z","title":"MindFlayer: Efficient Asynchronous Parallel SGD in the Presence of\n  Heterogeneous and Random Worker Compute Times","summary":"  We study the problem of minimizing the expectation of smooth nonconvex\nfunctions with the help of several parallel workers whose role is to compute\nstochastic gradients. In particular, we focus on the challenging situation\nwhere the workers' compute times are arbitrarily heterogeneous and random. In\nthe simpler regime characterized by arbitrarily heterogeneous but deterministic\ncompute times, Tyurin and Richt\\'arik (NeurIPS 2023) recently designed the\nfirst theoretically optimal asynchronous SGD method, called Rennala SGD, in\nterms of a novel complexity notion called time complexity. The starting point\nof our work is the observation that Rennala SGD can have arbitrarily bad\nperformance in the presence of random compute times -- a setting it was not\ndesigned to handle. To advance our understanding of stochastic optimization in\nthis challenging regime, we propose a new asynchronous SGD method, for which we\ncoin the name MindFlayer SGD. Our theory and empirical results demonstrate the\nsuperiority of MindFlayer SGD over existing baselines, including Rennala SGD,\nin cases when the noise is heavy tailed.\n","authors":["Artavazd Maranjyan","Omar Shaikh Omar","Peter Richtárik"],"pdf_url":"https://arxiv.org/pdf/2410.04285v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04268v1","updated":"2024-10-05T19:13:59Z","published":"2024-10-05T19:13:59Z","title":"Slim-ABC: An Optimized Atomic Broadcast Protocol","summary":"  The Byzantine Agreement (BA) problem is a fundamental challenge in\ndistributed systems, focusing on achieving reaching an agreement among parties,\nsome of which may behave maliciously. With the rise of cryptocurrencies, there\nhas been significant interest in developing atomic broadcast protocols, which\nfacilitate agreement on a subset of parties' requests. However, these protocols\noften come with high communication complexity ($O(ln^2 + \\lambda n^3 \\log n)$,\nwhere $l$ is the bit length of the input, $n$ is the number of parties, and\n$\\lambda$ represents the security parameter bit length). This can lead to\ninefficiency, especially when the requests across parties exhibit little\nvariation, resulting in unnecessary resource consumption. In this paper, we\nintroduce Slim-ABC, a novel atomic broadcast protocol that eliminates the\n$O(ln^2 + \\lambda n^3 \\log n)$ term associated with traditional atomic\nbroadcast protocols. While Slim-ABC reduces the number of accepted requests, it\nsignificantly mitigates resource wastage, making it more efficient. The\nprotocol leverages the asynchronous common subset and provable-broadcast\nmechanisms to achieve a communication complexity of $O(ln^2 + \\lambda n^2)$.\nDespite the trade-off in accepted requests, Slim-ABC maintains robust security\nby allowing only a fraction ($f+1$) of parties to broadcast requests. We\npresent an extensive efficiency analysis of Slim-ABC, evaluating its\nperformance across key metrics such as message complexity, communication\ncomplexity, and time complexity. Additionally, we provide a rigorous security\nanalysis, demonstrating that Slim-ABC satisfies the \\textit{agreement},\n\\textit{validity}, and \\textit{totality} properties of the asynchronous common\nsubset protocol.\n","authors":["Nasit S Sony","Xianzhong Ding","Mukesh Singhal"],"pdf_url":"https://arxiv.org/pdf/2410.04268v1.pdf","comment":"21 pages"},{"id":"http://arxiv.org/abs/2410.04255v1","updated":"2024-10-05T18:22:40Z","published":"2024-10-05T18:22:40Z","title":"Advancements in Robotics Process Automation: A Novel Model with Enhanced\n  Empirical Validation and Theoretical Insights","summary":"  Robotics Process Automation is revolutionizing business operations by\nsignificantly enhancing efficiency, productivity, and operational excellence\nacross various industries. This manuscript delivers a comprehensive review of\nrecent advancements in RPA technologies and proposes a novel model designed to\nelevate RPA capabilities.\n","authors":["Gokul Pandy","Vivekananda Jayaram","Manjunatha Sughaturu Krishnappa","Balaji Shesharao Ingole","Koushik Kumar Ganeeb","Shenson Joseph"],"pdf_url":"https://arxiv.org/pdf/2410.04255v1.pdf","comment":"9 pages. European Journal of Computer Science and Information\n  Technology 2024"},{"id":"http://arxiv.org/abs/2410.04252v1","updated":"2024-10-05T18:20:37Z","published":"2024-10-05T18:20:37Z","title":"Lazy Qubit Reordering for Accelerating Parallel State-Vector-based\n  Quantum Circuit Simulation","summary":"  This paper proposes two quantum operation scheduling methods for accelerating\nparallel state-vector-based quantum circuit simulation using multiple graphics\nprocessing units (GPUs). The proposed methods reduce all-to-all communication\ncaused by qubit reordering (QR), which can dominate the overhead of parallel\nsimulation. Our approach eliminates redundant QRs by introducing intentional\ndelays in QR communications such that multiple QRs can be aggregated into a\nsingle QR. The delays are carefully introduced based on the principles of\ntime-space tiling, or a cache optimization technique for classical computers,\nwhich we use to arrange the execution order of quantum operations. Moreover, we\npresent an extended scheduling method for the hierarchical interconnection of\nGPU cluster systems to avoid slow inter-node communication. We develop these\nmethods tailored for two primary procedures in variational quantum eigensolver\n(VQE) simulation: quantum state update (QSU) and expectation value computation\n(EVC). Experimental validation on 32-GPU executions demonstrates acceleration\nin QSU and EVC -- up to 54$\\times$ and 606$\\times$, respectively -- compared to\nexisting methods. Moreover, our extended scheduling method further reduced\ncommunication time by up to 15\\% in a two-layered interconnected cluster\nsystem. Our approach is useful for any quantum circuit simulations, including\nQSU and/or EVC.\n","authors":["Yusuke Teranishi","Shoma Hiraoka","Wataru Mizukami","Masao Okita","Fumihiko Ino"],"pdf_url":"https://arxiv.org/pdf/2410.04252v1.pdf","comment":"24 pages, 18 figures"},{"id":"http://arxiv.org/abs/2410.04111v1","updated":"2024-10-05T10:24:52Z","published":"2024-10-05T10:24:52Z","title":"180 Days After EIP-4844: Will Blob Sharing Solve Dilemma for Small\n  Rollups?","summary":"  The introduction of blobs through EIP-4844 has significantly reduced the Data\nAvailability (DA) costs for rollups on Ethereum. However, due to the fixed size\nof blobs at 128 KB, rollups with low data throughput face a dilemma: they\neither use blobs inefficiently or decrease the frequency of DA submissions.\nBlob sharing, where multiple rollups share a single blob, has been proposed as\na solution to this problem. This paper examines the effectiveness of blob\nsharing based on real-world data collected approximately six months after the\nimplementation of EIP-4844. By simulating cost changes using a simple blob\nsharing format, we demonstrate that blob sharing can substantially improve the\ncosts and DA service quality for small rollups, effectively resolving their\ndilemma. Notably, we observed cost reductions in USD exceeding 90% for most of\nthe rollups when they cooperate, attributable to the smoothing effect of the\nblob base fee achieved through blob sharing.\n","authors":["Suhyeon Lee"],"pdf_url":"https://arxiv.org/pdf/2410.04111v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04050v1","updated":"2024-10-05T06:09:59Z","published":"2024-10-05T06:09:59Z","title":"Dispersion on Time-Varying Graphs","summary":"  The dispersion involves the coordination of $k \\leq n$ agents on a graph of\nsize $n$ to reach a configuration where at each node at most one agent can be\npresent. It is a well-studied problem. Also, this problem is studied on dynamic\ngraphs with $n$ nodes where at each discrete time step the graph is a connected\nsub-graph of the complete graph $K_n$. An optimal algorithm is provided\nassuming global communication and 1-hop visibility of the agents. How this\nproblem pans out on Time-Varying Graphs (TVG) is an open question in the\nliterature. In this work we study this problem on TVG where at each discrete\ntime step the graph is a connected sub-graph of an underlying graph $G$ (known\nas a footprint) consisting of $n$ nodes. We have the following results even if\nonly one edge from $G$ is missing in the connected sub-graph at any time step\nand all agents start from a rooted initial configuration. Even with unlimited\nmemory at each agent and 1-hop visibility, it is impossible to solve dispersion\nfor $n$ co-located agents on a TVG in the local communication model.\nFurthermore, even with unlimited memory at each agent but without 1-hop\nvisibility, it is impossible to achieve dispersion for $n$ co-located agents in\nthe global communication model. From the positive side, the existing algorithm\nfor dispersion on dynamic graphs with the assumptions of global communication\nand 1-hop visibility works on TVGs as well. This fact and the impossibility\nresults push us to come up with a modified definition of the dispersion problem\non TVGs, as one needs to start with more than $n$ agents if the objective is to\ndrop the strong assumptions of global communication and 1-hop visibility. Then,\nwe provide an algorithm to solve the modified dispersion problem on TVG\nstarting with $n+1$ agents with $O(\\log n)$ memory per agent while dropping\nboth the assumptions of global communication and 1-hop visibility.\n","authors":["Ashish Saxena","Tanvir Kaur","Kaushik Mondal"],"pdf_url":"https://arxiv.org/pdf/2410.04050v1.pdf","comment":null}]},"2024-10-04T00:00:00Z":{"Software Engineering":[{"id":"http://arxiv.org/abs/2410.03981v1","updated":"2024-10-04T23:45:17Z","published":"2024-10-04T23:45:17Z","title":"Survey on Code Generation for Low resource and Domain Specific\n  Programming Languages","summary":"  Large Language Models (LLMs) have shown impressive capabilities in code\ngeneration for popular programming languages. However, their performance on\nLow-Resource Programming Languages (LRPLs) and Domain-Specific Languages (DSLs)\nremains a significant challenge, affecting millions of developers-3.5 million\nusers in Rust alone-who cannot fully utilize LLM capabilities. LRPLs and DSLs\nencounter unique obstacles, including data scarcity and, for DSLs, specialized\nsyntax that is poorly represented in general-purpose datasets.\n  Addressing these challenges is crucial, as LRPLs and DSLs enhance development\nefficiency in specialized domains, such as finance and science. While several\nsurveys discuss LLMs in software engineering, none focus specifically on the\nchallenges and opportunities associated with LRPLs and DSLs. Our survey fills\nthis gap by systematically reviewing the current state, methodologies, and\nchallenges in leveraging LLMs for code generation in these languages. We\nfiltered 111 papers from over 27,000 published studies between 2020 and 2024 to\nevaluate the capabilities and limitations of LLMs in LRPLs and DSLs. We report\nthe LLMs used, benchmarks, and metrics for evaluation, strategies for enhancing\nperformance, and methods for dataset collection and curation.\n  We identified four main evaluation techniques and several metrics for\nassessing code generation in LRPLs and DSLs. Our analysis categorizes\nimprovement methods into six groups and summarizes novel architectures proposed\nby researchers. Despite various techniques and metrics, a standard approach and\nbenchmark dataset for evaluating code generation in LRPLs and DSLs are lacking.\nThis survey serves as a resource for researchers and practitioners at the\nintersection of LLMs, software engineering, and specialized programming\nlanguages, laying the groundwork for future advancements in code generation for\nLRPLs and DSLs.\n","authors":["Sathvik Joel","Jie JW Wu","Fatemeh H. Fard"],"pdf_url":"https://arxiv.org/pdf/2410.03981v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.03859v1","updated":"2024-10-04T18:48:58Z","published":"2024-10-04T18:48:58Z","title":"SWE-bench Multimodal: Do AI Systems Generalize to Visual Software\n  Domains?","summary":"  Autonomous systems for software engineering are now capable of fixing bugs\nand developing features. These systems are commonly evaluated on SWE-bench\n(Jimenez et al., 2024a), which assesses their ability to solve software issues\nfrom GitHub repositories. However, SWE-bench uses only Python repositories,\nwith problem statements presented predominantly as text and lacking visual\nelements such as images. This limited coverage motivates our inquiry into how\nexisting systems might perform on unrepresented software engineering domains\n(e.g., front-end, game development, DevOps), which use different programming\nlanguages and paradigms. Therefore, we propose SWE-bench Multimodal (SWE-bench\nM), to evaluate systems on their ability to fix bugs in visual, user-facing\nJavaScript software. SWE-bench M features 617 task instances collected from 17\nJavaScript libraries used for web interface design, diagramming, data\nvisualization, syntax highlighting, and interactive mapping. Each SWE-bench M\ntask instance contains at least one image in its problem statement or unit\ntests. Our analysis finds that top-performing SWE-bench systems struggle with\nSWE-bench M, revealing limitations in visual problem-solving and cross-language\ngeneralization. Lastly, we show that SWE-agent's flexible language-agnostic\nfeatures enable it to substantially outperform alternatives on SWE-bench M,\nresolving 12% of task instances compared to 6% for the next best system.\n","authors":["John Yang","Carlos E. Jimenez","Alex L. Zhang","Kilian Lieret","Joyce Yang","Xindi Wu","Ori Press","Niklas Muennighoff","Gabriel Synnaeve","Karthik R. Narasimhan","Diyi Yang","Sida I. Wang","Ofir Press"],"pdf_url":"https://arxiv.org/pdf/2410.03859v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.03837v1","updated":"2024-10-04T18:05:22Z","published":"2024-10-04T18:05:22Z","title":"Learning Code Preference via Synthetic Evolution","summary":"  Large Language Models (LLMs) have recently demonstrated remarkable coding\ncapabilities. However, assessing code generation based on well-formed\nproperties and aligning it with developer preferences remains challenging. In\nthis paper, we explore two key questions under the new challenge of code\npreference learning: (i) How do we train models to predict meaningful\npreferences for code? and (ii) How do human and LLM preferences align with\nverifiable code properties and developer code tastes? To this end, we propose\nCodeFavor, a framework for training pairwise code preference models from\nsynthetic evolution data, including code commits and code critiques. To\nevaluate code preferences, we introduce CodePrefBench, a benchmark comprising\n1364 rigorously curated code preference tasks to cover three verifiable\nproperties-correctness, efficiency, and security-along with human preference.\nOur evaluation shows that CodeFavor holistically improves the accuracy of\nmodel-based code preferences by up to 28.8%. Meanwhile, CodeFavor models can\nmatch the performance of models with 6-9x more parameters while being 34x more\ncost-effective. We also rigorously validate the design choices in CodeFavor via\na comprehensive set of controlled experiments. Furthermore, we discover the\nprohibitive costs and limitations of human-based code preference: despite\nspending 23.4 person-minutes on each task, 15.1-40.3% of tasks remain unsolved.\nCompared to model-based preference, human preference tends to be more accurate\nunder the objective of code correctness, while being sub-optimal for\nnon-functional objectives.\n","authors":["Jiawei Liu","Thanh Nguyen","Mingyue Shang","Hantian Ding","Xiaopeng Li","Yu Yu","Varun Kumar","Zijian Wang"],"pdf_url":"https://arxiv.org/pdf/2410.03837v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.16310v3","updated":"2024-10-04T18:02:55Z","published":"2024-01-29T17:13:44Z","title":"An Insight into Security Code Review with LLMs: Capabilities, Obstacles\n  and Influential Factors","summary":"  Security code review is a time-consuming and labor-intensive process\ntypically requiring integration with automated security defect detection tools.\nHowever, existing security analysis tools struggle with poor generalization,\nhigh false positive rates, and coarse detection granularity. Large Language\nModels (LLMs) have been considered promising candidates for addressing those\nchallenges. In this study, we conducted an empirical study to explore the\npotential of LLMs in detecting security defects during code review.\nSpecifically, we evaluated the performance of six LLMs under five different\nprompts and compared them with state-of-theart static analysis tools. We also\nperformed linguistic and regression analyses for the best-performing LLM to\nidentify quality problems in its responses and factors influencing its\nperformance. Our findings show that: (1) existing pre-trained LLMs have limited\ncapability in security code review but? significantly outperform the\nstate-of-the-art static analysis tools. (2) GPT-4 performs best among all LLMs\nwhen provided with a CWE list for reference. (3) GPT-4 frequently generates\nresponses that are verbose or not compliant with the task requirements given in\nthe prompts. (4) GPT-4 is more adept at identifying security defects in code\nfiles with fewer tokens, containing functional logic, or written by developers\nwith less involvement in the project.\n","authors":["Jiaxin Yu","Peng Liang","Yujia Fu","Amjed Tahir","Mojtaba Shahin","Chong Wang","Yangxiao Cai"],"pdf_url":"https://arxiv.org/pdf/2401.16310v3.pdf","comment":"26 pages, 5 images, 7 tables, Manuscript submitted to a journal\n  (2024)"},{"id":"http://arxiv.org/abs/2410.03585v1","updated":"2024-10-04T16:43:53Z","published":"2024-10-04T16:43:53Z","title":"MeDeT: Medical Device Digital Twins Creation with Few-shot Meta-learning","summary":"  Testing healthcare Internet of Things (IoT) applications at system and\nintegration levels necessitates integrating numerous medical devices of various\ntypes. Challenges of incorporating medical devices are: (i) their continuous\nevolution, making it infeasible to include all device variants, and (ii)\nrigorous testing at scale requires multiple devices and their variants, which\nis time-intensive, costly, and impractical. Our collaborator, Oslo City's\nhealth department, faced these challenges in developing automated test\ninfrastructure, which our research aims to address. In this context, we propose\na meta-learning-based approach (MeDeT) to generate digital twins (DTs) of\nmedical devices and adapt DTs to evolving devices. We evaluate MeDeT in\nOsloCity's context using five widely-used medical devices integrated with a\nreal-world healthcare IoT application. Our evaluation assesses MeDeT's ability\nto generate and adapt DTs across various devices and versions using different\nfew-shot methods, the fidelity of these DTs, the scalability of operating 1000\nDTs concurrently, and the associated time costs. Results show that MeDeT can\ngenerate DTs with over 96% fidelity, adapt DTs to different devices and newer\nversions with reduced time cost (around one minute), and operate 1000 DTs in a\nscalable manner while maintaining the fidelity level, thus serving in place of\nphysical devices for testing.\n","authors":["Hassan Sartaj","Shaukat Ali","Julie Marie Gjøby"],"pdf_url":"https://arxiv.org/pdf/2410.03585v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.03580v1","updated":"2024-10-04T16:38:27Z","published":"2024-10-04T16:38:27Z","title":"A Multi-model Approach for Video Data Retrieval in Autonomous Vehicle\n  Development","summary":"  Autonomous driving software generates enormous amounts of data every second,\nwhich software development organizations save for future analysis and testing\nin the form of logs. However, given the vast size of this data, locating\nspecific scenarios within a collection of vehicle logs can be challenging.\nWriting the correct SQL queries to find these scenarios requires engineers to\nhave a strong background in SQL and the specific databases in question, further\ncomplicating the search process. This paper presents and evaluates a pipeline\nthat allows searching for specific scenarios in log collections using natural\nlanguage descriptions instead of SQL. The generated descriptions were evaluated\nby engineers working with vehicle logs at the Zenseact on a scale from 1 to 5.\nOur approach achieved a mean score of 3.3, demonstrating the potential of using\na multi-model architecture to improve the software development workflow. We\nalso present an interface that can visualize the query process and visualize\nthe results.\n","authors":["Jesper Knapp","Klas Moberg","Yuchuan Jin","Simin Sun","Miroslaw Staron"],"pdf_url":"https://arxiv.org/pdf/2410.03580v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.03571v1","updated":"2024-10-04T16:20:39Z","published":"2024-10-04T16:20:39Z","title":"Generative AI in the Software Engineering Domain: Tensions of\n  Occupational Identity and Patterns of Identity Protection","summary":"  The adoption of generative Artificial Intelligence (GAI) in organizational\nsettings calls into question workers' roles, and relatedly, the implications\nfor their long-term skill development and domain expertise. In our qualitative\nstudy in the software engineering domain, we build on the theoretical lenses of\noccupational identity and self-determination theory to understand how and why\nsoftware engineers make sense of GAI for their work. We find that engineers'\nsense-making is contingent on domain expertise, as juniors and seniors felt\ntheir needs for competence, autonomy, and relatedness to be differently\nimpacted by GAI. We shed light on the importance of the individual's role in\npreserving tacit domain knowledge as engineers engaged in sense-making that\nprotected their occupational identity. We illustrate how organizations play an\nactive role in shaping workers' sense-making process and propose design\nguidelines on how organizations and system designers can facilitate the impact\nof technological change on workers' occupational identity.\n","authors":["Anuschka Schmitt","Krzysztof Z. Gajos","Osnat Mokryn"],"pdf_url":"https://arxiv.org/pdf/2410.03571v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.03504v1","updated":"2024-10-04T15:17:52Z","published":"2024-10-04T15:17:52Z","title":"Uncertainty-Aware Environment Simulation of Medical Devices Digital\n  Twins","summary":"  Smart medical devices are an integral component of the healthcare Internet of\nThings (IoT), providing patients with various healthcare services through an\nIoT-based application. Ensuring the dependability of such applications through\nsystem and integration-level testing mandates the physical integration of\nnumerous medical devices, which is costly and impractical. In this context,\ndigital twins of medical devices play an essential role in facilitating testing\nautomation. Testing with digital twins without accounting for uncertain\nenvironmental factors of medical devices leaves many functionalities of\nIoT-based healthcare applications untested. In addition, digital twins\noperating without environmental factors remain out of sync and uncalibrated\nwith their corresponding devices functioning in the real environment. To deal\nwith these challenges, in this paper, we propose a model-based approach (EnvDT)\nfor modeling and simulating the environment of medical devices' digital twins\nunder uncertainties. We empirically evaluate the EnvDT using three medicine\ndispensers, Karie, Medido, and Pilly connected to a real-world IoT-based\nhealthcare application. Our evaluation targets analyzing the coverage of\nenvironment models and the diversity of uncertain scenarios generated for\ndigital twins. Results show that EnvDT achieves approximately 61% coverage of\nenvironment models and generates diverse uncertain scenarios (with a\nnear-maximum diversity value of 0.62) during multiple environmental\nsimulations.\n","authors":["Hassan Sartaj","Shaukat Ali","Julie Marie Gjøby"],"pdf_url":"https://arxiv.org/pdf/2410.03504v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.03490v1","updated":"2024-10-04T15:00:17Z","published":"2024-10-04T15:00:17Z","title":"Applying the FAIR Principles to Computational Workflows","summary":"  Recent trends within computational and data sciences show an increasing\nrecognition and adoption of computational workflows as tools for productivity,\nreproducibility, and democratized access to platforms and processing know-how.\nAs digital objects to be shared, discovered, and reused, computational\nworkflows benefit from the FAIR principles, which stand for Findable,\nAccessible, Interoperable, and Reusable. The Workflows Community Initiative's\nFAIR Workflows Working Group (WCI-FW), a global and open community of\nresearchers and developers working with computational workflows across\ndisciplines and domains, has systematically addressed the application of both\nFAIR data and software principles to computational workflows. We present our\nrecommendations with commentary that reflects our discussions and justifies our\nchoices and adaptations. Like the software and data principles on which they\nare based, these are offered to workflow users and authors, workflow management\nsystem developers, and providers of workflow services as guide rails for\nadoption and fodder for discussion. Workflows are becoming more prevalent as\ndocumented, automated instruments for data analysis, data collection, AI-based\npredictions, and simulations. The FAIR recommendations for workflows that we\npropose in this paper will maximize their value as research assets and\nfacilitate their adoption by the wider community.\n","authors":["Sean R. Wilkinson","Meznah Aloqalaa","Khalid Belhajjame","Michael R. Crusoe","Bruno de Paula Kinoshita","Luiz Gadelha","Daniel Garijo","Ove Johan Ragnar Gustafsson","Nick Juty","Sehrish Kanwal","Farah Zaib Khan","Johannes Köster","Karsten Peters-von Gehlen","Line Pouchard","Randy K. Rannow","Stian Soiland-Reyes","Nicola Soranzo","Shoaib Sufi","Ziheng Sun","Baiba Vilne","Merridee A. Wouters","Denis Yuen","Carole Goble"],"pdf_url":"https://arxiv.org/pdf/2410.03490v1.pdf","comment":"17 pages, 1 figure, 1 table"},{"id":"http://arxiv.org/abs/2407.16741v2","updated":"2024-10-04T14:54:08Z","published":"2024-07-23T17:50:43Z","title":"OpenHands: An Open Platform for AI Software Developers as Generalist\n  Agents","summary":"  Software is one of the most powerful tools that we humans have at our\ndisposal; it allows a skilled programmer to interact with the world in complex\nand profound ways. At the same time, thanks to improvements in large language\nmodels (LLMs), there has also been a rapid development in AI agents that\ninteract with and affect change in their surrounding environments. In this\npaper, we introduce OpenHands (f.k.a. OpenDevin), a platform for the\ndevelopment of powerful and flexible AI agents that interact with the world in\nsimilar ways to those of a human developer: by writing code, interacting with a\ncommand line, and browsing the web. We describe how the platform allows for the\nimplementation of new agents, safe interaction with sandboxed environments for\ncode execution, coordination between multiple agents, and incorporation of\nevaluation benchmarks. Based on our currently incorporated benchmarks, we\nperform an evaluation of agents over 15 challenging tasks, including software\nengineering (e.g., SWE-BENCH) and web browsing (e.g., WEBARENA), among others.\nReleased under the permissive MIT license, OpenHands is a community project\nspanning academia and industry with more than 2.1K contributions from over 188\ncontributors.\n","authors":["Xingyao Wang","Boxuan Li","Yufan Song","Frank F. Xu","Xiangru Tang","Mingchen Zhuge","Jiayi Pan","Yueqi Song","Bowen Li","Jaskirat Singh","Hoang H. Tran","Fuqiang Li","Ren Ma","Mingzhang Zheng","Bill Qian","Yanjun Shao","Niklas Muennighoff","Yizhe Zhang","Binyuan Hui","Junyang Lin","Robert Brennan","Hao Peng","Heng Ji","Graham Neubig"],"pdf_url":"https://arxiv.org/pdf/2407.16741v2.pdf","comment":"Code: https://github.com/All-Hands-AI/OpenHands"},{"id":"http://arxiv.org/abs/2311.05243v7","updated":"2024-10-04T14:47:53Z","published":"2023-11-09T09:55:10Z","title":"A higher-order transformation approach to the formalization and analysis\n  of BPMN using graph transformation systems","summary":"  The Business Process Modeling Notation (BPMN) is a widely used standard\nnotation for defining intra- and inter-organizational workflows. However, the\ninformal description of the BPMN execution semantics leads to different\ninterpretations of BPMN elements and difficulties in checking behavioral\nproperties. In this article, we propose a formalization of the execution\nsemantics of BPMN that, compared to existing approaches, covers more BPMN\nelements while also facilitating property checking. Our approach is based on a\nhigher-order transformation from BPMN models to graph transformation systems.\nTo show the capabilities of our approach, we implemented it as an open-source\nweb-based tool.\n","authors":["Tim Kräuter","Adrian Rutle","Harald König","Yngve Lamo"],"pdf_url":"https://arxiv.org/pdf/2311.05243v7.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.03431v1","updated":"2024-10-04T13:42:54Z","published":"2024-10-04T13:42:54Z","title":"Approaching Code Search for Python as a Translation Retrieval Problem\n  with Dual Encoders","summary":"  Code search is vital in the maintenance and extension of software systems.\nPast works have used separate language models for the natural language and\nprogramming language artifacts on models with multiple encoders and different\nloss functions. Similarly, this work approaches code search for Python as a\ntranslation retrieval problem while the natural language queries and the\nprogramming language are treated as two types of languages. By using dual\nencoders, these two types of language sequences are projected onto a shared\nembedding space, in which the distance reflects the similarity between a given\npair of query and code. However, in contrast to previous work, this approach\nuses a unified language model, and a dual encoder structure with a cosine\nsimilarity loss function. A unified language model helps the model take\nadvantage of the considerable overlap of words between the artifacts, making\nthe learning much easier. On the other hand, the dual encoders trained with\ncosine similarity loss helps the model learn the underlining patterns of which\nterms are important for predicting linked pairs of artifacts. Evaluation shows\nthe proposed model achieves performance better than state-of-the-art code\nsearch models. In addition, this model is much less expensive in terms of time\nand complexity, offering a cheaper, faster, and better alternative.\n","authors":["Monoshiz Mahbub Khan","Zhe Yu"],"pdf_url":"https://arxiv.org/pdf/2410.03431v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.03351v1","updated":"2024-10-04T12:17:08Z","published":"2024-10-04T12:17:08Z","title":"Generating Equivalent Representations of Code By A Self-Reflection\n  Approach","summary":"  Equivalent Representations (ERs) of code are textual representations that\npreserve the same semantics as the code itself, e.g., natural language comments\nand pseudocode. ERs play a critical role in software development and\nmaintenance. However, how to automatically generate ERs of code remains an open\nchallenge. In this paper, we propose a self-reflection approach to generating\nERs of code. It enables two Large Language Models (LLMs) to work mutually and\nproduce an ER through a reflection process. Depending on whether constraints on\nERs are applied, our approach generates ERs in both open and constrained\nsettings. We conduct a empirical study to generate ERs in two settings and\nobtain eight findings. (1) Generating ERs in the open setting. In the open\nsetting, we allow LLMs to represent code without any constraints, analyzing the\nresulting ERs and uncovering five key findings. These findings shed light on\nhow LLMs comprehend syntactic structures, APIs, and numerical computations in\ncode. (2) Generating ERs in the constrained setting. In the constrained\nsetting, we impose constraints on ERs, such as natural language comments,\npseudocode, and flowcharts. This allows our approach to address a range of\nsoftware engineering tasks. Based on our experiments, we have three findings\ndemonstrating that our approach can effectively generate ERs that adhere to\nspecific constraints, thus supporting various software engineering tasks. (3)\nFuture directions. We also discuss potential future research directions, such\nas deriving intermediate languages for code generation, exploring LLM-friendly\nrequirement descriptions, and further supporting software engineering tasks. We\nbelieve that this paper will spark discussions in research communities and\ninspire many follow-up studies.\n","authors":["Jia Li","Ge Li","Lecheng Wang","Hao Zhu","Zhi Jin"],"pdf_url":"https://arxiv.org/pdf/2410.03351v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.03234v1","updated":"2024-10-04T08:51:31Z","published":"2024-10-04T08:51:31Z","title":"Showing LLM-Generated Code Selectively Based on Confidence of LLMs","summary":"  Large Language Models (LLMs) have shown impressive abilities in code\ngeneration, but they may generate erroneous programs. Reading a program takes\nten times longer than writing it. Showing these erroneous programs to\ndevelopers will waste developers' energies and introduce security risks to\nsoftware.\n  To address the above limitations, we propose HonestCoder, a novel LLM-based\ncode generation approach. HonestCoder selectively shows the generated programs\nto developers based on LLMs' confidence. The confidence provides valuable\ninsights into the correctness of generated programs. To achieve this goal, we\npropose a novel approach to estimate LLMs' confidence in code generation. It\nestimates confidence by measuring the multi-modal similarity between\nLLMs-generated programs.\n  We collect and release a multilingual benchmark named TruthCodeBench, which\nconsists of 2,265 samples and covers two popular programming languages (i.e.,\nPython and Java). We apply HonestCoder to four popular LLMs (e.g.,\nDeepSeek-Coder and Code Llama) and evaluate it on TruthCodeBench. Based on the\nexperiments, we obtain the following insights. (1) HonestCoder can effectively\nestimate LLMs' confidence and accurately determine the correctness of generated\nprograms. For example, HonestCoder outperforms the state-of-the-art baseline by\n27.79% in AUROC and 63.74% in AUCPR. (2) HonestCoder can decrease the number of\nerroneous programs shown to developers. Compared to eight baselines, it can\nshow more correct programs and fewer erroneous programs to developers. (3)\nCompared to showing code indiscriminately, HonestCoder only adds slight time\noverhead (approximately 0.4 seconds per requirement). (4) We discuss future\ndirections to facilitate the application of LLMs in software development. We\nhope this work can motivate broad discussions about measuring the reliability\nof LLMs' outputs in performing code-related tasks.\n","authors":["Jia Li","Yuqi Zhu","Yongmin Li","Ge Li","Zhi Jin"],"pdf_url":"https://arxiv.org/pdf/2410.03234v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.03800v1","updated":"2024-10-04T07:52:46Z","published":"2024-10-04T07:52:46Z","title":"M2AR: A Web-based Modeling Environment for the Augmented Reality\n  Workflow Modeling Language","summary":"  This paper introduces M2AR, a new web-based, two- and three-dimensional\nmodeling environment that enables the modeling and execution of augmented\nreality applications without requiring programming knowledge. The platform is\nbased on a 3D JavaScript library and the mixed reality immersive web standard\nWebXR. For a first demonstration of its feasibility, the previously introduced\nAugmented Reality Workflow Modeling Language (ARWFML) has been successfully\nimplemented using this environment. The usefulness of the new modeling\nenvironment is demonstrated by showing use cases of the ARWFML on M2AR.\n","authors":["Fabian Muff","Hans-Georg Fill"],"pdf_url":"https://arxiv.org/pdf/2410.03800v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.03202v1","updated":"2024-10-04T07:34:02Z","published":"2024-10-04T07:34:02Z","title":"Learning test generators for cyber-physical systems","summary":"  Black-box runtime verification methods for cyber-physical systems can be used\nto discover errors in systems whose inputs and outputs are expressed as signals\nover time and their correctness requirements are specified in a temporal logic.\nExisting methods, such as requirement falsification, often focus on finding a\nsingle input that is a counterexample to system correctness. In this paper, we\nstudy how to create test generators that can produce multiple and diverse\ncounterexamples for a single requirement. Several counterexamples expose system\nfailures in varying input conditions and support the root cause analysis of the\nfaults.\n  We present the WOGAN algorithm to create such test generators automatically.\nThe algorithm works by training iteratively a Wasserstein generative\nadversarial network that models the target distribution of the uniform\ndistribution on the set of counterexamples. WOGAN is an algorithm that trains\ngenerative models that act as test generators for runtime verification. The\ntraining is performed online without the need for a previous model or dataset.\nWe also propose criteria to evaluate such test generators.\n  We evaluate the trained generators on several well-known problems including\nthe ARCH-COMP falsification benchmarks. Our experimental results indicate that\ngenerators trained by the WOGAN algorithm are as effective as state-of-the-art\nrequirement falsification algorithms while producing tests that are as diverse\nas a sample from uniform random sampling. We conclude that WOGAN is a viable\nmethod to produce test generators automatically and that these test generators\ncan generate multiple and diverse counterexamples for the runtime verification\nof cyber-physical systems.\n","authors":["Jarkko Peltomäki","Ivan Porres"],"pdf_url":"https://arxiv.org/pdf/2410.03202v1.pdf","comment":"34 pages, 4 figures, 7 tables"},{"id":"http://arxiv.org/abs/2409.07272v3","updated":"2024-10-04T07:26:24Z","published":"2024-09-11T13:46:52Z","title":"RePlay: a Recommendation Framework for Experimentation and Production\n  Use","summary":"  Using a single tool to build and compare recommender systems significantly\nreduces the time to market for new models. In addition, the comparison results\nwhen using such tools look more consistent. This is why many different tools\nand libraries for researchers in the field of recommendations have recently\nappeared. Unfortunately, most of these frameworks are aimed primarily at\nresearchers and require modification for use in production due to the inability\nto work on large datasets or an inappropriate architecture. In this demo, we\npresent our open-source toolkit RePlay - a framework containing an end-to-end\npipeline for building recommender systems, which is ready for production use.\nRePlay also allows you to use a suitable stack for the pipeline on each stage:\nPandas, Polars, or Spark. This allows the library to scale computations and\ndeploy to a cluster. Thus, RePlay allows data scientists to easily move from\nresearch mode to production mode using the same interfaces.\n","authors":["Alexey Vasilev","Anna Volodkevich","Denis Kulandin","Tatiana Bysheva","Anton Klenitskiy"],"pdf_url":"https://arxiv.org/pdf/2409.07272v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.03195v1","updated":"2024-10-04T07:18:26Z","published":"2024-10-04T07:18:26Z","title":"The Potential of Citizen Platforms for Requirements Engineering of Large\n  Socio-Technical Software Systems","summary":"  Participatory citizen platforms are innovative solutions to digitally better\nengage citizens in policy-making and deliberative democracy in general.\nAlthough these platforms have been used also in an engineering context, thus\nfar, there is no existing work for connecting the platforms to requirements\nengineering. The present paper fills this notable gap. In addition to\ndiscussing the platforms in conjunction with requirements engineering, the\npaper elaborates potential advantages and disadvantages, thus paving the way\nfor a future pilot study in a software engineering context. With these\nengineering tenets, the paper also contributes to the research of large\nsocio-technical software systems in a public sector context, including their\nimplementation and governance.\n","authors":["Jukka Ruohonen","Kalle Hjerppe"],"pdf_url":"https://arxiv.org/pdf/2410.03195v1.pdf","comment":"Submitted to REFSQ"},{"id":"http://arxiv.org/abs/2410.03180v1","updated":"2024-10-04T06:35:01Z","published":"2024-10-04T06:35:01Z","title":"Specification Slicing for VDM-SL","summary":"  The executable specification is one of the powerful tools in lightweight\nformal software development. VDM-SL allows the explicit and executable\ndefinition of operations that reference and update internal state through\nimperative statements. While the extensive executable subset of VDM-SL enables\nvalidation and testing in the specification phase, it also brings difficulties\nin reading and debugging as in imperative programming. In this paper, we define\nspecification slicing for VDM-SL based on program slicing, a technique used for\ndebugging and maintaining program source code in implementation languages. We\nthen present and discuss its applications. The slicer for VDM-SL is implemented\non ViennaTalk and can be used on browsers and debuggers describing the VDM-SL\nspecification.\n","authors":["Tomohiro Oda","Han-Myung Chang"],"pdf_url":"https://arxiv.org/pdf/2410.03180v1.pdf","comment":"15 pages, submitted to the 22nd Overture Workshop"},{"id":"http://arxiv.org/abs/2311.00317v2","updated":"2024-10-04T04:16:21Z","published":"2023-11-01T06:01:22Z","title":"Data Augmentation for Code Translation with Comparable Corpora and\n  Multiple References","summary":"  One major challenge of translating code between programming languages is that\nparallel training data is often limited. To overcome this challenge, we present\ntwo data augmentation techniques, one that builds comparable corpora (i.e.,\ncode pairs with similar functionality), and another that augments existing\nparallel data with multiple reference translations. Specifically, we build and\nanalyze multiple types of comparable corpora, including programs generated from\nnatural language documentation using a code generation model. Furthermore, to\nreduce overfitting to a single reference translation, we automatically generate\nadditional translation references for available parallel data and filter the\ntranslations by unit tests, which increases variation in target translations.\nExperiments show that our data augmentation techniques significantly improve\nCodeT5 for translation between Java, Python, and C++ by an average of 7.5%\nComputational Accuracy (CA@1), which verifies the correctness of translations\nby execution. The code is available at https://github.com/Veronicium/CMTrans.\n","authors":["Yiqing Xie","Atharva Naik","Daniel Fried","Carolyn Rose"],"pdf_url":"https://arxiv.org/pdf/2311.00317v2.pdf","comment":"EMNLP 2023 Findings (with minor updates on the flowcharts)"},{"id":"http://arxiv.org/abs/2311.11791v3","updated":"2024-10-04T03:50:40Z","published":"2023-11-20T14:17:52Z","title":"Metamorphic Testing of Image Captioning Systems via Image-Level\n  Reduction","summary":"  The Image Captioning (IC) technique is widely used to describe images in\nnatural language. Recently, some IC system testing methods have been proposed.\nHowever, these methods still rely on pre-annotated information and hence cannot\nreally alleviate the oracle problem in testing. Besides, their method\nartificially manipulates objects, which may generate unreal images as test\ncases and thus lead to less meaningful testing results. Thirdly, existing\nmethods have various requirements on the eligibility of source test cases, and\nhence cannot fully utilize the given images to perform testing. To tackle these\nissues, in this paper, we propose REIC to perform metamorphic testing for IC\nsystems with some image-level reduction transformations like image cropping and\nstretching. Instead of relying on the pre-annotated information, REIC uses a\nlocalization method to align objects in the caption with corresponding objects\nin the image, and checks whether each object is correctly described or deleted\nin the caption after transformation. With the image-level reduction\ntransformations, REIC does not artificially manipulate any objects and hence\ncan avoid generating unreal follow-up images. Besides, it eliminates the\nrequirement on the eligibility of source test cases in the metamorphic\ntransformation process, as well as decreases the ambiguity and boosts the\ndiversity among the follow-up test cases, which consequently enables testing to\nbe performed on any test image and reveals more distinct valid violations. We\nemploy REIC to test five popular IC systems. The results demonstrate that REIC\ncan sufficiently leverage the provided test images to generate follow-up cases\nof good reality, and effectively detect a great number of distinct violations,\nwithout the need for any pre-annotated information.\n","authors":["Xiaoyuan Xie","Xingpeng Li","Songqiang Chen"],"pdf_url":"https://arxiv.org/pdf/2311.11791v3.pdf","comment":"Accepted by IEEE Transactions on Software Engineering (TSE) in\n  September 2024"},{"id":"http://arxiv.org/abs/2410.03103v1","updated":"2024-10-04T02:53:52Z","published":"2024-10-04T02:53:52Z","title":"Horizon-Length Prediction: Advancing Fill-in-the-Middle Capabilities for\n  Code Generation with Lookahead Planning","summary":"  Fill-in-the-Middle (FIM) has become integral to code language models,\nenabling generation of missing code given both left and right contexts.\nHowever, the current FIM training paradigm, which reorders original training\nsequences and then performs regular next-token prediction (NTP), often leads to\nmodels struggling to generate content that aligns smoothly with the surrounding\ncontext. Crucially, while existing works rely on rule-based post-processing to\ncircumvent this weakness, such methods are not practically usable in\nopen-domain code completion tasks as they depend on restrictive,\ndataset-specific assumptions (e.g., generating the same number of lines as in\nthe ground truth). Moreover, model performance on FIM tasks deteriorates\nsignificantly without these unrealistic assumptions.\n  We hypothesize that NTP alone is insufficient for models to learn effective\nplanning conditioned on the distant right context, a critical factor for\nsuccessful code infilling. To overcome this, we propose Horizon-Length\nPrediction (HLP), a novel training objective that teaches models to predict the\nnumber of remaining middle tokens (i.e., horizon length) at each step. HLP\nadvances FIM with lookahead planning, enabling models to inherently learn\ninfilling boundaries for arbitrary left and right contexts without relying on\ndataset-specific post-processing. Our evaluation across different models and\nsizes shows that HLP significantly improves FIM performance by up to 24%\nrelatively on diverse benchmarks, across file-level and repository-level, and\nwithout resorting to unrealistic post-processing methods. Furthermore, the\nenhanced planning capability gained through HLP boosts model performance on\ncode reasoning. Importantly, HLP only incurs negligible training overhead and\nno additional inference cost, ensuring its practicality for real-world\nscenarios.\n","authors":["Yifeng Ding","Hantian Ding","Shiqi Wang","Qing Sun","Varun Kumar","Zijian Wang"],"pdf_url":"https://arxiv.org/pdf/2410.03103v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.03795v1","updated":"2024-10-04T02:50:58Z","published":"2024-10-04T02:50:58Z","title":"Deep Learning and Machine Learning: Advancing Big Data Analytics and\n  Management with Design Patterns","summary":"  This book, Design Patterns in Machine Learning and Deep Learning: Advancing\nBig Data Analytics Management, presents a comprehensive study of essential\ndesign patterns tailored for large-scale machine learning and deep learning\napplications. The book explores the application of classical software\nengineering patterns, Creational, Structural, Behavioral, and Concurrency\nPatterns, to optimize the development, maintenance, and scalability of big data\nanalytics systems. Through practical examples and detailed Python\nimplementations, it bridges the gap between traditional object-oriented design\npatterns and the unique demands of modern data analytics environments. Key\ndesign patterns such as Singleton, Factory, Observer, and Strategy are analyzed\nfor their impact on model management, deployment strategies, and team\ncollaboration, providing invaluable insights into the engineering of efficient,\nreusable, and flexible systems. This volume is an essential resource for\ndevelopers, researchers, and engineers aiming to enhance their technical\nexpertise in both machine learning and software design.\n","authors":["Keyu Chen","Ziqian Bi","Tianyang Wang","Yizhu Wen","Pohsun Feng","Qian Niu","Junyu Liu","Benji Peng","Sen Zhang","Ming Li","Xuanhe Pan","Jiawei Xu","Jinlang Wang","Caitlyn Heqi Yin","Ming Liu"],"pdf_url":"https://arxiv.org/pdf/2410.03795v1.pdf","comment":"138pages"},{"id":"http://arxiv.org/abs/2410.03069v1","updated":"2024-10-04T01:22:16Z","published":"2024-10-04T01:22:16Z","title":"Interactive GDPR-Compliant Privacy Policy Generation for Software\n  Applications","summary":"  Software applications are designed to assist users in conducting a wide range\nof tasks or interactions. They have become prevalent and play an integral part\nin people's lives in this digital era. To use those software applications,\nusers are sometimes requested to provide their personal information. As privacy\nhas become a significant concern and many data protection regulations exist\nworldwide, software applications must provide users with a privacy policy\ndetailing how their personal information is collected and processed. We propose\nan approach that generates a comprehensive and compliant privacy policy with\nrespect to the General Data Protection Regulation (GDPR) for diverse software\napplications. To support this, we first built a library of privacy clauses\nbased on existing privacy policy analysis. We then developed an interactive\nrule-based system that prompts software developers with a series of questions\nand uses their answers to generate a customised privacy policy for a given\nsoftware application. We evaluated privacy policies generated by our approach\nin terms of readability, completeness and coverage and compared them to privacy\npolicies generated by three existing privacy policy generators and a Generative\nAI-based tool. Our evaluation results show that the privacy policy generated by\nour approach is the most complete and comprehensive.\n","authors":["Pattaraporn Sangaroonsilp","Hoa Khanh Dam","Omar Haggag","John Grundy"],"pdf_url":"https://arxiv.org/pdf/2410.03069v1.pdf","comment":null}],"Human-Computer Interaction":[{"id":"http://arxiv.org/abs/2409.16732v2","updated":"2024-10-04T22:43:08Z","published":"2024-09-25T08:31:11Z","title":"\"It Explains What I am Currently Going Through Perfectly to a Tee\":\n  Understanding User Perceptions on LLM-Enhanced Narrative Interventions","summary":"  Stories about overcoming personal struggles can effectively illustrate the\napplication of psychological theories in real life, yet they may fail to\nresonate with individuals' experiences. In this work, we employ large language\nmodels (LLMs) to create tailored narratives that acknowledge and address unique\nchallenging thoughts and situations faced by individuals. Our study, involving\n346 young adults across two settings, demonstrates that LLM-enhanced stories\nwere perceived to be better than human-written ones in conveying key takeaways,\npromoting reflection, and reducing belief in negative thoughts. These stories\nwere not only seen as more relatable but also similarly authentic to\nhuman-written ones, highlighting the potential of LLMs in helping young adults\nmanage their struggles. The findings of this work provide crucial design\nconsiderations for future narrative-based digital mental health interventions,\nsuch as the need to maintain relatability without veering into implausibility\nand refining the wording and tone of AI-enhanced content.\n","authors":["Ananya Bhattacharjee","Sarah Yi Xu","Pranav Rao","Yuchen Zeng","Jonah Meyerhoff","Syed Ishtiaque Ahmed","David C Mohr","Michael Liut","Alex Mariakakis","Rachel Kornfield","Joseph Jay Williams"],"pdf_url":"https://arxiv.org/pdf/2409.16732v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.10841v2","updated":"2024-10-04T21:23:07Z","published":"2024-09-17T02:15:27Z","title":"Dark Mode or Light Mode? Exploring the Impact of Contrast Polarity on\n  Visualization Performance Between Age Groups","summary":"  This study examines the impact of positive and negative contrast polarities\n(i.e., light and dark modes) on the performance of younger adults and people in\ntheir late adulthood (PLA). In a crowdsourced study with 134 participants (69\nbelow age 60, 66 aged 60 and above), we assessed their accuracy and time\nperforming analysis tasks across three common visualization types (Bar, Line,\nScatterplot) and two contrast polarities (positive and negative). We observed\nthat, across both age groups, the polarity that led to better performance and\nthe resulting amount of improvement varied on an individual basis, with each\npolarity benefiting comparable proportions of participants. However, the\ncontrast polarity that led to better performance did not always match their\npreferred polarity. Additionally, we observed that the choice of contrast\npolarity can have an impact on time similar to that of the choice of\nvisualization type, resulting in an average percent difference of around 36%.\nThese findings indicate that, overall, the effects of contrast polarity on\nvisual analysis performance do not noticeably change with age. Furthermore,\nthey underscore the importance of making visualizations available in both\ncontrast polarities to better-support a broad audience with differing needs.\nSupplementary materials for this work can be found at https://osf.io/539a4/.\n","authors":["Zack While","Ali Sarvghad"],"pdf_url":"https://arxiv.org/pdf/2409.10841v2.pdf","comment":"5 pages, 5 figures, accepted as a short paper to IEEE VIS '24"},{"id":"http://arxiv.org/abs/2410.03929v1","updated":"2024-10-04T21:11:43Z","published":"2024-10-04T21:11:43Z","title":"Toward Understanding the Experiences of People in Late Adulthood with\n  Embedded Information Displays in the Home","summary":"  Embedded information displays (EIDs) are becoming increasingly ubiquitous on\nhome appliances and devices such as microwaves, coffee machines, fridges, or\ndigital thermostats. These displays are often multi-purpose, functioning as\ninterfaces for selecting device settings, communicating operating status using\nsimple visualizations, and displaying notifications. However, their usability\nfor people in the late adulthood (PLA) development stage is not\nwell-understood. We report on two focus groups with PLA (n = 11, ages 76-94)\nfrom a local retirement community. Participants were shown images of everyday\nhome electronics and appliances, answering questions about their experiences\nusing the EIDs. Using open coding, we qualitatively analyzed their comments to\ndistill key themes regarding how EIDs can negatively affect PLA's ability to\ntake in information (e.g., poor labels) and interact with these devices (e.g.,\nunintuitive steps) alongside strategies employed to work around these issues.\nWe argue that understanding the equitable design and communication of devices'\nfunctions, operating status, and messages is important for future information\ndisplay designers. We hope this work stimulates further investigation into more\nequitable EID design.\n","authors":["Zack While","Henry Wheeler-Klainberg","Tanja Blascheck","Petra Isenberg","Ali Sarvghad"],"pdf_url":"https://arxiv.org/pdf/2410.03929v1.pdf","comment":"5 pages, 1 figure, accepted to the 1st Workshop on Accessible\n  Visualization at IEEE VIS '24"},{"id":"http://arxiv.org/abs/2410.03895v1","updated":"2024-10-04T19:52:41Z","published":"2024-10-04T19:52:41Z","title":"Demystifying Technology for Policymaking: Exploring the Rideshare\n  Context and Data Initiative Opportunities to Advance Tech Policymaking\n  Efforts","summary":"  In the face of rapidly advancing technologies, evidence of harms they can\nexacerbate, and insufficient policy to ensure accountability from tech\ncompanies, what are HCI opportunities for advancing policymaking of technology?\nIn this paper, we explore challenges and opportunities for tech policymaking\nthrough a case study of app-based rideshare driving. We begin with background\non rideshare platforms and how they operate. Next, we review literature on\nalgorithmic management about how rideshare drivers actually experience platform\nfeatures -- often to the detriment of their well-being -- and ways they\nrespond. In light of this, researchers and advocates have called for increased\nworker protections, thus we turn to rideshare policy and regulation efforts in\nthe U.S. Here, we differentiate the political strategies of platforms with\nthose of drivers to illustrate the conflicting narratives policymakers face\nwhen trying to oversee gig work platforms. We reflect that past methods\nsurfacing drivers' experiences may be insufficient for policymaker needs when\ndeveloping oversight. To address this gap and our original inquiry -- what are\nHCI opportunities for advancing tech policymaking -- we briefly explore two\npaths forward for holding tech companies accountable in the rideshare context:\n(1) data transparency initiatives to enable collective auditing by workers and\n(2) legal frameworks for holding platforms accountable.\n","authors":["Angie Zhang"],"pdf_url":"https://arxiv.org/pdf/2410.03895v1.pdf","comment":"12 pages"},{"id":"http://arxiv.org/abs/2410.03884v1","updated":"2024-10-04T19:35:44Z","published":"2024-10-04T19:35:44Z","title":"KidLM: Advancing Language Models for Children -- Early Insights and\n  Future Directions","summary":"  Recent studies highlight the potential of large language models in creating\neducational tools for children, yet significant challenges remain in\nmaintaining key child-specific properties such as linguistic nuances, cognitive\nneeds, and safety standards. In this paper, we explore foundational steps\ntoward the development of child-specific language models, emphasizing the\nnecessity of high-quality pre-training data. We introduce a novel user-centric\ndata collection pipeline that involves gathering and validating a corpus\nspecifically written for and sometimes by children. Additionally, we propose a\nnew training objective, Stratified Masking, which dynamically adjusts masking\nprobabilities based on our domain-specific child language data, enabling models\nto prioritize vocabulary and concepts more suitable for children. Experimental\nevaluations demonstrate that our model excels in understanding lower\ngrade-level text, maintains safety by avoiding stereotypes, and captures\nchildren's unique preferences. Furthermore, we provide actionable insights for\nfuture research and development in child-specific language modeling.\n","authors":["Mir Tafseer Nayeem","Davood Rafiei"],"pdf_url":"https://arxiv.org/pdf/2410.03884v1.pdf","comment":"Accepted to EMNLP 2024 (long, main)"},{"id":"http://arxiv.org/abs/2410.03882v1","updated":"2024-10-04T19:29:44Z","published":"2024-10-04T19:29:44Z","title":"JumpStarter: Getting Started on Personal Goals with AI-Powered Context\n  Curation","summary":"  Everyone aspires to achieve personal goals. However, getting started is often\ncomplex and daunting, especially for large projects. AI has the potential to\ncreate plans and help jumpstart progress, but it often lacks sufficient\npersonal context to be useful. We introduce JumpStarter, a system that uses\nAI-powered context curation to create action plans and draft personalized\nworking solutions. JumpStarter assists users by posing questions to elicit\nrelevant context, breaking down goals into manageable steps, and selecting\nappropriate context to draft working solutions for each step. A technical\nevaluation indicates that context curation results in plans and working\nsolutions of higher quality. A user study demonstrates that compared to\nChatGPT, JumpStarter significantly reduces users' mental load and increases\ntheir efficiency in kickstarting personal projects. We discuss the design\nimplications of AI-powered context curation to facilitate the use of generative\nAI in complex problem-solving.\n","authors":["Sitong Wang","Xuanming Zhang","Jenny Ma","Alyssa Hwang","Lydia B. Chilton"],"pdf_url":"https://arxiv.org/pdf/2410.03882v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.03866v1","updated":"2024-10-04T19:01:37Z","published":"2024-10-04T19:01:37Z","title":"A Tool to Facilitate Web-Browsing","summary":"  Search engine results often misalign with users' goals due to opaque\nalgorithms, leading to unhelpful or detrimental information consumption. To\naddress this, we developed a Google Chrome plugin that provides \"content\nlabels\" for webpages in Google search results, assessing Actionability (guiding\nactions), Knowledge (enhancing understanding), and Emotion. Using natural\nlanguage processing and machine learning, the plugin predicts these properties\nfrom webpage text based on models trained on participants' ratings, effectively\nreflecting user perceptions. The implications include enhanced user control\nover information consumption and promotion of healthier engagement with online\ncontent, potentially improving decision-making and well-being.\n","authors":["Christopher Kelly","Jonatan Fontanez","Tali Sharot"],"pdf_url":"https://arxiv.org/pdf/2410.03866v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.18918v2","updated":"2024-10-04T18:55:19Z","published":"2024-07-08T18:08:01Z","title":"Review on the Role of Virtual Reality in Reducing Mental Health Diseases\n  Specifically Stress, Anxiety, and Depression","summary":"  Objective: Virtual Reality (VR) is a technological interface that allows\nusers to interact with a simulated environment. VR has been used extensively\nfor mental health and clinical research. Mental health disorders are globally\nburdening health problems in the world. According to the Psychological\nInterventions Implementation Manual published by WHO on 6th March 2024, around\none in eight people in the world lived with a mental disorder. This literature\nreview is synthesized to find out the effects of VR therapy on stress, anxiety\nand depression. Method: We used Google Scholar database using keywords of VR,\nstress, anxiety and depression. Publication from last ten years (2014 to 1024)\nare considered. Researches only in the English language are included. All the\npapers and articles with the keyword VR missing were rejected. Result: Google\nScholar yielded 17,700 results from our keywords. Nine studies met our search\ncriteria that are included in this review. Out of nine, five studies\nencountered mental stress and gave effective results in reducing it by VR\ntherapy. The other four targeted mood disorders, Social anxiety disorders,\ndepression, loss of happiness and sleep deprivation. They also showed immense\npotential in reducing mental illness while using VR. Conclusion: Findings are\nin favor of the effectiveness of VR in reducing stress, anxiety and depression.\nStill, it is insufficient evidence to consider VR as solely independent\ntreatment over the traditional medication. In future, the limitations can be\novercome to relying on VR and using it in hospitals as a reliable source of\ncure for mental illness.\n","authors":["Sadia Saeed","Khan Bahadar Khan","Muhammad Abul Hassan","Abdul Qayyum","Saba Salahuddin"],"pdf_url":"https://arxiv.org/pdf/2407.18918v2.pdf","comment":"12 pages, 3 figures, 2 tables"},{"id":"http://arxiv.org/abs/2410.03642v1","updated":"2024-10-04T17:48:29Z","published":"2024-10-04T17:48:29Z","title":"Aligning LLMs with Individual Preferences via Interaction","summary":"  As large language models (LLMs) demonstrate increasingly advanced\ncapabilities, aligning their behaviors with human values and preferences\nbecomes crucial for their wide adoption. While previous research focuses on\ngeneral alignment to principles such as helpfulness, harmlessness, and honesty,\nthe need to account for individual and diverse preferences has been largely\noverlooked, potentially undermining customized human experiences. To address\nthis gap, we train LLMs that can ''interact to align'', essentially cultivating\nthe meta-skill of LLMs to implicitly infer the unspoken personalized\npreferences of the current user through multi-turn conversations, and then\ndynamically align their following behaviors and responses to these inferred\npreferences. Our approach involves establishing a diverse pool of 3,310\ndistinct user personas by initially creating seed examples, which are then\nexpanded through iterative self-generation and filtering. Guided by distinct\nuser personas, we leverage multi-LLM collaboration to develop a multi-turn\npreference dataset containing 3K+ multi-turn conversations in tree structures.\nFinally, we apply supervised fine-tuning and reinforcement learning to enhance\nLLMs using this dataset. For evaluation, we establish the ALOE (ALign With\nCustOmized PrEferences) benchmark, consisting of 100 carefully selected\nexamples and well-designed metrics to measure the customized alignment\nperformance during conversations. Experimental results demonstrate the\neffectiveness of our method in enabling dynamic, personalized alignment via\ninteraction.\n","authors":["Shujin Wu","May Fung","Cheng Qian","Jeonghwan Kim","Dilek Hakkani-Tur","Heng Ji"],"pdf_url":"https://arxiv.org/pdf/2410.03642v1.pdf","comment":"The code and dataset are made public at\n  https://github.com/ShujinWu-0814/ALOE"},{"id":"http://arxiv.org/abs/2407.18215v2","updated":"2024-10-04T17:35:24Z","published":"2024-07-25T17:28:30Z","title":"Tool-Assisted Learning of Computational Reductions","summary":"  Computational reductions are an important and powerful concept in computer\nscience. However, they are difficult for many students to grasp. In this paper,\nwe outline a concept for how the learning of reductions can be supported by\neducational support systems. We present an implementation of the concept within\nsuch a system, concrete web-based and interactive learning material for\nreductions, and report on our experiences using the material in a large\nintroductory course on theoretical computer science.\n","authors":["Tristan Kneisel","Elias Radtke","Marko Schmellenkamp","Fabian Vehlken","Thomas Zeume"],"pdf_url":"https://arxiv.org/pdf/2407.18215v2.pdf","comment":"Fixed a typo compared to last version; 6 pages + references,\n  including one page of screenshots; accepted at SIGCSE TS 2025"},{"id":"http://arxiv.org/abs/2311.08644v3","updated":"2024-10-04T17:23:15Z","published":"2023-11-15T01:50:53Z","title":"Wrapper Boxes: Faithful Attribution of Model Predictions to Training\n  Data","summary":"  Can we preserve the accuracy of neural models while also providing faithful\nexplanations of model decisions to training data? We propose a \"wrapper box''\npipeline: training a neural model as usual and then using its learned feature\nrepresentation in classic, interpretable models to perform prediction. Across\nseven language models of varying sizes, including four large language models\n(LLMs), two datasets at different scales, three classic models, and four\nevaluation metrics, we first show that the predictive performance of wrapper\nclassic models is largely comparable to the original neural models.\n  Because classic models are transparent, each model decision is determined by\na known set of training examples that can be directly shown to users. Our\npipeline thus preserves the predictive performance of neural language models\nwhile faithfully attributing classic model decisions to training data. Among\nother use cases, such attribution enables model decisions to be contested based\non responsible training instances. Compared to prior work, our approach\nachieves higher coverage and correctness in identifying which training data to\nremove to change a model decision. To reproduce findings, our source code is\nonline at: https://github.com/SamSoup/WrapperBox.\n","authors":["Yiheng Su","Junyi Jessy Li","Matthew Lease"],"pdf_url":"https://arxiv.org/pdf/2311.08644v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.03608v1","updated":"2024-10-04T17:09:08Z","published":"2024-10-04T17:09:08Z","title":"TICKing All the Boxes: Generated Checklists Improve LLM Evaluation and\n  Generation","summary":"  Given the widespread adoption and usage of Large Language Models (LLMs), it\nis crucial to have flexible and interpretable evaluations of their\ninstruction-following ability. Preference judgments between model outputs have\nbecome the de facto evaluation standard, despite distilling complex,\nmulti-faceted preferences into a single ranking. Furthermore, as human\nannotation is slow and costly, LLMs are increasingly used to make these\njudgments, at the expense of reliability and interpretability. In this work, we\npropose TICK (Targeted Instruct-evaluation with ChecKlists), a fully automated,\ninterpretable evaluation protocol that structures evaluations with\nLLM-generated, instruction-specific checklists. We first show that, given an\ninstruction, LLMs can reliably produce high-quality, tailored evaluation\nchecklists that decompose the instruction into a series of YES/NO questions.\nEach question asks whether a candidate response meets a specific requirement of\nthe instruction. We demonstrate that using TICK leads to a significant increase\n(46.4% $\\to$ 52.2%) in the frequency of exact agreements between LLM judgements\nand human preferences, as compared to having an LLM directly score an output.\nWe then show that STICK (Self-TICK) can be used to improve generation quality\nacross multiple benchmarks via self-refinement and Best-of-N selection. STICK\nself-refinement on LiveBench reasoning tasks leads to an absolute gain of\n$+$7.8%, whilst Best-of-N selection with STICK attains $+$6.3% absolute\nimprovement on the real-world instruction dataset, WildBench. In light of this,\nstructured, multi-faceted self-improvement is shown to be a promising way to\nfurther advance LLM capabilities. Finally, by providing LLM-generated\nchecklists to human evaluators tasked with directly scoring LLM responses to\nWildBench instructions, we notably increase inter-annotator agreement (0.194\n$\\to$ 0.256).\n","authors":["Jonathan Cook","Tim Rocktäschel","Jakob Foerster","Dennis Aumiller","Alex Wang"],"pdf_url":"https://arxiv.org/pdf/2410.03608v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.11229v2","updated":"2024-10-04T16:52:57Z","published":"2024-07-15T20:29:24Z","title":"Unraveling the Truth: Do VLMs really Understand Charts? A Deep Dive into\n  Consistency and Robustness","summary":"  Chart question answering (CQA) is a crucial area of Visual Language\nUnderstanding. However, the robustness and consistency of current Visual\nLanguage Models (VLMs) in this field remain under-explored. This paper\nevaluates state-of-the-art VLMs on comprehensive datasets, developed\nspecifically for this study, encompassing diverse question categories and chart\nformats. We investigate two key aspects: 1) the models' ability to handle\nvarying levels of chart and question complexity, and 2) their robustness across\ndifferent visual representations of the same underlying data. Our analysis\nreveals significant performance variations based on question and chart types,\nhighlighting both strengths and weaknesses of current models. Additionally, we\nidentify areas for improvement and propose future research directions to build\nmore robust and reliable CQA systems. This study sheds light on the limitations\nof current models and paves the way for future advancements in the field.\n","authors":["Srija Mukhopadhyay","Adnan Qidwai","Aparna Garimella","Pritika Ramu","Vivek Gupta","Dan Roth"],"pdf_url":"https://arxiv.org/pdf/2407.11229v2.pdf","comment":"22 pages, 9 Tables, 5 figures, 22 examples"},{"id":"http://arxiv.org/abs/2406.02018v2","updated":"2024-10-04T16:46:00Z","published":"2024-06-04T06:57:47Z","title":"Why Would You Suggest That? Human Trust in Language Model Responses","summary":"  The emergence of Large Language Models (LLMs) has revealed a growing need for\nhuman-AI collaboration, especially in creative decision-making scenarios where\ntrust and reliance are paramount. Through human studies and model evaluations\non the open-ended News Headline Generation task from the LaMP benchmark, we\nanalyze how the framing and presence of explanations affect user trust and\nmodel performance. Overall, we provide evidence that adding an explanation in\nthe model response to justify its reasoning significantly increases\nself-reported user trust in the model when the user has the opportunity to\ncompare various responses. Position and faithfulness of these explanations are\nalso important factors. However, these gains disappear when users are shown\nresponses independently, suggesting that humans trust all model responses,\nincluding deceptive ones, equitably when they are shown in isolation. Our\nfindings urge future research to delve deeper into the nuanced evaluation of\ntrust in human-machine teaming systems.\n","authors":["Manasi Sharma","Ho Chit Siu","Rohan Paleja","Jaime D. Peña"],"pdf_url":"https://arxiv.org/pdf/2406.02018v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.03571v1","updated":"2024-10-04T16:20:39Z","published":"2024-10-04T16:20:39Z","title":"Generative AI in the Software Engineering Domain: Tensions of\n  Occupational Identity and Patterns of Identity Protection","summary":"  The adoption of generative Artificial Intelligence (GAI) in organizational\nsettings calls into question workers' roles, and relatedly, the implications\nfor their long-term skill development and domain expertise. In our qualitative\nstudy in the software engineering domain, we build on the theoretical lenses of\noccupational identity and self-determination theory to understand how and why\nsoftware engineers make sense of GAI for their work. We find that engineers'\nsense-making is contingent on domain expertise, as juniors and seniors felt\ntheir needs for competence, autonomy, and relatedness to be differently\nimpacted by GAI. We shed light on the importance of the individual's role in\npreserving tacit domain knowledge as engineers engaged in sense-making that\nprotected their occupational identity. We illustrate how organizations play an\nactive role in shaping workers' sense-making process and propose design\nguidelines on how organizations and system designers can facilitate the impact\nof technological change on workers' occupational identity.\n","authors":["Anuschka Schmitt","Krzysztof Z. Gajos","Osnat Mokryn"],"pdf_url":"https://arxiv.org/pdf/2410.03571v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.03525v1","updated":"2024-10-04T15:45:41Z","published":"2024-10-04T15:45:41Z","title":"Artificial Human Lecturers: Initial Findings From Asia's First AI\n  Lecturers in Class to Promote Innovation in Education","summary":"  In recent years, artificial intelligence (AI) has become increasingly\nintegrated into education, reshaping traditional learning environments. Despite\nthis, there has been limited investigation into fully operational artificial\nhuman lecturers. To the best of our knowledge, our paper presents the world's\nfirst study examining their deployment in a real-world educational setting.\nSpecifically, we investigate the use of \"digital teachers,\" AI-powered virtual\nlecturers, in a postgraduate course at the Hong Kong University of Science and\nTechnology (HKUST). Our study explores how features such as appearance,\nnon-verbal cues, voice, and verbal expression impact students' learning\nexperiences. Findings suggest that students highly value naturalness,\nauthenticity, and interactivity in digital teachers, highlighting areas for\nimprovement, such as increased responsiveness, personalized avatars, and\nintegration with larger learning platforms. We conclude that digital teachers\nhave significant potential to enhance education by providing a more flexible,\nengaging, personalized, and accessible learning experience for students.\n","authors":["Ching Christie Pang","Yawei Zhao","Zhizhuo Yin","Jia Sun","Reza Hadi Mogavi","Pan Hui"],"pdf_url":"https://arxiv.org/pdf/2410.03525v1.pdf","comment":"28 pages, 6 figures (10 sub-figures), 3 tables"},{"id":"http://arxiv.org/abs/2403.07721v7","updated":"2024-10-04T14:36:04Z","published":"2024-03-12T14:58:57Z","title":"Visual Decoding and Reconstruction via EEG Embeddings with Guided\n  Diffusion","summary":"  How to decode human vision through neural signals has attracted a\nlong-standing interest in neuroscience and machine learning. Modern contrastive\nlearning and generative models improved the performance of visual decoding and\nreconstruction based on functional Magnetic Resonance Imaging (fMRI). However,\nthe high cost and low temporal resolution of fMRI limit their applications in\nbrain-computer interfaces (BCIs), prompting a high need for visual decoding\nbased on electroencephalography (EEG). In this study, we present an end-to-end\nEEG-based visual reconstruction zero-shot framework, consisting of a tailored\nbrain encoder, called the Adaptive Thinking Mapper (ATM), which projects neural\nsignals from different sources into the shared subspace as the clip embedding,\nand a two-stage multi-pipe EEG-to-image generation strategy. In stage one, EEG\nis embedded to align the high-level clip embedding, and then the prior\ndiffusion model refines EEG embedding into image priors. A blurry image also\ndecoded from EEG for maintaining the low-level feature. In stage two, we input\nboth the high-level clip embedding, the blurry image and caption from EEG\nlatent to a pre-trained diffusion model. Furthermore, we analyzed the impacts\nof different time windows and brain regions on decoding and reconstruction. The\nversatility of our framework is demonstrated in the magnetoencephalogram (MEG)\ndata modality. The experimental results indicate that our EEG-based visual\nzero-shot framework achieves SOTA performance in classification, retrieval and\nreconstruction, highlighting the portability, low cost, and high temporal\nresolution of EEG, enabling a wide range of BCI applications. Our code is\navailable at https://github.com/ncclab-sustech/EEG_Image_decode.\n","authors":["Dongyang Li","Chen Wei","Shiying Li","Jiachen Zou","Haoyang Qin","Quanying Liu"],"pdf_url":"https://arxiv.org/pdf/2403.07721v7.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.03448v1","updated":"2024-10-04T14:09:12Z","published":"2024-10-04T14:09:12Z","title":"How Toxicity Classifiers and Large Language Models Respond to Ableism","summary":"  People with disabilities (PwD) regularly encounter ableist hate and\nmicroaggressions online. While online platforms use machine learning models to\nmoderate online harm, there is little research investigating how these models\ninteract with ableism. In this paper, we curated a dataset of 100 social media\ncomments targeted towards PwD, and recruited 160 participants to rate and\nexplain how toxic and ableist these comments were. We then prompted\nstate-of-the art toxicity classifiers (TCs) and large language models (LLMs) to\nrate and explain the harm. Our analysis revealed that TCs and LLMs rated\ntoxicity significantly lower than PwD, but LLMs rated ableism generally on par\nwith PwD. However, ableism explanations by LLMs overlooked emotional harm, and\nlacked specificity and acknowledgement of context, important facets of PwD\nexplanations. Going forward, we discuss challenges in designing\ndisability-aware toxicity classifiers, and advocate for the shift from ableism\ndetection to ableism interpretation and explanation.\n","authors":["Mahika Phutane","Ananya Seelam","Aditya Vashistha"],"pdf_url":"https://arxiv.org/pdf/2410.03448v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.03811v1","updated":"2024-10-04T13:46:58Z","published":"2024-10-04T13:46:58Z","title":"Enhanced Digital Twin for Human-Centric and Integrated Lighting Asset\n  Management in Public Libraries: From Corrective to Predictive Maintenance","summary":"  Lighting asset management in public libraries has traditionally been\nreactive, focusing on corrective maintenance, addressing issues only when\nfailures occur. Although standards now encourage preventive measures, such as\nincorporating a maintenance factor, the broader goal of human centric,\nsustainable lighting systems requires a shift toward predictive maintenance\nstrategies. This study introduces an enhanced digital twin model designed for\nthe proactive management of lighting assets in public libraries. By integrating\ndescriptive, diagnostic, predictive, and prescriptive analytics, the model\nenables a comprehensive, multilevel view of asset health. The proposed\nframework supports both preventive and predictive maintenance strategies,\nallowing for early detection of issues and the timely resolution of potential\nfailures. In addition to the specific application for lighting systems, the\ndesign is adaptable for other building assets, providing a scalable solution\nfor integrated asset management in various public spaces.\n","authors":["Jing Lin","Jingchun Shen"],"pdf_url":"https://arxiv.org/pdf/2410.03811v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.03434v1","updated":"2024-10-04T13:45:50Z","published":"2024-10-04T13:45:50Z","title":"Self-supervised Spatio-Temporal Graph Mask-Passing Attention Network for\n  Perceptual Importance Prediction of Multi-point Tactility","summary":"  While visual and auditory information are prevalent in modern multimedia\nsystems, haptic interaction, e.g., tactile and kinesthetic interaction,\nprovides a unique form of human perception. However, multimedia technology for\ncontact interaction is less mature than non-contact multimedia technologies and\nrequires further development. Specialized haptic media technologies, requiring\nlow latency and bitrates, are essential to enable haptic interaction,\nnecessitating haptic information compression. Existing vibrotactile signal\ncompression methods, based on the perceptual model, do not consider the\ncharacteristics of fused tactile perception at multiple spatially distributed\ninteraction points. In fact, differences in tactile perceptual importance are\nnot limited to conventional frequency and time domains, but also encompass\ndifferences in the spatial locations on the skin unique to tactile perception.\nFor the most frequently used tactile information, vibrotactile texture\nperception, we have developed a model to predict its perceptual importance at\nmultiple points, based on self-supervised learning and Spatio-Temporal Graph\nNeural Network. Current experimental results indicate that this model can\neffectively predict the perceptual importance of various points in multi-point\ntactile perception scenarios.\n","authors":["Dazhong He","Qian Liu"],"pdf_url":"https://arxiv.org/pdf/2410.03434v1.pdf","comment":"Published as a conference paper at Eurohaptics 2024"},{"id":"http://arxiv.org/abs/2404.06919v3","updated":"2024-10-04T10:55:17Z","published":"2024-04-10T11:10:50Z","title":"Longitudinal Analysis and Quantitative Assessment of Child Development\n  through Mobile Interaction","summary":"  This article provides a comprehensive overview of recent research in the area\nof Child-Computer Interaction (CCI). The main contributions of the present\narticle are two-fold. First, we present a novel longitudinal CCI database named\nChildCIdbLong, which comprises over 600 children aged 18 months to 8 years old,\nacquired continuously over 4 academic years (2019-2023). As a result,\nChildCIdbLong comprises over 12K test acquisitions over a tablet device.\nDifferent tests are considered in ChildCIdbLong, requiring different touch and\nstylus gestures, enabling the evaluation of praxical and cognitive skills such\nas attentional, visuo-spatial, and executive, among others. In addition to the\nChildCIdbLong database, we propose a novel quantitative metric called Test\nQuality (Q), designed to measure the motor and cognitive development of\nchildren through their interaction with a tablet device. In order to provide a\nbetter comprehension of the proposed Q metric, popular percentile-based growth\nrepresentations are introduced for each test, providing a two-dimensional space\nto compare children's development with respect to the typical age skills of the\npopulation. The results achieved in the present article highlight the potential\nof the novel ChildCIdbLong database in conjunction with the proposed Q metric\nto measure the motor and cognitive development of children as they grow up. The\nproposed framework could be very useful as an automatic tool to support child\nexperts (e.g., paediatricians, educators, or neurologists) for early detection\nof potential physical/cognitive impairments during children's development.\n","authors":["Juan Carlos Ruiz-Garcia","Ruben Tolosana","Ruben Vera-Rodriguez","Aythami Morales","Julian Fierrez","Javier Ortega-Garcia","Jaime Herreros-Rodriguez"],"pdf_url":"https://arxiv.org/pdf/2404.06919v3.pdf","comment":"13 pages, 5 figures, 7 tables, 46 references"},{"id":"http://arxiv.org/abs/2410.03268v1","updated":"2024-10-04T09:39:17Z","published":"2024-10-04T09:39:17Z","title":"Narrative Player: Reviving Data Narratives with Visuals","summary":"  Data-rich documents are commonly found across various fields such as\nbusiness, finance, and science. However, a general limitation of these\ndocuments for reading is their reliance on text to convey data and facts.\nVisual representation of text aids in providing a satisfactory reading\nexperience in comprehension and engagement. However, existing work emphasizes\npresenting the insights of local text context, rather than fully conveying data\nstories within the whole paragraphs and engaging readers. To provide readers\nwith satisfactory data stories, this paper presents Narrative Player, a novel\nmethod that automatically revives data narratives with consistent and\ncontextualized visuals. Specifically, it accepts a paragraph and corresponding\ndata table as input and leverages LLMs to characterize the clauses and extract\ncontextualized data facts. Subsequently, the facts are transformed into a\ncoherent visualization sequence with a carefully designed optimization-based\napproach. Animations are also assigned between adjacent visualizations to\nenable seamless transitions. Finally, the visualization sequence, transition\nanimations, and audio narration generated by text-to-speech technologies are\nrendered into a data video. The evaluation results showed that the\nautomatic-generated data videos were well-received by participants and experts\nfor enhancing reading.\n","authors":["Zekai Shao","Leixian Shen","Haotian Li","Yi Shan","Huamin Qu","Yun Wang","Siming Chen"],"pdf_url":"https://arxiv.org/pdf/2410.03268v1.pdf","comment":"11 pages, 7 figures"},{"id":"http://arxiv.org/abs/2109.03631v4","updated":"2024-10-04T08:54:39Z","published":"2021-09-08T13:23:25Z","title":"Renovo: Sensor-Based Visual Assistive Technology for Physiotherapists in\n  the Rehabilitation of Stroke Patients with Upper Limb Motor Impairments","summary":"  Stroke patients with upper limb motor impairments are re-acclimated to their\ncorresponding motor functionalities through therapeutic interventions.\nPhysiotherapists typically assess these functionalities using various\nqualitative protocols. However, such assessments are often biased and prone to\nerrors, reducing rehabilitation efficacy. Therefore, real-time visualization\nand quantitative analysis of performance metrics, such as range of motion,\nrepetition rate, velocity, etc., are crucial for accurate progress assessment.\nThis study introduces Renovo, a working prototype of a wearable motion\nsensor-based assistive technology that assists physiotherapists with real-time\nvisualization of these metrics. We also propose a novel mathematical framework\nfor generating quantitative performance scores without relying on any machine\nlearning model. We present the results of a three-week pilot study involving 16\nstroke patients with upper limb disabilities, evaluated across three successive\nsessions at one-week intervals by both Renovo and physiotherapists (N=5).\nResults suggest that while the expertise of a physiotherapist is irreplaceable,\nRenovo can assist in the decision-making process by providing valuable\nquantitative information.\n","authors":["Mohammad Ridwan Kabir","Mohammad Ishrak Abedin","Mohaimin Ehsan","Mohammad Anas Jawad","Hasan Mahmud","Md. Kamrul Hasan"],"pdf_url":"https://arxiv.org/pdf/2109.03631v4.pdf","comment":"41 pages, 14 figures, 4 tables"},{"id":"http://arxiv.org/abs/2409.14247v2","updated":"2024-10-04T08:49:43Z","published":"2024-09-21T21:06:25Z","title":"Repairs in a Block World: A New Benchmark for Handling User Corrections\n  with Multi-Modal Language Models","summary":"  In dialogue, the addressee may initially misunderstand the speaker and\nrespond erroneously, often prompting the speaker to correct the\nmisunderstanding in the next turn with a Third Position Repair (TPR). The\nability to process and respond appropriately to such repair sequences is thus\ncrucial in conversational AI systems. In this paper, we first collect, analyse,\nand publicly release BlockWorld-Repairs: a dataset of multi-modal TPR sequences\nin an instruction-following manipulation task that is, by design, rife with\nreferential ambiguity. We employ this dataset to evaluate several\nstate-of-the-art Vision and Language Models (VLM) across multiple settings,\nfocusing on their capability to process and accurately respond to TPRs and thus\nrecover from miscommunication. We find that, compared to humans, all models\nsignificantly underperform in this task. We then show that VLMs can benefit\nfrom specialised losses targeting relevant tokens during fine-tuning, achieving\nbetter performance and generalising better to new scenarios. Our results\nsuggest that these models are not yet ready to be deployed in multi-modal\ncollaborative settings where repairs are common, and highlight the need to\ndesign training regimes and objectives that facilitate learning from\ninteraction. Our code and data are available at\nwww.github.com/JChiyah/blockworld-repairs\n","authors":["Javier Chiyah-Garcia","Alessandro Suglia","Arash Eshghi"],"pdf_url":"https://arxiv.org/pdf/2409.14247v2.pdf","comment":"Accepted to EMNLP'24 Main (Upcoming). Data and code at\n  www.github.com/JChiyah/blockworld-repairs - for Bibtex see\n  https://raw.githubusercontent.com/JChiyah/blockworld-repairs/refs/heads/main/citation.bib"},{"id":"http://arxiv.org/abs/2410.03224v1","updated":"2024-10-04T08:23:56Z","published":"2024-10-04T08:23:56Z","title":"ScriptViz: A Visualization Tool to Aid Scriptwriting based on a Large\n  Movie Database","summary":"  Scriptwriters usually rely on their mental visualization to create a vivid\nstory by using their imagination to see, feel, and experience the scenes they\nare writing. Besides mental visualization, they often refer to existing images\nor scenes in movies and analyze the visual elements to create a certain mood or\natmosphere. In this paper, we develop ScriptViz to provide external\nvisualization based on a large movie database for the screenwriting process. It\nretrieves reference visuals on the fly based on scripts' text and dialogue from\na large movie database. The tool provides two types of control on visual\nelements that enable writers to 1) see exactly what they want with fixed visual\nelements and 2) see variances in uncertain elements. User evaluation among 15\nscriptwriters shows that ScriptViz is able to present scriptwriters with\nconsistent yet diverse visual possibilities, aligning closely with their\nscripts and helping their creation.\n","authors":["Anyi Rao","Jean-Peïc Chou","Maneesh Agrawala"],"pdf_url":"https://arxiv.org/pdf/2410.03224v1.pdf","comment":"Accepted in the 37th Annual ACM Symposium on User Interface Software\n  and Technology (UIST'24). Webpage:\n  https://virtualfilmstudio.github.io/projects/scriptviz"},{"id":"http://arxiv.org/abs/2410.03800v1","updated":"2024-10-04T07:52:46Z","published":"2024-10-04T07:52:46Z","title":"M2AR: A Web-based Modeling Environment for the Augmented Reality\n  Workflow Modeling Language","summary":"  This paper introduces M2AR, a new web-based, two- and three-dimensional\nmodeling environment that enables the modeling and execution of augmented\nreality applications without requiring programming knowledge. The platform is\nbased on a 3D JavaScript library and the mixed reality immersive web standard\nWebXR. For a first demonstration of its feasibility, the previously introduced\nAugmented Reality Workflow Modeling Language (ARWFML) has been successfully\nimplemented using this environment. The usefulness of the new modeling\nenvironment is demonstrated by showing use cases of the ARWFML on M2AR.\n","authors":["Fabian Muff","Hans-Georg Fill"],"pdf_url":"https://arxiv.org/pdf/2410.03800v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.03207v1","updated":"2024-10-04T07:44:01Z","published":"2024-10-04T07:44:01Z","title":"StoryNavi: On-Demand Narrative-Driven Reconstruction of Video Play With\n  Generative AI","summary":"  Manually navigating lengthy videos to seek information or answer questions\ncan be a tedious and time-consuming task for users. We introduce StoryNavi, a\nnovel system powered by VLLMs for generating customised video play experiences\nby retrieving materials from original videos. It directly answers users' query\nby constructing non-linear sequence with identified relevant clips to form a\ncohesive narrative. StoryNavi offers two modes of playback of the constructed\nvideo plays: 1) video-centric, which plays original audio and skips irrelevant\nsegments, and 2) narrative-centric, narration guides the experience, and the\noriginal audio is muted. Our technical evaluation showed adequate retrieval\nperformance compared to human retrieval. Our user evaluation shows that\nmaintaining narrative coherence significantly enhances user engagement when\nviewing disjointed video segments. However, factors like video genre, content,\nand the query itself may lead to varying user preferences for the playback\nmode.\n","authors":["Alston Lantian Xu","Tianwei Ma","Tianmeng Liu","Can Liu","Alvaro Cassinelli"],"pdf_url":"https://arxiv.org/pdf/2410.03207v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2203.14187v2","updated":"2024-10-04T05:52:42Z","published":"2022-03-27T02:21:19Z","title":"Educational Question Generation of Children Storybooks via Question Type\n  Distribution Learning and Event-Centric Summarization","summary":"  Generating educational questions of fairytales or storybooks is vital for\nimproving children's literacy ability. However, it is challenging to generate\nquestions that capture the interesting aspects of a fairytale story with\neducational meaningfulness. In this paper, we propose a novel question\ngeneration method that first learns the question type distribution of an input\nstory paragraph, and then summarizes salient events which can be used to\ngenerate high-cognitive-demand questions. To train the event-centric\nsummarizer, we finetune a pre-trained transformer-based sequence-to-sequence\nmodel using silver samples composed by educational question-answer pairs. On a\nnewly proposed educational question answering dataset FairytaleQA, we show good\nperformance of our method on both automatic and human evaluation metrics. Our\nwork indicates the necessity of decomposing question type distribution learning\nand event-centric summary generation for educational question generation.\n","authors":["Zhenjie Zhao","Yufang Hou","Dakuo Wang","Mo Yu","Chengzhong Liu","Xiaojuan Ma"],"pdf_url":"https://arxiv.org/pdf/2203.14187v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.03147v1","updated":"2024-10-04T05:07:55Z","published":"2024-10-04T05:07:55Z","title":"Analysis and Detection of Differences in Spoken User Behaviors between\n  Autonomous and Wizard-of-Oz Systems","summary":"  This study examined users' behavioral differences in a large corpus of\nJapanese human-robot interactions, comparing interactions between a\ntele-operated robot and an autonomous dialogue system. We analyzed user spoken\nbehaviors in both attentive listening and job interview dialogue scenarios.\nResults revealed significant differences in metrics such as speech length,\nspeaking rate, fillers, backchannels, disfluencies, and laughter between\noperator-controlled and autonomous conditions. Furthermore, we developed\npredictive models to distinguish between operator and autonomous system\nconditions. Our models demonstrated higher accuracy and precision compared to\nthe baseline model, with several models also achieving a higher F1 score than\nthe baseline.\n","authors":["Mikey Elmers","Koji Inoue","Divesh Lala","Keiko Ochi","Tatsuya Kawahara"],"pdf_url":"https://arxiv.org/pdf/2410.03147v1.pdf","comment":"Accepted and will be presented at the 27th conference of the Oriental\n  COCOSDA (O-COCOSDA 2024)"},{"id":"http://arxiv.org/abs/2410.03126v1","updated":"2024-10-04T03:43:26Z","published":"2024-10-04T03:43:26Z","title":"Understanding Decision Subjects' Engagement with and Perceived Fairness\n  of AI Models When Opportunities of Qualification Improvement Exist","summary":"  We explore how an AI model's decision fairness affects people's engagement\nwith and perceived fairness of the model if they are subject to its decisions,\nbut could repeatedly and strategically respond to these decisions. Two types of\nstrategic responses are considered -- people could determine whether to\ncontinue interacting with the model, and whether to invest in themselves to\nimprove their chance of future favorable decisions from the model. Via three\nhuman-subject experiments, we found that in decision subjects' strategic,\nrepeated interactions with an AI model, the model's decision fairness does not\nchange their willingness to interact with the model or to improve themselves,\neven when the model exhibits unfairness on salient protected attributes.\nHowever, decision subjects still perceive the AI model to be less fair when it\nsystematically biases against their group, especially if the difficulty of\nimproving one's qualification for the favorable decision is larger for the\nlowly-qualified people.\n","authors":["Meric Altug Gemalmaz","Ming Yin"],"pdf_url":"https://arxiv.org/pdf/2410.03126v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.03093v1","updated":"2024-10-04T02:34:53Z","published":"2024-10-04T02:34:53Z","title":"Data Playwright: Authoring Data Videos with Annotated Narration","summary":"  Creating data videos that effectively narrate stories with animated visuals\nrequires substantial effort and expertise. A promising research trend is\nleveraging the easy-to-use natural language (NL) interaction to automatically\nsynthesize data video components from narrative content like text narrations,\nor NL commands that specify user-required designs. Nevertheless, previous\nresearch has overlooked the integration of narrative content and specific\ndesign authoring commands, leading to generated results that lack customization\nor fail to seamlessly fit into the narrative context. To address these issues,\nwe introduce a novel paradigm for creating data videos, which seamlessly\nintegrates users' authoring and narrative intents in a unified format called\nannotated narration, allowing users to incorporate NL commands for design\nauthoring as inline annotations within the narration text. Informed by a\nformative study on users' preference for annotated narration, we develop a\nprototype system named Data Playwright that embodies this paradigm for\neffective creation of data videos. Within Data Playwright, users can write\nannotated narration based on uploaded visualizations. The system's interpreter\nautomatically understands users' inputs and synthesizes data videos with\nnarration-animation interplay, powered by large language models. Finally, users\ncan preview and fine-tune the video. A user study demonstrated that\nparticipants can effectively create data videos with Data Playwright by\neffortlessly articulating their desired outcomes through annotated narration.\n","authors":["Leixian Shen","Haotian Li","Yun Wang","Tianqi Luo","Yuyu Luo","Huamin Qu"],"pdf_url":"https://arxiv.org/pdf/2410.03093v1.pdf","comment":"11 pages, 7 figures, accepted by IEEE TVCG"},{"id":"http://arxiv.org/abs/2404.18533v3","updated":"2024-10-04T01:21:28Z","published":"2024-04-29T09:20:25Z","title":"Evaluating Readability and Faithfulness of Concept-based Explanations","summary":"  With the growing popularity of general-purpose Large Language Models (LLMs),\ncomes a need for more global explanations of model behaviors. Concept-based\nexplanations arise as a promising avenue for explaining high-level patterns\nlearned by LLMs. Yet their evaluation poses unique challenges, especially due\nto their non-local nature and high dimensional representation in a model's\nhidden space. Current methods approach concepts from different perspectives,\nlacking a unified formalization. This makes evaluating the core measures of\nconcepts, namely faithfulness or readability, challenging. To bridge the gap,\nwe introduce a formal definition of concepts generalizing to diverse\nconcept-based explanations' settings. Based on this, we quantify the\nfaithfulness of a concept explanation via perturbation. We ensure adequate\nperturbation in the high-dimensional space for different concepts via an\noptimization problem. Readability is approximated via an automatic and\ndeterministic measure, quantifying the coherence of patterns that maximally\nactivate a concept while aligning with human understanding. Finally, based on\nmeasurement theory, we apply a meta-evaluation method for evaluating these\nmeasures, generalizable to other types of explanations or tasks as well.\nExtensive experimental analysis has been conducted to inform the selection of\nexplanation evaluation measures.\n","authors":["Meng Li","Haoran Jin","Ruixuan Huang","Zhihao Xu","Defu Lian","Zijia Lin","Di Zhang","Xiting Wang"],"pdf_url":"https://arxiv.org/pdf/2404.18533v3.pdf","comment":"EMNLP 2024; code:\n  https://github.com/hr-jin/Concept-Explanation-Evaluation"}],"Programming Languages":[{"id":"http://arxiv.org/abs/2101.08181v5","updated":"2024-10-04T15:07:12Z","published":"2021-01-20T15:29:27Z","title":"Fair Asynchronous Session Subtyping","summary":"  Session types are widely used as abstractions of asynchronous message passing\nsystems. Refinement for such abstractions is crucial as it allows improvements\nof a given component without compromising its compatibility with the rest of\nthe system. In the context of session types, the most general notion of\nrefinement is asynchronous session subtyping, which allows message emissions to\nbe anticipated w.r.t. a bounded amount of message consumptions. In this paper\nwe investigate the possibility to anticipate emissions w.r.t. an unbounded\namount of consumptions: to this aim we propose to consider fair compliance over\nasynchronous session types and fair refinement as the relation that preserves\nit. This allows us to propose a novel variant of session subtyping that\nleverages the notion of controllability from service contract theory and that\nis a sound characterisation of fair refinement. In addition, we show that both\nfair refinement and our novel subtyping are undecidable. We also present a\nsound algorithm which deals with examples that feature potentially unbounded\nbuffering. Finally, we present an implementation of our algorithm and an\nempirical evaluation of it on synthetic benchmarks.\n","authors":["Mario Bravetti","Julien Lange","Gianluigi Zavattaro"],"pdf_url":"https://arxiv.org/pdf/2101.08181v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.03351v1","updated":"2024-10-04T12:17:08Z","published":"2024-10-04T12:17:08Z","title":"Generating Equivalent Representations of Code By A Self-Reflection\n  Approach","summary":"  Equivalent Representations (ERs) of code are textual representations that\npreserve the same semantics as the code itself, e.g., natural language comments\nand pseudocode. ERs play a critical role in software development and\nmaintenance. However, how to automatically generate ERs of code remains an open\nchallenge. In this paper, we propose a self-reflection approach to generating\nERs of code. It enables two Large Language Models (LLMs) to work mutually and\nproduce an ER through a reflection process. Depending on whether constraints on\nERs are applied, our approach generates ERs in both open and constrained\nsettings. We conduct a empirical study to generate ERs in two settings and\nobtain eight findings. (1) Generating ERs in the open setting. In the open\nsetting, we allow LLMs to represent code without any constraints, analyzing the\nresulting ERs and uncovering five key findings. These findings shed light on\nhow LLMs comprehend syntactic structures, APIs, and numerical computations in\ncode. (2) Generating ERs in the constrained setting. In the constrained\nsetting, we impose constraints on ERs, such as natural language comments,\npseudocode, and flowcharts. This allows our approach to address a range of\nsoftware engineering tasks. Based on our experiments, we have three findings\ndemonstrating that our approach can effectively generate ERs that adhere to\nspecific constraints, thus supporting various software engineering tasks. (3)\nFuture directions. We also discuss potential future research directions, such\nas deriving intermediate languages for code generation, exploring LLM-friendly\nrequirement descriptions, and further supporting software engineering tasks. We\nbelieve that this paper will spark discussions in research communities and\ninspire many follow-up studies.\n","authors":["Jia Li","Ge Li","Lecheng Wang","Hao Zhu","Zhi Jin"],"pdf_url":"https://arxiv.org/pdf/2410.03351v1.pdf","comment":null}],"Operating Systems":[{"id":"http://arxiv.org/abs/2409.01241v3","updated":"2024-10-04T11:32:08Z","published":"2024-09-02T13:14:50Z","title":"CyberCortex.AI: An AI-based Operating System for Autonomous Robotics and\n  Complex Automation","summary":"  The underlying framework for controlling autonomous robots and complex\nautomation applications are Operating Systems (OS) capable of scheduling\nperception-and-control tasks, as well as providing real-time data communication\nto other robotic peers and remote cloud computers. In this paper, we introduce\nCyberCortex AI, a robotics OS designed to enable heterogeneous AI-based\nrobotics and complex automation applications. CyberCortex AI is a decentralized\ndistributed OS which enables robots to talk to each other, as well as to High\nPerformance Computers (HPC) in the cloud. Sensory and control data from the\nrobots is streamed towards HPC systems with the purpose of training AI\nalgorithms, which are afterwards deployed on the robots. Each functionality of\na robot (e.g. sensory data acquisition, path planning, motion control, etc.) is\nexecuted within a so-called DataBlock of Filters shared through the internet,\nwhere each filter is computed either locally on the robot itself, or remotely\non a different robotic system. The data is stored and accessed via a so-called\nTemporal Addressable Memory (TAM), which acts as a gateway between each\nfilter's input and output. CyberCortex AI has two main components: i) the\nCyberCortex AI inference system, which is a real-time implementation of the\nDataBlock running on the robots' embedded hardware, and ii) the CyberCortex AI\ndojo, which runs on an HPC computer in the cloud, and it is used to design,\ntrain and deploy AI algorithms. We present a quantitative and qualitative\nperformance analysis of the proposed approach using two collaborative robotics\napplications: i) a forest fires prevention system based on an Unitree A1 legged\nrobot and an Anafi Parrot 4K drone, as well as ii) an autonomous driving system\nwhich uses CyberCortex AI for collaborative perception and motion control.\n","authors":["Sorin Grigorescu","Mihai Zaha"],"pdf_url":"https://arxiv.org/pdf/2409.01241v3.pdf","comment":null}],"Networking and Internet Architecture":[{"id":"http://arxiv.org/abs/2305.14135v3","updated":"2024-10-04T19:24:22Z","published":"2023-05-23T14:58:09Z","title":"Reparo: Loss-Resilient Generative Codec for Video Conferencing","summary":"  Packet loss during video conferencing often results in poor quality and video\nfreezing. Retransmitting lost packets is often impractical due to the need for\nreal-time playback, and using Forward Error Correction (FEC) for packet\nrecovery is challenging due to the unpredictable and bursty nature of Internet\nlosses. Excessive redundancy leads to inefficiency and wasted bandwidth, while\ninsufficient redundancy results in undecodable frames, causing video freezes\nand quality degradation in subsequent frames.\n  We introduce Reparo -- a loss-resilient video conferencing framework based on\ngenerative deep learning models to address these issues. Our approach generates\nmissing information when a frame or part of a frame is lost. This generation is\nconditioned on the data received thus far, considering the model's\nunderstanding of how people and objects appear and interact within the visual\nrealm. Experimental results, using publicly available video conferencing\ndatasets, demonstrate that Reparo outperforms state-of-the-art FEC-based video\nconferencing solutions in terms of both video quality (measured through PSNR,\nSSIM, and LPIPS) and the occurrence of video freezes.\n","authors":["Tianhong Li","Vibhaalakshmi Sivaraman","Pantea Karimi","Lijie Fan","Mohammad Alizadeh","Dina Katabi"],"pdf_url":"https://arxiv.org/pdf/2305.14135v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.03583v1","updated":"2024-10-04T16:42:09Z","published":"2024-10-04T16:42:09Z","title":"AraSync: Precision Time Synchronization in Rural Wireless Living Lab","summary":"  Time synchronization is a critical component in network operation and\nmanagement, and it is also required by Ultra-Reliable, Low-Latency\nCommunications (URLLC) in next-generation wireless systems such as those of 5G,\n6G, and Open RAN. In this context, we design and implement AraSync as an\nend-to-end time synchronization system in the ARA wireless living lab to enable\nadvanced wireless experiments and applications involving stringent time\nconstraints. We make use of Precision Time Protocol (PTP) at different levels\nto achieve synchronization accuracy in the order of nanoseconds. Along with\nfiber networks, AraSync enables time synchronization across the AraHaul\nwireless x-haul network consisting of long-range, high-capacity mmWave and\nmicrowave links. In this paper, we present the detailed design and\nimplementation of AraSync, including its hardware and software components and\nthe PTP network topology. Further, we experimentally characterize the\nperformance of AraSync from spatial and temporal dimensions. Our measurement\nand analysis of the clock offset and mean path delay show the impact of the\nwireless channel and weather conditions on the PTP synchronization accuracy.\n","authors":["Md Nadim","Taimoor Ul Islam","Salil Reddy","Tianyi Zhang","Zhibo Meng","Reshal Afzal","Sarath Babu","Arsalan Ahmad","Daji Qiao","Anish Arora","Hongwei Zhang"],"pdf_url":"https://arxiv.org/pdf/2410.03583v1.pdf","comment":"8 pages, 10 figures, accepted in ACM WiNTECH 2024 (The 18th ACM\n  Workshop on Wireless Network Testbeds, Experimental evaluation &\n  Characterization 2024)"},{"id":"http://arxiv.org/abs/2410.03472v1","updated":"2024-10-04T14:42:33Z","published":"2024-10-04T14:42:33Z","title":"Deep Reinforcement Learning for Delay-Optimized Task Offloading in\n  Vehicular Fog Computin","summary":"  The imminent rise of autonomous vehicles (AVs) is revolutionizing the future\nof transport. The Vehicular Fog Computing (VFC) paradigm has emerged to\nalleviate the load of compute-intensive and delay-sensitive AV programs via\ntask offloading to nearby vehicles. Effective VFC requires an intelligent and\ndy?namic offloading algorithm. As a result, this paper adapts Deep\nReinforcement Learning (DRL) for VFC offloading. First, a simulation\nenvironment utilizing realistic hardware and task specifications, in addition\nto a novel vehicular movement model based on grid-planned cities, is created.\nAfterward, a DRL-based algorithm is trained and tested on the environment with\nthe goal of minimizing global task delay. The DRL model displays impressive\nresults, outperforming other greedy and conventional methods. The findings\nfurther demonstrate the effectiveness of the DRL model in minimizing queue\ncongestion, especially when compared to traditional cloud computing methods\nthat struggle to handle the demands of a large fleet of vehicles. This is\ncorroborated by queuing theory, highlighting the self-scalability of the\nVFC-based DRL approach.\n","authors":["Mohammad Parsa Toopchinezhad","Mahmood Ahmadi"],"pdf_url":"https://arxiv.org/pdf/2410.03472v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.03339v1","updated":"2024-10-04T11:53:41Z","published":"2024-10-04T11:53:41Z","title":"Tarzan: Passively-Learned Real-Time Rate Control for Video Conferencing","summary":"  Rate control algorithms are at the heart of video conferencing platforms,\ndetermining target bitrates that match dynamic network characteristics for high\nquality. Recent data-driven strategies have shown promise for this challenging\ntask, but the performance degradation they introduce during training has been a\nnonstarter for many production services, precluding adoption. This paper aims\nto bolster the practicality of data-driven rate control by presenting an\nalternative avenue for experiential learning: leveraging purely existing\ntelemetry logs produced by the incumbent algorithm in production. We observe\nthat these logs contain effective decisions, although often at the wrong times\nor in the wrong order. To realize this approach despite the inherent\nuncertainty that log-based learning brings (i.e., lack of feedback for new\ndecisions), our system, Tarzan, combines a variety of robust learning\ntechniques (i.e., conservatively reasoning about alternate behavior to minimize\nrisk and using a richer model formulation to account for environmental noise).\nAcross diverse networks (emulated and real-world), Tarzan outperforms the\nwidely deployed GCC algorithm, increasing average video bitrates by 15-39%\nwhile reducing freeze rates by 60-100%.\n","authors":["Neil Agarwal","Rui Pan","Francis Y. Yan","Ravi Netravali"],"pdf_url":"https://arxiv.org/pdf/2410.03339v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.18736v2","updated":"2024-10-04T09:38:06Z","published":"2024-09-27T13:27:29Z","title":"Adversarial Challenges in Network Intrusion Detection Systems: Research\n  Insights and Future Prospects","summary":"  Machine learning has brought significant advances in cybersecurity,\nparticularly in the development of Intrusion Detection Systems (IDS). These\nimprovements are mainly attributed to the ability of machine learning\nalgorithms to identify complex relationships between features and effectively\ngeneralize to unseen data. Deep neural networks, in particular, contributed to\nthis progress by enabling the analysis of large amounts of training data,\nsignificantly enhancing detection performance. However, machine learning models\nremain vulnerable to adversarial attacks, where carefully crafted input data\ncan mislead the model into making incorrect predictions. While adversarial\nthreats in unstructured data, such as images and text, have been extensively\nstudied, their impact on structured data like network traffic is less explored.\nThis survey aims to address this gap by providing a comprehensive review of\nmachine learning-based Network Intrusion Detection Systems (NIDS) and\nthoroughly analyzing their susceptibility to adversarial attacks. We critically\nexamine existing research in NIDS, highlighting key trends, strengths, and\nlimitations, while identifying areas that require further exploration.\nAdditionally, we discuss emerging challenges in the field and offer insights\nfor the development of more robust and resilient NIDS. In summary, this paper\nenhances the understanding of adversarial attacks and defenses in NIDS and\nguide future research in improving the robustness of machine learning models in\ncybersecurity applications.\n","authors":["Sabrine Ennaji","Fabio De Gaspari","Dorjan Hitaj","Alicia K Bidi","Luigi V. Mancini"],"pdf_url":"https://arxiv.org/pdf/2409.18736v2.pdf","comment":"35 pages"},{"id":"http://arxiv.org/abs/2410.03177v1","updated":"2024-10-04T06:27:56Z","published":"2024-10-04T06:27:56Z","title":"Hybrid Centralized-Distributed Resource Allocation Based on Deep\n  Reinforcement Learning for Cooperative D2D Communications","summary":"  Device-to-device (D2D) technology enables direct communication between\nadjacent devices within cellular networks. Due to its high data rate, low\nlatency, and performance improvement in spectrum and energy efficiency, it has\nbeen widely investigated and applied as a critical technology in 5G New Radio\n(NR). In addition to conventional overlay and underlay D2D communications,\ncooperative D2D communication, which can achieve a win-win situation between\ncellular users (CUs) and D2D users (DUs) through cooperative relaying\ntechnique, has attracted extensive attention from academic and industrial\ncircles in the past decade. This paper delves into optimizing joint spectrum\nallocation, power control, and link-matching between multiple CUs and DUs for\ncooperative D2D communications, using weighted sum energy efficiency (WSEE) as\nthe performance metric to address the challenges of green communication and\nsustainable development. This integer programming problem can be decomposed\ninto a classic weighted bipartite graph matching and a series of nonconvex\nspectrum allocation and power control problems between potentially matched\ncellular and D2D link pairs. To address this issue, we propose a hybrid\ncentralized-distributed scheme based on deep reinforcement learning (DRL) and\nthe Kuhn-Munkres (KM) algorithm. Leveraging the latter, the CUs and DUs\nautonomously optimize spectrum allocation and power control by only utilizing\nlocal information. Then, the base station (BS) determines the link matching.\nSimulation results reveal that it achieves near-optimal performance and\nsignificantly enhances the network convergence speed with low signaling\noverheads. In addition, we also propose and utilize cooperative link sets for\ncorresponding D2D links to accelerate the proposed scheme and reduce signaling\nexchange further.\n","authors":["Yang Yu","Xiaoqing Tang"],"pdf_url":"https://arxiv.org/pdf/2410.03177v1.pdf","comment":"12 pages,9 figures"}],"Distributed, Parallel, and Cluster Computing":[{"id":"http://arxiv.org/abs/2410.01901v2","updated":"2024-10-04T23:38:22Z","published":"2024-10-02T18:02:16Z","title":"Generic Multicast (Extended Version)","summary":"  Communication primitives play a central role in modern computing. They offer\na panel of reliability and ordering guarantees for messages, enabling the\nimplementation of complex distributed interactions. In particular, atomic\nbroadcast is a pivotal abstraction for implementing fault-tolerant distributed\nservices. This primitive allows disseminating messages across the system in a\ntotal order. There are two group communication primitives closely related to\natomic broadcast. Atomic multicast permits targeting a subset of participants,\npossibly stricter than the whole system. Generic broadcast leverages the\nsemantics of messages to order them only where necessary (that is when they\nconflict). In this paper, we propose to combine all these primitives into a\nsingle, more general one, called generic multicast. We formally specify the\nguarantees offered by generic multicast and present efficient algorithms.\nCompared to prior works, our solutions offer appealing properties in terms of\ntime and space complexity. In particular, when a run is conflict-free, that is\nno two messages conflict, a message is delivered after at most three message\ndelays.\n","authors":["José Augusto Bolina","Pierre Sutra","Douglas Antunes Rocha","Lasaro Camargos"],"pdf_url":"https://arxiv.org/pdf/2410.01901v2.pdf","comment":"12 pages, 2 figures"},{"id":"http://arxiv.org/abs/2410.03499v1","updated":"2024-10-04T15:13:31Z","published":"2024-10-04T15:13:31Z","title":"FedStein: Enhancing Multi-Domain Federated Learning Through James-Stein\n  Estimator","summary":"  Federated Learning (FL) facilitates data privacy by enabling collaborative\nin-situ training across decentralized clients. Despite its inherent advantages,\nFL faces significant challenges of performance and convergence when dealing\nwith data that is not independently and identically distributed (non-i.i.d.).\nWhile previous research has primarily addressed the issue of skewed label\ndistribution across clients, this study focuses on the less explored challenge\nof multi-domain FL, where client data originates from distinct domains with\nvarying feature distributions. We introduce a novel method designed to address\nthese challenges FedStein: Enhancing Multi-Domain Federated Learning Through\nthe James-Stein Estimator. FedStein uniquely shares only the James-Stein (JS)\nestimates of batch normalization (BN) statistics across clients, while\nmaintaining local BN parameters. The non-BN layer parameters are exchanged via\nstandard FL techniques. Extensive experiments conducted across three datasets\nand multiple models demonstrate that FedStein surpasses existing methods such\nas FedAvg and FedBN, with accuracy improvements exceeding 14% in certain\ndomains leading to enhanced domain generalization. The code is available at\nhttps://github.com/sunnyinAI/FedStein\n","authors":["Sunny Gupta","Nikita Jangid","Amit Sethi"],"pdf_url":"https://arxiv.org/pdf/2410.03499v1.pdf","comment":"12 pages, 2 figures. Accepted at International Workshop on Federated\n  Foundation Models In Conjunction with NeurIPS 2024 (FL@FM-NeurIPS'24)"},{"id":"http://arxiv.org/abs/2310.11331v2","updated":"2024-10-04T12:21:17Z","published":"2023-10-17T15:11:14Z","title":"TOB-SVD: Total-Order Broadcast with Single-Vote Decisions in the Sleepy\n  Model","summary":"  Over the past years, distributed consensus research has extended its focus\ntowards addressing challenges in large-scale, permissionless systems, such as\nblockchains. This shift is characterized by the need to accommodate dynamic\nparticipation, contrasting the traditional approach of a static set of\ncontinuously online participants. Works like Bitcoin and the sleepy model have\nset the stage for this evolving framework.\n  Notable contributions from Momose and Ren (CCS 2022) and subsequent works\nhave introduced Total-Order Broadcast protocols leveraging Graded Agreement\nprimitives and supporting dynamic participation. However, these approaches\noften require multiple phases of voting per decision, creating a potential\nbottleneck for real-world large-scale systems.\n  Addressing this, our paper introduces TOB-SVD, a novel Total-Order Broadcast\nprotocol in the sleepy model, which is resilient to up to 1/2 of adversarial\nparticipants. TOB-SVD requires only a single phase of voting per decision in\nthe best case and achieves lower expected latency compared to existing\napproaches offering the same optimal adversarial resilience. This work paves\nthe way to more practical Total-Order Broadcast protocols to be implemented in\nreal-world systems where a large number of participants are involved\nsimultaneously and their participation level might fluctuate over time.\n","authors":["Francesco D'Amato","Roberto Saltini","Thanh-Hai Tran","Luca Zanolini"],"pdf_url":"https://arxiv.org/pdf/2310.11331v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.03315v1","updated":"2024-10-04T11:00:17Z","published":"2024-10-04T11:00:17Z","title":"Influence-oriented Personalized Federated Learning","summary":"  Traditional federated learning (FL) methods often rely on fixed weighting for\nparameter aggregation, neglecting the mutual influence by others. Hence, their\neffectiveness in heterogeneous data contexts is limited. To address this\nproblem, we propose an influence-oriented federated learning framework, namely\nFedC^2I, which quantitatively measures Client-level and Class-level Influence\nto realize adaptive parameter aggregation for each client. Our core idea is to\nexplicitly model the inter-client influence within an FL system via the\nwell-crafted influence vector and influence matrix. The influence vector\nquantifies client-level influence, enables clients to selectively acquire\nknowledge from others, and guides the aggregation of feature representation\nlayers. Meanwhile, the influence matrix captures class-level influence in a\nmore fine-grained manner to achieve personalized classifier aggregation. We\nevaluate the performance of FedC^2I against existing federated learning methods\nunder non-IID settings and the results demonstrate the superiority of our\nmethod.\n","authors":["Yue Tan","Guodong Long","Jing Jiang","Chengqi Zhang"],"pdf_url":"https://arxiv.org/pdf/2410.03315v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.12148v2","updated":"2024-10-04T08:00:59Z","published":"2024-02-19T14:01:34Z","title":"Local certification of forbidden subgraphs","summary":"  Detecting specific structures in a network has been a very active theme of\nresearch in distributed computing for at least a decade. In this paper, we\nstart the study of subgraph detection from the perspective of local\ncertification. Remember that a local certification is a distributed mechanism\nenabling the nodes of a network to check the correctness of the current\nconfiguration, thanks to small pieces of information called certificates. Our\nmain question is: For a given graph $H$, what is the minimum certificate size\nthat allows checking that the network does not contain $H$ as a (possibly\ninduced) subgraph?\n  We show a variety of lower and upper bounds, uncovering an interesting\ninterplay between the optimal certificate size, the size of the forbidden\nsubgraph, and the locality of the verification. Along the way we introduce\nseveral new technical tools, in particular what we call the \\emph{layered map},\nwhich is not specific to forbidden subgraphs and that we expect to be useful\nfor certifying many other properties.\n","authors":["Nicolas Bousquet","Linda Cook","Laurent Feuilloley","Théo Pierron","Sébastien Zeitoun"],"pdf_url":"https://arxiv.org/pdf/2402.12148v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.03148v1","updated":"2024-10-04T05:15:23Z","published":"2024-10-04T05:15:23Z","title":"Memory-distributed level set-based inverse homogenisation of\n  three-dimensional piezoelectric materials","summary":"  In this paper we use level set-based topology optimisation to design\nthree-dimensional periodic piezoelectric materials with enhanced properties.\nOur methodology is fully memory-distributed and written in Julia using the\npackage GridapTopOpt. We compare and assess several existing iterative solvers\nwith respect to their weak scalability and find that an approximate Schur\ncomplement preconditioned GMRES method demonstrates the best performance and\nscalability for solving the piezoelectric homogenisation equations. We use the\ndeveloped techniques to computationally design high-resolution piezoelectric\nmetamaterials with enhanced stiffness and piezoelectric properties that yield\nnew insights into material design for sensor, hydrophone, and actuator\napplications. We suggest two robust structures with simple geometric features\nthat exhibit enhanced piezoelectric properties several times larger than those\nof the base material. We find that level set-based topology optimisation is\nwell suited to problems involving piezoelectricity and has the advantage of\navoiding large regions of intermediate density material.\n","authors":["Zachary J. Wegert","Anthony P. Roberts","Vivien J. Challis"],"pdf_url":"https://arxiv.org/pdf/2410.03148v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.08245v2","updated":"2024-10-04T03:44:02Z","published":"2024-03-13T05:00:23Z","title":"Scattered Mixture-of-Experts Implementation","summary":"  We present ScatterMoE, an implementation of Sparse Mixture-of-Experts (SMoE)\non GPUs. ScatterMoE builds upon existing implementations, and overcoming some\nof the limitations to improve inference and training speed, and memory\nfootprint. This implementation achieves this by avoiding padding and making\nexcessive copies of the input. We introduce ParallelLinear, the main component\nwe use to build our implementation and the various kernels used to speed up the\noperation. We benchmark our implementation against Megablocks, and show that it\nenables a higher throughput and lower memory footprint. We also show how\nParallelLinear enables extension of the Mixture-of-Experts concept by\ndemonstrating with an implementation of Mixture of Attention.\n","authors":["Shawn Tan","Yikang Shen","Rameswar Panda","Aaron Courville"],"pdf_url":"https://arxiv.org/pdf/2403.08245v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.03067v1","updated":"2024-10-04T01:19:09Z","published":"2024-10-04T01:19:09Z","title":"FedCert: Federated Accuracy Certification","summary":"  Federated Learning (FL) has emerged as a powerful paradigm for training\nmachine learning models in a decentralized manner, preserving data privacy by\nkeeping local data on clients. However, evaluating the robustness of these\nmodels against data perturbations on clients remains a significant challenge.\nPrevious studies have assessed the effectiveness of models in centralized\ntraining based on certified accuracy, which guarantees that a certain\npercentage of the model's predictions will remain correct even if the input\ndata is perturbed. However, the challenge of extending these evaluations to FL\nremains unresolved due to the unknown client's local data. To tackle this\nchallenge, this study proposed a method named FedCert to take the first step\ntoward evaluating the robustness of FL systems. The proposed method is designed\nto approximate the certified accuracy of a global model based on the certified\naccuracy and class distribution of each client. Additionally, considering the\nNon-Independent and Identically Distributed (Non-IID) nature of data in\nreal-world scenarios, we introduce the client grouping algorithm to ensure\nreliable certified accuracy during the aggregation step of the approximation\nalgorithm. Through theoretical analysis, we demonstrate the effectiveness of\nFedCert in assessing the robustness and reliability of FL systems. Moreover,\nexperimental results on the CIFAR-10 and CIFAR-100 datasets under various\nscenarios show that FedCert consistently reduces the estimation error compared\nto baseline methods. This study offers a solution for evaluating the robustness\nof FL systems and lays the groundwork for future research to enhance the\ndependability of decentralized learning. The source code is available at\nhttps://github.com/thanhhff/FedCert/.\n","authors":["Minh Hieu Nguyen","Huu Tien Nguyen","Trung Thanh Nguyen","Manh Duong Nguyen","Trong Nghia Hoang","Truong Thao Nguyen","Phi Le Nguyen"],"pdf_url":"https://arxiv.org/pdf/2410.03067v1.pdf","comment":"The 22nd International Symposium on Network Computing and\n  Applications (NCA 2024)"}]},"2024-10-03T00:00:00Z":{"Software Engineering":[{"id":"http://arxiv.org/abs/2310.02407v2","updated":"2024-10-03T19:52:09Z","published":"2023-10-03T20:01:51Z","title":"Automated Bug Generation in the era of Large Language Models","summary":"  Bugs are essential in software engineering; many research studies in the past\ndecades have been proposed to detect, localize, and repair bugs in software\nsystems. Effectiveness evaluation of such techniques requires complex bugs,\ni.e., those that are hard to detect through testing and hard to repair through\ndebugging. From the classic software engineering point of view, a\nhard-to-repair bug differs from the correct code in multiple locations, making\nit hard to localize and repair. Hard-to-detect bugs, on the other hand,\nmanifest themselves under specific test inputs and reachability conditions.\nThese two objectives, i.e., generating hard-to-detect and hard-to-repair bugs,\nare mostly aligned; a bug generation technique can change multiple statements\nto be covered only under a specific set of inputs. However, these two\nobjectives are conflicting for learning-based techniques: A bug should have a\nsimilar code representation to the correct code in the training data to\nchallenge a bug prediction model to distinguish them. The hard-to-repair bug\ndefinition remains the same but with a caveat: the more a bug differs from the\noriginal code, the more distant their representations are and easier to be\ndetected. We propose BugFarm, to transform arbitrary code into multiple complex\nbugs. BugFarm leverages LLMs to mutate code in multiple locations\n(hard-to-repair). To ensure that multiple modifications do not notably change\nthe code representation, BugFarm analyzes the attention of the underlying model\nand instructs LLMs to only change the least attended locations\n(hard-to-detect). Our comprehensive evaluation of 435k+ bugs from over 1.9M\nmutants generated by BUGFARM and two alternative approaches demonstrates our\nsuperiority in generating bugs that are hard to detect by learning-based bug\nprediction approaches and hard-to-repair by state-of-the-art learning-based\nprogram repair technique.\n","authors":["Ali Reza Ibrahimzada","Yang Chen","Ryan Rong","Reyhaneh Jabbarvand"],"pdf_url":"https://arxiv.org/pdf/2310.02407v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.02915v1","updated":"2024-10-03T19:07:14Z","published":"2024-10-03T19:07:14Z","title":"Does the Order of Fine-tuning Matter and Why?","summary":"  To improve the performance on a target task, researchers have fine-tuned\nlanguage models with an intermediate task before the target task of interest.\nHowever, previous works have focused on the pre-trained language models and\ndownstream tasks in Natural Language Processing (NLP) and considered only one\nintermediate task. The effect of fine-tuning multiple intermediate tasks and\ntheir ordering on target task performance has not been fully explored in\nSoftware Engineering. In this study, we perform the first empirical study on\nanalyzing the impact of task ordering on target task performance. Experimental\nresults show that there is an impact of task ordering on target task\nperformance by up to 6% of performance gain and up to 4% of performance loss.\nTo explain such an impact, we consider a variety of potential factors,\nincluding the characteristics of dataset (syntactic similarity and semantic\nsimilarity analysis, dataset size), model (probing task and attention\nanalysis), and task (task affinity analysis). Our study provides Software\nEngineering researchers and practitioners with insights into the effect of task\norderings and how to select the one that is cost-effective while achieving the\nbest performance gain.\n","authors":["Qihong Chen","Jiawei Li","Hyunjae Suh","Lianghao Jiang","Zheng Zhou","Jingze Chen","Jiri Gesi","Iftekhar Ahmed"],"pdf_url":"https://arxiv.org/pdf/2410.02915v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.02721v1","updated":"2024-10-03T17:40:55Z","published":"2024-10-03T17:40:55Z","title":"Domain-Specific Retrieval-Augmented Generation Using Vector Stores,\n  Knowledge Graphs, and Tensor Factorization","summary":"  Large Language Models (LLMs) are pre-trained on large-scale corpora and excel\nin numerous general natural language processing (NLP) tasks, such as question\nanswering (QA). Despite their advanced language capabilities, when it comes to\ndomain-specific and knowledge-intensive tasks, LLMs suffer from hallucinations,\nknowledge cut-offs, and lack of knowledge attributions. Additionally, fine\ntuning LLMs' intrinsic knowledge to highly specific domains is an expensive and\ntime consuming process. The retrieval-augmented generation (RAG) process has\nrecently emerged as a method capable of optimization of LLM responses, by\nreferencing them to a predetermined ontology. It was shown that using a\nKnowledge Graph (KG) ontology for RAG improves the QA accuracy, by taking into\naccount relevant sub-graphs that preserve the information in a structured\nmanner. In this paper, we introduce SMART-SLIC, a highly domain-specific LLM\nframework, that integrates RAG with KG and a vector store (VS) that store\nfactual domain specific information. Importantly, to avoid hallucinations in\nthe KG, we build these highly domain-specific KGs and VSs without the use of\nLLMs, but via NLP, data mining, and nonnegative tensor factorization with\nautomatic model selection. Pairing our RAG with a domain-specific: (i) KG\n(containing structured information), and (ii) VS (containing unstructured\ninformation) enables the development of domain-specific chat-bots that\nattribute the source of information, mitigate hallucinations, lessen the need\nfor fine-tuning, and excel in highly domain-specific question answering tasks.\nWe pair SMART-SLIC with chain-of-thought prompting agents. The framework is\ndesigned to be generalizable to adapt to any specific or specialized domain. In\nthis paper, we demonstrate the question answering capabilities of our framework\non a corpus of scientific publications on malware analysis and anomaly\ndetection.\n","authors":["Ryan C. Barron","Ves Grantcharov","Selma Wanna","Maksim E. Eren","Manish Bhattarai","Nicholas Solovyev","George Tompkins","Charles Nicholas","Kim Ø. Rasmussen","Cynthia Matuszek","Boian S. Alexandrov"],"pdf_url":"https://arxiv.org/pdf/2410.02721v1.pdf","comment":"9 pages 7 figures, 1 table, 1 cypher code Accepted to ICMLA 2024"},{"id":"http://arxiv.org/abs/2406.05514v3","updated":"2024-10-03T17:15:34Z","published":"2024-06-08T16:24:24Z","title":"RAG-Enhanced Commit Message Generation","summary":"  Commit message is one of the most important textual information in software\ndevelopment and maintenance. However, it is time-consuming to write commit\nmessages manually. Commit Message Generation (CMG) has become a research\nhotspot. Recently, several pre-trained language models (PLMs) and large\nlanguage models (LLMs) with code capabilities have been introduced,\ndemonstrating impressive performance on code-related tasks. Meanwhile, prior\nstudies have explored the utilization of retrieval techniques for CMG, but it\nis still unclear what effects would emerge from combining advanced retrieval\ntechniques with various generation models. This paper proposed REACT, a\nREtrieval-Augmented framework for CommiT message generation. It integrates\nadvanced retrieval techniques with different PLMs and LLMs, to enhance the\nperformance of these models on the CMG task. Specifically, a hybrid retriever\nis designed and used to retrieve the most relevant code diff and commit message\npair as an exemplar. Then, the retrieved pair is utilized to guide and enhance\nthe CMG task by PLMs and LLMs through fine-tuning and in-context learning. The\nexperimental results show that REACT significantly enhances these models'\nperformance on the CMG task, improving the BLEU score of CodeT5 by up to 55%,\nboosting Llama 3's BLEU score by 102%, and substantially surpassing all\nbaselines.\n","authors":["Linghao Zhang","Hongyi Zhang","Chong Wang","Peng Liang"],"pdf_url":"https://arxiv.org/pdf/2406.05514v3.pdf","comment":"22 pages, 5 images, 6 tables, Manuscript submitted to a journal\n  (2024)"},{"id":"http://arxiv.org/abs/2401.03741v2","updated":"2024-10-03T17:15:24Z","published":"2024-01-08T09:01:29Z","title":"Enhanced Automated Code Vulnerability Repair using Large Language Models","summary":"  This research addresses the complex challenge of automated repair of code\nvulnerabilities, vital for enhancing digital security in an increasingly\ntechnology-driven world. The study introduces a novel and efficient format for\nthe representation of code modification, using advanced Large Language Models\n(LLMs) such as Code Llama and Mistral. These models, fine-tuned on datasets\nfeaturing C code vulnerabilities, significantly improve the accuracy and\nadaptability of automated code repair techniques. A key finding is the enhanced\nrepair accuracy of these models when compared to previous methods such as\nVulRepair, which underscores their practical utility and efficiency. The\nresearch also offers a critical assessment of current evaluation metrics, such\nas perfect predictions, and their limitations in reflecting the true\ncapabilities of automated repair models in real-world scenarios. Following\nthis, it underscores the importance of using test datasets devoid of train\nsamples, emphasizing the need for dataset integrity to enhance the\neffectiveness of LLMs in code repair tasks. The significance of this work is\nits contribution to digital security, setting new standards for automated code\nvulnerability repair and paving the way for future advancements in the fields\nof cybersecurity and artificial intelligence. The study does not only highlight\nthe potential of LLMs in enhancing code security but also fosters further\nexploration and research in these crucial areas.\n","authors":["David de-Fitero-Dominguez","Eva Garcia-Lopez","Antonio Garcia-Cabot","Jose-Javier Martinez-Herraiz"],"pdf_url":"https://arxiv.org/pdf/2401.03741v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.02627v1","updated":"2024-10-03T16:08:30Z","published":"2024-10-03T16:08:30Z","title":"Preparing for Super-Reactivity: Early Fault-Detection in the Development\n  of Exceedingly Complex Reactive Systems","summary":"  We introduce the term Super-Reactive Systems to refer to reactive systems\nwhose construction and behavior are complex, constantly changing and evolving,\nand heavily interwoven with other systems and the physical world. Finding\nhidden faults in such systems early in planning and development is critical for\nhuman safety, the environment, society and the economy. However, the complexity\nof the system and its interactions and the absence of adequate technical\ndetails pose a great obstacle. We propose an architecture for models and tools\nto overcome such barriers and enable simulation, systematic analysis, and fault\ndetection and handling, early in the development of super-reactive systems. The\napproach is facilitated by the inference and abstraction capabilities and the\npower and knowledge afforded by large language models and associated AI tools.\nIt is based on: (i) deferred, just-in-time interpretation of model elements\nthat are stored in natural language form, and (ii) early capture of tacit\ninterdependencies among seemingly orthogonal requirements.\n","authors":["David Harel","Assaf Marron"],"pdf_url":"https://arxiv.org/pdf/2410.02627v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.02482v1","updated":"2024-10-03T13:40:00Z","published":"2024-10-03T13:40:00Z","title":"It is Giving Major Satisfaction: Why Fairness Matters for Developers","summary":"  Software practitioners often face unfairness in their work, such as unequal\nrecognition of contributions, gender bias, and unclear criteria for performance\nreviews. While the link between fairness and job satisfaction has been\nestablished in other fields, its relevance to software professionals remains\nunderexplored. This study aims to examine how fairness perceptions relate to\njob satisfaction among software practitioners, focusing on both general trends\nand demographic-specific differences. We conducted an online survey of 108\nsoftware practitioners, followed by ordinal logistic regression to analyze the\nrelationship between fairness perceptions and job satisfaction in software\nengineering contexts, with moderation analysis examining how this relationship\nvaries across demographic groups.\n  Our findings indicate that all four fairness dimensions, distributive,\nprocedural, interpersonal, and informational, significantly affect both overall\njob satisfaction and satisfaction with job security. Among these, interpersonal\nfairness has the biggest impact, being more than twice as influential on\noverall job satisfaction. The relationship between fairness perceptions and job\nsatisfaction is notably stronger for female, ethnically underrepresented, less\nexperienced practitioners, and those with work limitations. Fairness in\nauthorship emerged as an important factor for job satisfaction collectively,\nwhile fairness in policy implementation, high-demand situations, and working\nhours particularly impacted specific demographic groups. This study highlights\nthe unique role of fairness in software engineering, offering strategies for\norganizations to promote fair practices and targeted approaches specific for\ncertain demographic groups.\n","authors":["Emeralda Sesari","Federica Sarro","Ayushi Rastogi"],"pdf_url":"https://arxiv.org/pdf/2410.02482v1.pdf","comment":"This work has been submitted to the IEEE for possible publication"},{"id":"http://arxiv.org/abs/2410.01242v2","updated":"2024-10-03T13:12:24Z","published":"2024-10-02T05:07:02Z","title":"RGD: Multi-LLM Based Agent Debugger via Refinement and Generation\n  Guidance","summary":"  Large Language Models (LLMs) have shown incredible potential in code\ngeneration tasks, and recent research in prompt engineering have enhanced LLMs'\nunderstanding of textual information. However, ensuring the accuracy of\ngenerated code often requires extensive testing and validation by programmers.\nWhile LLMs can typically generate code based on task descriptions, their\naccuracy remains limited, especially for complex tasks that require a deeper\nunderstanding of both the problem statement and the code generation process.\nThis limitation is primarily due to the LLMs' need to simultaneously comprehend\ntext and generate syntactically and semantically correct code, without having\nthe capability to automatically refine the code. In real-world software\ndevelopment, programmers rarely produce flawless code in a single attempt based\non the task description alone, they rely on iterative feedback and debugging to\nrefine their programs. Inspired by this process, we introduce a novel\narchitecture of LLM-based agents for code generation and automatic debugging:\nRefinement and Guidance Debugging (RGD). The RGD framework is a multi-LLM-based\nagent debugger that leverages three distinct LLM agents-Guide Agent, Debug\nAgent, and Feedback Agent. RGD decomposes the code generation task into\nmultiple steps, ensuring a clearer workflow and enabling iterative code\nrefinement based on self-reflection and feedback. Experimental results\ndemonstrate that RGD exhibits remarkable code generation capabilities,\nachieving state-of-the-art performance with a 9.8% improvement on the HumanEval\ndataset and a 16.2% improvement on the MBPP dataset compared to the\nstate-of-the-art approaches and traditional direct prompting approaches. We\nhighlight the effectiveness of the RGD framework in enhancing LLMs' ability to\ngenerate and refine code autonomously.\n","authors":["Haolin Jin","Zechao Sun","Huaming Chen"],"pdf_url":"https://arxiv.org/pdf/2410.01242v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.02841v1","updated":"2024-10-03T12:59:29Z","published":"2024-10-03T12:59:29Z","title":"Demonstration Attack against In-Context Learning for Code Intelligence","summary":"  Recent advancements in large language models (LLMs) have revolutionized code\nintelligence by improving programming productivity and alleviating challenges\nfaced by software developers. To further improve the performance of LLMs on\nspecific code intelligence tasks and reduce training costs, researchers reveal\na new capability of LLMs: in-context learning (ICL). ICL allows LLMs to learn\nfrom a few demonstrations within a specific context, achieving impressive\nresults without parameter updating. However, the rise of ICL introduces new\nsecurity vulnerabilities in the code intelligence field. In this paper, we\nexplore a novel security scenario based on the ICL paradigm, where attackers\nact as third-party ICL agencies and provide users with bad ICL content to\nmislead LLMs outputs in code intelligence tasks. Our study demonstrates the\nfeasibility and risks of such a scenario, revealing how attackers can leverage\nmalicious demonstrations to construct bad ICL content and induce LLMs to\nproduce incorrect outputs, posing significant threats to system security. We\npropose a novel method to construct bad ICL content called DICE, which is\ncomposed of two stages: Demonstration Selection and Bad ICL Construction,\nconstructing targeted bad ICL content based on the user query and transferable\nacross different query inputs. Ultimately, our findings emphasize the critical\nimportance of securing ICL mechanisms to protect code intelligence systems from\nadversarial manipulation.\n","authors":["Yifei Ge","Weisong Sun","Yihang Lou","Chunrong Fang","Yiran Zhang","Yiming Li","Xiaofang Zhang","Yang Liu","Zhihong Zhao","Zhenyu Chen"],"pdf_url":"https://arxiv.org/pdf/2410.02841v1.pdf","comment":"17 pages, 5 figures"},{"id":"http://arxiv.org/abs/2406.17233v2","updated":"2024-10-03T08:43:25Z","published":"2024-06-25T02:37:53Z","title":"Self-Constructed Context Decompilation with Fined-grained Alignment\n  Enhancement","summary":"  Decompilation transforms compiled code back into a high-level programming\nlanguage for analysis when source code is unavailable. Previous work has\nprimarily focused on enhancing decompilation performance by increasing the\nscale of model parameters or training data for pre-training. Based on the\ncharacteristics of the decompilation task, we propose two methods: (1) Without\nfine-tuning, the Self-Constructed Context Decompilation (sc$^2$dec) method\nrecompiles the LLM's decompilation results to construct pairs for in-context\nlearning, helping the model improve decompilation performance. (2) Fine-grained\nAlignment Enhancement (FAE), which meticulously aligns assembly code with\nsource code at the statement level by leveraging debugging information, is\nemployed during the fine-tuning phase to achieve further improvements in\ndecompilation. By integrating these two methods, we achieved a Re-Executability\nperformance improvement of approximately 3.90% on the Decompile-Eval benchmark,\nestablishing a new state-of-the-art performance of 52.41%. The code, data, and\nmodels are available at https://github.com/AlongWY/sccdec.\n","authors":["Yunlong Feng","Dechuan Teng","Yang Xu","Honglin Mu","Xiao Xu","Libo Qin","Qingfu Zhu","Wanxiang Che"],"pdf_url":"https://arxiv.org/pdf/2406.17233v2.pdf","comment":"EMNLP 2024 Findings"},{"id":"http://arxiv.org/abs/2410.02184v1","updated":"2024-10-03T03:58:03Z","published":"2024-10-03T03:58:03Z","title":"CodeJudge: Evaluating Code Generation with Large Language Models","summary":"  Large Language Models (LLMs) have shown promising performance in code\ngeneration. However, how to reliably evaluate code generated by LLMs remains an\nunresolved problem. This paper presents CodeJudge, a code evaluation framework\nthat leverages LLMs to evaluate the semantic correctness of generated code\nwithout the need for test cases. We investigate different ways to guide the LLM\nin performing \"slow thinking\" to arrive at an in-depth and reliable evaluation.\nWe experimented with four LLMs as evaluators on four code generation datasets\nand five programming languages. The results show that CodeJudge significantly\noutperformed existing methods in most settings. Furthermore, compared with a\nSOTA GPT-3.5-based code evaluation method, CodeJudge achieved better results\neven when using a much smaller model, Llama-3-8B-Instruct. Our code and\ndatasets are available on GitHub https://github.com/VichyTong/CodeJudge.\n","authors":["Weixi Tong","Tianyi Zhang"],"pdf_url":"https://arxiv.org/pdf/2410.02184v1.pdf","comment":"Accepted to EMNLP 2024 (Main, Long Paper)"},{"id":"http://arxiv.org/abs/2410.00249v2","updated":"2024-10-03T00:37:10Z","published":"2024-09-30T21:44:05Z","title":"Enhancing Pre-Trained Language Models for Vulnerability Detection via\n  Semantic-Preserving Data Augmentation","summary":"  With the rapid development and widespread use of advanced network systems,\nsoftware vulnerabilities pose a significant threat to secure communications and\nnetworking. Learning-based vulnerability detection systems, particularly those\nleveraging pre-trained language models, have demonstrated significant potential\nin promptly identifying vulnerabilities in communication networks and reducing\nthe risk of exploitation. However, the shortage of accurately labeled\nvulnerability datasets hinders further progress in this field. Failing to\nrepresent real-world vulnerability data variety and preserve vulnerability\nsemantics, existing augmentation approaches provide limited or even\ncounterproductive contributions to model training. In this paper, we propose a\ndata augmentation technique aimed at enhancing the performance of pre-trained\nlanguage models for vulnerability detection. Given the vulnerability dataset,\nour method performs natural semantic-preserving program transformation to\ngenerate a large volume of new samples with enriched data diversity and\nvariety. By incorporating our augmented dataset in fine-tuning a series of\nrepresentative code pre-trained models (i.e., CodeBERT, GraphCodeBERT,\nUnixCoder, and PDBERT), up to 10.1% increase in accuracy and 23.6% increase in\nF1 can be achieved in the vulnerability detection task. Comparison results also\nshow that our proposed method can substantially outperform other prominent\nvulnerability augmentation approaches.\n","authors":["Weiliang Qi","Jiahao Cao","Darsh Poddar","Sophia Li","Xinda Wang"],"pdf_url":"https://arxiv.org/pdf/2410.00249v2.pdf","comment":"Accepted by EAI International Conference on Security and Privacy in\n  Communication Networks (SecureComm 2024)"}],"Human-Computer Interaction":[{"id":"http://arxiv.org/abs/2410.03032v1","updated":"2024-10-03T22:29:20Z","published":"2024-10-03T22:29:20Z","title":"CounterQuill: Investigating the Potential of Human-AI Collaboration in\n  Online Counterspeech Writing","summary":"  Online hate speech has become increasingly prevalent on social media\nplatforms, causing harm to individuals and society. While efforts have been\nmade to combat this issue through content moderation, the potential of\nuser-driven counterspeech as an alternative solution remains underexplored.\nExisting counterspeech methods often face challenges such as fear of\nretaliation and skill-related barriers. To address these challenges, we\nintroduce CounterQuill, an AI-mediated system that assists users in composing\neffective and empathetic counterspeech. CounterQuill provides a three-step\nprocess: (1) a learning session to help users understand hate speech and\ncounterspeech; (2) a brainstorming session that guides users in identifying key\nelements of hate speech and exploring counterspeech strategies; and (3) a\nco-writing session that enables users to draft and refine their counterspeech\nwith CounterQuill. We conducted a within-subjects user study with 20\nparticipants to evaluate CounterQuill in comparison to ChatGPT. Results show\nthat CounterQuill's guidance and collaborative writing process provided users a\nstronger sense of ownership over their co-authored counterspeech. Users\nperceived CounterQuill as a writing partner and thus were more willing to post\nthe co-written counterspeech online compared to the one written with ChatGPT.\n","authors":["Xiaohan Ding","Kaike Ping","Uma Sushmitha Gunturi","Buse Carik","Sophia Stil","Lance T Wilhelm","Taufiq Daryanto","James Hawdon","Sang Won Lee","Eugenia H Rho"],"pdf_url":"https://arxiv.org/pdf/2410.03032v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.03022v1","updated":"2024-10-03T22:10:43Z","published":"2024-10-03T22:10:43Z","title":"Uncovering the New Accessibility Crisis in Scholarly PDFs","summary":"  Most scholarly works are distributed online in PDF format, which can present\nsignificant accessibility challenges for blind and low-vision readers. To\ncharacterize the scope of this issue, we perform a large-scale analysis of 20K\nopen- and closed-access scholarly PDFs published between 2014-2023 sampled\nacross broad fields of study. We assess the accessibility compliance of these\ndocuments based on six criteria: Default Language, Appropriate Nesting, Tagged\nPDF, Table Headers, Tab Order, and Alt-Text; selected based on prior work and\nthe SIGACCESS Guide for Accessible PDFs. To ensure robustness, we corroborate\nour findings through automated accessibility checking, manual evaluation of alt\ntext, comparative assessments with an alternate accessibility checker, and\nmanual assessments with screen readers. Our findings reveal that less than 3.2%\nof tested PDFs satisfy all criteria, while a large majority (74.9%) fail to\nmeet any criteria at all. Worse yet, we observe a concerning drop in PDF\naccessibility since 2019, largely among open-access papers, suggesting that\nefforts to improve document accessibility have not taken hold and are on a\nbackslide. While investigating factors contributing to this drop, we identify\nkey associations between fields of study, creation platforms used, models of\npublishing, and PDF accessibility compliance, suggesting that publisher and\nauthor choices significantly influence document accessibility. This paper\nhighlights a new crisis in scholarly document accessibility and the need for a\nmulti-faceted approach to address the problem, involving the development of\nbetter tools, enhanced author education, and systemic changes in academic\npublishing practices.\n","authors":["Anukriti Kumar","Lucy Lu Wang"],"pdf_url":"https://arxiv.org/pdf/2410.03022v1.pdf","comment":"16 pages"},{"id":"http://arxiv.org/abs/2410.03791v1","updated":"2024-10-03T21:26:58Z","published":"2024-10-03T21:26:58Z","title":"People are poorly equipped to detect AI-powered voice clones","summary":"  As generative AI continues its ballistic trajectory, everything from text to\naudio, image, and video generation continues to improve in mimicking\nhuman-generated content. Through a series of perceptual studies, we report on\nthe realism of AI-generated voices in terms of identity matching and\nnaturalness. We find human participants cannot reliably identify short\nrecordings (less than 20 seconds) of AI-generated voices. Specifically,\nparticipants mistook the identity of an AI-voice for its real counterpart 80%\nof the time, and correctly identified a voice as AI-generated only 60% of the\ntime. In all cases, performance is independent of the demographics of the\nspeaker or listener.\n","authors":["Sarah Barrington","Hany Farid"],"pdf_url":"https://arxiv.org/pdf/2410.03791v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.02967v1","updated":"2024-10-03T20:12:56Z","published":"2024-10-03T20:12:56Z","title":"Label-Free Subjective Player Experience Modelling via Let's Play Videos","summary":"  Player Experience Modelling (PEM) is the study of AI techniques applied to\nmodelling a player's experience within a video game. PEM development can be\nlabour-intensive, requiring expert hand-authoring or specialized data\ncollection. In this work, we propose a novel PEM development approach,\napproximating player experience from gameplay video. We evaluate this approach\npredicting affect in the game Angry Birds via a human subject study. We\nvalidate that our PEM can strongly correlate with self-reported and sensor\nmeasures of affect, demonstrating the potential of this approach.\n","authors":["Dave Goel","Athar Mahmoudi-Nejad","Matthew Guzdial"],"pdf_url":"https://arxiv.org/pdf/2410.02967v1.pdf","comment":"9 pages, 3 figures, AAAI Conference on Artificial Intelligence and\n  Interactive Digital Entertainment"},{"id":"http://arxiv.org/abs/2410.02955v1","updated":"2024-10-03T19:57:05Z","published":"2024-10-03T19:57:05Z","title":"AiBAT: Artificial Intelligence/Instructions for Build, Assembly, and\n  Test","summary":"  Instructions for Build, Assembly, and Test (IBAT) refers to the process used\nwhenever any operation is conducted on hardware, including tests, assembly, and\nmaintenance. Currently, the generation of IBAT documents is time-intensive, as\nusers must manually reference and transfer information from engineering\ndiagrams and parts lists into IBAT instructions. With advances in machine\nlearning and computer vision, however, it is possible to have an artificial\nintelligence (AI) model perform the partial filling of the IBAT template,\nfreeing up engineer time for more highly skilled tasks. AiBAT is a novel system\nfor assisting users in authoring IBATs. It works by first analyzing assembly\ndrawing documents, extracting information and parsing it, and then filling in\nIBAT templates with the extracted information. Such assisted authoring has\npotential to save time and reduce cost. This paper presents an overview of the\nAiBAT system, including promising preliminary results and discussion on future\nwork.\n","authors":["Benjamin Nuernberger","Anny Liu","Heather Stefanini","Richard Otis","Amanda Towler","R. Peter Dillon"],"pdf_url":"https://arxiv.org/pdf/2410.02955v1.pdf","comment":"9 pages, 6 figures, 2 tables"},{"id":"http://arxiv.org/abs/2410.03786v1","updated":"2024-10-03T18:44:05Z","published":"2024-10-03T18:44:05Z","title":"AI-rays: Exploring Bias in the Gaze of AI Through a Multimodal\n  Interactive Installation","summary":"  Data surveillance has become more covert and pervasive with AI algorithms,\nwhich can result in biased social classifications. Appearance offers intuitive\nidentity signals, but what does it mean to let AI observe and speculate on\nthem? We introduce AI-rays, an interactive installation where AI generates\nspeculative identities from participants' appearance which are expressed\nthrough synthesized personal items placed in participants' bags. It uses\nspeculative X-ray visions to contrast reality with AI-generated assumptions,\nmetaphorically highlighting AI's scrutiny and biases. AI-rays promotes\ndiscussions on modern surveillance and the future of human-machine reality\nthrough a playful, immersive experience exploring AI biases.\n","authors":["Ziyao Gao","Yiwen Zhang","Ling Li","Theodoros Papatheodorou","Wei Zeng"],"pdf_url":"https://arxiv.org/pdf/2410.03786v1.pdf","comment":"Siggraph Asia 2024 Art Paper"},{"id":"http://arxiv.org/abs/2410.02888v1","updated":"2024-10-03T18:19:52Z","published":"2024-10-03T18:19:52Z","title":"Pseudo-Automation: How Labor-Offsetting Technologies Reconfigure Roles\n  and Relationships in Frontline Retail Work","summary":"  Self-service machines are a form of pseudo-automation; rather than actually\nautomate tasks, they offset them to unpaid customers. Typically implemented for\ncustomer convenience and to reduce labor costs, self-service is often\ncriticized for worsening customer service and increasing loss and theft for\nretailers. Though millions of frontline service workers continue to interact\nwith these technologies on a day-to-day basis, little is known about how these\nmachines change the nature of frontline labor. Through interviews with current\nand former cashiers who work with self-checkout technologies, we investigate\nhow technology that offsets labor from an employee to a customer can\nreconfigure frontline work. We find three changes to cashiering tasks as a\nresult of self-checkout: (1) Working at self-checkout involved parallel demands\nfrom multiple customers, (2) self-checkout work was more problem-oriented\n(including monitoring and policing customers), and (3) traditional checkout\nbegan to become more demanding as easier transactions were filtered to\nself-checkout. As their interactions with customers became more focused on\nproblem solving and rule enforcement, cashiers were often positioned as\nadversaries to customers at self-checkout. To cope with perceived\nadversarialism, cashiers engaged in a form of relational patchwork, using\ntechniques like scapegoating the self-checkout machine and providing excessive\ncustomer service in order to maintain positive customer interactions in the\nface of potential conflict. Our findings highlight how even under\npseudo-automation, workers must engage in relational work to manage and mend\nnegative human-to-human interactions so that machines can be properly\nimplemented in context.\n","authors":["Pegah Moradi","Karen Levy","Cristobal Cheyre"],"pdf_url":"https://arxiv.org/pdf/2410.02888v1.pdf","comment":"Forthcoming in the Proceedings of the 2025 Conference on Computer\n  Supported Cooperative Work and Social Computing"},{"id":"http://arxiv.org/abs/2407.07950v2","updated":"2024-10-03T16:54:59Z","published":"2024-07-10T18:00:05Z","title":"Rel-A.I.: An Interaction-Centered Approach To Measuring Human-LM\n  Reliance","summary":"  The ability to communicate uncertainty, risk, and limitation is crucial for\nthe safety of large language models. However, current evaluations of these\nabilities rely on simple calibration, asking whether the language generated by\nthe model matches appropriate probabilities. Instead, evaluation of this aspect\nof LLM communication should focus on the behaviors of their human\ninterlocutors: how much do they rely on what the LLM says? Here we introduce an\ninteraction-centered evaluation framework called Rel-A.I. (pronounced \"rely\"})\nthat measures whether humans rely on LLM generations. We use this framework to\nstudy how reliance is affected by contextual features of the interaction (e.g,\nthe knowledge domain that is being discussed), or the use of greetings\ncommunicating warmth or competence (e.g., \"I'm happy to help!\"). We find that\ncontextual characteristics significantly affect human reliance behavior. For\nexample, people rely 10% more on LMs when responding to questions involving\ncalculations and rely 30% more on LMs that are perceived as more competent. Our\nresults show that calibration and language quality alone are insufficient in\nevaluating the risks of human-LM interactions, and illustrate the need to\nconsider features of the interactional context.\n","authors":["Kaitlyn Zhou","Jena D. Hwang","Xiang Ren","Nouha Dziri","Dan Jurafsky","Maarten Sap"],"pdf_url":"https://arxiv.org/pdf/2407.07950v2.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2410.03781v1","updated":"2024-10-03T16:15:41Z","published":"2024-10-03T16:15:41Z","title":"Towards the Pedagogical Steering of Large Language Models for Tutoring:\n  A Case Study with Modeling Productive Failure","summary":"  One-to-one tutoring is one of the most efficient methods of teaching.\nFollowing the rise in popularity of Large Language Models (LLMs), there have\nbeen efforts to use them to create conversational tutoring systems, which can\nmake the benefits of one-to-one tutoring accessible to everyone. However,\ncurrent LLMs are primarily trained to be helpful assistants and thus lack\ncrucial pedagogical skills. For example, they often quickly reveal the solution\nto the student and fail to plan for a richer multi-turn pedagogical\ninteraction. To use LLMs in pedagogical scenarios, they need to be steered\ntowards using effective teaching strategies: a problem we introduce as\nPedagogical Steering and believe to be crucial for the efficient use of LLMs as\ntutors. We address this problem by formalizing a concept of tutoring strategy,\nand introducing StratL, an algorithm to model a strategy and use prompting to\nsteer the LLM to follow this strategy. As a case study, we create a prototype\ntutor for high school math following Productive Failure (PF), an advanced and\neffective learning design. To validate our approach in a real-world setting, we\nrun a field study with 17 high school students in Singapore. We quantitatively\nshow that StratL succeeds in steering the LLM to follow a Productive Failure\ntutoring strategy. We also thoroughly investigate the existence of spillover\neffects on desirable properties of the LLM, like its ability to generate\nhuman-like answers. Based on these results, we highlight the challenges in\nPedagogical Steering and suggest opportunities for further improvements. We\nfurther encourage follow-up research by releasing a dataset of Productive\nFailure problems and the code of our prototype and algorithm.\n","authors":["Romain Puech","Jakub Macina","Julia Chatain","Mrinmaya Sachan","Manu Kapur"],"pdf_url":"https://arxiv.org/pdf/2410.03781v1.pdf","comment":"18 pages, 9 figures, 6 tables"},{"id":"http://arxiv.org/abs/2402.08702v4","updated":"2024-10-03T16:11:43Z","published":"2024-02-13T16:38:01Z","title":"PRompt Optimization in Multi-Step Tasks (PROMST): Integrating Human\n  Feedback and Heuristic-based Sampling","summary":"  Prompt optimization aims to find the best prompt to a large language model\n(LLM) for a given task. LLMs have been successfully used to help find and\nimprove prompt candidates for single-step tasks. However, realistic tasks for\nagents are multi-step and introduce new challenges: (1) Prompt content is\nlikely to be more extensive and complex, making it more difficult for LLMs to\nanalyze errors, (2) the impact of an individual step is difficult to evaluate,\nand (3) different people may have varied preferences about task execution.\nWhile humans struggle to optimize prompts, they are good at providing feedback\nabout LLM outputs; we therefore introduce a new LLM-driven discrete prompt\noptimization framework PRompt Optimization in Multi-Step Tasks (PROMST) that\nincorporates human-designed feedback rules to automatically offer direct\nsuggestions for improvement. We also use an extra learned heuristic model that\npredicts prompt performance to efficiently sample from prompt candidates. This\napproach significantly outperforms both human-engineered prompts and several\nother prompt optimization methods across 11 representative multi-step tasks (an\naverage 10.6\\%-29.3\\% improvement to current best methods on five LLMs\nrespectively). We believe our work can serve as a benchmark for automatic\nprompt optimization for LLM-driven multi-step tasks. Datasets and Codes are\navailable at https://github.com/yongchao98/PROMST. Project Page is available at\nhttps://yongchao98.github.io/MIT-REALM-PROMST.\n","authors":["Yongchao Chen","Jacob Arkin","Yilun Hao","Yang Zhang","Nicholas Roy","Chuchu Fan"],"pdf_url":"https://arxiv.org/pdf/2402.08702v4.pdf","comment":"62 pages, 14 figures, Published in EMNLP 2024 Main"},{"id":"http://arxiv.org/abs/2410.02454v1","updated":"2024-10-03T13:02:34Z","published":"2024-10-03T13:02:34Z","title":"Aggregation of Constrained Crowd Opinions for Urban Planning","summary":"  Collective decision making is often a customary action taken in government\ncrowdsourcing. Through ensemble of opinions (popularly known as judgment\nanalysis), governments can satisfy majority of the people who provided\nopinions. This has various real-world applications like urban planning or\nparticipatory budgeting that require setting up {\\em facilities} based on the\nopinions of citizens. Recently, there is an emerging interest in performing\njudgment analysis on opinions that are constrained. We consider a new dimension\nof this problem that accommodate background constraints in the problem of\njudgment analysis, which ensures the collection of more responsible opinions.\nThe background constraints refer to the restrictions (with respect to the\nexisting infrastructure) to be taken care of while performing the consensus of\nopinions. In this paper, we address the said kind of problems with efficient\nunsupervised approaches of learning suitably modified to cater to the\nconstraints of urban planning. We demonstrate the effectiveness of this\napproach in various scenarios where the opinions are taken for setting up ATM\ncounters and sewage lines. Our main contributions encompass a novel approach of\ncollecting data for smart city planning (in the presence of constraints),\ndevelopment of methods for opinion aggregation in various formats. As a whole,\nwe present a new dimension of judgment analysis by adding background\nconstraints to the problem.\n","authors":["Akanksha Das","Jyoti Patel","Malay Bhattacharyya"],"pdf_url":"https://arxiv.org/pdf/2410.02454v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.02406v1","updated":"2024-10-03T11:32:53Z","published":"2024-10-03T11:32:53Z","title":"ELLMA-T: an Embodied LLM-agent for Supporting English Language Learning\n  in Social VR","summary":"  Many people struggle with learning a new language, with traditional tools\nfalling short in providing contextualized learning tailored to each learner's\nneeds. The recent development of large language models (LLMs) and embodied\nconversational agents (ECAs) in social virtual reality (VR) provide new\nopportunities to practice language learning in a contextualized and\nnaturalistic way that takes into account the learner's language level and\nneeds. To explore this opportunity, we developed ELLMA-T, an ECA that leverages\nan LLM (GPT-4) and situated learning framework for supporting learning English\nlanguage in social VR (VRChat). Drawing on qualitative interviews (N=12), we\nreveal the potential of ELLMA-T to generate realistic, believable and\ncontext-specific role plays for agent-learner interaction in VR, and LLM's\ncapability to provide initial language assessment and continuous feedback to\nlearners. We provide five design implications for the future development of\nLLM-based language agents in social VR.\n","authors":["Mengxu Pan","Alexandra Kitson","Hongyu Wan","Mirjana Prpa"],"pdf_url":"https://arxiv.org/pdf/2410.02406v1.pdf","comment":"20 pages, 6 figures"},{"id":"http://arxiv.org/abs/2410.02360v1","updated":"2024-10-03T10:17:37Z","published":"2024-10-03T10:17:37Z","title":"Source Data Selection for Brain-Computer Interfaces based on Simple\n  Features","summary":"  This paper demonstrates that simple features available during the calibration\nof a brain-computer interface can be utilized for source data selection to\nimprove the performance of the brain-computer interface for a new target user\nthrough transfer learning. To support this, a public motor imagery dataset is\nused for analysis, and a method called the Transfer Performance Predictor\nmethod is presented. The simple features are based on the covariance matrices\nof the data and the Riemannian distance between them. The Transfer Performance\nPredictor method outperforms other source data selection methods as it selects\nsource data that gives a better transfer learning performance for the target\nusers.\n","authors":["Frida Heskebeck","Carolina Bergeling","Bo Bernhardsson"],"pdf_url":"https://arxiv.org/pdf/2410.02360v1.pdf","comment":"10 pages, 3 figures, This work has been submitted to the IEEE for\n  possible publication. Copyright may be transferred without notice, after\n  which this version may no longer be accessible"},{"id":"http://arxiv.org/abs/2410.02264v1","updated":"2024-10-03T07:29:04Z","published":"2024-10-03T07:29:04Z","title":"Can Capacitive Touch Images Enhance Mobile Keyboard Decoding?","summary":"  Capacitive touch sensors capture the two-dimensional spatial profile\n(referred to as a touch heatmap) of a finger's contact with a mobile\ntouchscreen. However, the research and design of touchscreen mobile keyboards\n-- one of the most speed and accuracy demanding touch interfaces -- has focused\non the location of the touch centroid derived from the touch image heatmap as\nthe input, discarding the rest of the raw spatial signals. In this paper, we\ninvestigate whether touch heatmaps can be leveraged to further improve the tap\ndecoding accuracy for mobile touchscreen keyboards. Specifically, we developed\nand evaluated machine-learning models that interpret user taps by using the\ncentroids and/or the heatmaps as their input and studied the contribution of\nthe heatmaps to model performance. The results show that adding the heatmap\ninto the input feature set led to 21.4% relative reduction of character error\nrates on average, compared to using the centroid alone. Furthermore, we\nconducted a live user study with the centroid-based and heatmap-based decoders\nbuilt into Pixel 6 Pro devices and observed lower error rate, faster typing\nspeed, and higher self-reported satisfaction score based on the heatmap-based\ndecoder than the centroid-based decoder. These findings underline the promise\nof utilizing touch heatmaps for improving typing experience in mobile\nkeyboards.\n","authors":["Piyawat Lertvittayakumjorn","Shanqing Cai","Billy Dou","Cedric Ho","Shumin Zhai"],"pdf_url":"https://arxiv.org/pdf/2410.02264v1.pdf","comment":"Accepted to UIST 2024"},{"id":"http://arxiv.org/abs/2410.02221v1","updated":"2024-10-03T05:32:16Z","published":"2024-10-03T05:32:16Z","title":"Capturing complex hand movements and object interactions using machine\n  learning-powered stretchable smart textile gloves","summary":"  Accurate real-time tracking of dexterous hand movements and interactions has\nnumerous applications in human-computer interaction, metaverse, robotics, and\ntele-health. Capturing realistic hand movements is challenging because of the\nlarge number of articulations and degrees of freedom. Here, we report accurate\nand dynamic tracking of articulated hand and finger movements using\nstretchable, washable smart gloves with embedded helical sensor yarns and\ninertial measurement units. The sensor yarns have a high dynamic range,\nresponding to low 0.005 % to high 155 % strains, and show stability during\nextensive use and washing cycles. We use multi-stage machine learning to report\naverage joint angle estimation root mean square errors of 1.21 and 1.45 degrees\nfor intra- and inter-subjects cross-validation, respectively, matching accuracy\nof costly motion capture cameras without occlusion or field of view\nlimitations. We report a data augmentation technique that enhances robustness\nto noise and variations of sensors. We demonstrate accurate tracking of\ndexterous hand movements during object interactions, opening new avenues of\napplications including accurate typing on a mock paper keyboard, recognition of\ncomplex dynamic and static gestures adapted from American Sign Language and\nobject identification.\n","authors":["Arvin Tashakori","Zenan Jiang","Amir Servati","Saeid Soltanian","Harishkumar Narayana","Katherine Le","Caroline Nakayama","Chieh-ling Yang","Z. Jane Wang","Janice J. Eng","Peyman Servati"],"pdf_url":"https://arxiv.org/pdf/2410.02221v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.04620v3","updated":"2024-10-03T05:03:16Z","published":"2024-02-07T07:07:02Z","title":"CataractBot: An LLM-Powered Expert-in-the-Loop Chatbot for Cataract\n  Patients","summary":"  The healthcare landscape is evolving, with patients seeking reliable\ninformation about their health conditions and available treatment options.\nDespite the abundance of information sources, the digital age overwhelms\nindividuals with excess, often inaccurate information. Patients primarily trust\nmedical professionals, highlighting the need for expert-endorsed health\ninformation. However, increased patient loads on experts has led to reduced\ncommunication time, impacting information sharing. To address this gap, we\ndevelop CataractBot, an experts-in-the-loop chatbot powered by LLMs, in\ncollaboration with an eye hospital in India. CataractBot answers cataract\nsurgery related questions instantly by querying a curated knowledge base, and\nprovides expert-verified responses asynchronously. It has multimodal and\nmultilingual capabilities. In an in-the-wild deployment study with 55\nparticipants, CataractBot proved valuable, providing anytime accessibility,\nsaving time, accommodating diverse literacy levels, alleviating power\ndifferences, and adding a privacy layer between patients and doctors. Users\nreported that their trust in the system was established through expert\nverification. Broadly, our results could inform future work on designing\nexpert-mediated LLM bots.\n","authors":["Pragnya Ramjee","Bhuvan Sachdeva","Satvik Golechha","Shreyas Kulkarni","Geeta Fulari","Kaushik Murali","Mohit Jain"],"pdf_url":"https://arxiv.org/pdf/2402.04620v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.01672v2","updated":"2024-10-03T04:46:41Z","published":"2024-10-02T15:41:22Z","title":"Practicing Stress Relief for the Everyday: Designing Social Simulation\n  Using VR, AR, and LLMs","summary":"  Stress is an inevitable part of day-to-day life yet many find themselves\nunable to manage it themselves, particularly when professional or peer support\nare not always readily available. As self-care becomes increasingly vital for\nmental well-being, this paper explores the potential of social simulation as a\nsafe, virtual environment for practicing stress relief for everyday situations.\nLeveraging the immersive capabilities of VR, AR, and LLMs, we developed eight\ninteractive prototypes for various everyday stressful scenarios (e.g. public\nspeaking) then conducted prototype-driven semi-structured interviews with 19\nparticipants. We reveal that people currently lack effective means to support\nthemselves through everyday stress and found that social simulation fills a gap\nfor simulating real environments for training mental health practices. We\noutline key considerations for future development of simulation for self-care,\nincluding risks of trauma from hyper-realism, distrust of LLM-recommended\ntiming for mental health recommendations, and the value of accessibility for\nself-care interventions.\n","authors":["Anna Fang","Hriday Chhabria","Alekhya Maram","Haiyi Zhu"],"pdf_url":"https://arxiv.org/pdf/2410.01672v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.03775v1","updated":"2024-10-03T03:08:29Z","published":"2024-10-03T03:08:29Z","title":"Beyond correlation: The impact of human uncertainty in measuring the\n  effectiveness of automatic evaluation and LLM-as-a-judge","summary":"  The effectiveness of automatic evaluation of generative models is typically\nmeasured by comparing it to human evaluation using correlation metrics.\nHowever, metrics like Krippendorff's $\\alpha$ and Randolph's $\\kappa$,\noriginally designed to measure the reliability of human labeling, make\nassumptions about human behavior and the labeling process. In this paper, we\nshow how *relying on a single aggregate correlation score* can obscure\nfundamental differences between human behavior and automatic evaluation\nmethods, including LLM-as-a-Judge. Specifically, we demonstrate that when the\nproportion of samples with variation or uncertainty in human labels (gathered\nduring human evaluation) is relatively high, machine labels (generated by\nautomatic evaluation methods) may superficially appear to have similar or\nbetter correlation with the human majority label compared to human-to-human\n(HH) correlation. This can create the misleading impression that automatic\nevaluation is accurate enough to approximate the human majority label. However,\nas the proportion of samples with consistent human labels increases, the\ncorrelation between machine labels and human majority labels declines, falling\nbelow HH correlation. Based on these findings, we first propose stratifying\nresults by human label uncertainty to provide a more robust analysis of\nautomatic evaluation performance. Second, recognizing that uncertainty and\nvariation are inherent in perception-based human evaluations, such as those\ninvolving attitudes or preferences, we introduce a new metric - *binned\nJensen-Shannon Divergence for perception* for such scenarios to better measure\nthe effectiveness of automatic evaluations. Third, we present visualization\ntechniques -- *perception charts*, to compare the strengths and limitations of\nautomatic evaluation and to contextualize correlation measures appropriately\n","authors":["Aparna Elangovan","Jongwoo Ko","Lei Xu","Mahsa Elyasi","Ling Liu","Sravan Bodapati","Dan Roth"],"pdf_url":"https://arxiv.org/pdf/2410.03775v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.03774v1","updated":"2024-10-03T02:10:13Z","published":"2024-10-03T02:10:13Z","title":"Human-Based Risk Model for Improved Driver Support in Interactive\n  Driving Scenarios","summary":"  This paper addresses the problem of human-based driver support. Nowadays,\ndriver support systems help users to operate safely in many driving situations.\nNevertheless, these systems do not fully use the rich information that is\navailable from sensing the human driver. In this paper, we therefore present a\nhuman-based risk model that uses driver information for improved driver\nsupport. In contrast to state of the art, our proposed risk model combines a)\nthe current driver perception based on driver errors, such as the driver\noverlooking another vehicle (i.e., notice error), and b) driver\npersonalization, such as the driver being defensive or confident. In extensive\nsimulations of multiple interactive driving scenarios, we show that our novel\nhuman-based risk model achieves earlier warning times and reduced warning\nerrors compared to a baseline risk model not using human driver information.\n","authors":["Tim Puphal","Benedict Flade","Matti Krüger","Ryohei Hirano","Akihito Kimata"],"pdf_url":"https://arxiv.org/pdf/2410.03774v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.02141v1","updated":"2024-10-03T01:58:34Z","published":"2024-10-03T01:58:34Z","title":"E2H: A Two-Stage Non-Invasive Neural Signal Driven Humanoid Robotic\n  Whole-Body Control Framework","summary":"  Recent advancements in humanoid robotics, including the integration of\nhierarchical reinforcement learning-based control and the utilization of LLM\nplanning, have significantly enhanced the ability of robots to perform complex\ntasks. In contrast to the highly developed humanoid robots, the human factors\ninvolved remain relatively unexplored. Directly controlling humanoid robots\nwith the brain has already appeared in many science fiction novels, such as\nPacific Rim and Gundam. In this work, we present E2H (EEG-to-Humanoid), an\ninnovative framework that pioneers the control of humanoid robots using\nhigh-frequency non-invasive neural signals. As the none-invasive signal quality\nremains low in decoding precise spatial trajectory, we decompose the E2H\nframework in an innovative two-stage formation: 1) decoding neural signals\n(EEG) into semantic motion keywords, 2) utilizing LLM facilitated motion\ngeneration with a precise motion imitation control policy to realize humanoid\nrobotics control. The method of directly driving robots with brainwave commands\noffers a novel approach to human-machine collaboration, especially in\nsituations where verbal commands are impractical, such as in cases of speech\nimpairments, space exploration, or underwater exploration, unlocking\nsignificant potential. E2H offers an exciting glimpse into the future, holding\nimmense potential for human-computer interaction.\n","authors":["Yiqun Duan","Jinzhao Zhou","Xiaowei Jiang","Qiang Zhang","Jingkai Sun","Jiahang Cao","Jiaxu Wang","Yiqian Yang","Wen Zhao","Gang Han","Yijie Guo","Chin-Teng Lin"],"pdf_url":"https://arxiv.org/pdf/2410.02141v1.pdf","comment":null}],"Programming Languages":[{"id":"http://arxiv.org/abs/2410.02232v1","updated":"2024-10-03T06:03:40Z","published":"2024-10-03T06:03:40Z","title":"The Long Way to Deforestation (Technical Report): A Type Inference and\n  Elaboration Technique for Removing Intermediate Data Structures","summary":"  Deforestation is a compiler optimization that removes intermediate data\nstructure allocations from functional programs to improve their efficiency.\nThis is an old idea, but previous approaches have proved limited or\nimpractical: they either only worked on compositions of predefined combinators\n(shortcut fusion), or involved the aggressive unfolding of recursive\ndefinitions until a depth limit was reached or a reoccurring pattern was found\nto tie the recursive knot, resulting in impractical algorithmic complexity and\nlarge amounts of code duplication. We present Lumberhack, a general-purpose\ndeforestation approach for purely functional call-by-value programs. Lumberhack\nuses subtype inference to reason about data structure production and\nconsumption and uses an elaboration pass to fuse the corresponding recursive\ndefinitions. It fuses large classes of mutually recursive definitions while\navoiding much of the unproductive (and sometimes counter-productive) code\nduplication inherent in previous approaches. We prove the soundness of\nLumberhack using logical relations and experimentally demonstrate significant\nspeedups in the standard nofib benchmark suite.\n","authors":["Yijia Chen","Lionel Parreaux"],"pdf_url":"https://arxiv.org/pdf/2410.02232v1.pdf","comment":"This is the technical report version of the paper published at ICFP\n  2024"},{"id":"http://arxiv.org/abs/2410.02156v1","updated":"2024-10-03T02:36:30Z","published":"2024-10-03T02:36:30Z","title":"The why, what, and how of AI-based coding in scientific research","summary":"  Computer programming (coding) is indispensable for researchers across\ndisciplines, yet it remains challenging to learn and time-consuming to carry\nout. Generative AI, particularly large language models (LLMs), has the\npotential to transform coding into intuitive conversations, but best practices\nand effective workflows are only emerging. We dissect AI-based coding through\nthree key lenses: the nature and role of LLMs in coding (why), six types of\ncoding assistance they provide (what), and a five-step workflow in action with\npractical implementation strategies (how). Additionally, we address the\nlimitations and future outlook of AI in coding. By offering actionable\ninsights, this framework helps to guide researchers in effectively leveraging\nAI to enhance coding practices and education, accelerating scientific progress.\n","authors":["Tonghe Zhuang","Zhicheng Lin"],"pdf_url":"https://arxiv.org/pdf/2410.02156v1.pdf","comment":"23 pages, 7 figure, 3 boxes"},{"id":"http://arxiv.org/abs/1907.01257v3","updated":"2024-10-03T01:19:52Z","published":"2019-07-02T09:34:59Z","title":"A robust graph-based approach to observational equivalence","summary":"  We propose a new step-wise approach to proving observational equivalence, and\nin particular reasoning about fragility of observational equivalence. Our\napproach is based on what we call local reasoning. The local reasoning exploits\nthe graphical concept of neighbourhood, and it extracts a new, formal, concept\nof robustness as a key sufficient condition of observational equivalence.\nMoreover, our proof methodology is capable of proving a generalised notion of\nobservational equivalence. The generalised notion can be quantified over\nsyntactically restricted contexts instead of all contexts, and also\nquantitatively constrained in terms of the number of reduction steps. The\noperational machinery we use is given by a hypergraph-rewriting abstract\nmachine inspired by Girard's Geometry of Interaction. The behaviour of language\nfeatures, including function abstraction and application, is provided by\nhypergraph-rewriting rules. We demonstrate our proof methodology using the\ncall-by-value lambda-calculus equipped with (higher-order) state.\n","authors":["Dan R. Ghica","Koko Muroya","Todd Waugh Ambridge"],"pdf_url":"https://arxiv.org/pdf/1907.01257v3.pdf","comment":null}],"Operating Systems":[{"id":"http://arxiv.org/abs/2410.00026v2","updated":"2024-10-03T10:23:05Z","published":"2024-09-16T13:28:07Z","title":"The eBPF Runtime in the Linux Kernel","summary":"  Extended Berkeley Packet Filter (eBPF) is a runtime that enables users to\nload programs into the operating system (OS) kernel, like Linux or Windows, and\nexecute them safely and efficiently at designated kernel hooks. Each program\npasses through a verifier that reasons about the safety guarantees for\nexecution. Hosting a safe virtual machine runtime within the kernel makes it\ndynamically programmable. Unlike the popular approach of bypassing or\ncompletely replacing the kernel, eBPF gives users the flexibility to modify the\nkernel on the fly, rapidly experiment and iterate, and deploy solutions to\nachieve their workload-specific needs, while working in concert with the\nkernel.\n  In this paper, we present the first comprehensive description of the design\nand implementation of the eBPF runtime in the Linux kernel. We argue that eBPF\ntoday provides a mature and safe programming environment for the kernel. It has\nseen wide adoption since its inception and is increasingly being used not just\nto extend, but program entire components of the kernel, while preserving its\nruntime integrity. We outline the compelling advantages it offers for\nreal-world production usage, and illustrate current use cases. Finally, we\nidentify its key challenges, and discuss possible future directions.\n","authors":["Bolaji Gbadamosi","Luigi Leonardi","Tobias Pulls","Toke Høiland-Jørgensen","Simone Ferlin-Reiter","Simo Sorce","Anna Brunström"],"pdf_url":"https://arxiv.org/pdf/2410.00026v2.pdf","comment":"22 pages, 6 figures"},{"id":"http://arxiv.org/abs/2305.18639v3","updated":"2024-10-03T01:58:25Z","published":"2023-05-29T22:27:37Z","title":"Securing Cloud File Systems with Trusted Execution","summary":"  Cloud file systems offer organizations a scalable and reliable file storage\nsolution. However, cloud file systems have become prime targets for\nadversaries, and traditional designs are not equipped to protect organizations\nagainst the myriad of attacks that may be initiated by a malicious cloud\nprovider, co-tenant, or end-client. Recently proposed designs leveraging\ncryptographic techniques and trusted execution environments (TEEs) still force\norganizations to make undesirable trade-offs, consequently leading to either\nsecurity, functional, or performance limitations. In this paper, we introduce\nBFS, a cloud file system that leverages the security capabilities provided by\nTEEs to bootstrap new security protocols that deliver strong security\nguarantees, high-performance, and a transparent POSIX-like interface to\nclients. BFS delivers stronger security guarantees and up to a 2.5X speedup\nover a state-of-the-art secure file system. Moreover, compared to the industry\nstandard NFS, BFS achieves up to 2.2X speedups across micro-benchmarks and\nincurs <1X overhead for most macro-benchmark workloads. BFS demonstrates a\nholistic cloud file system design that does not sacrifice an organizations'\nsecurity yet can embrace all of the functional and performance advantages of\noutsourcing.\n","authors":["Quinn Burke","Yohan Beugin","Blaine Hoak","Rachel King","Eric Pauley","Ryan Sheatsley","Mingli Yu","Ting He","Thomas La Porta","Patrick McDaniel"],"pdf_url":"https://arxiv.org/pdf/2305.18639v3.pdf","comment":null}],"Networking and Internet Architecture":[{"id":"http://arxiv.org/abs/2410.02954v1","updated":"2024-10-03T19:55:20Z","published":"2024-10-03T19:55:20Z","title":"Digital Twin for O-RAN Towards 6G","summary":"  In future wireless systems of beyond 5G and 6G, addressing diverse\napplications with varying quality requirements is essential. Open Radio Access\nNetwork (O-RAN) architectures offer the potential for dynamic resource\nadaptation based on traffic demands. However, achieving real-time resource\norchestration remains a challenge. Simultaneously, Digital Twin (DT) technology\nholds promise for testing and analysing complex systems, offering a unique\nplatform for addressing dynamic operation and automation in O-RAN\narchitectures. Yet, developing DTs for complex 5G/6G networks poses challenges,\nincluding data exchanges, ML model training data availability, network\ndynamics, processing power limitations, interdisciplinary collaboration needs,\nand a lack of standardized methodologies. This paper provides an overview of\nOpen RAN architecture, trend and challenges, proposing the DT concepts for\nO-RAN with solution examples showcasing its integration into the framework.\n","authors":["Huan X. Nguyen","Kexuan Sun","Duc To","Quoc-Tuan Vien","Tuan Anh Le"],"pdf_url":"https://arxiv.org/pdf/2410.02954v1.pdf","comment":"IEEE Communications Magazine 2024"},{"id":"http://arxiv.org/abs/2311.14613v4","updated":"2024-10-03T19:14:56Z","published":"2023-11-24T17:12:01Z","title":"Routing and Spectrum Allocation in Broadband Degenerate EPR-Pair\n  Distribution","summary":"  We investigate resource allocation for quantum entanglement distribution over\nan optical network. We characterize and model a network architecture that\nemploys a single quasideterministic time-frequency heralded EPR-pair source,\nand develop a routing scheme for distributing entangled photon pairs over such\na network. We focus on fairness in entanglement distribution, and compare both\nthe performance of various spectrum allocation schemes as well as their Jain\nindex.\n","authors":["Rohan Bali","Ashley Tittelbaugh","Shelbi L. Jenkins","Anuj Agrawal","Jerry Horgan","Marco Ruffini","Daniel Kilper","Boulat A. Bash"],"pdf_url":"https://arxiv.org/pdf/2311.14613v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.02733v1","updated":"2024-10-03T17:51:21Z","published":"2024-10-03T17:51:21Z","title":"Data Similarity-Based One-Shot Clustering for Multi-Task Hierarchical\n  Federated Learning","summary":"  We address the problem of cluster identity estimation in a hierarchical\nfederated learning setting in which users work toward learning different tasks.\nTo overcome the challenge of task heterogeneity, users need to be grouped in a\nway such that users with the same task are in the same group, conducting\ntraining together, while sharing the weights of feature extraction layers with\nthe other groups. Toward that end, we propose a one-shot clustering algorithm\nthat can effectively identify and group users based on their data similarity.\nThis enables more efficient collaboration and sharing of a common layer\nrepresentation within the federated learning system. Our proposed algorithm not\nonly enhances the clustering process, but also overcomes challenges related to\nprivacy concerns, communication overhead, and the need for prior knowledge\nabout learning models or loss function behaviors. We validate our proposed\nalgorithm using various datasets such as CIFAR-10 and Fashion MNIST, and show\nthat it outperforms the baseline in terms of accuracy and variance reduction.\n","authors":["Abdulmoneam Ali","Ahmed Arafa"],"pdf_url":"https://arxiv.org/pdf/2410.02733v1.pdf","comment":"To appear in Asilomar 2024"},{"id":"http://arxiv.org/abs/2410.02688v1","updated":"2024-10-03T17:15:53Z","published":"2024-10-03T17:15:53Z","title":"User-centric Immersive Communications in 6G: A Data-oriented Approach\n  via Digital Twin","summary":"  In this article, we present a novel user-centric service provision for\nimmersive communications (IC) in 6G to deal with the uncertainty of individual\nuser behaviors while satisfying unique requirements on the quality of\nmulti-sensory experience. To this end, we propose a data-oriented approach for\nnetwork resource management, featuring personalized data management that can\nsupport network modeling tailored to different user demands. Our approach\nleverages the digital twin (DT) technique as a key enabler. Particularly, a DT\nis established for each user, and the data attributes in the DT are customized\nbased on the characteristics of the user. The DT functions, corresponding to\nvarious data operations, are customized in the development, evaluation, and\nupdate of network models to meet unique user demands. A trace-driven case study\ndemonstrates the effectiveness of our approach in achieving user-centric IC and\nthe significance of personalized data management in 6G.\n","authors":["Conghao Zhou","Shisheng Hu","Jie Gao","Xinyu Huang","Weihua Zhuang","Xuemin Shen"],"pdf_url":"https://arxiv.org/pdf/2410.02688v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.02610v1","updated":"2024-10-03T15:49:36Z","published":"2024-10-03T15:49:36Z","title":"Research Directions and Modeling Guidelines for Industrial Internet of\n  Things Applications","summary":"  The Industrial Internet of Things (IIoT) paradigm has emerged as a\ntransformative force, revolutionizing industrial processes by integrating\nadvanced wireless technologies into traditional procedures to enhance their\nefficiency. The importance of this paradigm shift has produced a massive, yet\nheterogeneous, proliferation of scientific contributions. However, these works\nlack a standardized and cohesive characterization of the IIoT framework coming\nfrom different entities, like the 3rd Generation Partnership Project (3GPP) or\nthe 5G Alliance for Connected Industries and Automation (5G-ACIA), resulting in\ndivergent perspectives and potentially hindering interoperability. To bridge\nthis gap, this article offers a unified characterization of (i) the main IIoT\napplication domains, (ii) their respective requirements, (iii) the principal\ntechnological gaps existing in the current literature, and, most importantly,\n(iv) we propose a systematic approach for assessing and addressing the\nidentified research challenges. Therefore, this article serves as a roadmap for\nfuture research endeavors, promoting a unified vision of the IIoT paradigm and\nfostering collaborative efforts to advance the field.\n","authors":["Giampaolo Cuozzo","Enrico Testi","Salvatore Riolo","Luciano Miuccio","Gianluca Cena","Gianni Pasolini","Luca De Nardis","Daniela Panno","Marco Chiani","Maria-Gabriella Di Benedetto","Enrico Buracchini","Roberto Verdone"],"pdf_url":"https://arxiv.org/pdf/2410.02610v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.02563v1","updated":"2024-10-03T15:06:48Z","published":"2024-10-03T15:06:48Z","title":"Machine Learning Approaches for Active Queue Management: A Survey,\n  Taxonomy, and Future Directions","summary":"  Active Queue Management (AQM), a network-layer congestion control technique\nendorsed by the Internet Engineering Task Force (IETF), encourages routers to\ndiscard packets before the occurrence of buffer overflow. Traditional AQM\ntechniques often employ heuristic approaches that require meticulous parameter\nadjustments, limiting their real-world applicability. In contrast, Machine\nLearning (ML) approaches offer highly adaptive, data-driven solutions custom to\ndynamic network conditions. Consequently, many researchers have adapted ML for\nAQM throughout the years, resulting in a wide variety of algorithms ranging\nfrom predicting congestion via supervised learning to discovering optimal\npacket-dropping policies with reinforcement learning. Despite these remarkable\nadvancements, no previous work has compiled these methods in the form of a\nsurvey article. This paper presents the first thorough documentation and\nanalysis of ML-based algorithms for AQM, in which the strengths and limitations\nof each proposed method are evaluated and compared. In addition, a novel\ntaxonomy of ML approaches based on methodology is also established. The review\nis concluded by discussing unexplored research gaps and potential new\ndirections for more robust ML-AQM methods.\n","authors":["Mohammad Parsa Toopchinezhad","Mahmood Ahmadi"],"pdf_url":"https://arxiv.org/pdf/2410.02563v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.02487v1","updated":"2024-10-03T13:50:45Z","published":"2024-10-03T13:50:45Z","title":"Optimal Digital Twinning of Random Systems with Twinning Rate\n  Constraints","summary":"  With the massive advancements in processing power, Digital Twins (DTs) have\nbecome powerful tools to monitor and analyze physical entities. However, due to\nthe potentially very high number of Physical Systems (PSs) to be tracked and\nemulated, for instance, in a factory environment or an Internet of Things (IoT)\nnetwork, continuous twinning might become infeasible. In this paper, a DT\nsystem is investigated with a set of random PSs, where the twinning rate is\nlimited due to resource constraints. Three cost functions are considered to\nquantify and penalize the twinning delay. For these cost functions, the optimal\ntwinning problem under twinning rate constraints is formulated. In a numerical\nexample, the proposed cost functions are evaluated for two, one push-based and\none pull-based, benchmark twinning policies. The proposed methodology is the\nfirst to investigate the optimal twinning problem with random PSs and twinning\nrate constraints, and serves as a guideline for real-world implementations on\nhow frequently PSs should be twinned.\n","authors":["Caglar Tunc"],"pdf_url":"https://arxiv.org/pdf/2410.02487v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.02434v1","updated":"2024-10-03T12:28:44Z","published":"2024-10-03T12:28:44Z","title":"Load Balancing-based Topology Adaptation for Integrated Access and\n  Backhaul Networks","summary":"  Integrated access and backhaul (IAB) technology is a flexible solution for\nnetwork densification. IAB nodes can also be deployed in moving nodes such as\nbuses and trains, i.e., mobile IAB (mIAB). As mIAB nodes can move around the\ncoverage area, the connection between mIAB nodes and their parent macro base\nstations (BSs), IAB donor, is sometimes required to change in order to keep an\nacceptable backhaul link, the so called topology adaptation (TA). The change\nfrom one IAB donor to another may strongly impact the system load distribution,\npossibly causing unsatisfactory backhaul service due to the lack of radio\nresources. Based on this, TA should consider both backhaul link quality and\ntraffic load. In this work, we propose a load balancing algorithm based on TA\nfor IAB networks, and compare it with an approach in which TA is triggered\nbased on reference signal received power (RSRP) only. The results show that our\nproposed algorithm improves the passengers worst connections throughput in\nuplink (UL) and, more modestly, also in downlink (DL), without impairing the\npedestrian quality of service (QoS) significantly.\n","authors":["Raul Victor de O. Paiva","Fco. Italo G. Carvalho","Fco. Rafael M. Lima","Victor F. Monteiro","Diego A. Sousa","Darlan C. Moreira","Tarcisio F. Maciel","Behrooz Makki"],"pdf_url":"https://arxiv.org/pdf/2410.02434v1.pdf","comment":"Paper submitted to Journal of Communication and Information Systems\n  (JCIS)"},{"id":"http://arxiv.org/abs/2410.02415v1","updated":"2024-10-03T12:03:56Z","published":"2024-10-03T12:03:56Z","title":"Cellular Network Densification: a System-level Analysis with IAB, NCR\n  and RIS","summary":"  As the number of user equipments increases in fifth generation (5G) and\nbeyond, it is desired to densify the cellular network with auxiliary nodes\nassisting the base stations. Examples of these nodes are integrated access and\nbackhaul (IAB) nodes, network-controlled repeaters (NCRs) and reconfigurable\nintelligent surfaces (RISs). In this context, this work presents a system level\noverview of these three nodes. Moreover, this work evaluates through\nsimulations the impact of network planning aiming at enhancing the performance\nof a network used to cover an outdoor sport event. We show that, in the\nconsidered scenario, in general, IAB nodes provide an improved signal to\ninterference-plus-noise ratio and throughput, compared to NCRs and RISs.\nHowever, there are situations where NCR outperforms IAB due to higher level of\ninterference caused by the latter. Finally, we show that the deployment of\nthese nodes in unmanned aerial vehicles (UAVs) also achieves performance gains\ndue to their aerial mobility. However, UAV constraints related to aerial\ndeployment may prevent these nodes from reaching results as good as the ones\nachieved by their stationary deployment.\n","authors":["Gabriel C. M. da Silva","Victor F. Monteiro","Diego A. Sousa","Darlan C. Moreira","Tarcisio F. Maciel","Fco. Rafael M. Lima","Behrooz Makki"],"pdf_url":"https://arxiv.org/pdf/2410.02415v1.pdf","comment":"Paper submitted to IEEE Systems Journal"},{"id":"http://arxiv.org/abs/2403.05301v2","updated":"2024-10-03T11:59:20Z","published":"2024-03-08T13:31:43Z","title":"Wykorzystanie Rekonfigurowalnych Iinteligentnych Matryc Antenowych w\n  Łączu Dosyłowym Sieci 5G/6G Wykorzystującej Bezzałogowe\n  Statki Powietrzne","summary":"  Drony, dzi\\k{e}ki mo\\.zliwo\\'sci ich szybkiego rozmieszczenia w trudnym\nterenie, uwa\\.zane s\\k{a} za jeden z kluczowych element\\'ow system\\'ow\nbezprzewodowych 6G. Jednak w celu wykorzystania ich jako punkty dost\\k{e}powe\nsieci konieczne jest zapewnienie {\\l}\\k{a}cza dosy{\\l}owego o odpowiedniej\nprzepustowo\\'sci. Dlatego w niniejszym artykule rozwa\\.zane jest\nzwi\\k{e}kszenie zasi\\k{e}gu sieci bezprzewodowej przez zapewnienie {\\l}\\k{a}cza\ndosy{\\l}owego dla ko\\'ncowego punktu dost\\k{e}powego z wykorzystaniem\nokre\\'slonej liczby dron\\'ow-przeka\\'znik\\'ow oraz rekonfigurowalnych\ninteligentnych matryc antenowych (RIS). Zaprezentowane wyniki bada\\'n\nsymulacyjnych pokazuj\\k{a}, \\.ze u\\.zycie RIS pozwala na znacz\\k{a}ce\nzwi\\k{e}kszenie zasi\\k{e}gu sieci bez konieczno\\'sci stosowania dodatkowych\nprzeka\\'znik\\'ow.\n  --\n  Unmanned Aerial Vehicles, due to the possibility of their fast deployment,\nare considered an essential element of the future wireless 6G communication\nsystems. However, an essential enabler for their use as access points is to\nprovide a sufficient throughput wireless backhaul link. Thus, in this paper we\nconsider the aspect of extension of network coverage with the use of\ndrone-based relaying and reconfigurable intelligent surfaces (RIS) for\nbackhauling. Presented results of simulation experiments indicate that the use\nof RIS allows for significant improvement of network coverage without the need\nto use additional relays.\n","authors":["Salim Janji","Paweł Sroka","Adrian Kliks"],"pdf_url":"https://arxiv.org/pdf/2403.05301v2.pdf","comment":"in Polish language"},{"id":"http://arxiv.org/abs/2410.02329v1","updated":"2024-10-03T09:28:10Z","published":"2024-10-03T09:28:10Z","title":"AirTags for Human Localization, Not Just Objects","summary":"  Indoor localization has become increasingly important due to its wide-ranging\napplications in indoor navigation, emergency services, the Internet of Things\n(IoT), and accessibility for individuals with special needs. Traditional\nlocalization systems often require extensive calibration to achieve high\naccuracy. We introduce UbiLoc, an innovative, calibration-free indoor\nlocalization system that leverages Apple AirTags in a novel way to localize\nusers instead of tracking objects. By utilizing the ubiquitous presence of\nAirTags and their Ultra-Wideband (UWB) technology, UbiLoc achieves\ncentimeter-level accuracy, surpassing traditional WiFi and Bluetooth Low Energy\n(BLE) systems. UbiLoc addresses key challenges, including ranging errors caused\nby multipath and noise, through a novel AirTag selection technique. The system\noperates without the need for manual calibration, ensuring robustness and\nself-maintenance. Deployed on various Apple devices and tested in real-world\nenvironments, UbiLoc achieved median localization errors as low as 26 cm in a\ncampus building and 31.5 cm in an apartment setting. These results demonstrate\nthat UbiLoc is the first system to offer reliable, cm-level accuracy using\nwidely available technology without requiring calibration, making it a\npromising solution for next-generation indoor localization systems.\n","authors":["Mohamed I. Hany","Hamada Rizk","Moustafa Youssef"],"pdf_url":"https://arxiv.org/pdf/2410.02329v1.pdf","comment":"Accepted for publication in 2nd ACM SIGSPATIAL International Workshop\n  on Geo-Privacy and Data Utility for Smart Societies: 7 pages, 9 figures"},{"id":"http://arxiv.org/abs/2410.02312v1","updated":"2024-10-03T08:51:32Z","published":"2024-10-03T08:51:32Z","title":"Federated Reinforcement Learning to Optimize Teleoperated Driving\n  Networks","summary":"  Several sixth generation (6G) use cases have tight requirements in terms of\nreliability and latency, in particular teleoperated driving (TD). To address\nthose requirements, Predictive Quality of Service (PQoS), possibly combined\nwith reinforcement learning (RL), has emerged as a valid approach to\ndynamically adapt the configuration of the TD application (e.g., the level of\ncompression of automotive data) to the experienced network conditions. In this\nwork, we explore different classes of RL algorithms for PQoS, namely MAB\n(stateless), SARSA (stateful on-policy), Q-Learning (stateful off-policy), and\nDSARSA and DDQN (with Neural Network (NN) approximation). We trained the agents\nin a federated learning (FL) setup to improve the convergence time and\nfairness, and to promote privacy and security. The goal is to optimize the\ntrade-off between Quality of Service (QoS), measured in terms of the end-to-end\nlatency, and Quality of Experience (QoE), measured in terms of the quality of\nthe resulting compression operation. We show that Q-Learning uses a small\nnumber of learnable parameters, and is the best approach to perform PQoS in the\nTD scenario in terms of average reward, convergence, and computational cost.\n","authors":["Filippo Bragato","Marco Giordani","Michele Zorzi"],"pdf_url":"https://arxiv.org/pdf/2410.02312v1.pdf","comment":"This paper has been accepted for publication at IEEE Global\n  Communications Conference (GLOBECOM), 2024"},{"id":"http://arxiv.org/abs/2410.02254v1","updated":"2024-10-03T06:47:16Z","published":"2024-10-03T06:47:16Z","title":"MTDNS: Moving Target Defense for Resilient DNS Infrastructure","summary":"  One of the most critical components of the Internet that an attacker could\nexploit is the DNS (Domain Name System) protocol and infrastructure.\nResearchers have been constantly developing methods to detect and defend\nagainst the attacks against DNS, specifically DNS flooding attacks. However,\nmost solutions discard packets for defensive approaches, which can cause\nlegitimate packets to be dropped, making them highly dependable on detection\nstrategies. In this paper, we propose MTDNS, a resilient MTD-based approach\nthat employs Moving Target Defense techniques through Software Defined\nNetworking (SDN) switches to redirect traffic to alternate DNS servers that are\ndynamically created and run under the Network Function Virtualization (NFV)\nframework. The proposed approach is implemented in a testbed environment by\nrunning our DNS servers as separate Virtual Network Functions, NFV Manager, SDN\nswitches, and an SDN Controller. The experimental result shows that the MTDNS\napproach achieves a much higher success rate in resolving DNS queries and\nsignificantly reduces average latency even if there is a DNS flooding attack.\n","authors":["Abdullah Aydeger","Pei Zhou","Sanzida Hoque","Marco Carvalho","Engin Zeydan"],"pdf_url":"https://arxiv.org/pdf/2410.02254v1.pdf","comment":"6 pages, Accepted for publication at IEEE CCNC 2025"},{"id":"http://arxiv.org/abs/2410.02122v1","updated":"2024-10-03T01:01:29Z","published":"2024-10-03T01:01:29Z","title":"Resource Allocation Based on Optimal Transport Theory in ISAC-Enabled\n  Multi-UAV Networks","summary":"  This paper investigates the resource allocation optimization for cooperative\ncommunication with non-cooperative localization in integrated sensing and\ncommunications (ISAC)-enabled multi-unmanned aerial vehicle (UAV) cooperative\nnetworks. Our goal is to maximize the weighted sum of the system's average sum\nrate and the localization quality of service (QoS) by jointly optimizing cell\nassociation, communication power allocation, and sensing power allocation.\nSince the formulated problem is a mixed-integer nonconvex problem, we propose\nthe alternating iteration algorithm based on optimal transport theory (AIBOT)\nto solve the optimization problem more effectively. Simulation results\ndemonstrate that the AIBOT can improve the system sum rate by nearly 12% and\nreduce the localization Cr'amer-Rao bound (CRB) by almost 29% compared to\nbenchmark algorithms.\n","authors":["Yufeng Zheng","Lixin Li","Wensheng Lin","Wei Liang","Qinghe Du","Zhu Han"],"pdf_url":"https://arxiv.org/pdf/2410.02122v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.02121v1","updated":"2024-10-03T01:01:04Z","published":"2024-10-03T01:01:04Z","title":"SC-CDM: Enhancing Quality of Image Semantic Communication with a Compact\n  Diffusion Model","summary":"  Semantic Communication (SC) is an emerging technology that has attracted much\nattention in the sixth-generation (6G) mobile communication systems. However,\nfew literature has fully considered the perceptual quality of the reconstructed\nimage. To solve this problem, we propose a generative SC for wireless image\ntransmission (denoted as SC-CDM). This approach leverages compact diffusion\nmodels to improve the fidelity and semantic accuracy of the images\nreconstructed after transmission, ensuring that the essential content is\npreserved even in bandwidth-constrained environments. Specifically, we aim to\nredesign the swin Transformer as a new backbone for efficient semantic feature\nextraction and compression. Next, the receiver integrates the slim prior and\nimage reconstruction networks. Compared to traditional Diffusion Models (DMs),\nit leverages DMs' robust distribution mapping capability to generate a compact\ncondition vector, guiding image recovery, thus enhancing the perceptual details\nof the reconstructed images. Finally, a series of evaluation and ablation\nstudies are conducted to validate the effectiveness and robustness of the\nproposed algorithm and further increase the Peak Signal-to-Noise Ratio (PSNR)\nby over 17% on top of CNN-based DeepJSCC.\n","authors":["Kexin Zhang","Lixin Li","Wensheng Lin","Yuna Yan","Wenchi Cheng","Zhu Han"],"pdf_url":"https://arxiv.org/pdf/2410.02121v1.pdf","comment":"arXiv admin note: text overlap with arXiv:2408.05112"},{"id":"http://arxiv.org/abs/2410.02120v1","updated":"2024-10-03T01:00:47Z","published":"2024-10-03T01:00:47Z","title":"Lossy Cooperative UAV Relaying Networks: Outage Probability Analysis and\n  Location Optimization","summary":"  In this paper, performance of a lossy cooperative unmanned aerial vehicle\n(UAV) relay communication system is analyzed. In this system, the UAV relay\nadopts lossy forward (LF) strategy and the receiver has certain distortion\nrequirements for the received information. For the system described above, we\nfirst derive the achievable rate distortion region of the system. Then, on the\nbasis of the region analysis, the system outage probability when the channel\nsuffers Nakagami-$m$ fading is analyzed. Finally, we design an optimal relay\nposition identification algorithm based on the Soft Actor-Critic (SAC)\nalgorithm, which determines the optimal UAV position to minimize the outage\nprobability. The simulation results show that the proposed algorithm can\noptimize the UAV position and reduce the system outage probability effectively.\n","authors":["Ya Lian","Wensheng Lin","Lixin Li","Fucheng Yang","Zhu Han","Tad Matsumoto"],"pdf_url":"https://arxiv.org/pdf/2410.02120v1.pdf","comment":null}],"Distributed, Parallel, and Cluster Computing":[{"id":"http://arxiv.org/abs/2410.03042v1","updated":"2024-10-03T23:16:13Z","published":"2024-10-03T23:16:13Z","title":"FedPeWS: Personalized Warmup via Subnetworks for Enhanced Heterogeneous\n  Federated Learning","summary":"  Statistical data heterogeneity is a significant barrier to convergence in\nfederated learning (FL). While prior work has advanced heterogeneous FL through\nbetter optimization objectives, these methods fall short when there is extreme\ndata heterogeneity among collaborating participants. We hypothesize that\nconvergence under extreme data heterogeneity is primarily hindered due to the\naggregation of conflicting updates from the participants in the initial\ncollaboration rounds. To overcome this problem, we propose a warmup phase where\neach participant learns a personalized mask and updates only a subnetwork of\nthe full model. This personalized warmup allows the participants to focus\ninitially on learning specific subnetworks tailored to the heterogeneity of\ntheir data. After the warmup phase, the participants revert to standard\nfederated optimization, where all parameters are communicated. We empirically\ndemonstrate that the proposed personalized warmup via subnetworks (FedPeWS)\napproach improves accuracy and convergence speed over standard federated\noptimization methods.\n","authors":["Nurbek Tastan","Samuel Horvath","Martin Takac","Karthik Nandakumar"],"pdf_url":"https://arxiv.org/pdf/2410.03042v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.00023v2","updated":"2024-10-03T17:50:33Z","published":"2024-05-08T06:30:58Z","title":"Preble: Efficient Distributed Prompt Scheduling for LLM Serving","summary":"  Prompts to large language models (LLMs) have evolved beyond simple user\nquestions. For LLMs to solve complex problems, today's practices are to include\ndomain-specific instructions, illustration of tool usages, and/or long context\nsuch as textbook chapters in prompts. As such, many parts of prompts are\nrepetitive across requests. Recent works propose to cache and reuse KV state of\nprompts. However, they are all confined to a single-GPU optimization, while\nproduction LLM serving systems are distributed by nature.\n  This paper proposes Preble, the first distributed LLM serving platform that\ntargets and optimizes for prompt sharing. We designed a distributed scheduling\nsystem that co-optimizes KV state reuse and computation load-balancing with a\nnew scheduling algorithm and a hierarchical scheduling mechanism. Our\nevaluation of Preble with real workloads and request arrival patterns on two\nopen-source LLMs shows that Preble outperforms the SOTA serving systems by 1.5X\nto 14.5X on average latency and 2X to 10X on p99 latency.\n","authors":["Vikranth Srivatsa","Zijian He","Reyna Abhyankar","Dongming Li","Yiying Zhang"],"pdf_url":"https://arxiv.org/pdf/2407.00023v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.02682v1","updated":"2024-10-03T17:08:03Z","published":"2024-10-03T17:08:03Z","title":"EinDecomp: Decomposition of Declaratively-Specified Machine Learning and\n  Numerical Computations for Parallel Execution","summary":"  We consider the problem of automatically decomposing operations over tensors\nor arrays so that they can be executed in parallel on multiple devices. We\naddress two, closely-linked questions. First, what programming abstraction\nshould systems for tensor-based computing offer to enable such decompositions?\nSecond, given that abstraction, how should such systems automatically decompose\na tensor-based computation? We assert that tensor-based systems should offer a\nprogramming abstraction based on an extended Einstein summation notation, which\nis a fully declarative, mathematical specification for tensor computations. We\nshow that any computation specified in the Einstein summation notation can be\nre-written into an equivalent tensor-relational computation, and this re-write\ngeneralizes existing notations of tensor parallelism such as \"data parallel''\nand \"model parallel.'' We consider the algorithmic problem of optimally\ncomputing a tensor-relational decomposition of a graph of operations specified\nin our extended Einstein summation notation, and we experimentally show the\nvalue of the algorithm that we develop.\n","authors":["Daniel Bourgeois","Zhimin Ding","Dimitrije Jankov","Jiehui Li","Mahmoud Sleem","Yuxin Tang","Jiawen Yao","Xinyu Yao","Chris Jermaine"],"pdf_url":"https://arxiv.org/pdf/2410.02682v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.16283v3","updated":"2024-10-03T16:33:21Z","published":"2024-05-25T15:49:04Z","title":"TURNIP: A \"Nondeterministic\" GPU Runtime with CPU RAM Offload","summary":"  An obvious way to alleviate memory difficulties in GPU-based AI computing is\nvia CPU offload, where data are moved between GPU and CPU RAM, so inexpensive\nCPU RAM is used to increase the amount of storage available. While CPU offload\nis an obvious idea, it can greatly slow down a computation, due to the\nrelatively slow transfer rate between CPU RAM and GPU RAM. Thus, any system for\nCPU offload needs to ensure that when such a transfer needs to happen, no\ncomputation is blocked waiting for the transfer to finish. One of the key\nchallenges when using CPU offload is that memory transfers introduce\nnondeterminacy into the system: it is not possible to know before runtime when\nthe transfers will finish, and hence what is the best order of operations to\nrun to ensure there is no blocking. In this paper, we describe TURNIP, which is\na system for running AI computations using CPU offload. The key innovation in\nTURNIP is the compilation of the AI computation into a dependency graph that\ngives the TURNIP runtime freedom to run operations such as GPU kernel calls in\nmany different orders; at runtime, TURNIP chooses the best order in response to\nreal-time events.\n","authors":["Zhimin Ding","Jiawen Yao","Brianna Barrow","Tania Lorido Botran","Christopher Jermaine","Yuxin Tang","Jiehui Li","Xinyu Yao","Sleem Mahmoud Abdelghafar","Daniel Bourgeois"],"pdf_url":"https://arxiv.org/pdf/2405.16283v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.10960v3","updated":"2024-10-03T15:48:45Z","published":"2024-07-15T17:55:42Z","title":"Fast Matrix Multiplications for Lookup Table-Quantized LLMs","summary":"  The deployment of large language models (LLMs) is often constrained by memory\nbandwidth, where the primary bottleneck is the cost of transferring model\nparameters from the GPU's global memory to its registers. When coupled with\ncustom kernels that fuse the dequantization and matmul operations, weight-only\nquantization can thus enable faster inference by reducing the amount of memory\nmovement. However, developing high-performance kernels for weight-quantized\nLLMs presents substantial challenges, especially when the weights are\ncompressed to non-evenly-divisible bit widths (e.g., 3 bits) with non-uniform,\nlookup table (LUT) quantization. This paper describes FLUTE, a flexible lookup\ntable engine for LUT-quantized LLMs, which uses offline restructuring of the\nquantized weight matrix to minimize bit manipulations associated with\nunpacking, and vectorization and duplication of the lookup table to mitigate\nshared memory bandwidth constraints. At batch sizes < 32 and quantization group\nsize of 128 (typical in LLM inference), the FLUTE kernel can be 2-4x faster\nthan existing GEMM kernels. As an application of FLUTE, we explore a simple\nextension to lookup table-based NormalFloat quantization and apply it to\nquantize LLaMA3 to various configurations, obtaining competitive quantization\nperformance against strong baselines while obtaining an end-to-end throughput\nincrease of 1.5 to 2 times.\n","authors":["Han Guo","William Brandon","Radostin Cholakov","Jonathan Ragan-Kelley","Eric P. Xing","Yoon Kim"],"pdf_url":"https://arxiv.org/pdf/2407.10960v3.pdf","comment":"EMNLP 2024 (Findings)"},{"id":"http://arxiv.org/abs/2410.02599v1","updated":"2024-10-03T15:41:31Z","published":"2024-10-03T15:41:31Z","title":"Disaggregated Memory with SmartNIC Offloading: a Case Study on Graph\n  Processing","summary":"  Disaggregated memory breaks the boundary of monolithic servers to enable\nmemory provisioning on demand. Using network-attached memory to provide memory\nexpansion for memory-intensive applications on compute nodes can improve the\noverall memory utilization on a cluster and reduce the total cost of ownership.\nHowever, current software solutions for leveraging network-attached memory must\nconsume resources on the compute node for memory management tasks. Emerging\noff-path smartNICs provide general-purpose programmability at low-cost\nlow-power cores. This work provides a general architecture design that enables\nnetwork-attached memory and offloading tasks onto off-path programmable\nSmartNIC. We provide a prototype implementation called SODA on Nvidia BlueField\nDPU. SODA adapts communication paths and data transfer alternatives, pipelines\ndata movement stages, and enables customizable data caching and prefetching\noptimizations. We evaluate SODA in five representative graph applications on\nreal-world graphs. Our results show that SODA can achieve up to 7.9x speedup\ncompared to node-local SSD and reduce network traffic by 42% compared to\ndisaggregated memory without SmartNIC offloading at similar or better\nperformance.\n","authors":["Jacob Wahlgren","Gabin Schieffer","Maya Gokhale","Roger Pearce","Ivy Peng"],"pdf_url":"https://arxiv.org/pdf/2410.02599v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.02544v1","updated":"2024-10-03T14:48:36Z","published":"2024-10-03T14:48:36Z","title":"Federated k-Core Decomposition: A Secure Distributed Approach","summary":"  As one of the most well-studied cohesive subgraph models, the $k$-core is\nwidely used to find graph nodes that are ``central'' or ``important'' in many\napplications, such as biological networks, social networks, ecological\nnetworks, and financial networks. For distributed networks, e.g., Decentralized\nOnline Social Networks (DOSNs) such that each vertex is a client as a single\ncomputing unit, the distributed $k$-core decomposition algorithms are already\nproposed. However, current distributed approaches fail to adequately protect\nprivacy and security. In today's data-driven world, data privacy and security\nhave attracted more and more attention, e.g., DOSNs are proposed to protect\nprivacy by storing user information locally without using a single centralized\nserver. In this work, we are the first to propose the secure version of the\ndistributed $k$-core decomposition.\n","authors":["Bin Guo","Emil Sekerinski","Lingyang Chu"],"pdf_url":"https://arxiv.org/pdf/2410.02544v1.pdf","comment":"14 pages, 7 figures"},{"id":"http://arxiv.org/abs/2410.02541v1","updated":"2024-10-03T14:45:23Z","published":"2024-10-03T14:45:23Z","title":"Fair Decentralized Learning","summary":"  Decentralized learning (DL) is an emerging approach that enables nodes to\ncollaboratively train a machine learning model without sharing raw data. In\nmany application domains, such as healthcare, this approach faces challenges\ndue to the high level of heterogeneity in the training data's feature space.\nSuch feature heterogeneity lowers model utility and negatively impacts\nfairness, particularly for nodes with under-represented training data. In this\npaper, we introduce \\textsc{Facade}, a clustering-based DL algorithm\nspecifically designed for fair model training when the training data exhibits\nseveral distinct features. The challenge of \\textsc{Facade} is to assign nodes\nto clusters, one for each feature, based on the similarity in the features of\ntheir local data, without requiring individual nodes to know apriori which\ncluster they belong to. \\textsc{Facade} (1) dynamically assigns nodes to their\nappropriate clusters over time, and (2) enables nodes to collaboratively train\na specialized model for each cluster in a fully decentralized manner. We\ntheoretically prove the convergence of \\textsc{Facade}, implement our\nalgorithm, and compare it against three state-of-the-art baselines. Our\nexperimental results on three datasets demonstrate the superiority of our\napproach in terms of model accuracy and fairness compared to all three\ncompetitors. Compared to the best-performing baseline, \\textsc{Facade} on the\nCIFAR-10 dataset also reduces communication costs by 32.3\\% to reach a target\naccuracy when cluster sizes are imbalanced.\n","authors":["Sayan Biswas","Anne-Marie Kermarrec","Rishi Sharma","Thibaud Trinca","Martijn de Vos"],"pdf_url":"https://arxiv.org/pdf/2410.02541v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.02529v1","updated":"2024-10-03T14:36:32Z","published":"2024-10-03T14:36:32Z","title":"An Edge-Computing based Industrial Gateway for Industry 4.0 using ARM\n  TrustZone Technology","summary":"  Secure and efficient communication to establish a seamless nexus between the\nfive levels of a typical automation pyramid is paramount to Industry 4.0.\nSpecifically, vertical and horizontal integration of these levels is an\noverarching requirement to accelerate productivity and improve operational\nactivities. Vertical integration can improve visibility, flexibility, and\nproductivity by connecting systems and applications. Horizontal integration can\nprovide better collaboration and adaptability by connecting internal production\nfacilities, multi-site operations, and third-party partners in a supply chain.\nIn this paper, we propose an Edge-computing-based Industrial Gateway for\ninterfacing information technology and operational technology that can enable\nIndustry 4.0 vertical and horizontal integration. Subsequently, we design and\ndevelop a working prototype to demonstrate a remote production-line maintenance\nuse case with a strong focus on security aspects and the edge paradigm to bring\ncomputational resources and data storage closer to data sources.\n","authors":["Sandeep Gupta"],"pdf_url":"https://arxiv.org/pdf/2410.02529v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.02478v1","updated":"2024-10-03T13:35:28Z","published":"2024-10-03T13:35:28Z","title":"Temporal Predictive Coding for Gradient Compression in Distributed\n  Learning","summary":"  This paper proposes a prediction-based gradient compression method for\ndistributed learning with event-triggered communication. Our goal is to reduce\nthe amount of information transmitted from the distributed agents to the\nparameter server by exploiting temporal correlation in the local gradients. We\nuse a linear predictor that \\textit{combines past gradients to form a\nprediction of the current gradient}, with coefficients that are optimized by\nsolving a least-square problem. In each iteration, every agent transmits the\npredictor coefficients to the server such that the predicted local gradient can\nbe computed. The difference between the true local gradient and the predicted\none, termed the \\textit{prediction residual, is only transmitted when its norm\nis above some threshold.} When this additional communication step is omitted,\nthe server uses the prediction as the estimated gradient. This proposed design\nshows notable performance gains compared to existing methods in the literature,\nachieving convergence with reduced communication costs.\n","authors":["Adrian Edin","Zheng Chen","Michel Kieffer","Mikael Johansson"],"pdf_url":"https://arxiv.org/pdf/2410.02478v1.pdf","comment":"8 pages, 3 figures, presented at the 60th Allerton conference on\n  Communication, Control, and Computing"},{"id":"http://arxiv.org/abs/2410.02450v1","updated":"2024-10-03T12:52:36Z","published":"2024-10-03T12:52:36Z","title":"Personalized Federated Learning for Generative AI-Assisted Semantic\n  Communications","summary":"  Semantic Communication (SC) focuses on transmitting only the semantic\ninformation rather than the raw data. This approach offers an efficient\nsolution to the issue of spectrum resource utilization caused by the various\nintelligent applications on Mobile Users (MUs). Generative Artificial\nIntelligence (GAI) models have recently exhibited remarkable content generation\nand signal processing capabilities, presenting new opportunities for enhancing\nSC. Therefore, we propose a GAI-assisted SC (GSC) model deployed between MUs\nand the Base Station (BS). Then, to train the GSC model using the local data of\nMUs while ensuring privacy and accommodating heterogeneous requirements of MUs,\nwe introduce Personalized Semantic Federated Learning (PSFL). This approach\nincorporates a novel Personalized Local Distillation (PLD) and Adaptive Global\nPruning (AGP). In PLD, each MU selects a personalized GSC model as a mentor\ntailored to its local resources and a unified Convolutional Neural Networks\n(CNN)-based SC (CSC) model as a student. This mentor model is then distilled\ninto the student model for global aggregation. In AGP, we perform network\npruning on the aggregated global model according to real-time communication\nenvironments, reducing communication energy. Finally, numerical results\ndemonstrate the feasibility and efficiency of the proposed PSFL scheme.\n","authors":["Yubo Peng","Feibo Jiang","Li Dong","Kezhi Wang","Kun Yang"],"pdf_url":"https://arxiv.org/pdf/2410.02450v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.03086v2","updated":"2024-10-03T12:45:48Z","published":"2024-07-03T13:15:12Z","title":"Effective Heterogeneous Federated Learning via Efficient\n  Hypernetwork-based Weight Generation","summary":"  While federated learning leverages distributed client resources, it faces\nchallenges due to heterogeneous client capabilities. This necessitates\nallocating models suited to clients' resources and careful parameter\naggregation to accommodate this heterogeneity. We propose HypeMeFed, a novel\nfederated learning framework for supporting client heterogeneity by combining a\nmulti-exit network architecture with hypernetwork-based model weight\ngeneration. This approach aligns the feature spaces of heterogeneous model\nlayers and resolves per-layer information disparity during weight aggregation.\nTo practically realize HypeMeFed, we also propose a low-rank factorization\napproach to minimize computation and memory overhead associated with\nhypernetworks. Our evaluations on a real-world heterogeneous device testbed\nindicate that \\system enhances accuracy by 5.12% over FedAvg, reduces the\nhypernetwork memory requirements by 98.22%, and accelerates its operations by\n1.86x compared to a naive hypernetwork approach. These results demonstrate\nHypeMeFed's effectiveness in leveraging and engaging heterogeneous clients for\nfederated learning.\n","authors":["Yujin Shin","Kichang Lee","Sungmin Lee","You Rim Choi","Hyung-Sin Kim","JeongGil Ko"],"pdf_url":"https://arxiv.org/pdf/2407.03086v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.02425v1","updated":"2024-10-03T12:19:06Z","published":"2024-10-03T12:19:06Z","title":"LLM-Pilot: Characterize and Optimize Performance of your LLM Inference\n  Services","summary":"  As Large Language Models (LLMs) are rapidly growing in popularity, LLM\ninference services must be able to serve requests from thousands of users while\nsatisfying performance requirements. The performance of an LLM inference\nservice is largely determined by the hardware onto which it is deployed, but\nunderstanding of which hardware will deliver on performance requirements\nremains challenging. In this work we present LLM-Pilot - a first-of-its-kind\nsystem for characterizing and predicting performance of LLM inference services.\nLLM-Pilot performs benchmarking of LLM inference services, under a realistic\nworkload, across a variety of GPUs, and optimizes the service configuration for\neach considered GPU to maximize performance. Finally, using this\ncharacterization data, LLM-Pilot learns a predictive model, which can be used\nto recommend the most cost-effective hardware for a previously unseen LLM.\nCompared to existing methods, LLM-Pilot can deliver on performance requirements\n33% more frequently, whilst reducing costs by 60% on average.\n","authors":["Małgorzata Łazuka","Andreea Anghel","Thomas Parnell"],"pdf_url":"https://arxiv.org/pdf/2410.02425v1.pdf","comment":"Accepted to the International Conference for High Performance\n  Computing, Networking, Storage and Analysis (SC '24)"},{"id":"http://arxiv.org/abs/2409.15558v2","updated":"2024-10-03T10:40:23Z","published":"2024-09-23T21:29:03Z","title":"Stalactite: Toolbox for Fast Prototyping of Vertical Federated Learning\n  Systems","summary":"  Machine learning (ML) models trained on datasets owned by different\norganizations and physically located in remote databases offer benefits in many\nreal-world use cases. State regulations or business requirements often prevent\ndata transfer to a central location, making it difficult to utilize standard\nmachine learning algorithms. Federated Learning (FL) is a technique that\nenables models to learn from distributed datasets without revealing the\noriginal data. Vertical Federated learning (VFL) is a type of FL where data\nsamples are divided by features across several data owners. For instance, in a\nrecommendation task, a user can interact with various sets of items, and the\nlogs of these interactions are stored by different organizations. In this demo\npaper, we present \\emph{Stalactite} - an open-source framework for VFL that\nprovides the necessary functionality for building prototypes of VFL systems. It\nhas several advantages over the existing frameworks. In particular, it allows\nresearchers to focus on the algorithmic side rather than engineering and to\neasily deploy learning in a distributed environment. It implements several VFL\nalgorithms and has a built-in homomorphic encryption layer. We demonstrate its\nuse on a real-world recommendation datasets.\n","authors":["Anastasiia Zakharova","Dmitriy Alexandrov","Maria Khodorchenko","Nikolay Butakov","Alexey Vasilev","Maxim Savchenko","Alexander Grigorievskiy"],"pdf_url":"https://arxiv.org/pdf/2409.15558v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.02295v1","updated":"2024-10-03T08:26:11Z","published":"2024-10-03T08:26:11Z","title":"Selection Guidelines for Geographical SMR Protocols: A Communication\n  Pattern-based Latency Modeling Approach","summary":"  State machine replication (SMR) is a replication technique that ensures fault\ntolerance by duplicating a service. Geographical SMR can enhance its robustness\nagainst disasters by distributing replicas in separate geographical locations.\nSeveral geographical SMR protocols have been proposed in the literature, each\nof which tailored to specific requirements; for example, protocols designed to\nmeet the requirement of latency reduction by either sacrificing a part of their\nfault tolerance or limiting the content of responses to clients. However, this\ndiversity complicates the decision-making process for selecting the best\nprotocol for a particular service. In this study, we introduce a latency\nestimation model for these SMR protocols based on the communication patterns of\nthe protocols and perform simulations for various cases. Based on the\nsimulation results and an experimental evaluation, we present five selection\nguidelines for geographical SMR protocols based on their log management policy,\ndistances between replicas, number of replicas, frequency of slow paths, and\nclient distribution. These selection guidelines enable determining the best\ngeographical SMR protocol for each situation.\n","authors":["Kohya Shiozaki","Junya Nakamura"],"pdf_url":"https://arxiv.org/pdf/2410.02295v1.pdf","comment":"This paper was submitted to the 26th International Symposium on\n  Stabilization, Safety, and Security of Distributed Systems"},{"id":"http://arxiv.org/abs/2410.02254v1","updated":"2024-10-03T06:47:16Z","published":"2024-10-03T06:47:16Z","title":"MTDNS: Moving Target Defense for Resilient DNS Infrastructure","summary":"  One of the most critical components of the Internet that an attacker could\nexploit is the DNS (Domain Name System) protocol and infrastructure.\nResearchers have been constantly developing methods to detect and defend\nagainst the attacks against DNS, specifically DNS flooding attacks. However,\nmost solutions discard packets for defensive approaches, which can cause\nlegitimate packets to be dropped, making them highly dependable on detection\nstrategies. In this paper, we propose MTDNS, a resilient MTD-based approach\nthat employs Moving Target Defense techniques through Software Defined\nNetworking (SDN) switches to redirect traffic to alternate DNS servers that are\ndynamically created and run under the Network Function Virtualization (NFV)\nframework. The proposed approach is implemented in a testbed environment by\nrunning our DNS servers as separate Virtual Network Functions, NFV Manager, SDN\nswitches, and an SDN Controller. The experimental result shows that the MTDNS\napproach achieves a much higher success rate in resolving DNS queries and\nsignificantly reduces average latency even if there is a DNS flooding attack.\n","authors":["Abdullah Aydeger","Pei Zhou","Sanzida Hoque","Marco Carvalho","Engin Zeydan"],"pdf_url":"https://arxiv.org/pdf/2410.02254v1.pdf","comment":"6 pages, Accepted for publication at IEEE CCNC 2025"},{"id":"http://arxiv.org/abs/2410.02170v1","updated":"2024-10-03T03:16:56Z","published":"2024-10-03T03:16:56Z","title":"Extracting the Potential of Emerging Hardware Accelerators for Symmetric\n  Eigenvalue Decomposition","summary":"  Benefiting from the advancement of hardware accelerators such as GPUs, deep\nneural networks and scientific computing applications can achieve superior\nperformance. Recently, the computing capacity of emerging hardware accelerators\nhas increased rapidly, while memory bandwidth has not kept pace with this\ngrowth. This disparity exacerbates the gap between computing and memory,\nleading to inefficiencies on conventional algorithms, as they're likely to be\nconverted from compute-bound to memory-bound. Symmetric eigenvalue\ndecomposition (EVD), a critical operation in various research domains including\nscientific computing, deep learning training, and inference algorithms,\nexhibits suboptimal performance due to achieving less than 3\\% hardware\ncomputing utilization on the H100 GPU. In this paper, we analyze the features\nof emerging hardware accelerators to identify the bottlenecks inherent in\nconventional EVD algorithms. To improve EVD performance, we propose several\nalgorithmic optimizations aimed at solving the memory-bound problem and\nproviding a better utilization of the rich computing capacity and parallelism\non the emerging hardware accelerators. Experimentally, our proposed method\ndemonstrates significant speedups on tridiagonalization, which is the main\nworkload that takes over 90\\% elapsed time of EVD, compared to the SOTA\ncuSOLVER tridiagonalization, achieving up to 10.1x, 7.5x, and 2.3x improvements\non H100, A100, and RTX 4090 GPUs, respectively. And the end-to-end the\nperformance of EVD solver is also up to 4.1x faster than cuSOVLER.\n","authors":["Hansheng Wang","Lu Shi","Zhekai duan","Panruo Wu","Liwei Guo","Shaoshuai Zhang"],"pdf_url":"https://arxiv.org/pdf/2410.02170v1.pdf","comment":null}]},"2024-10-02T00:00:00Z":{"Software Engineering":[{"id":"http://arxiv.org/abs/2404.00566v4","updated":"2024-10-02T23:38:34Z","published":"2024-03-31T05:20:53Z","title":"CodeBenchGen: Creating Scalable Execution-based Code Generation\n  Benchmarks","summary":"  To adequately test modern code generation systems, evaluation benchmarks must\nexecute and test the code generated by the system. However, these execution and\ntesting requirements have largely limited benchmarks to settings where code is\neasily executable or has human-written tests. To facilitate evaluation of code\ngeneration systems across diverse scenarios, we present CodeBenchGen, a\nframework to create scalable execution-based benchmarks from naturally\noccurring code sources. Specifically, we leverage a large language model (LLM)\nto sandbox arbitrary pieces of code into evaluation examples, including test\ncases for execution-based evaluation. We illustrate the usefulness of our\nframework by creating a dataset, Exec-CSN, which includes 1,931 examples\ninvolving 293 libraries converted from code in 367 GitHub repositories taken\nfrom the Code- SearchNet dataset. To demonstrate the solvability of examples in\nExec-CSN, we present a human study demonstrating that 81.3% of the examples can\nbe solved by humans and 61% are rated as \"requires effort to solve\". We conduct\ncode generation experiments on open-source and proprietary models and analyze\nthe performance of both humans and models. We provide code and data at:\nhttps://github.com/yiqingxyq/CodeBenchGen.\n","authors":["Yiqing Xie","Alex Xie","Divyanshu Sheth","Pengfei Liu","Daniel Fried","Carolyn Rose"],"pdf_url":"https://arxiv.org/pdf/2404.00566v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.02091v1","updated":"2024-10-02T23:26:10Z","published":"2024-10-02T23:26:10Z","title":"The Impact of Generative AI on Collaborative Open-Source Software\n  Development: Evidence from GitHub Copilot","summary":"  Generative artificial intelligence (AI) has opened the possibility of\nautomated content production, including coding in software development, which\ncan significantly influence the participation and performance of software\ndevelopers. To explore this impact, we investigate the role of GitHub Copilot,\na generative AI pair programmer, on software development in open-source\ncommunity, where multiple developers voluntarily collaborate on software\nprojects. Using GitHub's dataset for open-source repositories and a generalized\nsynthetic control method, we find that Copilot significantly enhances\nproject-level productivity by 6.5%. Delving deeper, we dissect the key\nmechanisms driving this improvement. Our findings reveal a 5.5% increase in\nindividual productivity and a 5.4% increase in participation. However, this is\naccompanied with a 41.6% increase in integration time, potentially due to\nhigher coordination costs. Interestingly, we also observe the differential\neffects among developers. We discover that core developers achieve greater\nproject-level productivity gains from using Copilot, benefiting more in terms\nof individual productivity and participation compared to peripheral developers,\nplausibly due to their deeper familiarity with software projects. We also find\nthat the increase in project-level productivity is accompanied with no change\nin code quality. We conclude that AI pair programmers bring benefits to\ndevelopers to automate and augment their code, but human developers' knowledge\nof software projects can enhance the benefits. In summary, our research\nunderscores the role of AI pair programmers in impacting project-level\nproductivity within the open-source community and suggests potential\nimplications for the structure of open-source software projects.\n","authors":["Fangchen Song","Ashish Agarwal","Wen Wen"],"pdf_url":"https://arxiv.org/pdf/2410.02091v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.03709v3","updated":"2024-10-02T22:58:42Z","published":"2024-05-03T23:06:31Z","title":"ScenicNL: Generating Probabilistic Scenario Programs from Natural\n  Language","summary":"  For cyber-physical systems (CPS), including robotics and autonomous vehicles,\nmass deployment has been hindered by fatal errors that occur when operating in\nrare events. To replicate rare events such as vehicle crashes, many companies\nhave created logging systems and employed crash reconstruction experts to\nmeticulously recreate these valuable events in simulation. However, in these\nmethods, \"what if\" questions are not easily formulated and answered. We present\nScenarioNL, an AI System for creating scenario programs from natural language.\nSpecifically, we generate these programs from police crash reports. Reports\nnormally contain uncertainty about the exact details of the incidents which we\nrepresent through a Probabilistic Programming Language (PPL), Scenic. By using\nScenic, we can clearly and concisely represent uncertainty and variation over\nCPS behaviors, properties, and interactions. We demonstrate how commonplace\nprompting techniques with the best Large Language Models (LLM) are incapable of\nreasoning about probabilistic scenario programs and generating code for\nlow-resource languages such as Scenic. Our system is comprised of several LLMs\nchained together with several kinds of prompting strategies, a compiler, and a\nsimulator. We evaluate our system on publicly available autonomous vehicle\ncrash reports in California from the last five years and share insights into\nhow we generate code that is both semantically meaningful and syntactically\ncorrect.\n","authors":["Karim Elmaaroufi","Devan Shanker","Ana Cismaru","Marcell Vazquez-Chanlatte","Alberto Sangiovanni-Vincentelli","Matei Zaharia","Sanjit A. Seshia"],"pdf_url":"https://arxiv.org/pdf/2405.03709v3.pdf","comment":"22 pages, 3 figures. Published at COLM 2024.\n  https://ke7.github.io/ScenicNL"},{"id":"http://arxiv.org/abs/2404.10100v2","updated":"2024-10-02T22:34:45Z","published":"2024-04-15T19:16:32Z","title":"LLM-Based Test-Driven Interactive Code Generation: User Study and\n  Empirical Evaluation","summary":"  Large language models (LLMs) have shown great potential in automating\nsignificant aspects of coding by producing natural code from informal natural\nlanguage (NL) intent. However, given NL is informal, it does not lend easily to\nchecking that the generated code correctly satisfies the user intent. In this\npaper, we propose a novel interactive workflow TiCoder for guided intent\nclarification (i.e., partial formalization) through tests to support the\ngeneration of more accurate code suggestions. Through a mixed methods user\nstudy with 15 programmers, we present an empirical evaluation of the\neffectiveness of the workflow to improve code generation accuracy. We find that\nparticipants using the proposed workflow are significantly more likely to\ncorrectly evaluate AI generated code, and report significantly less\ntask-induced cognitive load. Furthermore, we test the potential of the workflow\nat scale with four different state-of-the-art LLMs on two python datasets,\nusing an idealized proxy for a user feedback. We observe an average absolute\nimprovement of 45.97% in the pass@1 code generation accuracy for both datasets\nand across all LLMs within 5 user interactions, in addition to the automatic\ngeneration of accompanying unit tests.\n","authors":["Sarah Fakhoury","Aaditya Naik","Georgios Sakkas","Saikat Chakraborty","Shuvendu K. Lahiri"],"pdf_url":"https://arxiv.org/pdf/2404.10100v2.pdf","comment":"IEEE Transactions on Software Engineering, vol. 50, no. 09, pp.\n  2254-2268, 2024"},{"id":"http://arxiv.org/abs/2410.02046v1","updated":"2024-10-02T21:25:10Z","published":"2024-10-02T21:25:10Z","title":"QuickCheck for VDM","summary":"  We describe recent work on a lightweight verification tool for VDM\nspecifications, called QuickCheck. The objective of the tool is to quickly\ncategorise proof obligations: identifying those that fail with counterexamples,\nthose that are probably provable and those that require deeper analysis. The\npaper discusses the design of the tool and its use of pluggable strategies for\nadding extra checking. We present the results of the tool being used to check a\nlarge set of VDM specifications, and suggest future directions.\n","authors":["Nick Battle","Markus Solecki Ellyton"],"pdf_url":"https://arxiv.org/pdf/2410.02046v1.pdf","comment":"15 pages, 1 figure, submitted to the 22nd Overture Workshop"},{"id":"http://arxiv.org/abs/2410.01999v1","updated":"2024-10-02T20:04:02Z","published":"2024-10-02T20:04:02Z","title":"CodeMMLU: A Multi-Task Benchmark for Assessing Code Understanding\n  Capabilities of CodeLLMs","summary":"  Recent advancements in Code Large Language Models (CodeLLMs) have\npredominantly focused on open-ended code generation tasks, often neglecting the\ncritical aspect of code understanding and comprehension. To bridge this gap, we\npresent CodeMMLU, a comprehensive multiple-choice question-answer benchmark\ndesigned to evaluate the depth of software and code understanding in LLMs.\nCodeMMLU includes over 10,000 questions sourced from diverse domains,\nencompassing tasks such as code analysis, defect detection, and software\nengineering principles across multiple programming languages. Unlike\ntraditional benchmarks, CodeMMLU assesses models's ability to reason about code\nrather than merely generate it, providing deeper insights into their grasp of\ncomplex software concepts and systems. Our extensive evaluation reveals that\neven state-of-the-art models face significant challenges with CodeMMLU,\nhighlighting deficiencies in comprehension beyond code generation. By\nunderscoring the crucial relationship between code understanding and effective\ngeneration, CodeMMLU serves as a vital resource for advancing AI-assisted\nsoftware development, ultimately aiming to create more reliable and capable\ncoding assistants.\n","authors":["Dung Nguyen Manh","Thang Phan Chau","Nam Le Hai","Thong T. Doan","Nam V. Nguyen","Quang Pham","Nghi D. Q. Bui"],"pdf_url":"https://arxiv.org/pdf/2410.01999v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.13784v5","updated":"2024-10-02T19:16:19Z","published":"2024-03-20T17:47:08Z","title":"The Model Openness Framework: Promoting Completeness and Openness for\n  Reproducibility, Transparency, and Usability in Artificial Intelligence","summary":"  Generative AI (GAI) offers numerous opportunities for research and\ninnovation, but its commercialization has raised concerns about transparency,\nreproducibility, and safety. Most open GAI models lack the necessary components\nfor full understanding, auditing, and reproducibility, and some use restrictive\nlicenses whilst claiming to be \"open-source\". To address these concerns, we\nintroduce the Model Openness Framework (MOF), a ranked classification system\nthat rates machine learning models based on their completeness and openness,\nfollowing principles of open science, as well as the Model Openness Tool (MOT),\nwhich provides a reference implementation designed to evaluate ML models\nagainst the principles outlined by the MOF. The MOF requires specific\ncomponents of the model development lifecycle to be included and released under\nappropriate open licenses. This framework aims to prevent misrepresentation of\nmodels claiming to be open, to guide researchers and developers in providing\nall model components under permissive licenses, and to help individuals and\norganizations identify models that can be safely adopted. By promoting\ntransparency and reproducibility, the MOF combats open-washing and establishes\ncompleteness and openness as core tenets of responsible AI research and\ndevelopment. Widespread adoption of the MOF will foster a more open AI\necosystem, benefiting research, innovation, and the adoption of\nstate-of-the-art models.\n","authors":["Matt White","Ibrahim Haddad","Cailean Osborne","Xiao-Yang Liu Yanglet","Ahmed Abdelmonsef","Sachin Varghese"],"pdf_url":"https://arxiv.org/pdf/2403.13784v5.pdf","comment":"28 pages"},{"id":"http://arxiv.org/abs/2410.01899v1","updated":"2024-10-02T18:01:12Z","published":"2024-10-02T18:01:12Z","title":"The potential of LLM-generated reports in DevSecOps","summary":"  Alert fatigue is a common issue faced by software teams using the DevSecOps\nparadigm. The overwhelming number of warnings and alerts generated by security\nand code scanning tools, particularly in smaller teams where resources are\nlimited, leads to desensitization and diminished responsiveness to security\nwarnings, potentially exposing systems to vulnerabilities. This paper explores\nthe potential of LLMs in generating actionable security reports that emphasize\nthe financial impact and consequences of detected security issues, such as\ncredential leaks, if they remain unaddressed. A survey conducted among\ndevelopers indicates that LLM-generated reports significantly enhance the\nlikelihood of immediate action on security issues by providing clear,\ncomprehensive, and motivating insights. Integrating these reports into\nDevSecOps workflows can mitigate attention saturation and alert fatigue,\nensuring that critical security warnings are addressed effectively.\n","authors":["Nikolaos Lykousas","Vasileios Argyropoulos","Fran Casino"],"pdf_url":"https://arxiv.org/pdf/2410.01899v1.pdf","comment":"Published in AIESE 2024 (International Conference on AI empowered\n  Software Engineering)"},{"id":"http://arxiv.org/abs/2410.01869v1","updated":"2024-10-02T17:21:51Z","published":"2024-10-02T17:21:51Z","title":"Enhancing LLM Fine-tuning for Text-to-SQLs by SQL Quality Measurement","summary":"  Text-to-SQLs enables non-expert users to effortlessly retrieve desired\ninformation from relational databases using natural language queries. While\nrecent advancements, particularly with Large Language Models (LLMs) like GPT\nand T5, have shown impressive performance on large-scale benchmarks such as\nBIRD, current state-of-the-art (SOTA) LLM-based Text-to-SQLs models often\nrequire significant efforts to develop auxiliary tools like SQL classifiers to\nachieve high performance. This paper proposed a novel approach that only needs\nSQL Quality Measurement to enhance LLMs-based Text-to-SQLs performance. It\nestablishes a SQL quality evaluation mechanism to assess the generated SQL\nqueries against predefined criteria and actual database responses. This\nfeedback loop enables continuous learning and refinement of model outputs based\non both syntactic correctness and semantic accuracy. The proposed method\nundergoes comprehensive validation on the BIRD benchmark, assessing Execution\nAccuracy (EX) and Valid Efficiency Score (VES) across various Text-to-SQLs\ndifficulty levels. Experimental results reveal competitive performance in both\nEX and VES compared to SOTA models like GPT4 and T5.\n","authors":["Shouvon Sarker","Xishuang Dong","Xiangfang Li","Lijun Qian"],"pdf_url":"https://arxiv.org/pdf/2410.01869v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.01762v1","updated":"2024-10-02T17:17:14Z","published":"2024-10-02T17:17:14Z","title":"LightSC: The Making of a Usable Security Classification Tool for\n  DevSecOps","summary":"  DevSecOps, as the extension of DevOps with security training and tools, has\nbecome a popular way of developing modern software, especially in the Internet\nof Things arena, due to its focus on rapid development, with short release\ncycles, involving the user/client very closely. Security classification\nmethods, on the other hand, are heavy and slow processes that require high\nexpertise in security, the same as in other similar areas such as risk analysis\nor certification. As such, security classification methods are hardly\ncompatible with the DevSecOps culture, which to the contrary, has moved away\nfrom the traditional style of penetration testing done only when the software\nproduct is in the final stages or already deployed.\n  In this work, we first propose five principles for a security classification\nto be \\emph{DevOps-ready}, two of which will be the focus for the rest of the\npaper, namely to be tool-based and easy to use for non-security experts, such\nas ordinary developers or system architects. We then exemplify how one can make\na security classification methodology DevOps-ready. We do this through an\ninteraction design process, where we create and evaluate the usability of a\ntool implementing the chosen methodology. Since such work seems to be new\nwithin the usable security community, and even more so in the software\ndevelopment (DevOps) community, we extract from our process a general,\nthree-steps `recipe' that others can follow when making their own security\nmethodologies DevOps-ready. The tool that we build is in itself a contribution\nof this process, as it can be independently used, extended, and/or integrated\nby developer teams into their DevSecOps tool-chains. Our tool is perceived (by\nthe test subjects) as most useful in the design phase, but also during the\ntesting phase where the security class would be one of the metrics used to\nevaluate the quality of their software.\n","authors":["Manish Shrestha","Christian Johansen","Johanna Johansen"],"pdf_url":"https://arxiv.org/pdf/2410.01762v1.pdf","comment":"29 pages of which 7 are appendix with figures"},{"id":"http://arxiv.org/abs/2401.00757v2","updated":"2024-10-02T16:30:34Z","published":"2024-01-01T13:53:53Z","title":"LogicAsker: Evaluating and Improving the Logical Reasoning Ability of\n  Large Language Models","summary":"  We introduce LogicAsker, a novel approach for evaluating and enhancing the\nlogical reasoning capabilities of large language models (LLMs) such as ChatGPT\nand GPT-4. Despite LLMs' prowess in tasks like writing assistance, code\ngeneration, and machine translation, assessing their ability to reason has been\nchallenging. Traditional evaluations often prioritize accuracy on downstream\ntasks over direct assessments of reasoning processes. LogicAsker addresses this\ngap by employing a set of atomic reasoning skills grounded in propositional and\npredicate logic to systematically examine and improve the reasoning prowess of\nLLMs. Our methodology reveals significant gaps in LLMs' learning of logical\nrules, with identified reasoning failures ranging from 29\\% to 90\\% across\ndifferent models. Moreover, we leverage these findings to construct targeted\ndemonstration examples and fine-tune data, notably enhancing logical reasoning\nin models like GPT-4o by up to 5\\%. To our knowledge, this is the first effort\nto utilize test case outcomes to effectively refine LLMs' formal reasoning\ncapabilities. We make our code, data, and results publicly available\n(https://github.com/yxwan123/LogicAsker) to facilitate further research and\nreplication of our findings.\n","authors":["Yuxuan Wan","Wenxuan Wang","Yiliu Yang","Youliang Yuan","Jen-tse Huang","Pinjia He","Wenxiang Jiao","Michael R. Lyu"],"pdf_url":"https://arxiv.org/pdf/2401.00757v2.pdf","comment":"Accepted by EMNLP 2024"},{"id":"http://arxiv.org/abs/2405.02355v2","updated":"2024-10-02T14:37:01Z","published":"2024-05-03T02:48:55Z","title":"CodeGRAG: Bridging the Gap between Natural Language and Programming\n  Language via Graphical Retrieval Augmented Generation","summary":"  Utilizing large language models to generate codes has shown promising meaning\nin software development revolution. Despite the intelligence shown by the\ngeneral large language models, their specificity in code generation can still\nbe improved due to the syntactic gap and mismatched vocabulary existing among\nnatural language and different programming languages. In this paper, we propose\nCodeGRAG, a Graphical Retrieval Augmented Code Generation framework to enhance\nthe performance of LLMs. CodeGRAG builds the graphical view of code blocks\nbased on the control flow and data flow of them to fill the gap between\nprogramming languages and natural language, which can facilitate natural\nlanguage based LLMs for better understanding of code syntax and serve as a\nbridge among different programming languages. To take the extracted structural\nknowledge into the foundation models, we propose 1) a hard meta-graph prompt\ntemplate to transform the challenging graphical representation into informative\nknowledge for tuning-free models and 2) a soft prompting technique that injects\nthe domain knowledge of programming languages into the model parameters via\nfinetuning the models with the help of a pretrained GNN expert model. Various\nexperiments and ablations are done on four datasets including both the C++ and\npython languages to validate the hard meta-graph prompt, the soft prompting\ntechnique, and the effectiveness of the objectives for pretrained GNN expert.\nCodeGRAG improves the code generation ability of LLMs and can even offer\nperformance gain for cross-lingual code generation. The implementation is\navailable at https://anonymous.4open.science/r/Code-5970/.\n","authors":["Kounianhua Du","Jizheng Chen","Renting Rui","Huacan Chai","Lingyue Fu","Wei Xia","Yasheng Wang","Ruiming Tang","Yong Yu","Weinan Zhang"],"pdf_url":"https://arxiv.org/pdf/2405.02355v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.09610v2","updated":"2024-10-02T13:42:53Z","published":"2023-12-15T08:53:45Z","title":"A Synthesis of Green Architectural Tactics for ML-Enabled Systems","summary":"  The rapid adoption of artificial intelligence (AI) and machine learning (ML)\nhas generated growing interest in understanding their environmental impact and\nthe challenges associated with designing environmentally friendly ML-enabled\nsystems. While Green AI research, i.e., research that tries to minimize the\nenergy footprint of AI, is receiving increasing attention, very few concrete\nguidelines are available on how ML-enabled systems can be designed to be more\nenvironmentally sustainable. In this paper, we provide a catalog of 30 green\narchitectural tactics for ML-enabled systems to fill this gap. An architectural\ntactic is a high-level design technique to improve software quality, in our\ncase environmental sustainability. We derived the tactics from the analysis of\n51 peer-reviewed publications that primarily explore Green AI, and validated\nthem using a focus group approach with three experts. The 30 tactics we\nidentified are aimed to serve as an initial reference guide for further\nexploration into Green AI from a software engineering perspective, and assist\nin designing sustainable ML-enabled systems. To enhance transparency and\nfacilitate their widespread use and extension, we make the tactics available\nonline in easily consumable formats. Wide-spread adoption of these tactics has\nthe potential to substantially reduce the societal impact of ML-enabled systems\nregarding their energy and carbon footprint.\n","authors":["Heli Järvenpää","Patricia Lago","Justus Bogner","Grace Lewis","Henry Muccini","Ipek Ozkaya"],"pdf_url":"https://arxiv.org/pdf/2312.09610v2.pdf","comment":"Accepted for publication at the 2024 International Conference on\n  Software Engineering - Software Engineering in Society (ICSE-SEIS'2024)"},{"id":"http://arxiv.org/abs/2410.01454v1","updated":"2024-10-02T12:03:37Z","published":"2024-10-02T12:03:37Z","title":"The Impact of the COVID-19 Pandemic on Women's Contribution to Public\n  Code","summary":"  Despite its promise of openness and inclusiveness, the development of free\nand open source software (FOSS) remains significantly unbalanced in terms of\ngender representation among contributors. To assist open source project\nmaintainers and communities in addressing this imbalance, it is crucial to\nunderstand the causes of this inequality.In this study, we aim to establish how\nthe COVID-19 pandemic has influenced the ability of women to contribute to\npublic code. To do so, we use the Software Heritage archive, which holds the\nlargest dataset of commits to public code, and the difference in differences\n(DID) methodology from econometrics that enables the derivation of causality\nfrom historical data.Our findings show that the COVID-19 pandemic has\ndisproportionately impacted women's ability to contribute to the development of\npublic code, relatively to men. Further, our observations of specific\ncontributor subgroups indicate that COVID-19 particularly affected women\nhobbyists, identified using contribution patterns and email address domains.\n","authors":["Annalí Casanueva","Davide Rossi","Stefano Zacchiroli","Théo Zimmermann"],"pdf_url":"https://arxiv.org/pdf/2410.01454v1.pdf","comment":"Empirical Software Engineering, In press"},{"id":"http://arxiv.org/abs/2410.01415v1","updated":"2024-10-02T10:54:00Z","published":"2024-10-02T10:54:00Z","title":"QCRMut: Quantum Circuit Random Mutant generator tool","summary":"  Quantum computing has been on the rise in recent years, evidenced by a surge\nin publications on quantum software engineering and testing. Progress in\nquantum hardware has also been notable, with the introduction of impressive\nsystems like Condor boasting 1121 qubits, and IBM Quantum System Two, which\nemploys three 133-qubit Heron processors. As this technology edges closer to\npractical application, ensuring the efficacy of our software becomes\nimperative. Mutation testing, a well-established technique in classical\ncomputing, emerges as a valuable approach in this context.\n  In our paper, we aim to introduce QCRMut, a mutation tool tailored for\nquantum programs, leveraging the inherent Quantum Circuit structure. We propose\na randomised approach compared to previous works with exhaustive creation\nprocesses and the capability for marking immutable positions within the\ncircuit. These features facilitate the preservation of program structure, which\nis crucial for future applications such as metamorphic testing.\n","authors":["Sinhué García Gil","Luis Llana Díaz","José Ignacio Requeno Jarabo"],"pdf_url":"https://arxiv.org/pdf/2410.01415v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.01353v1","updated":"2024-10-02T09:11:10Z","published":"2024-10-02T09:11:10Z","title":"Codev-Bench: How Do LLMs Understand Developer-Centric Code Completion?","summary":"  Code completion, a key downstream task in code generation, is one of the most\nfrequent and impactful methods for enhancing developer productivity in software\ndevelopment. As intelligent completion tools evolve, we need a robust\nevaluation benchmark that enables meaningful comparisons between products and\nguides future advancements. However, existing benchmarks focus more on\ncoarse-grained tasks without industrial analysis resembling general code\ngeneration rather than the real-world scenarios developers encounter. Moreover,\nthese benchmarks often rely on costly and time-consuming human annotation, and\nthe standalone test cases fail to leverage minimal tests for maximum\nrepository-level understanding and code coverage. To address these limitations,\nwe first analyze business data from an industrial code completion tool and\nredefine the evaluation criteria to better align with the developer's intent\nand desired completion behavior throughout the coding process. Based on these\ninsights, we introduce Codev-Agent, an agent-based system that automates\nrepository crawling, constructs execution environments, extracts dynamic\ncalling chains from existing unit tests, and generates new test samples to\navoid data leakage, ensuring fair and effective comparisons. Using Codev-Agent,\nwe present the Code-Development Benchmark (Codev-Bench), a fine-grained,\nreal-world, repository-level, and developer-centric evaluation framework.\nCodev-Bench assesses whether a code completion tool can capture a developer's\nimmediate intent and suggest appropriate code across diverse contexts,\nproviding a more realistic benchmark for code completion in modern software\ndevelopment.\n","authors":["Zhenyu Pan","Rongyu Cao","Yongchang Cao","Yingwei Ma","Binhua Li","Fei Huang","Han Liu","Yongbin Li"],"pdf_url":"https://arxiv.org/pdf/2410.01353v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.00639v2","updated":"2024-10-02T07:18:32Z","published":"2024-10-01T12:41:15Z","title":"On the Creation of Representative Samples of Software Repositories","summary":"  Software repositories is one of the sources of data in Empirical Software\nEngineering, primarily in the Mining Software Repositories field, aimed at\nextracting knowledge from the dynamics and practice of software projects. With\nthe emergence of social coding platforms such as GitHub, researchers have now\naccess to millions of software repositories to use as source data for their\nstudies. With this massive amount of data, sampling techniques are needed to\ncreate more manageable datasets. The creation of these datasets is a crucial\nstep, and researchers have to carefully select the repositories to create\nrepresentative samples according to a set of variables of interest. However,\ncurrent sampling methods are often based on random selection or rely on\nvariables which may not be related to the research study (e.g., popularity or\nactivity). In this paper, we present a methodology for creating representative\nsamples of software repositories, where such representativeness is properly\naligned with both the characteristics of the population of repositories and the\nrequirements of the empirical study. We illustrate our approach with use cases\nbased on Hugging Face repositories.\n","authors":["June Gorostidi","Adem Ait","Jordi Cabot","Javier Luis Cánovas Izquierdo"],"pdf_url":"https://arxiv.org/pdf/2410.00639v2.pdf","comment":"The paper has been accepted for publication in the Proceedings of the\n  18th International Symposium on Empirical Software Engineering and\n  Measurement (ESEM 2024)"}],"Human-Computer Interaction":[{"id":"http://arxiv.org/abs/2410.02091v1","updated":"2024-10-02T23:26:10Z","published":"2024-10-02T23:26:10Z","title":"The Impact of Generative AI on Collaborative Open-Source Software\n  Development: Evidence from GitHub Copilot","summary":"  Generative artificial intelligence (AI) has opened the possibility of\nautomated content production, including coding in software development, which\ncan significantly influence the participation and performance of software\ndevelopers. To explore this impact, we investigate the role of GitHub Copilot,\na generative AI pair programmer, on software development in open-source\ncommunity, where multiple developers voluntarily collaborate on software\nprojects. Using GitHub's dataset for open-source repositories and a generalized\nsynthetic control method, we find that Copilot significantly enhances\nproject-level productivity by 6.5%. Delving deeper, we dissect the key\nmechanisms driving this improvement. Our findings reveal a 5.5% increase in\nindividual productivity and a 5.4% increase in participation. However, this is\naccompanied with a 41.6% increase in integration time, potentially due to\nhigher coordination costs. Interestingly, we also observe the differential\neffects among developers. We discover that core developers achieve greater\nproject-level productivity gains from using Copilot, benefiting more in terms\nof individual productivity and participation compared to peripheral developers,\nplausibly due to their deeper familiarity with software projects. We also find\nthat the increase in project-level productivity is accompanied with no change\nin code quality. We conclude that AI pair programmers bring benefits to\ndevelopers to automate and augment their code, but human developers' knowledge\nof software projects can enhance the benefits. In summary, our research\nunderscores the role of AI pair programmers in impacting project-level\nproductivity within the open-source community and suggests potential\nimplications for the structure of open-source software projects.\n","authors":["Fangchen Song","Ashish Agarwal","Wen Wen"],"pdf_url":"https://arxiv.org/pdf/2410.02091v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.03771v1","updated":"2024-10-02T23:14:29Z","published":"2024-10-02T23:14:29Z","title":"SeeSay: An Assistive Device for the Visually Impaired Using Retrieval\n  Augmented Generation","summary":"  In this paper, we present SeeSay, an assistive device designed for\nindividuals with visual impairments. This system leverages large language\nmodels (LLMs) for speech recognition and visual querying. It effectively\nidentifies, records, and responds to the user's environment by providing audio\nguidance using retrieval-augmented generation (RAG). Our experiments\ndemonstrate the system's capability to recognize its surroundings and respond\nto queries with audio feedback in diverse settings. We hope that the SeeSay\nsystem will facilitate users' comprehension and recollection of their\nsurroundings, thereby enhancing their environmental perception, improving\nnavigational capabilities, and boosting overall independence.\n","authors":["Melody Yu"],"pdf_url":"https://arxiv.org/pdf/2410.03771v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.02054v1","updated":"2024-10-02T22:00:28Z","published":"2024-10-02T22:00:28Z","title":"Comparing Criteria Development Across Domain Experts, Lay Users, and\n  Models in Large Language Model Evaluation","summary":"  Large Language Models (LLMs) are increasingly utilized for domain-specific\ntasks, yet integrating domain expertise into evaluating their outputs remains\nchallenging. A common approach to evaluating LLMs is to use metrics, or\ncriteria, which are assertions used to assess performance that help ensure that\ntheir outputs align with domain-specific standards. Previous efforts have\ninvolved developers, lay users, or the LLMs themselves in creating these\ncriteria, however, evaluation particularly from a domain expertise perspective,\nremains understudied. This study explores how domain experts contribute to LLM\nevaluation by comparing their criteria with those generated by LLMs and lay\nusers. We further investigate how the criteria-setting process evolves,\nanalyzing changes between a priori and a posteriori stages. Our findings\nemphasize the importance of involving domain experts early in the evaluation\nprocess while utilizing complementary strengths of lay users and LLMs. We\nsuggest implications for designing workflows that leverage these strengths at\ndifferent evaluation stages.\n","authors":["Annalisa Szymanski","Simret Araya Gebreegziabher","Oghenemaro Anuyah","Ronald A. Metoyer","Toby Jia-Jun Li"],"pdf_url":"https://arxiv.org/pdf/2410.02054v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.16610v2","updated":"2024-10-02T21:59:36Z","published":"2024-01-29T22:43:12Z","title":"Perceptions of Moderators as a Large-Scale Measure of Online Community\n  Governance","summary":"  Millions of online communities are governed by volunteer moderators, who\nshape their communities by setting and enforcing rules, recruiting additional\nmoderators, and participating in the community themselves. These moderators\nmust regularly make decisions about how to govern, yet measuring the 'success'\nof governance is complex and nuanced, making it challenging to determine what\ngovernance strategies are most successful. Furthermore, prior work has shown\nthat communities have differing values, suggesting that 'one-size-fits-all'\napproaches to governance are unlikely to serve all communities well. In this\nwork, we assess governance practices on reddit by classifying the sentiment of\ncommunity members' public discussion of their own moderators. We label 1.89\nmillion posts and comments made on reddit over an 18 month period. We relate\nthese perceptions to characteristics of community governance, and to different\nactions that community moderators take. We identify types of communities where\nmoderators are perceived particularly positively and negatively, and highlight\npromising strategies for moderator teams. Amongst other findings, we show that\nstrict rule enforcement is linked to more favorable perceptions of moderators\nof communities dedicated to certain topics, such as news communities, than\nothers. We investigate what kinds of moderators are associated with improved\ncommunity perceptions upon their addition to a mod team, and find that\nmoderators who are active community members before and during their mod tenures\nare seen more favorably. We make all our models, datasets, and code public.\n","authors":["Galen Weld","Leon Leibmann","Amy X. Zhang","Tim Althoff"],"pdf_url":"https://arxiv.org/pdf/2401.16610v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.02053v1","updated":"2024-10-02T21:53:12Z","published":"2024-10-02T21:53:12Z","title":"Digital Eyes: Social Implications of XR EyeSight","summary":"  The EyeSight feature, introduced with the new Apple Vision Pro XR headset,\npromises to revolutionize user interaction by simulating real human eye\nexpressions on a digital display. This feature could enhance XR devices' social\nacceptability and social presence when communicating with others outside the XR\nexperience. In this pilot study, we explore the implications of the EyeSight\nfeature by examining social acceptability, social presence, emotional\nresponses, and technology acceptance. Eight participants engaged in\nconversational tasks in three conditions to contrast experiencing the Apple\nVision Pro with EyeSight, the Meta Quest 3 as a reference XR headset, and a\nface-to-face setting. Our preliminary findings indicate that while the EyeSight\nfeature improves perceptions of social presence and acceptability compared to\nthe reference headsets, it does not match the social connectivity of direct\nhuman interactions.\n","authors":["Maurizio Vergari","Tanja Kojić","Wafaa Wardah","Maximilian Warsinke","Sebastian Möller","Jan-Niklas Voigt-Antons","Robert P. Spang"],"pdf_url":"https://arxiv.org/pdf/2410.02053v1.pdf","comment":"In 30th ACM Symposium on Virtual Reality Software and Technology\n  (VRST 2024)"},{"id":"http://arxiv.org/abs/2402.08420v2","updated":"2024-10-02T21:17:31Z","published":"2024-02-13T12:49:13Z","title":"Vision-Based Hand Gesture Customization from a Single Demonstration","summary":"  Hand gesture recognition is becoming a more prevalent mode of human-computer\ninteraction, especially as cameras proliferate across everyday devices. Despite\ncontinued progress in this field, gesture customization is often underexplored.\nCustomization is crucial since it enables users to define and demonstrate\ngestures that are more natural, memorable, and accessible. However,\ncustomization requires efficient usage of user-provided data. We introduce a\nmethod that enables users to easily design bespoke gestures with a monocular\ncamera from one demonstration. We employ transformers and meta-learning\ntechniques to address few-shot learning challenges. Unlike prior work, our\nmethod supports any combination of one-handed, two-handed, static, and dynamic\ngestures, including different viewpoints, and the ability to handle irrelevant\nhand movements. We implement three real-world applications using our\ncustomization method, conduct a user study, and achieve up to 94% average\nrecognition accuracy from one demonstration. Our work provides a viable path\nfor vision-based gesture customization, laying the foundation for future\nadvancements in this domain.\n","authors":["Soroush Shahi","Vimal Mollyn","Cori Tymoszek Park","Richard Kang","Asaf Liberman","Oron Levy","Jun Gong","Abdelkareem Bedri","Gierad Laput"],"pdf_url":"https://arxiv.org/pdf/2402.08420v2.pdf","comment":"2024 (UIST' 24). USA, 14 pages"},{"id":"http://arxiv.org/abs/2404.00026v5","updated":"2024-10-02T20:45:53Z","published":"2024-03-20T21:02:16Z","title":"Ink and Individuality: Crafting a Personalised Narrative in the Age of\n  LLMs","summary":"  Individuality and personalization comprise the distinctive characteristics\nthat make each writer unique and influence their words in order to effectively\nengage readers while conveying authenticity. However, our growing reliance on\nLLM-based writing assistants risks compromising our creativity and\nindividuality over time. We often overlook the negative impacts of this trend\non our creativity and uniqueness, despite the possible consequences. This study\ninvestigates these concerns by performing a brief survey to explore different\nperspectives and concepts, as well as trying to understand people's viewpoints,\nin conjunction with past studies in the area. Addressing these issues is\nessential for improving human-computer interaction systems and enhancing\nwriting assistants for personalization and individuality.\n","authors":["Azmine Toushik Wasi","Raima Islam","Mst Rafia Islam"],"pdf_url":"https://arxiv.org/pdf/2404.00026v5.pdf","comment":"5 Pages, 4 Figures. Accepted in The Third Workshop on Intelligent and\n  Interactive Writing Assistants at CHI 2024"},{"id":"http://arxiv.org/abs/2404.00027v5","updated":"2024-10-02T20:45:35Z","published":"2024-03-20T21:06:42Z","title":"LLMs as Writing Assistants: Exploring Perspectives on Sense of Ownership\n  and Reasoning","summary":"  Sense of ownership in writing confines our investment of thoughts, time, and\ncontribution, leading to attachment to the output. However, using writing\nassistants introduces a mental dilemma, as some content isn't directly our\ncreation. For instance, we tend to credit Large Language Models (LLMs) more in\ncreative tasks, even though all tasks are equal for them. Additionally, while\nwe may not claim complete ownership of LLM-generated content, we freely claim\nauthorship. We conduct a short survey to examine these issues and understand\nunderlying cognitive processes in order to gain a better knowledge of\nhuman-computer interaction in writing and improve writing aid systems.\n","authors":["Azmine Toushik Wasi","Mst Rafia Islam","Raima Islam"],"pdf_url":"https://arxiv.org/pdf/2404.00027v5.pdf","comment":"5 Pages, 3 Figures. Accepted in The Third Workshop on Intelligent and\n  Interactive Writing Assistants at CHI 2024"},{"id":"http://arxiv.org/abs/2410.02003v1","updated":"2024-10-02T20:08:29Z","published":"2024-10-02T20:08:29Z","title":"SkyAI Sim: An Open-Source Simulation of UAV Aerial Imaging from\n  Satellite Data","summary":"  Capturing real-world aerial images for vision-based navigation (VBN) is\nchallenging due to limited availability and conditions that make it nearly\nimpossible to access all desired images from any location. The complexity\nincreases when multiple locations are involved. The state of the art solutions,\nsuch as flying a UAV (Unmanned Aerial Vehicle) to take pictures or using\nexisting research databases, have significant limitations. SkyAI Sim offers a\ncompelling alternative by simulating a UAV to capture bird's-eye view satellite\nimages at zero-yaw with real-world visible-band specifications. This\nopen-source tool allows users to specify the bounding box (top-left and\nbottom-right) coordinates of any region on a map. Without the need to\nphysically fly a drone, the virtual Python UAV performs a raster search to\ncapture satellite images using the Google Maps Static API. Users can define\nparameters such as flight altitude, aspect ratio and diagonal field of view of\nthe camera, and the overlap between consecutive images. SkyAI Sim's\ncapabilities range from capturing a few low-altitude images for basic\napplications to generating extensive datasets of entire cities for complex\ntasks like deep learning. This versatility makes SkyAI a valuable tool for not\nonly VBN, but also other applications including environmental monitoring,\nconstruction, and city management. The open-source nature of the tool also\nallows for extending the raster search to other missions. A dataset of Memphis,\nTN has been provided along with this simulator, partially generated using SkyAI\nand, also includes data from a 3D world generation package for comparison.\n","authors":["S. Parisa Dajkhosh","Peter M. Le","Orges Furxhi","Eddie L. Jacobs"],"pdf_url":"https://arxiv.org/pdf/2410.02003v1.pdf","comment":"15 pages, 11 figures"},{"id":"http://arxiv.org/abs/2410.01791v1","updated":"2024-10-02T17:49:07Z","published":"2024-10-02T17:49:07Z","title":"DreamGarden: A Designer Assistant for Growing Games from a Single Prompt","summary":"  Coding assistants are increasingly leveraged in game design, both generating\ncode and making high-level plans. To what degree can these tools align with\ndeveloper workflows, and what new modes of human-computer interaction can\nemerge from their use? We present DreamGarden, an AI system capable of\nassisting with the development of diverse game environments in Unreal Engine.\nAt the core of our method is an LLM-driven planner, capable of breaking down a\nsingle, high-level prompt -- a dream, memory, or imagined scenario provided by\na human user -- into a hierarchical action plan, which is then distributed\nacross specialized submodules facilitating concrete implementation. This system\nis presented to the user as a garden of plans and actions, both growing\nindependently and responding to user intervention via seed prompts, pruning,\nand feedback. Through a user study, we explore design implications of this\nsystem, charting courses for future work in semi-autonomous assistants and\nopen-ended simulation design.\n","authors":["Sam Earle","Samyak Parajuli","Andrzej Banburski-Fahey"],"pdf_url":"https://arxiv.org/pdf/2410.01791v1.pdf","comment":"21 pages + appendix, 11 figures"},{"id":"http://arxiv.org/abs/2409.02449v2","updated":"2024-10-02T17:40:25Z","published":"2024-09-04T05:08:23Z","title":"What is lost in Normalization? Exploring Pitfalls in Multilingual ASR\n  Model Evaluations","summary":"  This paper explores the pitfalls in evaluating multilingual automatic speech\nrecognition (ASR) models, with a particular focus on Indic language scripts. We\ninvestigate the text normalization routine employed by leading ASR models,\nincluding OpenAI Whisper, Meta's MMS, Seamless, and Assembly AI's Conformer,\nand their unintended consequences on performance metrics. Our research reveals\nthat current text normalization practices, while aiming to standardize ASR\noutputs for fair comparison, by removing inconsistencies such as variations in\nspelling, punctuation, and special characters, are fundamentally flawed when\napplied to Indic scripts. Through empirical analysis using text similarity\nscores and in-depth linguistic examination, we demonstrate that these flaws\nlead to artificially improved performance metrics for Indic languages. We\nconclude by proposing a shift towards developing text normalization routines\nthat leverage native linguistic expertise, ensuring more robust and accurate\nevaluations of multilingual ASR models.\n","authors":["Kavya Manohar","Leena G Pillai"],"pdf_url":"https://arxiv.org/pdf/2409.02449v2.pdf","comment":"Accepted to EMNLP 2024 Main"},{"id":"http://arxiv.org/abs/2410.00274v2","updated":"2024-10-02T17:34:41Z","published":"2024-09-30T23:02:51Z","title":"Social Conjuring: Multi-User Runtime Collaboration with AI in Building\n  Virtual 3D Worlds","summary":"  Generative artificial intelligence has shown promise in prompting virtual\nworlds into existence, yet little attention has been given to understanding how\nthis process unfolds as social interaction. We present Social Conjurer, a\nframework for AI-augmented dynamic 3D scene co-creation, where multiple users\ncollaboratively build and modify virtual worlds in real-time. Through an\nexpanded set of interactions, including social and tool-based engagements as\nwell as spatial reasoning, our framework facilitates the creation of rich,\ndiverse virtual environments. Findings from a preliminary user study (N=12)\nprovide insight into the user experience of this approach, how social contexts\nshape the prompting of spatial environments, and perspective on social\napplications of prompt-based 3D co-creation. In addition to highlighting the\npotential of AI-supported multi-user world creation and offering new pathways\nfor AI-augmented creative processes in VR, this article presents a set of\nimplications for designing human-centered interfaces that incorporate AI models\ninto 3D content generation.\n","authors":["Amina Kobenova","Cyan DeVeaux","Samyak Parajuli","Andrzej Banburski-Fahey","Judith Amores Fernandez","Jaron Lanier"],"pdf_url":"https://arxiv.org/pdf/2410.00274v2.pdf","comment":"27 pages + Appendix, 16 figures; fixed some minor UTF-8 encoding\n  issues in arXiv compilation"},{"id":"http://arxiv.org/abs/2410.01762v1","updated":"2024-10-02T17:17:14Z","published":"2024-10-02T17:17:14Z","title":"LightSC: The Making of a Usable Security Classification Tool for\n  DevSecOps","summary":"  DevSecOps, as the extension of DevOps with security training and tools, has\nbecome a popular way of developing modern software, especially in the Internet\nof Things arena, due to its focus on rapid development, with short release\ncycles, involving the user/client very closely. Security classification\nmethods, on the other hand, are heavy and slow processes that require high\nexpertise in security, the same as in other similar areas such as risk analysis\nor certification. As such, security classification methods are hardly\ncompatible with the DevSecOps culture, which to the contrary, has moved away\nfrom the traditional style of penetration testing done only when the software\nproduct is in the final stages or already deployed.\n  In this work, we first propose five principles for a security classification\nto be \\emph{DevOps-ready}, two of which will be the focus for the rest of the\npaper, namely to be tool-based and easy to use for non-security experts, such\nas ordinary developers or system architects. We then exemplify how one can make\na security classification methodology DevOps-ready. We do this through an\ninteraction design process, where we create and evaluate the usability of a\ntool implementing the chosen methodology. Since such work seems to be new\nwithin the usable security community, and even more so in the software\ndevelopment (DevOps) community, we extract from our process a general,\nthree-steps `recipe' that others can follow when making their own security\nmethodologies DevOps-ready. The tool that we build is in itself a contribution\nof this process, as it can be independently used, extended, and/or integrated\nby developer teams into their DevSecOps tool-chains. Our tool is perceived (by\nthe test subjects) as most useful in the design phase, but also during the\ntesting phase where the security class would be one of the metrics used to\nevaluate the quality of their software.\n","authors":["Manish Shrestha","Christian Johansen","Johanna Johansen"],"pdf_url":"https://arxiv.org/pdf/2410.01762v1.pdf","comment":"29 pages of which 7 are appendix with figures"},{"id":"http://arxiv.org/abs/2403.05334v2","updated":"2024-10-02T17:05:24Z","published":"2024-03-08T14:10:25Z","title":"WatChat: Explaining perplexing programs by debugging mental models","summary":"  Often, a good explanation for a program's unexpected behavior is a bug in the\nprogrammer's code. But sometimes, an even better explanation is a bug in the\nprogrammer's mental model of the language or API they are using. Instead of\nmerely debugging our current code (\"giving the programmer a fish\"), what if our\ntools could directly debug our mental models (\"teaching the programmer to\nfish\")? In this paper, we apply recent ideas from computational cognitive\nscience to offer a principled framework for doing exactly that. Given a \"why?\"\nquestion about a program, we automatically infer potential misconceptions about\nthe language/API that might cause the user to be surprised by the program's\nbehavior -- and then analyze those misconceptions to provide explanations of\nthe program's behavior. Our key idea is to formally represent misconceptions as\ncounterfactual (erroneous) semantics for the language/API, which can be\ninferred and debugged using program synthesis techniques. We demonstrate our\nframework, WatChat, by building systems for explanation in two domains:\nJavaScript type coercion, and the Git version control system. We evaluate\nWatChatJS and WatChatGit by comparing their outputs to experimentally-collected\nhuman-written explanations in these two domains: we show that WatChat's\nexplanations exhibit key features of human-written explanation, unlike those of\na state-of-the-art language model.\n","authors":["Kartik Chandra","Katherine M. Collins","Will Crichton","Tony Chen","Tzu-Mao Li","Adrian Weller","Rachit Nigam","Joshua Tenenbaum","Jonathan Ragan-Kelley"],"pdf_url":"https://arxiv.org/pdf/2403.05334v2.pdf","comment":"This is a preprint of work presented in early-stage non-archival form\n  at the ACL Natural Language Reasoning and Structured Explanations Workshop"},{"id":"http://arxiv.org/abs/2410.01604v1","updated":"2024-10-02T14:43:03Z","published":"2024-10-02T14:43:03Z","title":"Customizing Generated Signs and Voices of AI Avatars: Deaf-Centric\n  Mixed-Reality Design for Deaf-Hearing Communication","summary":"  This study investigates innovative interaction designs for communication and\ncollaborative learning between learners of mixed hearing and signing abilities,\nleveraging advancements in mixed reality technologies like Apple Vision Pro and\ngenerative AI for animated avatars. Adopting a participatory design approach,\nwe engaged 15 d/Deaf and hard of hearing (DHH) students to brainstorm ideas for\nan AI avatar with interpreting ability (sign language to English, voice to\nEnglish) that would facilitate their face-to-face communication with hearing\npeers. Participants envisioned the AI avatars to address some issues with human\ninterpreters, such as lack of availability, and provide affordable options to\nexpensive personalized interpreting service. Our findings indicate a range of\npreferences for integrating the AI avatars with actual human figures of both\nDHH and hearing communication partners. The participants highlighted the\nimportance of having control over customizing the AI avatar, such as\nAI-generated signs, voices, facial expressions, and their synchronization for\nenhanced emotional display in communication. Based on our findings, we propose\na suite of design recommendations that balance respecting sign language norms\nwith adherence to hearing social norms. Our study offers insights on improving\nthe authenticity of generative AI in scenarios involving specific, and\nsometimes unfamiliar, social norms.\n","authors":["Si Chen","Haocong Cheng","Suzy Su","Stephanie Patterson","Raja Kushalnagar","Qi Wang","Yun Huang"],"pdf_url":"https://arxiv.org/pdf/2410.01604v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.00320v2","updated":"2024-10-02T14:40:38Z","published":"2024-05-01T04:57:25Z","title":"Web3 and the State: Indian state's redescription of blockchain","summary":"  The article closely reads a discussion paper by the National Institution for\nTransforming India (NITI) Aayog and a strategy paper by the Ministry of\nElectronics and Information Technology (MeitY) advocating non-financial use\ncases of blockchain in India. By noting the discursive shift from transparency\nto trust to adjustably transparent enacted in these two documents, and\nconsequently the Indian state's redescription of blockchain, the paper\nforegrounds how blockchain systems are being designated as \"decentral\" but have\nrecentralizing effects where the state reinvents and re-establishes itself as\nan intermediary. The paper illustrates how discursive shifts concerning trust,\ntransparency, (de)centralization and (dis)intermediation are crucial sites for\ninvestigating redescriptions of emerging sociotechnical systems.\n","authors":["Debarun Sarkar","Cheshta Arora"],"pdf_url":"https://arxiv.org/pdf/2405.00320v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.01585v1","updated":"2024-10-02T14:18:08Z","published":"2024-10-02T14:18:08Z","title":"Avatar Appearance and Behavior of Potential Harassers Affect Users'\n  Perceptions and Response Strategies in Social Virtual Reality (VR): A\n  Mixed-Methods Study","summary":"  Sexual harassment has been recognized as a significant social issue. In\nrecent years, the emergence of harassment in social virtual reality (VR) has\nbecome an important and urgent research topic. We employed a mixed-methods\napproach by conducting online surveys with VR users (N = 166) and\nsemi-structured interviews with social VR users (N = 18) to investigate how\nusers perceive sexual harassment in social VR, focusing on the influence of\navatar appearance. Moreover, we derived users' response strategies to sexual\nharassment and gained insights on platform regulation. This study contributes\nto the research on sexual harassment in social VR by examining the moderating\neffect of avatar appearance on user perception of sexual harassment and\nuncovering the underlying reasons behind response strategies. Moreover, it\npresents novel prospects and challenges in platform design and regulation\ndomains.\n","authors":["Xuetong Wang","Ziyan Wang","Mingmin Zhang","Kangyou Yu","Pan Hui","Mingming Fan"],"pdf_url":"https://arxiv.org/pdf/2410.01585v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.01555v1","updated":"2024-10-02T13:52:09Z","published":"2024-10-02T13:52:09Z","title":"ACE: A LLM-based Negotiation Coaching System","summary":"  The growing prominence of LLMs has led to an increase in the development of\nAI tutoring systems. These systems are crucial in providing underrepresented\npopulations with improved access to valuable education. One important area of\neducation that is unavailable to many learners is strategic bargaining related\nto negotiation. To address this, we develop a LLM-based Assistant for Coaching\nnEgotiation (ACE). ACE not only serves as a negotiation partner for users but\nalso provides them with targeted feedback for improvement. To build our system,\nwe collect a dataset of negotiation transcripts between MBA students. These\ntranscripts come from trained negotiators and emulate realistic bargaining\nscenarios. We use the dataset, along with expert consultations, to design an\nannotation scheme for detecting negotiation mistakes. ACE employs this scheme\nto identify mistakes and provide targeted feedback to users. To test the\neffectiveness of ACE-generated feedback, we conducted a user experiment with\ntwo consecutive trials of negotiation and found that it improves negotiation\nperformances significantly compared to a system that doesn't provide feedback\nand one which uses an alternative method of providing feedback.\n","authors":["Ryan Shea","Aymen Kallala","Xin Lucy Liu","Michael W. Morris","Zhou Yu"],"pdf_url":"https://arxiv.org/pdf/2410.01555v1.pdf","comment":"EMNLP 2024"},{"id":"http://arxiv.org/abs/2410.01532v1","updated":"2024-10-02T13:24:56Z","published":"2024-10-02T13:24:56Z","title":"Seeing Eye to AI: Human Alignment via Gaze-Based Response Rewards for\n  Large Language Models","summary":"  Advancements in Natural Language Processing (NLP), have led to the emergence\nof Large Language Models (LLMs) such as GPT, Llama, Claude, and Gemini, which\nexcel across a range of tasks but require extensive fine-tuning to align their\noutputs with human expectations. A widely used method for achieving this\nalignment is Reinforcement Learning from Human Feedback (RLHF), which, despite\nits success, faces challenges in accurately modelling human preferences. In\nthis paper, we introduce GazeReward, a novel framework that integrates implicit\nfeedback -- and specifically eye-tracking (ET) data -- into the Reward Model\n(RM). In addition, we explore how ET-based features can provide insights into\nuser preferences. Through ablation studies we test our framework with different\nintegration methods, LLMs, and ET generator models, demonstrating that our\napproach significantly improves the accuracy of the RM on established human\npreference datasets. This work advances the ongoing discussion on optimizing AI\nalignment with human values, exploring the potential of cognitive data for\nshaping future NLP research.\n","authors":["Angela Lopez-Cardona","Carlos Segura","Alexandros Karatzoglou","Sergi Abadal","Ioannis Arapakis"],"pdf_url":"https://arxiv.org/pdf/2410.01532v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.16587v2","updated":"2024-10-02T13:22:27Z","published":"2024-05-26T14:38:24Z","title":"Cost-Effective Online Multi-LLM Selection with Versatile Reward Models","summary":"  With the rapid advancement of large language models (LLMs), the diversity of\nmulti-LLM tasks and the variability in their pricing structures have become\nincreasingly important, as costs can vary greatly between different LLMs. To\ntackle these challenges, we introduce the \\textit{C2MAB-V}, a\n\\underline{C}ost-effective \\underline{C}ombinatorial \\underline{M}ulti-armed\n\\underline{B}andit with \\underline{V}ersatile reward models for optimal LLM\nselection and usage. This online model differs from traditional static\napproaches or those reliant on a single LLM without cost consideration. With\nmultiple LLMs deployed on a scheduling cloud and a local server dedicated to\nhandling user queries, \\textit{C2MAB-V} facilitates the selection of multiple\nLLMs over a combinatorial search space, specifically tailored for various\ncollaborative task types with different reward models. Based on our designed\nonline feedback mechanism and confidence bound technique, \\textit{C2MAB-V} can\neffectively address the multi-LLM selection challenge by managing the\nexploration-exploitation trade-off across different models, while also\nbalancing cost and reward for diverse tasks. The NP-hard integer linear\nprogramming problem for selecting multiple LLMs with trade-off dilemmas is\naddressed by: i) decomposing the integer problem into a relaxed form by the\nlocal server, ii) utilizing a discretization rounding scheme that provides\noptimal LLM combinations by the scheduling cloud, and iii) continual online\nupdates based on feedback. Theoretically, we prove that \\textit{C2MAB-V} offers\nstrict guarantees over versatile reward models, matching state-of-the-art\nresults for regret and violations in some degenerate cases. Empirically, we\nshow that \\textit{C2MAB-V} effectively balances performance and cost-efficiency\nwith nine LLMs for three application scenarios.\n","authors":["Xiangxiang Dai","Jin Li","Xutong Liu","Anqi Yu","John C. S. Lui"],"pdf_url":"https://arxiv.org/pdf/2405.16587v2.pdf","comment":"32 pages, 14 figures, conference"},{"id":"http://arxiv.org/abs/2410.03762v1","updated":"2024-10-02T13:20:14Z","published":"2024-10-02T13:20:14Z","title":"Getting in the Door: Streamlining Intake in Civil Legal Services with\n  Large Language Models","summary":"  Legal intake, the process of finding out if an applicant is eligible for help\nfrom a free legal aid program, takes significant time and resources. In part\nthis is because eligibility criteria are nuanced, open-textured, and require\nfrequent revision as grants start and end. In this paper, we investigate the\nuse of large language models (LLMs) to reduce this burden. We describe a\ndigital intake platform that combines logical rules with LLMs to offer\neligibility recommendations, and we evaluate the ability of 8 different LLMs to\nperform this task. We find promising results for this approach to help close\nthe access to justice gap, with the best model reaching an F1 score of .82,\nwhile minimizing false negatives.\n","authors":["Quinten Steenhuis","Hannes Westermann"],"pdf_url":"https://arxiv.org/pdf/2410.03762v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.01495v1","updated":"2024-10-02T12:45:09Z","published":"2024-10-02T12:45:09Z","title":"Open-vocabulary Multimodal Emotion Recognition: Dataset, Metric, and\n  Benchmark","summary":"  Multimodal Emotion Recognition (MER) is an important research topic. This\npaper advocates for a transformative paradigm in MER. The rationale behind our\nwork is that current approaches often rely on a limited set of basic emotion\nlabels, which do not adequately represent the rich spectrum of human emotions.\nThese traditional and overly simplistic emotion categories fail to capture the\ninherent complexity and subtlety of human emotional experiences, leading to\nlimited generalizability and practicality. Therefore, we propose a new MER\nparadigm called Open-vocabulary MER (OV-MER), which encompasses a broader range\nof emotion labels to reflect the richness of human emotions. This paradigm\nrelaxes the label space, allowing for the prediction of arbitrary numbers and\ncategories of emotions. To support this transition, we provide a comprehensive\nsolution that includes a newly constructed database based on LLM and human\ncollaborative annotations, along with corresponding metrics and a series of\nbenchmarks. We hope this work advances emotion recognition from basic emotions\nto more nuanced emotions, contributing to the development of emotional AI.\n","authors":["Zheng Lian","Haiyang Sun","Licai Sun","Lan Chen","Haoyu Chen","Hao Gu","Zhuofan Wen","Shun Chen","Siyuan Zhang","Hailiang Yao","Mingyu Xu","Kang Chen","Bin Liu","Rui Liu","Shan Liang","Ya Li","Jiangyan Yi","Jianhua Tao"],"pdf_url":"https://arxiv.org/pdf/2410.01495v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.01459v1","updated":"2024-10-02T12:10:55Z","published":"2024-10-02T12:10:55Z","title":"A Smart Chair for Health Monitoring in Daily Life","summary":"  Recent research has focused on the risks associated with poor sitting posture\nand the impact of sitting on biological parameters, such as heart rate because\nprolonged sitting is common across all ages and professions. In this work, we\npropose a novel approach that can display simultaneously posture and heart rate\nin real-time. In this device, pressure sensors are embedded into a flexible\nseparate cushion easily put on any chair to provide sitting behaviours and a\nsmartwatch-like PPG module is worn on the user's wrist. Regarding posture\nclassification, pressure figures of ten pressure sensors under the seat bottom\nare inputs of four machine learning models, giving a high accuracy of 99 per\ncent. Besides, the Electrocardiography recording module is illustrated with the\nsame results as a commercial device called DFRobot. Another advantage of this\nsmart chair is that it not only simultaneously displays both sitting postures\nand heart rates on external devices like laptops, mobile phones, or televisions\nthrough microcontrollers but also offers the relationship between them to help\npeople adjust their sitting behaviours, avoiding influencing heart rate. The\nsmart chair is expected to be useful equipment for people with a sedentary\nlifestyle, especially office workers.\n","authors":["Nguyen Thi Minh Huong","Vo Quoc Bao","Nguyen Trung Hau","Huynh Quang Linh"],"pdf_url":"https://arxiv.org/pdf/2410.01459v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.01396v1","updated":"2024-10-02T10:16:54Z","published":"2024-10-02T10:16:54Z","title":"Can We Delegate Learning to Automation?: A Comparative Study of LLM\n  Chatbots, Search Engines, and Books","summary":"  Learning is a key motivator behind information search behavior. With the\nemergence of LLM-based chatbots, students are increasingly turning to these\ntools as their primary resource for acquiring knowledge. However, the\ntransition from traditional resources like textbooks and web searches raises\nconcerns among educators. They worry that these fully-automated LLMs might lead\nstudents to delegate critical steps of search as learning. In this paper, we\nsystematically uncover three main concerns from educators' perspectives. In\nresponse to these concerns, we conducted a mixed-methods study with 92\nuniversity students to compare three learning sources with different automation\nlevels. Our results show that LLMs support comprehensive understanding of key\nconcepts without promoting passive learning, though their effectiveness in\nknowledge retention was limited. Additionally, we found that academic\nperformance impacted both learning outcomes and search patterns. Notably,\nhigher-competence learners engaged more deeply with content through\nreading-intensive behaviors rather than relying on search activities.\n","authors":["Yeonsun Yang","Ahyeon Shin","Mincheol Kang","Jiheon Kang","Jean Young Song"],"pdf_url":"https://arxiv.org/pdf/2410.01396v1.pdf","comment":"21 pages, 14 figures"},{"id":"http://arxiv.org/abs/2410.03759v1","updated":"2024-10-02T10:09:26Z","published":"2024-10-02T10:09:26Z","title":"Intelligent CAD 2.0","summary":"  Integrating modern artificial intelligence (AI) techniques, particularly\ngenerative AI, holds the promise of revolutionizing computer-aided design (CAD)\ntools and the engineering design process. However, the direction of \"AI+CAD\"\nremains unclear: how will the current generation of intelligent CAD (ICAD)\ndiffer from its predecessor in the 1980s and 1990s, what strategic pathways\nshould researchers and engineers pursue for its implementation, and what\npotential technical challenges might arise?\n  As an attempt to address these questions, this paper investigates the\ntransformative role of modern AI techniques in advancing CAD towards ICAD. It\nfirst analyzes the design process and reconsiders the roles AI techniques can\nassume in this process, highlighting how they can restructure the path humans,\ncomputers, and designs interact with each other. The primary conclusion is that\nICAD systems should assume an intensional rather than extensional role in the\ndesign process. This offers insights into the evaluation of the previous\ngeneration of ICAD (ICAD 1.0) and outlines a prospective framework and\ntrajectory for the next generation of ICAD (ICAD 2.0).\n","authors":["Qiang Zou","Yincai Wu","Zhenyu Liu","Weiwei Xu","Shuming Gao"],"pdf_url":"https://arxiv.org/pdf/2410.03759v1.pdf","comment":"published in the journal of Visual Informatics"},{"id":"http://arxiv.org/abs/2410.01384v1","updated":"2024-10-02T09:54:55Z","published":"2024-10-02T09:54:55Z","title":"CSLens: Towards Better Deploying Charging Stations via Visual Analytics\n  -- A Coupled Networks Perspective","summary":"  In recent years, the global adoption of electric vehicles (EVs) has surged,\nprompting a corresponding rise in the installation of charging stations. This\nproliferation has underscored the importance of expediting the deployment of\ncharging infrastructure. Both academia and industry have thus devoted to\naddressing the charging station location problem (CSLP) to streamline this\nprocess. However, prevailing algorithms addressing CSLP are hampered by\nrestrictive assumptions and computational overhead, leading to a dearth of\ncomprehensive evaluations in the spatiotemporal dimensions. Consequently, their\npractical viability is restricted. Moreover, the placement of charging stations\nexerts a significant impact on both the road network and the power grid, which\nnecessitates the evaluation of the potential post-deployment impacts on these\ninterconnected networks holistically. In this study, we propose CSLens, a\nvisual analytics system designed to inform charging station deployment\ndecisions through the lens of coupled transportation and power networks. CSLens\noffers multiple visualizations and interactive features, empowering users to\ndelve into the existing charging station layout, explore alternative deployment\nsolutions, and assess the ensuring impact. To validate the efficacy of CSLens,\nwe conducted two case studies and engaged in interviews with domain experts.\nThrough these efforts, we substantiated the usability and practical utility of\nCSLens in enhancing the decision-making process surrounding charging station\ndeployment. Our findings underscore CSLens's potential to serve as a valuable\nasset in navigating the complexities of charging infrastructure planning.\n","authors":["Yutian Zhang","Liwen Xu","Shaocong Tao","Quanxue Guan","Quan Li","Haipeng Zeng"],"pdf_url":"https://arxiv.org/pdf/2410.01384v1.pdf","comment":"11 pages, 6 figures; Accepted by IEEE IEEE Transactions on\n  Visualization and Computer Graphics, 2024 (TVCG)"},{"id":"http://arxiv.org/abs/2410.01364v1","updated":"2024-10-02T09:24:44Z","published":"2024-10-02T09:24:44Z","title":"MARLens: Understanding Multi-agent Reinforcement Learning for Traffic\n  Signal Control via Visual Analytics","summary":"  The issue of traffic congestion poses a significant obstacle to the\ndevelopment of global cities. One promising solution to tackle this problem is\nintelligent traffic signal control (TSC). Recently, TSC strategies leveraging\nreinforcement learning (RL) have garnered attention among researchers. However,\nthe evaluation of these models has primarily relied on fixed metrics like\nreward and queue length. This limited evaluation approach provides only a\nnarrow view of the model's decision-making process, impeding its practical\nimplementation. Moreover, effective TSC necessitates coordinated actions across\nmultiple intersections. Existing visual analysis solutions fall short when\napplied in multi-agent settings. In this study, we delve into the challenge of\ninterpretability in multi-agent reinforcement learning (MARL), particularly\nwithin the context of TSC. We propose MARLens a visual analytics system\ntailored to understand MARL-based TSC. Our system serves as a versatile\nplatform for both RL and TSC researchers. It empowers them to explore the\nmodel's features from various perspectives, revealing its decision-making\nprocesses and shedding light on interactions among different agents. To\nfacilitate quick identification of critical states, we have devised multiple\nvisualization views, complemented by a traffic simulation module that allows\nusers to replay specific training scenarios. To validate the utility of our\nproposed system, we present three comprehensive case studies, incorporate\ninsights from domain experts through interviews, and conduct a user study.\nThese collective efforts underscore the feasibility and effectiveness of\nMARLens in enhancing our understanding of MARL-based TSC systems and pave the\nway for more informed and efficient traffic management strategies.\n","authors":["Yutian Zhang","Guohong Zheng","Zhiyuan Liu","Quan Li","Haipeng Zeng"],"pdf_url":"https://arxiv.org/pdf/2410.01364v1.pdf","comment":"16 pages, 8 figures; Accepted by IEEE Transactions on Visualization\n  and Computer Graphics, 2024"},{"id":"http://arxiv.org/abs/2410.00727v2","updated":"2024-10-02T08:08:45Z","published":"2024-10-01T14:16:10Z","title":"Show Me What's Wrong!: Combining Charts and Text to Guide Data Analysis","summary":"  Analyzing and finding anomalies in multi-dimensional datasets is a cumbersome\nbut vital task across different domains. In the context of financial fraud\ndetection, analysts must quickly identify suspicious activity among\ntransactional data. This is an iterative process made of complex exploratory\ntasks such as recognizing patterns, grouping, and comparing. To mitigate the\ninformation overload inherent to these steps, we present a tool combining\nautomated information highlights, Large Language Model generated textual\ninsights, and visual analytics, facilitating exploration at different levels of\ndetail. We perform a segmentation of the data per analysis area and visually\nrepresent each one, making use of automated visual cues to signal which require\nmore attention. Upon user selection of an area, our system provides textual and\ngraphical summaries. The text, acting as a link between the high-level and\ndetailed views of the chosen segment, allows for a quick understanding of\nrelevant details. A thorough exploration of the data comprising the selection\ncan be done through graphical representations. The feedback gathered in a study\nperformed with seven domain experts suggests our tool effectively supports and\nguides exploratory analysis, easing the identification of suspicious\ninformation.\n","authors":["Beatriz Feliciano","Rita Costa","Jean Alves","Javier Liébana","Diogo Duarte","Pedro Bizarro"],"pdf_url":"https://arxiv.org/pdf/2410.00727v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.01291v1","updated":"2024-10-02T07:35:58Z","published":"2024-10-02T07:35:58Z","title":"What Did I Say Again? Relating User Needs to Search Outcomes in\n  Conversational Commerce","summary":"  Recent advances in natural language processing and deep learning have\naccelerated the development of digital assistants. In conversational commerce,\nthese assistants help customers find suitable products in online shops through\nnatural language conversations. During the dialogue, the assistant identifies\nthe customer's needs and preferences and subsequently suggests potentially\nrelevant products. Traditional online shops often allow users to filter search\nresults based on their preferences using facets. Selected facets can also serve\nas a reminder of how the product base was filtered. In conversational commerce,\nhowever, the absence of facets and the use of advanced natural language\nprocessing techniques can leave customers uncertain about how their input was\nprocessed by the system. This can hinder transparency and trust, which are\ncritical factors influencing customers' purchase intentions. To address this\nissue, we propose a novel text-based digital assistant that, in the product\nassessment step, explains how specific product aspects relate to the user's\nprevious utterances to enhance transparency and facilitate informed\ndecision-making. We conducted a user study (N=135) and found a significant\nincrease in user-perceived transparency when natural language explanations and\nhighlighted text passages were provided, demonstrating their potential to\nextend system transparency to the product assessment step in conversational\ncommerce.\n","authors":["Kevin Schott","Andrea Papenmeier","Daniel Hienert","Dagmar Kern"],"pdf_url":"https://arxiv.org/pdf/2410.01291v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.01240v1","updated":"2024-10-02T05:04:06Z","published":"2024-10-02T05:04:06Z","title":"Automatic deductive coding in discourse analysis: an application of\n  large language models in learning analytics","summary":"  Deductive coding is a common discourse analysis method widely used by\nlearning science and learning analytics researchers for understanding teaching\nand learning interactions. It often requires researchers to manually label all\ndiscourses to be analyzed according to a theoretically guided coding scheme,\nwhich is time-consuming and labor-intensive. The emergence of large language\nmodels such as GPT has opened a new avenue for automatic deductive coding to\novercome the limitations of traditional deductive coding. To evaluate the\nusefulness of large language models in automatic deductive coding, we employed\nthree different classification methods driven by different artificial\nintelligence technologies, including the traditional text classification method\nwith text feature engineering, BERT-like pretrained language model and GPT-like\npretrained large language model (LLM). We applied these methods to two\ndifferent datasets and explored the potential of GPT and prompt engineering in\nautomatic deductive coding. By analyzing and comparing the accuracy and Kappa\nvalues of these three classification methods, we found that GPT with prompt\nengineering outperformed the other two methods on both datasets with limited\nnumber of training samples. By providing detailed prompt structures, the\nreported work demonstrated how large language models can be used in the\nimplementation of automatic deductive coding.\n","authors":["Lishan Zhang","Han Wu","Xiaoshan Huang","Tengfei Duan","Hanxiang Du"],"pdf_url":"https://arxiv.org/pdf/2410.01240v1.pdf","comment":"20 pages"},{"id":"http://arxiv.org/abs/2409.04081v3","updated":"2024-10-02T05:00:57Z","published":"2024-09-06T07:44:44Z","title":"UI-JEPA: Towards Active Perception of User Intent through Onscreen User\n  Activity","summary":"  Generating user intent from a sequence of user interface (UI) actions is a\ncore challenge in comprehensive UI understanding. Recent advancements in\nmultimodal large language models (MLLMs) have led to substantial progress in\nthis area, but their demands for extensive model parameters, computing power,\nand high latency makes them impractical for scenarios requiring lightweight,\non-device solutions with low latency or heightened privacy. Additionally, the\nlack of high-quality datasets has hindered the development of such lightweight\nmodels. To address these challenges, we propose UI-JEPA, a novel framework that\nemploys masking strategies to learn abstract UI embeddings from unlabeled data\nthrough self-supervised learning, combined with an LLM decoder fine-tuned for\nuser intent prediction. We also introduce two new UI-grounded multimodal\ndatasets, \"Intent in the Wild\" (IIW) and \"Intent in the Tame\" (IIT), designed\nfor few-shot and zero-shot UI understanding tasks. IIW consists of 1.7K videos\nacross 219 intent categories, while IIT contains 914 videos across 10\ncategories. We establish the first baselines for these datasets, showing that\nrepresentations learned using a JEPA-style objective, combined with an LLM\ndecoder, can achieve user intent predictions that match the performance of\nstate-of-the-art large MLLMs, but with significantly reduced annotation and\ndeployment resources. Measured by intent similarity scores, UI-JEPA outperforms\nGPT-4 Turbo and Claude 3.5 Sonnet by 10.0% and 7.2% respectively, averaged\nacross two datasets. Notably, UI-JEPA accomplishes the performance with a 50.5x\nreduction in computational cost and a 6.6x improvement in latency in the IIW\ndataset. These results underscore the effectiveness of UI-JEPA, highlighting\nits potential for lightweight, high-performance UI understanding.\n","authors":["Yicheng Fu","Raviteja Anantha","Prabal Vashisht","Jianpeng Cheng","Etai Littwin"],"pdf_url":"https://arxiv.org/pdf/2409.04081v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.03806v2","updated":"2024-10-02T03:27:36Z","published":"2024-05-06T19:30:57Z","title":"In Situ AI Prototyping: Infusing Multimodal Prompts into Mobile Settings\n  with MobileMaker","summary":"  Recent advances in multimodal large language models (LLMs) have made it\neasier to rapidly prototype AI-powered features, especially for mobile use\ncases. However, gathering early, mobile-situated user feedback on these AI\nprototypes remains challenging. The broad scope and flexibility of LLMs means\nthat, for a given use-case-specific prototype, there is a crucial need to\nunderstand the wide range of in-the-wild input users are likely to provide and\ntheir in-context expectations for the AI's behavior. To explore the concept of\nin situ AI prototyping and testing, we created MobileMaker: a platform that\nenables designers to rapidly create and test mobile AI prototypes directly on\ndevices. This tool also enables testers to make on-device, in-the-field\nrevisions of prototypes using natural language. In an exploratory study with 16\nparticipants, we explored how user feedback on prototypes created with\nMobileMaker compares to that of existing prototyping tools (e.g., Figma, prompt\neditors). Our findings suggest that MobileMaker prototypes enabled more\nserendipitous discovery of: model input edge cases, discrepancies between AI's\nand user's in-context interpretation of the task, and contextual signals missed\nby the AI. Furthermore, we learned that while the ability to make in-the-wild\nrevisions led users to feel more fulfilled as active participants in the design\nprocess, it might also constrain their feedback to the subset of changes\nperceived as more actionable or implementable by the prototyping tool.\n","authors":["Savvas Petridis","Michael Xieyang Liu","Alexander J. Fiannaca","Vivian Tsai","Michael Terry","Carrie J. Cai"],"pdf_url":"https://arxiv.org/pdf/2405.03806v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03548v2","updated":"2024-10-02T00:57:37Z","published":"2023-03-06T23:16:24Z","title":"Large Language Models as Zero-Shot Human Models for Human-Robot\n  Interaction","summary":"  Human models play a crucial role in human-robot interaction (HRI), enabling\nrobots to consider the impact of their actions on people and plan their\nbehavior accordingly. However, crafting good human models is challenging;\ncapturing context-dependent human behavior requires significant prior knowledge\nand/or large amounts of interaction data, both of which are difficult to\nobtain. In this work, we explore the potential of large-language models (LLMs)\n-- which have consumed vast amounts of human-generated text data -- to act as\nzero-shot human models for HRI. Our experiments on three social datasets yield\npromising results; the LLMs are able to achieve performance comparable to\npurpose-built models. That said, we also discuss current limitations, such as\nsensitivity to prompts and spatial/numerical reasoning mishaps. Based on our\nfindings, we demonstrate how LLM-based human models can be integrated into a\nsocial robot's planning process and applied in HRI scenarios. Specifically, we\npresent one case study on a simulated trust-based table-clearing task and\nreplicate past results that relied on custom models. Next, we conduct a new\nrobot utensil-passing experiment (n = 65) where preliminary results show that\nplanning with a LLM-based human model can achieve gains over a basic myopic\nplan. In summary, our results show that LLMs offer a promising (but incomplete)\napproach to human modeling for HRI.\n","authors":["Bowen Zhang","Harold Soh"],"pdf_url":"https://arxiv.org/pdf/2303.03548v2.pdf","comment":"8 pages"}],"Programming Languages":[{"id":"http://arxiv.org/abs/2405.03709v3","updated":"2024-10-02T22:58:42Z","published":"2024-05-03T23:06:31Z","title":"ScenicNL: Generating Probabilistic Scenario Programs from Natural\n  Language","summary":"  For cyber-physical systems (CPS), including robotics and autonomous vehicles,\nmass deployment has been hindered by fatal errors that occur when operating in\nrare events. To replicate rare events such as vehicle crashes, many companies\nhave created logging systems and employed crash reconstruction experts to\nmeticulously recreate these valuable events in simulation. However, in these\nmethods, \"what if\" questions are not easily formulated and answered. We present\nScenarioNL, an AI System for creating scenario programs from natural language.\nSpecifically, we generate these programs from police crash reports. Reports\nnormally contain uncertainty about the exact details of the incidents which we\nrepresent through a Probabilistic Programming Language (PPL), Scenic. By using\nScenic, we can clearly and concisely represent uncertainty and variation over\nCPS behaviors, properties, and interactions. We demonstrate how commonplace\nprompting techniques with the best Large Language Models (LLM) are incapable of\nreasoning about probabilistic scenario programs and generating code for\nlow-resource languages such as Scenic. Our system is comprised of several LLMs\nchained together with several kinds of prompting strategies, a compiler, and a\nsimulator. We evaluate our system on publicly available autonomous vehicle\ncrash reports in California from the last five years and share insights into\nhow we generate code that is both semantically meaningful and syntactically\ncorrect.\n","authors":["Karim Elmaaroufi","Devan Shanker","Ana Cismaru","Marcell Vazquez-Chanlatte","Alberto Sangiovanni-Vincentelli","Matei Zaharia","Sanjit A. Seshia"],"pdf_url":"https://arxiv.org/pdf/2405.03709v3.pdf","comment":"22 pages, 3 figures. Published at COLM 2024.\n  https://ke7.github.io/ScenicNL"},{"id":"http://arxiv.org/abs/2410.01981v1","updated":"2024-10-02T19:40:18Z","published":"2024-10-02T19:40:18Z","title":"Surveying the Rust Verification Landscape","summary":"  Rust aims to be a safe programming language applicable to systems programming\napplications. In particular, its type system has strong guardrails to prevent a\nvariety of issues, such as memory safety bugs and data races. However, these\nguardrails can be sidestepped via the unsafe keyword. unsafe allows certain\notherwise-prohibited operations, but shifts the onus of preventing undefined\nbehaviour from the Rust language's compile-time checks to the developer. We\nbelieve that tools have a role to play in ensuring the absence of undefined\nbehaviour in the presence of unsafe code. Moreover, safety aside, programs\nwould also benefit from being verified for functional correctness, ensuring\nthat they meet their specifications.\n  In this research proposal, we explore what it means to do Rust verification.\nSpecifically, we explore which properties are worth verifying for Rust; what\ntechniques exist to verify them; and which code is worth verifying. In doing\nso, we motivate an effort to verify safety properties of the Rust standard\nlibrary, presenting the relevant challenges along with ideas to address them.\n","authors":["Alex Le Blanc","Patrick Lam"],"pdf_url":"https://arxiv.org/pdf/2410.01981v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.05334v2","updated":"2024-10-02T17:05:24Z","published":"2024-03-08T14:10:25Z","title":"WatChat: Explaining perplexing programs by debugging mental models","summary":"  Often, a good explanation for a program's unexpected behavior is a bug in the\nprogrammer's code. But sometimes, an even better explanation is a bug in the\nprogrammer's mental model of the language or API they are using. Instead of\nmerely debugging our current code (\"giving the programmer a fish\"), what if our\ntools could directly debug our mental models (\"teaching the programmer to\nfish\")? In this paper, we apply recent ideas from computational cognitive\nscience to offer a principled framework for doing exactly that. Given a \"why?\"\nquestion about a program, we automatically infer potential misconceptions about\nthe language/API that might cause the user to be surprised by the program's\nbehavior -- and then analyze those misconceptions to provide explanations of\nthe program's behavior. Our key idea is to formally represent misconceptions as\ncounterfactual (erroneous) semantics for the language/API, which can be\ninferred and debugged using program synthesis techniques. We demonstrate our\nframework, WatChat, by building systems for explanation in two domains:\nJavaScript type coercion, and the Git version control system. We evaluate\nWatChatJS and WatChatGit by comparing their outputs to experimentally-collected\nhuman-written explanations in these two domains: we show that WatChat's\nexplanations exhibit key features of human-written explanation, unlike those of\na state-of-the-art language model.\n","authors":["Kartik Chandra","Katherine M. Collins","Will Crichton","Tony Chen","Tzu-Mao Li","Adrian Weller","Rachit Nigam","Joshua Tenenbaum","Jonathan Ragan-Kelley"],"pdf_url":"https://arxiv.org/pdf/2403.05334v2.pdf","comment":"This is a preprint of work presented in early-stage non-archival form\n  at the ACL Natural Language Reasoning and Structured Explanations Workshop"},{"id":"http://arxiv.org/abs/2410.01488v1","updated":"2024-10-02T12:36:53Z","published":"2024-10-02T12:36:53Z","title":"SecCoder: Towards Generalizable and Robust Secure Code Generation","summary":"  After large models (LMs) have gained widespread acceptance in code-related\ntasks, their superior generative capacity has greatly promoted the application\nof the code LM. Nevertheless, the security of the generated code has raised\nattention to its potential damage. Existing secure code generation methods have\nlimited generalizability to unseen test cases and poor robustness against the\nattacked model, leading to safety failures in code generation. In this paper,\nwe propose a generalizable and robust secure code generation method SecCoder by\nusing in-context learning (ICL) and the safe demonstration. The dense retriever\nis also used to select the most helpful demonstration to maximize the\nimprovement of the generated code's security. Experimental results show the\nsuperior generalizability of the proposed model SecCoder compared to the\ncurrent secure code generation method, achieving a significant security\nimprovement of an average of 7.20% on unseen test cases. The results also show\nthe better robustness of SecCoder compared to the current attacked code LM,\nachieving a significant security improvement of an average of 7.74%. Our\nanalysis indicates that SecCoder enhances the security of LMs in generating\ncode, and it is more generalizable and robust.\n","authors":["Boyu Zhang","Tianyu Du","Junkai Tong","Xuhong Zhang","Kingsum Chow","Sheng Cheng","Xun Wang","Jianwei Yin"],"pdf_url":"https://arxiv.org/pdf/2410.01488v1.pdf","comment":"To Appear in the 2024 Conference on Empirical Methods in Natural\n  Language Processing (EMNLP)"}],"Operating Systems":[{"id":"http://arxiv.org/abs/2410.01528v1","updated":"2024-10-02T13:20:21Z","published":"2024-10-02T13:20:21Z","title":"Global Scheduling of Weakly-Hard Real-Time Tasks using Job-Level\n  Priority Classes","summary":"  Real-time systems are intrinsic components of many pivotal applications, such\nas self-driving vehicles, aerospace and defense systems. The trend in these\napplications is to incorporate multiple tasks onto fewer, more powerful\nhardware platforms, e.g., multi-core systems, mainly for reducing cost and\npower consumption. Many real-time tasks, like control tasks, can tolerate\noccasional deadline misses due to robust algorithms. These tasks can be modeled\nusing the weakly-hard model. Literature shows that leveraging the weakly-hard\nmodel can relax the over-provisioning associated with designed real-time\nsystems. However, a wide-range of the research focuses on single-core\nplatforms. Therefore, we strive to extend the state-of-the-art of scheduling\nweakly-hard real-time tasks to multi-core platforms. We present a global\njob-level fixed priority scheduling algorithm together with its schedulability\nanalysis. The scheduling algorithm leverages the tolerable continuous deadline\nmisses to assigning priorities to jobs. The proposed analysis extends the\nResponse Time Analysis (RTA) for global scheduling to test the schedulability\nof tasks. Hence, our analysis scales with the number of tasks and number of\ncores because, unlike literature, it depends neither on Integer Linear\nProgramming nor reachability trees. Schedulability analyses show that the\nschedulability ratio is improved by 40% comparing to the global Rate Monotonic\n(RM) scheduling and up to 60% more than the global EDF scheduling, which are\nthe state-of-the-art schedulers on the RTEMS real-time operating system. Our\nevaluation on industrial embedded multi-core platform running RTEMS shows that\nthe scheduling overhead of our proposal does not exceed 60 Nanosecond.\n","authors":["V. Gabriel Moyano","Zain A. H. Hammadeh","Selma Saidi","Daniel Lüdtke"],"pdf_url":"https://arxiv.org/pdf/2410.01528v1.pdf","comment":null}],"Networking and Internet Architecture":[{"id":"http://arxiv.org/abs/2410.02040v1","updated":"2024-10-02T21:17:44Z","published":"2024-10-02T21:17:44Z","title":"Clid: Identifying TLS Clients With Unsupervised Learning on Domain Names","summary":"  In this paper, we introduce Clid, a Transport Layer Security (TLS) client\nidentification tool based on unsupervised learning on domain names in the\nserver name indication (SNI) field. Clid aims to provide some information on a\nwide range of clients, even though it may not be able to identify a definitive\ncharacteristic about each one of the clients. This is a different approach from\nthat of many existing rule-based client identification tools that rely on\nhardcoded databases to identify granular characteristics of a few clients.\nOften times, these tools can identify only a small number of clients in a\nreal-world network as their databases grow outdated, which motivates an\nalternative approach like Clid. For this research, we utilize some 345 million\nanonymized TLS handshakes collected from a large university campus network.\nFrom each handshake, we create a TCP fingerprint that identifies each unique\nclient that corresponds to a physical device on the network. Clid uses Bayesian\noptimization to find the 'optimal' DBSCAN clustering of clients and domain\nnames for a set of TLS connections. Clid maps each client cluster to one or\nmore domain clusters that are most strongly associated with it based on the\nfrequency and exclusivity of their TLS connections. While learning highly\nassociated domain names of a client may not immediately tell us specific\ncharacteristics of the client like its the operating system, manufacturer, or\nTLS configuration, it may serve as a strong first step to doing so. We evaluate\nClid's performance on various subsets of our captured TLS handshakes and on\ndifferent parameter settings that affect the granularity of identification\nresults. Our experiments show that Clid is able to identify 'strongly\nassociated' domain names for at least 60% of all clients in all our\nexperiments.\n","authors":["Ihyun Nam","Gerry Wan"],"pdf_url":"https://arxiv.org/pdf/2410.02040v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2410.02021v1","updated":"2024-10-02T20:40:52Z","published":"2024-10-02T20:40:52Z","title":"On the Resilience of Fast Failover Routing Against Dynamic Link Failures","summary":"  Modern communication networks feature local fast failover mechanisms in the\ndata plane, to swiftly respond to link failures with pre-installed rerouting\nrules. This paper explores resilient routing meant to tolerate $\\leq k$\nsimultaneous link failures, ensuring packet delivery, provided that the source\nand destination remain connected. While past theoretical works studied failover\nrouting under static link failures, i.e., links which permanently and\nsimultaneously fail, real-world networks often face link flapping--dynamic down\nstates caused by, e.g., numerous short-lived software-related faults. Thus, in\nthis initial work, we re-investigate the resilience of failover routing against\nlink flapping, by categorizing link failures into static, semi-dynamic\n(removing the assumption that links fail simultaneously), and dynamic (removing\nthe assumption that links fail permanently) types, shedding light on the\ncapabilities and limitations of failover routing under these scenarios.\n  We show that $k$-edge-connected graphs exhibit $(k-1)$-resilient routing\nagainst dynamic failures for $k \\leq 5$. We further show that this result\nextends to arbitrary $k$ if it is possible to rewrite $\\log k$ bits in the\npacket header.\n  Rewriting $3$ bits suffices to cope with $k$ semi-dynamic failures. However,\non general graphs, tolerating $2$ dynamic failures becomes impossible without\nbit-rewriting. Even by rewriting $\\log k$ bits, resilient routing cannot\nresolve $k$ dynamic failures, demonstrating the limitation of local fast\nrerouting.\n","authors":["Wenkai Dai","Klaus-Tycho Foerster","Stefan Schmid"],"pdf_url":"https://arxiv.org/pdf/2410.02021v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.01982v1","updated":"2024-10-02T19:41:45Z","published":"2024-10-02T19:41:45Z","title":"Decentralized Collaborative Inertial Tracking","summary":"  Although people spend most of their time indoors, outdoor tracking systems,\nsuch as the Global Positioning System (GPS), are predominantly used for\nlocation-based services. These systems are accurate outdoors, easy to use, and\noperate autonomously on each mobile device. In contrast, Indoor Tracking\nSystems~(ITS) lack standardization and are often difficult to operate because\nthey require costly infrastructure. In this paper, we propose an indoor\ntracking algorithm that uses collected data from inertial sensors embedded in\nmost mobile devices. In this setting, mobile devices autonomously estimate\ntheir location, hence removing the burden of deploying and maintaining complex\nand scattered hardware infrastructure. In addition, these devices collaborate\nby anonymously exchanging data with other nearby devices, using wireless\ncommunication, such as Bluetooth, to correct errors in their location\nestimates. Our collaborative algorithm relies on low-complexity geometry\noperations and can be deployed on any recent mobile device with\ncommercial-grade sensors. We evaluate our solution on real-life data collected\nby different devices. Experimentation with 16 simultaneously moving and\ncollaborating devices shows an average accuracy improvement of 44% compared to\nthe standalone Pedestrian Dead Reckoning algorithm.\n","authors":["Alpha Diallo","Benoit Garbinato"],"pdf_url":"https://arxiv.org/pdf/2410.01982v1.pdf","comment":"ACCEPTED FOR PUBLICATION AND PRESENTED IN EAI MOBIQUITOUS 2023"},{"id":"http://arxiv.org/abs/2404.08003v3","updated":"2024-10-02T19:25:55Z","published":"2024-04-09T04:21:13Z","title":"Asynchronous Federated Reinforcement Learning with Policy Gradient\n  Updates: Algorithm Design and Convergence Analysis","summary":"  To improve the efficiency of reinforcement learning (RL), we propose a novel\nasynchronous federated reinforcement learning (FedRL) framework termed AFedPG,\nwhich constructs a global model through collaboration among $N$ agents using\npolicy gradient (PG) updates. To address the challenge of lagged policies in\nasynchronous settings, we design a delay-adaptive lookahead technique\n\\textit{specifically for FedRL} that can effectively handle heterogeneous\narrival times of policy gradients. We analyze the theoretical global\nconvergence bound of AFedPG, and characterize the advantage of the proposed\nalgorithm in terms of both the sample complexity and time complexity.\nSpecifically, our AFedPG method achieves $O(\\frac{{\\epsilon}^{-2.5}}{N})$\nsample complexity for global convergence at each agent on average. Compared to\nthe single agent setting with $O(\\epsilon^{-2.5})$ sample complexity, it enjoys\na linear speedup with respect to the number of agents. Moreover, compared to\nsynchronous FedPG, AFedPG improves the time complexity from\n$O(\\frac{t_{\\max}}{N})$ to $O({\\sum_{i=1}^{N} \\frac{1}{t_{i}}})^{-1}$, where\n$t_{i}$ denotes the time consumption in each iteration at agent $i$, and\n$t_{\\max}$ is the largest one. The latter complexity $O({\\sum_{i=1}^{N}\n\\frac{1}{t_{i}}})^{-1}$ is always smaller than the former one, and this\nimprovement becomes significant in large-scale federated settings with\nheterogeneous computing powers ($t_{\\max}\\gg t_{\\min}$). Finally, we\nempirically verify the improved performance of AFedPG in four widely-used\nMuJoCo environments with varying numbers of agents. We also demonstrate the\nadvantages of AFedPG in various computing heterogeneity scenarios.\n","authors":["Guangchen Lan","Dong-Jun Han","Abolfazl Hashemi","Vaneet Aggarwal","Christopher G. Brinton"],"pdf_url":"https://arxiv.org/pdf/2404.08003v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.00453v2","updated":"2024-10-02T18:18:36Z","published":"2024-10-01T07:17:19Z","title":"The NetMob2024 Dataset: Population Density and OD Matrices from Four\n  LMIC Countries","summary":"  The NetMob24 dataset offers a unique opportunity for researchers from a range\nof academic fields to access comprehensive spatiotemporal data sets spanning\nfour countries (India, Mexico, Indonesia, and Colombia) over the course of two\nyears (2019 and 2020). This dataset, developed in collaboration with Cuebiq\n(Also referred to as Spectus), comprises privacy-preserving aggregated data\nsets derived from mobile application (app) data collected from users who have\nvoluntarily consented to anonymous data collection for research purposes. It is\nour hope that this reference dataset will foster the production of new research\nmethods and the reproducibility of research outcomes.\n","authors":["Wenlan Zhang","Miguel Nunez del Prado","Vincent Gauthier","Sveta Milusheva"],"pdf_url":"https://arxiv.org/pdf/2410.00453v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.01603v1","updated":"2024-10-02T14:42:12Z","published":"2024-10-02T14:42:12Z","title":"Beamforming in Secure Integrated Sensing and Communication Systems with\n  Antenna Allocation","summary":"  In this paper, we consider joint antenna allocation and transmit beamforming\ndesign in secure integrated sensing and communication (ISAC) systems. A\ndual-function base station (DFBS) aims to securely deliver messages to a\nsingle-antenna receiver while detecting potential eavesdroppers. To prevent\neavesdropping, we incorporate specialized sensing signals, intentionally\nreducing communication signal power toward suspicious targets to improve\nsensing. We prioritize minimizing the matching error between the transmitting\nand required beampatterns for sensing and communication. Our design optimizes\nantenna allocation and beamforming at the DFBS, meeting minimum secrecy rate\nand power constraints. We propose solvers based on alternating optimization for\nthe non-convex design problem. Simulations show that the antenna allocation\nscheme significantly improves safety performance.\n","authors":["Yunxiang Shi","Lixin Li","Wensheng Lin","Wei Liang","Zhu Han"],"pdf_url":"https://arxiv.org/pdf/2410.01603v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.01597v1","updated":"2024-10-02T14:34:45Z","published":"2024-10-02T14:34:45Z","title":"SAFE: Semantic Adaptive Feature Extraction with Rate Control for 6G\n  Wireless Communications","summary":"  Most current Deep Learning-based Semantic Communication (DeepSC) systems are\ndesigned and trained exclusively for particular single-channel conditions,\nwhich restricts their adaptability and overall bandwidth utilization. To\naddress this, we propose an innovative Semantic Adaptive Feature Extraction\n(SAFE) framework, which significantly improves bandwidth efficiency by allowing\nusers to select different sub-semantic combinations based on their channel\nconditions. This paper also introduces three advanced learning algorithms to\noptimize the performance of SAFE framework as a whole. Through a series of\nsimulation experiments, we demonstrate that the SAFE framework can effectively\nand adaptively extract and transmit semantics under different channel bandwidth\nconditions, of which effectiveness is verified through objective and subjective\nquality evaluations.\n","authors":["Yuna Yan","Lixin Li","Xin Zhang","Wensheng Lin","Wenchi Cheng","Zhu Han"],"pdf_url":"https://arxiv.org/pdf/2410.01597v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.01584v1","updated":"2024-10-02T14:18:04Z","published":"2024-10-02T14:18:04Z","title":"AI-Native Network Digital Twin for Intelligent Network Management in 6G","summary":"  As a pivotal virtualization technology, network digital twin is expected to\naccurately reflect real-time status and abstract features in the on-going sixth\ngeneration (6G) networks. In this article, we propose an artificial\nintelligence (AI)-native network digital twin framework for 6G networks to\nenable the synergy of AI and network digital twin, thereby facilitating\nintelligent network management. In the proposed framework, AI models are\nutilized to establish network digital twin models to facilitate network status\nprediction, network pattern abstraction, and network management\ndecision-making. Furthermore, potential solutions are proposed for enhance the\nperformance of network digital twin. Finally, a case study is presented,\nfollowed by a discussion of open research issues that are essential for\nAI-native network digital twin in 6G networks.\n","authors":["Wen Wu","Xinyu Huangm","Tom H. Luan"],"pdf_url":"https://arxiv.org/pdf/2410.01584v1.pdf","comment":"This article is submitted to IEEE Wireless Communications"},{"id":"http://arxiv.org/abs/2410.01564v1","updated":"2024-10-02T14:01:07Z","published":"2024-10-02T14:01:07Z","title":"Outage Probability Analysis for OTFS in Lossy Communications","summary":"  This paper analyzes the outage probability of orthogonal time frequency space\n(OTFS) modulation under a lossy communication scenario. First of all, we\nintroduce the channel model and the vector form representation of OTFS this\npaper uses. Then, we derive an exact expression of the OTFS outage probability\nin lossy communication scenarios, using Shannon's lossy source-channel\nseparation theorem. Because the channel is time-varying, calculating the exact\noutage probability is computationally expensive. Therefore, this paper aims to\nderive a lower bound of the outage probability, which can relatively easily be\ncalculated. Thus, given the distortion requirement and number of the resolvable\npaths, we can obtain a performance limit under the optimal condition as a\nreference. Finally, the experimental results of outage probability are obtained\nby Monte-Carlo method, and compared with the theoretical results calculated by\nthe closed-from expression of the lower bound.\n","authors":["Xin Zhang","Wensheng Lin","Lixin Li","Fucheng Yang","Zhu Han","Tad Matsumoto"],"pdf_url":"https://arxiv.org/pdf/2410.01564v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.01554v1","updated":"2024-10-02T13:47:45Z","published":"2024-10-02T13:47:45Z","title":"Weighted Sum Power Minimization for Cooperative Spectrum Sharing in\n  Cognitive Radio Networks","summary":"  This letter introduces weighted sum power (WSP), a new performance metric for\nwireless resource allocation during cooperative spectrum sharing in cognitive\nradio networks, where the primary and secondary nodes have different priorities\nand quality of service (QoS) requirements. Compared to using energy efficiency\n(EE) and weighted sum energy efficiency (WSEE) as performance metrics and\noptimization objectives of wireless resource allocation towards green\ncommunication, the linear character of WSP can reduce the complexity of\noptimization problems. Meanwhile, the weights assigned to different nodes are\nbeneficial for managing their power budget. Using WSP as the optimization\nobjective, a suboptimal resource allocation scheme is proposed, leveraging\nlinear programming and Newton's method. Simulations verify that the proposed\nscheme provides near-optimal performance with low computation time.\nFurthermore, the initial approximate value selection in Newton's method is also\noptimized to accelerate the proposed scheme.\n","authors":["Yang Yu"],"pdf_url":"https://arxiv.org/pdf/2410.01554v1.pdf","comment":"5 pages, 7 figures"},{"id":"http://arxiv.org/abs/2410.01515v1","updated":"2024-10-02T13:04:35Z","published":"2024-10-02T13:04:35Z","title":"Task-Oriented Edge-Assisted Cooperative Data Compression, Communications\n  and Computing for UGV-Enhanced Warehouse Logistics","summary":"  Only the chairs can edit This paper explores the growing need for\ntask-oriented communications in warehouse logistics, where traditional\ncommunication Key Performance Indicators (KPIs)-such as latency, reliability,\nand throughput-often do not fully meet task requirements. As the complexity of\ndata flow management in large-scale device networks increases, there is also a\npressing need for innovative cross-system designs that balance data\ncompression, communication, and computation. To address these challenges, we\npropose a task-oriented, edge-assisted framework for cooperative data\ncompression, communication, and computing in Unmanned Ground Vehicle\n(UGV)-enhanced warehouse logistics. In this framework, two UGVs collaborate to\ntransport cargo, with control functions-navigation for the front UGV and\nfollowing/conveyance for the rear UGV-offloaded to the edge server to\naccommodate their limited on-board computing resources. We develop a Deep\nReinforcement Learning (DRL)-based two-stage point cloud data compression\nalgorithm that dynamically and collaboratively adjusts compression ratios\naccording to task requirements, significantly reducing communication overhead.\nSystem-level simulations of our UGV logistics prototype demonstrate the\nframework's effectiveness and its potential for swift real-world\nimplementation.\n","authors":["Jiaming Yang","Zhen Meng","Xiangmin Xu","Kan Chen","Emma Liying Li","Philip Guodong G. Zhao"],"pdf_url":"https://arxiv.org/pdf/2410.01515v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.02815v2","updated":"2024-10-02T12:09:31Z","published":"2024-07-03T05:27:14Z","title":"Optimization of End-to-End AoI in Edge-Enabled Vehicular Fog Systems: A\n  Dueling-DQN Approach","summary":"  In real-time status update services for the Internet of Things (IoT), the\ntimely dissemination of information requiring timely updates is crucial to\nmaintaining its relevance. Failing to keep up with these updates results in\noutdated information. The age of information (AoI) serves as a metric to\nquantify the freshness of information. The Existing works to optimize AoI\nprimarily focus on the transmission time from the information source to the\nmonitor, neglecting the transmission time from the monitor to the destination.\nThis oversight significantly impacts information freshness and subsequently\naffects decision-making accuracy. To address this gap, we designed an\nedge-enabled vehicular fog system to lighten the computational burden on IoT\ndevices. We examined how information transmission and request-response times\ninfluence end-to-end AoI. As a solution, we proposed Dueling-Deep Queue Network\n(dueling-DQN), a deep reinforcement learning (DRL)-based algorithm and compared\nits performance with DQN policy and analytical results. Our simulation results\ndemonstrate that the proposed dueling-DQN algorithm outperforms both DQN and\nanalytical methods, highlighting its effectiveness in improving real-time\nsystem information freshness. Considering the complete end-to-end transmission\nprocess, our optimization approach can improve decision-making performance and\noverall system efficiency.\n","authors":["Seifu Birhanu Tadele","Binayak Kar","Frezer Guteta Wakgra","Asif Uddin Khan"],"pdf_url":"https://arxiv.org/pdf/2407.02815v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.01298v1","updated":"2024-10-02T07:43:53Z","published":"2024-10-02T07:43:53Z","title":"Building a real-time physical layer labeled data logging facility for 6G\n  research","summary":"  This work describes the architecture and vision of designing and implementing\na new test infrastructure for 6G physical layer research at KU Leuven. The\nTestbed is designed for physical layer research and experimentation following\nseveral emerging trends, such as cell-free networking, integrated\ncommunication, sensing, open disaggregated Radio Access Networks, AI-Native\ndesign, and multiband operation. The software is almost entirely based on free\nand open-source software, making contributing and reusing any component easy.\nThe open Testbed is designed to provide real-time and labeled data on all parts\nof the physical layer, from raw IQ data to synchronization statistics, channel\nstate information, or symbol/bit/packet error rates. Real-time labeled datasets\ncan be collected by synchronizing the physical layer data logging with a\npositioning and motion capture system. One of the main goals of the design is\nto make it open and accessible to external users remotely. Most tests and data\ncaptures can easily be automated, and experiment code can be remotely deployed\nusing standard containers (e.g., Docker or Podman). Finally, the paper\ndescribes how the Testbed can be used for our research on joint communication\nand sensing, over-the-air synchronization, distributed processing, and AI in\nthe loop.\n","authors":["Franco Minucci","Raquel Marina Noguera Oishi","Haoqiu Xiong","Dieter Verbruggen","Cel Thys","Rizqi Hersyandika","Robbert Beerten","Achiel Colpaert","Vida Ranjbar","Sofie Pollin"],"pdf_url":"https://arxiv.org/pdf/2410.01298v1.pdf","comment":null}],"Distributed, Parallel, and Cluster Computing":[{"id":"http://arxiv.org/abs/2409.06474v2","updated":"2024-10-02T21:53:00Z","published":"2024-09-10T13:04:13Z","title":"Advancing Hybrid Defense for Byzantine Attacks in Federated Learning","summary":"  Federated learning (FL) enables multiple clients to collaboratively train a\nglobal model without sharing their local data. Recent studies have highlighted\nthe vulnerability of FL to Byzantine attacks, where malicious clients send\npoisoned updates to degrade model performance. Notably, many attacks have been\ndeveloped targeting specific aggregation rules, whereas various defense\nmechanisms have been designed for dedicated threat models. This paper studies\nthe resilience of an attack-agnostic FL scenario, where the server lacks prior\nknowledge of both the attackers' strategies and the number of malicious clients\ninvolved. We first introduce a hybrid defense against state-of-the-art attacks.\nOur goal is to identify a general-purpose aggregation rule that performs well\non average while also avoiding worst-case vulnerabilities. By adaptively\nselecting from available defenses, we demonstrate that the server remains\nrobust even when confronted with a substantial proportion of poisoned updates.\nTo better understand this resilience, we then assess the attackers' capability\nusing a proxy called client heterogeneity. We also emphasize that the existing\nFL defenses should not be regarded as secure, as demonstrated through the newly\nproposed Trapsetter attack. The proposed attack outperforms other\nstate-of-the-art attacks by further reducing the model test accuracy by 8-10%.\nOur findings highlight the ongoing need for the development of\nByzantine-resilient aggregation algorithms in FL.\n","authors":["Kai Yue","Richeng Jin","Chau-Wai Wong","Huaiyu Dai"],"pdf_url":"https://arxiv.org/pdf/2409.06474v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.02029v1","updated":"2024-10-02T20:49:24Z","published":"2024-10-02T20:49:24Z","title":"XChainWatcher: Monitoring and Identifying Attacks in Cross-Chain Bridges","summary":"  Cross-chain bridges are widely used blockchain interoperability mechanisms.\nHowever, several of these bridges have vulnerabilities that have caused 3.2\nbillion dollars in losses since May 2021. Some studies have revealed the\nexistence of these vulnerabilities, but little quantitative research is\navailable, and there are no safeguard mechanisms to protect bridges from such\nattacks. We propose XChainWatcher, the first mechanism for monitoring bridges\nand detecting attacks against them. XChainWatcher relies on a cross-chain model\npowered by a Datalog engine, designed to be pluggable into any cross-chain\nbridge. Analyzing data from the Ronin and Nomad bridges, we successfully\nidentified the transactions that led to losses of \\$611M and \\$190M USD,\nrespectively. XChainWatcher not only uncovers successful attacks but also\nreveals unintended behavior, such as 37 cross-chain transactions (cctx) that\nthese bridges should not have accepted, failed attempts to exploit Nomad, over\n\\$7.8M locked on one chain but never released on Ethereum, and \\$200K lost due\nto inadequate interaction with bridges. We provide the first open-source\ndataset of 81,000 cctxs across three blockchains, capturing \\$585M and \\$3.7B\nin token transfers in Nomad and Ronin, respectively.\n","authors":["André Augusto","Rafael Belchior","Jonas Pfannschmidt","André Vasconcelos","Miguel Correia"],"pdf_url":"https://arxiv.org/pdf/2410.02029v1.pdf","comment":"20 pages, 13 figures"},{"id":"http://arxiv.org/abs/2410.02021v1","updated":"2024-10-02T20:40:52Z","published":"2024-10-02T20:40:52Z","title":"On the Resilience of Fast Failover Routing Against Dynamic Link Failures","summary":"  Modern communication networks feature local fast failover mechanisms in the\ndata plane, to swiftly respond to link failures with pre-installed rerouting\nrules. This paper explores resilient routing meant to tolerate $\\leq k$\nsimultaneous link failures, ensuring packet delivery, provided that the source\nand destination remain connected. While past theoretical works studied failover\nrouting under static link failures, i.e., links which permanently and\nsimultaneously fail, real-world networks often face link flapping--dynamic down\nstates caused by, e.g., numerous short-lived software-related faults. Thus, in\nthis initial work, we re-investigate the resilience of failover routing against\nlink flapping, by categorizing link failures into static, semi-dynamic\n(removing the assumption that links fail simultaneously), and dynamic (removing\nthe assumption that links fail permanently) types, shedding light on the\ncapabilities and limitations of failover routing under these scenarios.\n  We show that $k$-edge-connected graphs exhibit $(k-1)$-resilient routing\nagainst dynamic failures for $k \\leq 5$. We further show that this result\nextends to arbitrary $k$ if it is possible to rewrite $\\log k$ bits in the\npacket header.\n  Rewriting $3$ bits suffices to cope with $k$ semi-dynamic failures. However,\non general graphs, tolerating $2$ dynamic failures becomes impossible without\nbit-rewriting. Even by rewriting $\\log k$ bits, resilient routing cannot\nresolve $k$ dynamic failures, demonstrating the limitation of local fast\nrerouting.\n","authors":["Wenkai Dai","Klaus-Tycho Foerster","Stefan Schmid"],"pdf_url":"https://arxiv.org/pdf/2410.02021v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.01982v1","updated":"2024-10-02T19:41:45Z","published":"2024-10-02T19:41:45Z","title":"Decentralized Collaborative Inertial Tracking","summary":"  Although people spend most of their time indoors, outdoor tracking systems,\nsuch as the Global Positioning System (GPS), are predominantly used for\nlocation-based services. These systems are accurate outdoors, easy to use, and\noperate autonomously on each mobile device. In contrast, Indoor Tracking\nSystems~(ITS) lack standardization and are often difficult to operate because\nthey require costly infrastructure. In this paper, we propose an indoor\ntracking algorithm that uses collected data from inertial sensors embedded in\nmost mobile devices. In this setting, mobile devices autonomously estimate\ntheir location, hence removing the burden of deploying and maintaining complex\nand scattered hardware infrastructure. In addition, these devices collaborate\nby anonymously exchanging data with other nearby devices, using wireless\ncommunication, such as Bluetooth, to correct errors in their location\nestimates. Our collaborative algorithm relies on low-complexity geometry\noperations and can be deployed on any recent mobile device with\ncommercial-grade sensors. We evaluate our solution on real-life data collected\nby different devices. Experimentation with 16 simultaneously moving and\ncollaborating devices shows an average accuracy improvement of 44% compared to\nthe standalone Pedestrian Dead Reckoning algorithm.\n","authors":["Alpha Diallo","Benoit Garbinato"],"pdf_url":"https://arxiv.org/pdf/2410.01982v1.pdf","comment":"ACCEPTED FOR PUBLICATION AND PRESENTED IN EAI MOBIQUITOUS 2023"},{"id":"http://arxiv.org/abs/2404.08003v3","updated":"2024-10-02T19:25:55Z","published":"2024-04-09T04:21:13Z","title":"Asynchronous Federated Reinforcement Learning with Policy Gradient\n  Updates: Algorithm Design and Convergence Analysis","summary":"  To improve the efficiency of reinforcement learning (RL), we propose a novel\nasynchronous federated reinforcement learning (FedRL) framework termed AFedPG,\nwhich constructs a global model through collaboration among $N$ agents using\npolicy gradient (PG) updates. To address the challenge of lagged policies in\nasynchronous settings, we design a delay-adaptive lookahead technique\n\\textit{specifically for FedRL} that can effectively handle heterogeneous\narrival times of policy gradients. We analyze the theoretical global\nconvergence bound of AFedPG, and characterize the advantage of the proposed\nalgorithm in terms of both the sample complexity and time complexity.\nSpecifically, our AFedPG method achieves $O(\\frac{{\\epsilon}^{-2.5}}{N})$\nsample complexity for global convergence at each agent on average. Compared to\nthe single agent setting with $O(\\epsilon^{-2.5})$ sample complexity, it enjoys\na linear speedup with respect to the number of agents. Moreover, compared to\nsynchronous FedPG, AFedPG improves the time complexity from\n$O(\\frac{t_{\\max}}{N})$ to $O({\\sum_{i=1}^{N} \\frac{1}{t_{i}}})^{-1}$, where\n$t_{i}$ denotes the time consumption in each iteration at agent $i$, and\n$t_{\\max}$ is the largest one. The latter complexity $O({\\sum_{i=1}^{N}\n\\frac{1}{t_{i}}})^{-1}$ is always smaller than the former one, and this\nimprovement becomes significant in large-scale federated settings with\nheterogeneous computing powers ($t_{\\max}\\gg t_{\\min}$). Finally, we\nempirically verify the improved performance of AFedPG in four widely-used\nMuJoCo environments with varying numbers of agents. We also demonstrate the\nadvantages of AFedPG in various computing heterogeneity scenarios.\n","authors":["Guangchen Lan","Dong-Jun Han","Abolfazl Hashemi","Vaneet Aggarwal","Christopher G. Brinton"],"pdf_url":"https://arxiv.org/pdf/2404.08003v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2304.05301v3","updated":"2024-10-02T19:15:05Z","published":"2023-04-11T15:50:54Z","title":"TACOS: Topology-Aware Collective Algorithm Synthesizer for Distributed\n  Machine Learning","summary":"  The surge of artificial intelligence, particularly large language models, has\ndriven the rapid development of large-scale machine learning clusters.\nExecuting distributed models on these clusters is often constrained by\ncommunication overhead, making efficient utilization of available network\nresources crucial. As a result, the routing algorithm employed for collective\ncommunications (i.e., collective algorithms) plays a pivotal role in\ndetermining overall performance. Unfortunately, existing collective\ncommunication libraries for distributed machine learning are limited by a fixed\nset of basic collective algorithms. This limitation hinders communication\noptimization, especially in modern clusters with heterogeneous and asymmetric\ntopologies. Furthermore, manually designing collective algorithms for all\npossible combinations of network topologies and collective patterns requires\nheavy engineering and validation efforts. To address these challenges, this\npaper presents TACOS, an autonomous synthesizer capable of automatically\ngenerating topology-aware collective algorithms tailored to specific collective\npatterns and network topologies. TACOS is highly flexible, synthesizing an\nAll-Reduce algorithm for a heterogeneous 128-NPU system in just 1.08 seconds,\nwhile achieving up to a 4.27x performance improvement over state-of-the-art\nsynthesizers. Additionally, TACOS demonstrates better scalability with\npolynomial synthesis times, in contrast to NP-hard approaches which only scale\nto systems with tens of NPUs. TACOS can synthesize for 40K NPUs in just 2.52\nhours.\n","authors":["William Won","Midhilesh Elavazhagan","Sudarshan Srinivasan","Swati Gupta","Tushar Krishna"],"pdf_url":"https://arxiv.org/pdf/2304.05301v3.pdf","comment":"Contains 12 main pages, 21 figures, 5 tables. Artifact appendix\n  attached"},{"id":"http://arxiv.org/abs/2410.01754v1","updated":"2024-10-02T17:04:50Z","published":"2024-10-02T17:04:50Z","title":"Constant pH Simulation with FMM Electrostatics in GROMACS. (B) GPU\n  Accelerated Hamiltonian Interpolation","summary":"  The structural dynamics of biological macromolecules, such as proteins,\nDNA/RNA, or their complexes, are strongly influenced by protonation changes of\ntheir typically many titratable groups, which explains their pH sensitivity. In\nturn, conformational and environmental changes in the biomolecule affect the\nprotonation state of these groups. With a few exceptions, conventional force\nfield-based molecular dynamics (MD) simulations do not account for these\neffects, nor do they allow for coupling to a pH buffer.\n  The $\\lambda$-dynamics method implements this coupling and thus allows for MD\nsimulations at constant pH. It uses separate Hamiltonians for the protonated\nand deprotonated states of each titratable group, with a $\\lambda$ variable\nthat continuously interpolates between them. However, rigorous implementations\nof Hamiltonian Interpolation (HI) $\\lambda$-dynamics are prohibitively slow\nwhen used with Particle Mesh Ewald (PME). To circumvent this problem, it has\nbeen proposed to interpolate the charges instead of the Hamiltonians (QI).\n  Here, we propose a rigorous yet efficient Multipole-Accelerated Hamiltonian\nInterpolation (MAHI) method to perform $\\lambda$-dynamics in GROMACS. Starting\nfrom a charge-scaled Hamiltonian, precomputed with the Fast Multipole Method\n(FMM) or with PME, the correct HI forces are calculated with negligible\ncomputational overhead. We compare HI with QI and show that HI leads to more\nfrequent transitions between protonation states, resulting in better sampling\nand accuracy. Our performance benchmarks show that introducing, e.g., 512\ntitratable sites to a one million atom MD system increases runtime by less than\n20% compared to a regular FMM-based simulation. We have integrated the scheme\ninto our GPU-FMM code for the simulation software GROMACS, allowing an easy and\neffortless transition from standard force field simulations to constant pH\nsimulations.\n","authors":["Bartosz Kohnke","Eliane Briand","Carsten Kutzner","Helmut Grubmüller"],"pdf_url":"https://arxiv.org/pdf/2410.01754v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.01657v1","updated":"2024-10-02T15:22:27Z","published":"2024-10-02T15:22:27Z","title":"Scalable and Consistent Graph Neural Networks for Distributed Mesh-based\n  Data-driven Modeling","summary":"  This work develops a distributed graph neural network (GNN) methodology for\nmesh-based modeling applications using a consistent neural message passing\nlayer. As the name implies, the focus is on enabling scalable operations that\nsatisfy physical consistency via halo nodes at sub-graph boundaries. Here,\nconsistency refers to the fact that a GNN trained and evaluated on one rank\n(one large graph) is arithmetically equivalent to evaluations on multiple ranks\n(a partitioned graph). This concept is demonstrated by interfacing GNNs with\nNekRS, a GPU-capable exascale CFD solver developed at Argonne National\nLaboratory. It is shown how the NekRS mesh partitioning can be linked to the\ndistributed GNN training and inference routines, resulting in a scalable\nmesh-based data-driven modeling workflow. We study the impact of consistency on\nthe scalability of mesh-based GNNs, demonstrating efficient scaling in\nconsistent GNNs for up to O(1B) graph nodes on the Frontier exascale\nsupercomputer.\n","authors":["Shivam Barwey","Riccardo Balin","Bethany Lusch","Saumil Patel","Ramesh Balakrishnan","Pinaki Pal","Romit Maulik","Venkatram Vishwanath"],"pdf_url":"https://arxiv.org/pdf/2410.01657v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.01644v1","updated":"2024-10-02T15:13:26Z","published":"2024-10-02T15:13:26Z","title":"A Novel Framework of Horizontal-Vertical Hybrid Federated Learning for\n  EdgeIoT","summary":"  This letter puts forth a new hybrid horizontal-vertical federated learning\n(HoVeFL) for mobile edge computing-enabled Internet of Things (EdgeIoT). In\nthis framework, certain EdgeIoT devices train local models using the same data\nsamples but analyze disparate data features, while the others focus on the same\nfeatures using non-independent and identically distributed (non-IID) data\nsamples. Thus, even though the data features are consistent, the data samples\nvary across devices. The proposed HoVeFL formulates the training of local and\nglobal models to minimize the global loss function. Performance evaluations on\nCIFAR-10 and SVHN datasets reveal that the testing loss of HoVeFL with 12\nhorizontal FL devices and six vertical FL devices is 5.5% and 25.2% higher,\nrespectively, compared to a setup with six horizontal FL devices and 12\nvertical FL devices.\n","authors":["Kai Li","Yilei Liang","Xin Yuan","Wei Ni","Jon Crowcroft","Chau Yuen","Ozgur B. Akan"],"pdf_url":"https://arxiv.org/pdf/2410.01644v1.pdf","comment":"5 pages, 3 figures"},{"id":"http://arxiv.org/abs/2410.01626v1","updated":"2024-10-02T15:01:05Z","published":"2024-10-02T15:01:05Z","title":"Constant pH Simulation with FMM Electrostatics in GROMACS. (A) Design\n  and Applications","summary":"  The structural dynamics of biological macromolecules, such as proteins,\nDNA/RNA, or complexes thereof, are strongly influenced by protonation changes\nof their typically many titratable groups, which explains their sensitivity to\npH changes. Conversely, conformational and environmental changes of the\nbiomolecule affect the protonation state of these groups. With few exceptions,\nconventional force field-based molecular dynamics (MD) simulations do not\naccount for these effects, nor do they allow for coupling to a pH buffer.\n  Here we present a GROMACS implementation of a rigorous Hamiltonian\ninterpolation $\\lambda$-dynamics constant pH method, which rests on\nGPU-accelerated Fast Multipole Method (FMM) electrostatics. Our implementation\nsupports both CHARMM36m and Amber99sb*-ILDN force fields and is largely\nautomated to enable seamless switching from regular MD to constant pH MD,\ninvolving minimal changes to the input files. Here, the first of two companion\npapers describes the underlying constant pH protocol and sample applications to\nseveral prototypical benchmark systems such as cardiotoxin V, lysozyme, and\nstaphylococcal nuclease. Enhanced convergence is achieved through a new dynamic\nbarrier height optimization method, and high p$K_a$ accuracy is demonstrated.\nWe use Functional Mode Analysis and Mutual Information to explore the complex\nintra- and intermolecular couplings between the protonation states of\ntitratable groups as well as those between protonation states and\nconformational dynamics. We identify striking conformation-dependent p$K_a$\nvariations and unexpected inter-residue couplings. Conformation-protonation\ncoupling is identified as a primary cause of the slow protonation convergence\nnotorious to constant pH simulations involving multiple titratable groups,\nsuggesting enhanced sampling methods to accelerate convergence.\n","authors":["Eliane Briand","Bartosz Kohnke","Carsten Kutzner","Helmut Grubmüller"],"pdf_url":"https://arxiv.org/pdf/2410.01626v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.01514v1","updated":"2024-10-02T13:04:01Z","published":"2024-10-02T13:04:01Z","title":"Multi-level Memory-Centric Profiling on ARM Processors with ARM SPE","summary":"  High-end ARM processors are emerging in data centers and HPC systems, posing\nas a strong contender to x86 machines. Memory-centric profiling is an important\napproach for dissecting an application's bottlenecks on memory access and\nguiding optimizations. Many existing memory profiling tools leverage hardware\nperformance counters and precise event sampling, such as Intel PEBS and AMD\nIBS, to achieve high accuracy and low overhead. In this work, we present a\nmulti-level memory profiling tool for ARM processors, leveraging Statistical\nProfiling Extension (SPE). We evaluate the tool using both HPC and Cloud\nworkloads on the ARM Ampere processor. Our results provide the first\nquantitative assessment of time overhead and sampling accuracy of ARM SPE for\nmemory-centric profiling at different sampling periods and aux buffer sizes.\n","authors":["Samuel Miksits","Ruimin Shi","Maya Gokhale","Jacob Wahlgren","Gabin Schieffer","Ivy Peng"],"pdf_url":"https://arxiv.org/pdf/2410.01514v1.pdf","comment":"To be published in Workshop Proceedings of The International\n  Conference for High Performance Computing Networking, Storage, and Analysis\n  (SC-W '24) (2024)"},{"id":"http://arxiv.org/abs/2409.19302v2","updated":"2024-10-02T13:03:51Z","published":"2024-09-28T10:09:37Z","title":"Leveraging MTD to Mitigate Poisoning Attacks in Decentralized FL with\n  Non-IID Data","summary":"  Decentralized Federated Learning (DFL), a paradigm for managing big data in a\nprivacy-preserved manner, is still vulnerable to poisoning attacks where\nmalicious clients tamper with data or models. Current defense methods often\nassume Independently and Identically Distributed (IID) data, which is\nunrealistic in real-world applications. In non-IID contexts, existing defensive\nstrategies face challenges in distinguishing between models that have been\ncompromised and those that have been trained on heterogeneous data\ndistributions, leading to diminished efficacy. In response, this paper proposes\na framework that employs the Moving Target Defense (MTD) approach to bolster\nthe robustness of DFL models. By continuously modifying the attack surface of\nthe DFL system, this framework aims to mitigate poisoning attacks effectively.\nThe proposed MTD framework includes both proactive and reactive modes,\nutilizing a reputation system that combines metrics of model similarity and\nloss, alongside various defensive techniques. Comprehensive experimental\nevaluations indicate that the MTD-based mechanism significantly mitigates a\nrange of poisoning attack types across multiple datasets with different\ntopologies.\n","authors":["Chao Feng","Alberto Huertas Celdrán","Zien Zeng","Zi Ye","Jan von der Assen","Gerome Bovet","Burkhard Stiller"],"pdf_url":"https://arxiv.org/pdf/2409.19302v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.01502v1","updated":"2024-10-02T12:53:25Z","published":"2024-10-02T12:53:25Z","title":"Personalized Federated Learning on Flowing Data Heterogeneity under\n  Restricted Storage","summary":"  Recent years, researchers focused on personalized federated learning (pFL) to\naddress the inconsistent requirements of clients causing by data heterogeneity\nin federated learning (FL). However, existing pFL methods typically assume that\nlocal data distribution remains unchanged during FL training, the changing data\ndistribution in actual heterogeneous data scenarios can affect model\nconvergence rate and reduce model performance. In this paper, we focus on\nsolving the pFL problem under the situation where data flows through each\nclient like a flowing stream which called Flowing Data Heterogeneity under\nRestricted Storage, and shift the training goal to the comprehensive\nperformance of the model throughout the FL training process. Therefore, based\non the idea of category decoupling, we design a local data distribution\nreconstruction scheme and a related generator architecture to reduce the error\nof the controllable replayed data distribution, then propose our pFL framework,\npFedGRP, to achieve knowledge transfer and personalized aggregation.\nComprehensive experiments on five datasets with multiple settings show the\nsuperiority of pFedGRP over eight baseline methods.\n","authors":["Sixing Tan","Xianmin Liu"],"pdf_url":"https://arxiv.org/pdf/2410.01502v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.01368v1","updated":"2024-10-02T09:30:01Z","published":"2024-10-02T09:30:01Z","title":"Theoretical Lower Bounds for the Oven Scheduling Problem","summary":"  The Oven Scheduling Problem (OSP) is an NP-hard real-world parallel batch\nscheduling problem arising in the semiconductor industry. The objective of the\nproblem is to schedule a set of jobs on ovens while minimizing several factors,\nnamely total oven runtime, job tardiness, and setup costs. At the same time, it\nmust adhere to various constraints such as oven eligibility and availability,\njob release dates, setup times between batches, and oven capacity limitations.\nThe key to obtaining efficient schedules is to process compatible jobs\nsimultaneously in batches. In this paper, we develop theoretical,\nproblem-specific lower bounds for the OSP that can be computed very quickly. We\nthoroughly examine these lower bounds, evaluating their quality and exploring\ntheir integration into existing solution methods. Specifically, we investigate\ntheir contribution to exact methods and a metaheuristic local search approach\nusing simulated annealing. Moreover, these problem-specific lower bounds enable\nus to assess the solution quality for large instances for which exact methods\noften fail to provide tight lower bounds.\n","authors":["Francesca Da Ros","Marie-Louise Lackner","Nysret Musliu"],"pdf_url":"https://arxiv.org/pdf/2410.01368v1.pdf","comment":"arXiv admin note: text overlap with arXiv:2203.12517"},{"id":"http://arxiv.org/abs/2409.20135v3","updated":"2024-10-02T08:32:02Z","published":"2024-09-30T09:34:31Z","title":"Federated Instruction Tuning of LLMs with Domain Coverage Augmentation","summary":"  Federated Domain-specific Instruction Tuning (FedDIT) utilizes limited\ncross-client private data together with server-side public data for instruction\naugmentation, ultimately boosting model performance within specific domains. To\ndate, the factors affecting FedDIT remain unclear, and existing instruction\naugmentation methods primarily focus on the centralized setting without\nconsidering distributed environments. Our experiments reveal that the\ncross-client domain coverage, rather than data heterogeneity, drives model\nperformance in FedDIT. In response, we propose FedDCA, which optimizes domain\ncoverage through greedy client center selection and retrieval-based\naugmentation. For client-side computational efficiency and system scalability,\nFedDCA$^*$, the variant of FedDCA, utilizes heterogeneous encoders with\nserver-side feature alignment. Extensive experiments across four distinct\ndomains (code, medical, financial, and mathematical) substantiate the\neffectiveness of both methods. Additionally, we investigate privacy\npreservation against memory extraction attacks utilizing various amounts of\npublic data. Results show that there is no significant correlation between the\nvolume of public data and the privacy-preserving capability. However, as the\nfine-tuning rounds increase, the risk of privacy leakage reduces or converges.\n","authors":["Zezhou Wang","Yaxin Du","Zhuzhong Qian","Siheng Chen"],"pdf_url":"https://arxiv.org/pdf/2409.20135v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.03756v1","updated":"2024-10-02T06:30:07Z","published":"2024-10-02T06:30:07Z","title":"Real-World Data and Calibrated Simulation Suite for Offline Training of\n  Reinforcement Learning Agents to Optimize Energy and Emission in Buildings\n  for Environmental Sustainability","summary":"  Commercial office buildings contribute 17 percent of Carbon Emissions in the\nUS, according to the US Energy Information Administration (EIA), and improving\ntheir efficiency will reduce their environmental burden and operating cost. A\nmajor contributor of energy consumption in these buildings are the Heating,\nVentilation, and Air Conditioning (HVAC) devices. HVAC devices form a complex\nand interconnected thermodynamic system with the building and outside weather\nconditions, and current setpoint control policies are not fully optimized for\nminimizing energy use and carbon emission. Given a suitable training\nenvironment, a Reinforcement Learning (RL) agent is able to improve upon these\npolicies, but training such a model, especially in a way that scales to\nthousands of buildings, presents many practical challenges. Most existing work\non applying RL to this important task either makes use of proprietary data, or\nfocuses on expensive and proprietary simulations that may not be grounded in\nthe real world. We present the Smart Buildings Control Suite, the first open\nsource interactive HVAC control dataset extracted from live sensor measurements\nof devices in real office buildings. The dataset consists of two components:\nsix years of real-world historical data from three buildings, for offline RL,\nand a lightweight interactive simulator for each of these buildings, calibrated\nusing the historical data, for online and model-based RL. For ease of use, our\nRL environments are all compatible with the OpenAI gym environment standard. We\nalso demonstrate a novel method of calibrating the simulator, as well as\nbaseline results on training an RL agent on the simulator, predicting\nreal-world data, and training an RL agent directly from data. We believe this\nbenchmark will accelerate progress and collaboration on building optimization\nand environmental sustainability research.\n","authors":["Judah Goldfeder","John Sipple"],"pdf_url":"https://arxiv.org/pdf/2410.03756v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.01256v1","updated":"2024-10-02T06:03:30Z","published":"2024-10-02T06:03:30Z","title":"ParallelSFL: A Novel Split Federated Learning Framework Tackling\n  Heterogeneity Issues","summary":"  Mobile devices contribute more than half of the world's web traffic,\nproviding massive and diverse data for powering various federated learning (FL)\napplications. In order to avoid the communication bottleneck on the parameter\nserver (PS) and accelerate the training of large-scale models on\nresourceconstraint workers in edge computing (EC) system, we propose a novel\nsplit federated learning (SFL) framework, termed ParallelSFL. Concretely, we\nsplit an entire model into a bottom submodel and a top submodel, and divide\nparticipating workers into multiple clusters, each of which collaboratively\nperforms the SFL training procedure and exchanges entire models with the PS.\nHowever, considering the statistical and system heterogeneity in edge systems,\nit is challenging to arrange suitable workers to specific clusters for\nefficient model training. To address these challenges, we carefully develop an\neffective clustering strategy by optimizing a utility function related to\ntraining efficiency and model accuracy. Specifically, ParallelSFL partitions\nworkers into different clusters under the heterogeneity restrictions, thereby\npromoting model accuracy as well as training efficiency. Meanwhile, ParallelSFL\nassigns diverse and appropriate local updating frequencies for each cluster to\nfurther address system heterogeneity. Extensive experiments are conducted on a\nphysical platform with 80 NVIDIA Jetson devices, and the experimental results\nshow that ParallelSFL can reduce the traffic consumption by at least 21%, speed\nup the model training by at least 1.36x, and improve model accuracy by at least\n5% in heterogeneous scenarios, compared to the baselines.\n","authors":["Yunming Liao","Yang Xu","Hongli Xu","Zhiwei Yao","Liusheng Huang","Chunming Qiao"],"pdf_url":"https://arxiv.org/pdf/2410.01256v1.pdf","comment":"arXiv admin note: text overlap with arXiv:2311.13348"},{"id":"http://arxiv.org/abs/2410.01228v1","updated":"2024-10-02T04:12:13Z","published":"2024-10-02T04:12:13Z","title":"ConServe: Harvesting GPUs for Low-Latency and High-Throughput Large\n  Language Model Serving","summary":"  Many applications are leveraging large language models (LLMs) for complex\ntasks, and they generally demand low inference latency and high serving\nthroughput for interactive online jobs such as chatbots. However, the tight\nlatency requirement and high load variance of applications pose challenges to\nserving systems in achieving high GPU utilization. Due to the high costs of\nscheduling and preemption, today's systems generally use separate clusters to\nserve online and offline inference tasks, and dedicate GPUs for online\ninferences to avoid interference. This approach leads to underutilized GPUs\nbecause one must reserve enough GPU resources for the peak expected load, even\nif the average load is low.\n  This paper proposes to harvest stranded GPU resources for offline LLM\ninference tasks such as document summarization and LLM benchmarking. Unlike\nonline inferences, these tasks usually run in a batch-processing manner with\nloose latency requirements, making them a good fit for stranded resources that\nare only available shortly. To enable safe and efficient GPU harvesting without\ninterfering with online tasks, we built ConServe, an LLM serving system that\ncontains (1) an execution engine that preempts running offline tasks upon the\narrival of online tasks, (2) an incremental checkpointing mechanism that\nminimizes the amount of recomputation required by preemptions, and (3) a\nscheduler that adaptively batches offline tasks for higher GPU utilization. Our\nevaluation demonstrates that ConServe achieves strong performance isolation\nwhen co-serving online and offline tasks but at a much higher GPU utilization.\nWhen colocating practical online and offline workloads on popular models such\nas Llama-2-7B, ConServe achieves 2.35$\\times$ higher throughput than\nstate-of-the-art online serving systems and reduces serving latency by\n84$\\times$ compared to existing co-serving systems.\n","authors":["Yifan Qiao","Shu Anzai","Shan Yu","Haoran Ma","Yang Wang","Miryung Kim","Harry Xu"],"pdf_url":"https://arxiv.org/pdf/2410.01228v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.01222v1","updated":"2024-10-02T04:01:55Z","published":"2024-10-02T04:01:55Z","title":"Exploring Fine-grained Task Parallelism on Simultaneous Multithreading\n  Cores","summary":"  Nowadays, latency-critical, high-performance applications are parallelized\neven on power-constrained client systems to improve performance. However, an\nimportant scenario of fine-grained tasking on simultaneous multithreading CPU\ncores in such systems has not been well researched in previous works. Hence, in\nthis paper, we conduct performance analysis of state-of-the-art shared-memory\nparallel programming frameworks on simultaneous multithreading cores using\nreal-world fine-grained application kernels. We introduce a specialized and\nsimple software-only parallel programming framework called Relic to enable\nextremely fine-grained tasking on simultaneous multithreading cores. Using\nRelic framework, we increase performance speedups over serial implementations\nof benchmark kernels by 19.1% compared to LLVM OpenMP, by 31.0% compared to GNU\nOpenMP, by 20.2% compared to Intel OpenMP, by 33.2% compared to X-OpenMP, by\n30.1% compared to oneTBB, by 23.0% compared to Taskflow, and by 21.4% compared\nto OpenCilk.\n","authors":["Denis Los","Igor Petushkov"],"pdf_url":"https://arxiv.org/pdf/2410.01222v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.19256v2","updated":"2024-10-02T04:01:47Z","published":"2024-09-28T06:20:03Z","title":"HybridFlow: A Flexible and Efficient RLHF Framework","summary":"  Reinforcement Learning from Human Feedback (RLHF) is widely used in Large\nLanguage Model (LLM) alignment. Traditional RL can be modeled as a dataflow,\nwhere each node represents computation of a neural network (NN) and each edge\ndenotes data dependencies between the NNs. RLHF complicates the dataflow by\nexpanding each node into a distributed LLM training or generation program, and\neach edge into a many-to-many multicast. Traditional RL frameworks execute the\ndataflow using a single controller to instruct both intra-node computation and\ninter-node communication, which can be inefficient in RLHF due to large control\ndispatch overhead for distributed intra-node computation. Existing RLHF systems\nadopt a multi-controller paradigm, which can be inflexible due to nesting\ndistributed computation and data communication. We propose HybridFlow, which\ncombines single-controller and multi-controller paradigms in a hybrid manner to\nenable flexible representation and efficient execution of the RLHF dataflow. We\ncarefully design a set of hierarchical APIs that decouple and encapsulate\ncomputation and data dependencies in the complex RLHF dataflow, allowing\nefficient operation orchestration to implement RLHF algorithms and flexible\nmapping of the computation onto various devices. We further design a\n3D-HybridEngine for efficient actor model resharding between training and\ngeneration phases, with zero memory redundancy and significantly reduced\ncommunication overhead. Our experimental results demonstrate\n1.53$\\times$~20.57$\\times$ throughput improvement when running various RLHF\nalgorithms using HybridFlow, as compared with state-of-the-art baselines.\nHybridFlow source code will be available at https://github.com/volcengine/verl.\n","authors":["Guangming Sheng","Chi Zhang","Zilingfeng Ye","Xibin Wu","Wang Zhang","Ru Zhang","Yanghua Peng","Haibin Lin","Chuan Wu"],"pdf_url":"https://arxiv.org/pdf/2409.19256v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.01209v1","updated":"2024-10-02T03:30:53Z","published":"2024-10-02T03:30:53Z","title":"Debiasing Federated Learning with Correlated Client Participation","summary":"  In cross-device federated learning (FL) with millions of mobile clients, only\na small subset of clients participate in training in every communication round,\nand Federated Averaging (FedAvg) is the most popular algorithm in practice.\nExisting analyses of FedAvg usually assume the participating clients are\nindependently sampled in each round from a uniform distribution, which does not\nreflect real-world scenarios. This paper introduces a theoretical framework\nthat models client participation in FL as a Markov chain to study optimization\nconvergence when clients have non-uniform and correlated participation across\nrounds. We apply this framework to analyze a more general and practical\npattern: every client must wait a minimum number of $R$ rounds (minimum\nseparation) before re-participating. We theoretically prove and empirically\nobserve that increasing minimum separation reduces the bias induced by\nintrinsic non-uniformity of client availability in cross-device FL systems.\nFurthermore, we develop an effective debiasing algorithm for FedAvg that\nprovably converges to the unbiased optimal solution under arbitrary minimum\nseparation and unknown client availability distribution.\n","authors":["Zhenyu Sun","Ziyang Zhang","Zheng Xu","Gauri Joshi","Pranay Sharma","Ermin Wei"],"pdf_url":"https://arxiv.org/pdf/2410.01209v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.08491v2","updated":"2024-10-02T01:27:54Z","published":"2024-03-20T13:36:59Z","title":"FPGA-based Distributed Union-Find Decoder for Surface Codes","summary":"  A fault-tolerant quantum computer must decode and correct errors faster than\nthey appear to prevent exponential slowdown due to error correction. The\nUnion-Find (UF) decoder is promising with an average time complexity slightly\nhigher than $O(d^3)$. We report a distributed version of the UF decoder that\nexploits parallel computing resources for further speedup. Using an FPGA-based\nimplementation, we empirically show that this distributed UF decoder has a\nsublinear average time complexity with regard to $d$, given $O(d^3)$ parallel\ncomputing resources. The decoding time per measurement round decreases as $d$\nincreases, the first time for a quantum error decoder. The implementation\nemploys a scalable architecture called Helios that organizes parallel computing\nresources into a hybrid tree-grid structure. Using a Xilinx VCU129 FPGA, we\nsuccessfully implement $d$ up to 21 with an average decoding time of 11.5 ns\nper measurement round under 0.1\\% phenomenological noise, and 23.7 ns for\n$d=17$ under equivalent circuit-level noise. This performance is significantly\nfaster than any existing decoder implementation. Furthermore, we show that\nHelios can optimize for resource efficiency by decoding $d=51$ on a Xilinx\nVCU129 FPGA with an average latency of 544ns per measurement round.\n","authors":["Namitha Liyanage","Yue Wu","Siona Tagare","Lin Zhong"],"pdf_url":"https://arxiv.org/pdf/2406.08491v2.pdf","comment":"The article extends the work in arXiv:2301.08419, which also appeared\n  in https://ieeexplore.ieee.org/document/10313800"},{"id":"http://arxiv.org/abs/2410.01857v1","updated":"2024-10-02T01:12:16Z","published":"2024-10-02T01:12:16Z","title":"Learning the Optimal Path and DNN Partition for Collaborative Edge\n  Inference","summary":"  Recent advancements in Deep Neural Networks (DNNs) have catalyzed the\ndevelopment of numerous intelligent mobile applications and services. However,\nthey also introduce significant computational challenges for\nresource-constrained mobile devices. To address this, collaborative edge\ninference has been proposed. This method involves partitioning a DNN inference\ntask into several subtasks and distributing these across multiple network\nnodes. Despite its potential, most current approaches presume known network\nparameters -- like node processing speeds and link transmission rates -- or\nrely on a fixed sequence of nodes for processing the DNN subtasks. In this\npaper, we tackle a more complex scenario where network parameters are unknown\nand must be learned, and multiple network paths are available for distributing\ninference tasks. Specifically, we explore the learning problem of selecting the\noptimal network path and assigning DNN layers to nodes along this path,\nconsidering potential security threats and the costs of switching paths. We\nbegin by deriving structural insights from the DNN layer assignment with\ncomplete network information, which narrows down the decision space and\nprovides crucial understanding of optimal assignments. We then cast the\nlearning problem with incomplete network information as a novel adversarial\ngroup linear bandits problem with switching costs, featuring rewards generation\nthrough a combined stochastic and adversarial process. We introduce a new\nbandit algorithm, B-EXPUCB, which combines elements of the classical blocked\nEXP3 and LinUCB algorithms, and demonstrate its sublinear regret. Extensive\nsimulations confirm B-EXPUCB's superior performance in learning for\ncollaborative edge inference over existing algorithms.\n","authors":["Yin Huang","Letian Zhang","Jie Xu"],"pdf_url":"https://arxiv.org/pdf/2410.01857v1.pdf","comment":"15 pages, 15 figures, submitted to IEEE journals for possible\n  publication"}]},"2024-10-01T00:00:00Z":{"Software Engineering":[{"id":"http://arxiv.org/abs/2407.20623v3","updated":"2024-10-01T22:29:49Z","published":"2024-07-30T07:59:28Z","title":"SharkTrack: an accurate, generalisable software for streamlining shark\n  and ray underwater video analysis","summary":"  Elasmobranchs (shark sand rays) represent a critical component of marine\necosystems. Yet, they are experiencing global population declines and effective\nmonitoring of populations is essential to their protection. Underwater\nstationary videos, such as those from Baited Remote Underwater Video Stations\n(BRUVS), are critical for understanding elasmobranch spatial ecology and\nabundance. However, processing these videos requires time-consuming manual\nanalysis that can delay conservation. To address this challenge, we developed\nSharkTrack, a semi-automatic underwater video analysis software. SharkTrack\nuses Convolutional Neural Networks (CNN) and Multi-Object Tracking to\nautomatically detect and track elasmobranchs and provides an annotation\npipeline to manually classify elasmobranch species and compute species-specific\nMaxN (ssMaxN), the standard metric of relative abundance. When tested on BRUVS\nfootage from locations unseen by the CNN model during training, SharkTrack\ncomputed ssMaxN with 89% accuracy over 207 hours of footage. The semi-automatic\nSharkTrack pipeline required two minutes of manual classification per hour of\nvideo, an estimated 95% reduction of manual analysis time compared to\ntraditional methods. Furthermore, we demonstrate SharkTrack accuracy across\ndiverse marine ecosystems and elasmobranch species, an advancement compared to\nprevious models, which were limited to specific species or locations.\nSharkTrack applications extend beyond BRUVS, facilitating the analysis of any\nunderwater stationary video. By making video analysis faster and more\naccessible, SharkTrack enables research and conservation organisations to\nmonitor elasmobranch populations more efficiently, thereby improving\nconservation efforts. To further support these goals, we provide public access\nto the SharkTrack software.\n","authors":["Filippo Varini","Joel H. Gayford","Jeremy Jenrette","Matthew J. Witt","Francesco Garzon","Francesco Ferretti","Sophie Wilday","Mark E. Bond","Michael R. Heithaus","Danielle Robinson","Devon Carter","Najee Gumbs","Vincent Webster","Ben Glocker"],"pdf_url":"https://arxiv.org/pdf/2407.20623v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.01026v1","updated":"2024-10-01T19:34:46Z","published":"2024-10-01T19:34:46Z","title":"Understanding the Human-LLM Dynamic: A Literature Survey of LLM Use in\n  Programming Tasks","summary":"  Large Language Models (LLMs) are transforming programming practices, offering\nsignificant capabilities for code generation activities. While researchers have\nexplored the potential of LLMs in various domains, this paper focuses on their\nuse in programming tasks, drawing insights from user studies that assess the\nimpact of LLMs on programming tasks. We first examined the user interaction\nbehaviors with LLMs observed in these studies, from the types of requests made\nto task completion strategies. Additionally, our analysis reveals both benefits\nand weaknesses of LLMs showing mixed effects on the human and task. Lastly, we\nlooked into what factors from the human, LLM or the interaction of both, affect\nthe human's enhancement as well as the task performance. Our findings highlight\nthe variability in human-LLM interactions due to the non-deterministic nature\nof both parties (humans and LLMs), underscoring the need for a deeper\nunderstanding of these interaction patterns. We conclude by providing some\npractical suggestions for researchers as well as programmers.\n","authors":["Deborah Etsenake","Meiyappan Nagappan"],"pdf_url":"https://arxiv.org/pdf/2410.01026v1.pdf","comment":"16 pages, 8 tables, 2 figures"},{"id":"http://arxiv.org/abs/2408.11699v5","updated":"2024-10-01T17:39:49Z","published":"2024-08-21T15:22:43Z","title":"Automating Semantic Analysis of System Assurance Cases using\n  Goal-directed ASP","summary":"  Assurance cases offer a structured way to present arguments and evidence for\ncertification of systems where safety and security are critical. However,\ncreating and evaluating these assurance cases can be complex and challenging,\neven for systems of moderate complexity. Therefore, there is a growing need to\ndevelop new automation methods for these tasks. While most existing assurance\ncase tools focus on automating structural aspects, they lack the ability to\nfully assess the semantic coherence and correctness of the assurance arguments.\n  In prior work, we introduced the Assurance 2.0 framework that prioritizes the\nreasoning process, evidence utilization, and explicit delineation of\ncounter-claims (defeaters) and counter-evidence. In this paper, we present our\napproach to enhancing Assurance 2.0 with semantic rule-based analysis\ncapabilities using common-sense reasoning and answer set programming solvers,\nspecifically s(CASP). By employing these analysis techniques, we examine the\nunique semantic aspects of assurance cases, such as logical consistency,\nadequacy, indefeasibility, etc. The application of these analyses provides both\nsystem developers and evaluators with increased confidence about the assurance\ncase.\n","authors":["Anitha Murugesan","Isaac Wong","Joaquín Arias","Robert Stroud","Srivatsan Varadarajan","Elmer Salazar","Gopal Gupta","Robin Bloomfield","John Rushby"],"pdf_url":"https://arxiv.org/pdf/2408.11699v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.00880v1","updated":"2024-10-01T17:14:54Z","published":"2024-10-01T17:14:54Z","title":"GEMS: Generative Expert Metric System through Iterative Prompt Priming","summary":"  Across domains, metrics and measurements are fundamental to identifying\nchallenges, informing decisions, and resolving conflicts. Despite the abundance\nof data available in this information age, not only can it be challenging for a\nsingle expert to work across multi-disciplinary data, but non-experts can also\nfind it unintuitive to create effective measures or transform theories into\ncontext-specific metrics that are chosen appropriately. This technical report\naddresses this challenge by examining software communities within large\nsoftware corporations, where different measures are used as proxies to locate\ncounterparts within the organization to transfer tacit knowledge. We propose a\nprompt-engineering framework inspired by neural activities, demonstrating that\ngenerative models can extract and summarize theories and perform basic\nreasoning, thereby transforming concepts into context-aware metrics to support\nsoftware communities given software repository data. While this research zoomed\nin on software communities, we believe the framework's applicability extends\nacross various fields, showcasing expert-theory-inspired metrics that aid in\ntriaging complex challenges.\n","authors":["Ti-Chung Cheng","Carmen Badea","Christian Bird","Thomas Zimmermann","Robert DeLine","Nicole Forsgren","Denae Ford"],"pdf_url":"https://arxiv.org/pdf/2410.00880v1.pdf","comment":"29 pages, 3 figures"},{"id":"http://arxiv.org/abs/2410.00752v1","updated":"2024-10-01T14:47:05Z","published":"2024-10-01T14:47:05Z","title":"TestGenEval: A Real World Unit Test Generation and Test Completion\n  Benchmark","summary":"  Code generation models can help improve many common software tasks ranging\nfrom code completion to defect prediction. Most of the existing benchmarks for\ncode generation LLMs focus on code authoring or code completion. Surprisingly,\nthere has been far less effort dedicated to benchmarking software testing,\ndespite the strong correlation between well-tested software and effective bug\ndetection. To address this gap, we create and release TestGenEval, a\nlarge-scale benchmark to measure test generation performance. Based on\nSWEBench, TestGenEval comprises 68,647 tests from 1,210 code and test file\npairs across 11 well-maintained Python repositories. It covers initial tests\nauthoring, test suite completion, and code coverage improvements. Test\nauthoring simulates the process of a developer writing a test suite from\nscratch, while test completion mimics the scenario where a developer aims to\nimprove the coverage of an existing test suite. We evaluate several popular\nmodels, with sizes ranging from 7B to 405B parameters. Our detailed analysis\nhighlights TestGenEval's contribution to a comprehensive evaluation of test\ngeneration performance. In particular, models struggle to generate\nhigh-coverage test suites, with the best model, GPT-4o, achieving an average\ncoverage of only 35.2%. This is primarily due to models struggling to reason\nabout execution, and their frequent assertion errors when addressing complex\ncode paths.\n","authors":["Kush Jain","Gabriel Synnaeve","Baptiste Rozière"],"pdf_url":"https://arxiv.org/pdf/2410.00752v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.00689v1","updated":"2024-10-01T13:43:55Z","published":"2024-10-01T13:43:55Z","title":"Multimodal Auto Validation For Self-Refinement in Web Agents","summary":"  As our world digitizes, web agents that can automate complex and monotonous\ntasks are becoming essential in streamlining workflows. This paper introduces\nan approach to improving web agent performance through multi-modal validation\nand self-refinement. We present a comprehensive study of different modalities\n(text, vision) and the effect of hierarchy for the automatic validation of web\nagents, building upon the state-of-the-art Agent-E web automation framework. We\nalso introduce a self-refinement mechanism for web automation, using the\ndeveloped auto-validator, that enables web agents to detect and self-correct\nworkflow failures. Our results show significant gains on Agent-E's (a SOTA web\nagent) prior state-of-art performance, boosting task-completion rates from\n76.2\\% to 81.24\\% on the subset of the WebVoyager benchmark. The approach\npresented in this paper paves the way for more reliable digital assistants in\ncomplex, real-world scenarios.\n","authors":["Ruhana Azam","Tamer Abuelsaad","Aditya Vempaty","Ashish Jagmohan"],"pdf_url":"https://arxiv.org/pdf/2410.00689v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.00650v1","updated":"2024-10-01T13:05:54Z","published":"2024-10-01T13:05:54Z","title":"A Survey on Testing and Analysis of Quantum Software","summary":"  Quantum computing is getting increasing interest from both academia and\nindustry, and the quantum software landscape has been growing rapidly. The\nquantum software stack comprises quantum programs, implementing algorithms, and\nplatforms like IBM Qiskit, Google Cirq, and Microsoft Q#, enabling their\ndevelopment. To ensure the reliability and performance of quantum software,\nvarious techniques for testing and analyzing it have been proposed, such as\ntest generation, bug pattern detection, and circuit optimization. However, the\nlarge amount of work and the fact that work on quantum software is performed by\nseveral research communities, make it difficult to get a comprehensive overview\nof the existing techniques. In this work, we provide an extensive survey of the\nstate of the art in testing and analysis of quantum software. We discuss\nliterature from several research communities, including quantum computing,\nsoftware engineering, programming languages, and formal methods. Our survey\ncovers a wide range of topics, including expected and unexpected behavior of\nquantum programs, testing techniques, program analysis approaches,\noptimizations, and benchmarks for testing and analyzing quantum software. We\ncreate novel connections between the discussed topics and present them in an\naccessible way. Finally, we discuss key challenges and open problems to inspire\nfuture research.\n","authors":["Matteo Paltenghi","Michael Pradel"],"pdf_url":"https://arxiv.org/pdf/2410.00650v1.pdf","comment":"36 pages, 12 figures, 7 tables"},{"id":"http://arxiv.org/abs/2410.00603v1","updated":"2024-10-01T11:44:29Z","published":"2024-10-01T11:44:29Z","title":"An Empirical Study of Large Language Models for Type and Call Graph\n  Analysis","summary":"  Large Language Models (LLMs) are increasingly being explored for their\npotential in software engineering, particularly in static analysis tasks. In\nthis study, we investigate the potential of current LLMs to enhance call-graph\nanalysis and type inference for Python and JavaScript programs. We empirically\nevaluated 24 LLMs, including OpenAI's GPT series and open-source models like\nLLaMA and Mistral, using existing and newly developed benchmarks. Specifically,\nwe enhanced TypeEvalPy, a micro-benchmarking framework for type inference in\nPython, with auto-generation capabilities, expanding its scope from 860 to\n77,268 type annotations for Python. Additionally, we introduced SWARM-CG and\nSWARM-JS, comprehensive benchmarking suites for evaluating call-graph\nconstruction tools across multiple programming languages. Our findings reveal a\ncontrasting performance of LLMs in static analysis tasks. For call-graph\ngeneration in Python, traditional static analysis tools like PyCG significantly\noutperform LLMs. In JavaScript, the static tool TAJS underperforms due to its\ninability to handle modern language features, while LLMs, despite showing\npotential with models like mistral-large-it-2407-123b and GPT-4o, struggle with\ncompleteness and soundness in both languages for call-graph analysis.\nConversely, LLMs demonstrate a clear advantage in type inference for Python,\nsurpassing traditional tools like HeaderGen and hybrid approaches such as\nHiTyper. These results suggest that while LLMs hold promise in type inference,\ntheir limitations in call-graph analysis highlight the need for further\nresearch. Our study provides a foundation for integrating LLMs into static\nanalysis workflows, offering insights into their strengths and current\nlimitations.\n","authors":["Ashwin Prasad Shivarpatna Venkatesh","Rose Sunil","Samkutty Sabu","Amir M. Mir","Sofia Reis","Eric Bodden"],"pdf_url":"https://arxiv.org/pdf/2410.00603v1.pdf","comment":"Pre-print: Submitted to EMSE journal for review"},{"id":"http://arxiv.org/abs/2410.00578v1","updated":"2024-10-01T10:49:41Z","published":"2024-10-01T10:49:41Z","title":"Towards an Argument Pattern for the Use of Safety Performance Indicators","summary":"  UL 4600, the safety standard for autonomous products, mandates the use of\nSafety Performance Indicators (SPIs) to continuously ensure the validity of\nsafety cases by monitoring and taking action when violations are identified.\nDespite numerous examples of concrete SPIs available in the standard and\ncompanion literature, their contribution rationale for achieving safety is\noften left implicit. In this paper, we present our initial work towards an\nargument pattern for the use of SPIs to ensure validity of safety cases\nthroughout the entire lifecycle of the system. Our aim is to make the implicit\nargument behind using SPIs explicit, and based on this, to analyze the\nsituations that can undermine confidence in the chosen set of SPIs. To maintain\nthe confidence in SPIs' effectiveness, we propose an approach to continuously\nmonitor their expected performance by using meta-SPIs.\n","authors":["Daniel Ratiu","Tihomir Rohlinger","Torben Stolte","Stefan Wagner"],"pdf_url":"https://arxiv.org/pdf/2410.00578v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.00558v1","updated":"2024-10-01T10:12:38Z","published":"2024-10-01T10:12:38Z","title":"AMR-Evol: Adaptive Modular Response Evolution Elicits Better Knowledge\n  Distillation for Large Language Models in Code Generation","summary":"  The impressive performance of proprietary LLMs like GPT4 in code generation\nhas led to a trend to replicate these capabilities in open-source models\nthrough knowledge distillation (e.g. Code Evol-Instruct). However, these\nefforts often neglect the crucial aspect of response quality, relying heavily\non teacher models for direct response distillation. This paradigm, especially\nfor complex instructions, can degrade the quality of synthesized data,\ncompromising the knowledge distillation process. To this end, our study\nintroduces the Adaptive Modular Response Evolution (AMR-Evol) framework, which\nemploys a two-stage process to refine response distillation. The first stage,\nmodular decomposition, breaks down the direct response into more manageable\nsub-modules. The second stage, adaptive response evolution, automatically\nevolves the response with the related function modules. Our experiments with\nthree popular code benchmarks (HumanEval, MBPP, and EvalPlus) attest to the\nsuperiority of the AMR-Evol framework over baseline response distillation\nmethods. By comparing with the open-source Code LLMs trained on a similar scale\nof data, we observed performance enhancements: more than +3.0 points on\nHumanEval-Plus and +1.0 points on MBPP-Plus, which underscores the\neffectiveness of our framework. Our codes are available at\nhttps://github.com/ChiYeungLaw/AMR-Evol.\n","authors":["Ziyang Luo","Xin Li","Hongzhan Lin","Jing Ma","Lidong Bing"],"pdf_url":"https://arxiv.org/pdf/2410.00558v1.pdf","comment":"EMNLP 2024"},{"id":"http://arxiv.org/abs/2410.00465v1","updated":"2024-10-01T07:46:59Z","published":"2024-10-01T07:46:59Z","title":"Distributed Monitoring of Timed Properties","summary":"  In formal verification, runtime monitoring consists of observing the\nexecution of a system in order to decide as quickly as possible whether or not\nit satisfies a given property. We consider monitoring in a distributed setting,\nfor properties given as reachability timed automata. In such a setting, the\nsystem is made of several components, each equipped with its own local clock\nand monitor. The monitors observe events occurring on their associated\ncomponent, and receive timestamped events from other monitors through FIFO\nchannels. Since clocks are local, they cannot be perfectly synchronized,\nresulting in imprecise timestamps. Consequently, they must be seen as\nintervals, leading monitors to consider possible reorderings of events. In this\ncontext, each monitor aims to provide, as early as possible, a verdict on the\nproperty it is monitoring, based on its potentially incomplete and imprecise\nknowledge of the current execution. In this paper, we propose an on-line\nmonitoring algorithm for timed properties, robust to time imprecision and\npartial information from distant components. We first identify the date at\nwhich a monitor can safely compute a verdict based on received events. We then\npropose a monitoring algorithm that updates this date when new information\narrives, maintains the current set of states in which the property can reside,\nand updates its verdict accordingly.\n","authors":["Léo Henry","Thierry Jéron","Nicolas Markey","Victor Roussanaly"],"pdf_url":"https://arxiv.org/pdf/2410.00465v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.04566v2","updated":"2024-10-01T05:19:17Z","published":"2024-04-06T09:27:04Z","title":"Efficient and Green Large Language Models for Software Engineering:\n  Vision and the Road Ahead","summary":"  Large Language Models (LLMs) have recently shown remarkable capabilities in\nvarious software engineering tasks, spurring the rapid growth of the Large\nLanguage Models for Software Engineering (LLM4SE) area. However, limited\nattention has been paid to developing efficient LLM4SE techniques that demand\nminimal computational cost, time, and memory resources, as well as green LLM4SE\nsolutions that reduce energy consumption, water usage, and carbon emissions.\n  This paper aims to redirect the focus of the research community towards the\nefficiency and greenness of LLM4SE, while also sharing potential research\ndirections to achieve this goal. It commences with a brief overview of the\nsignificance of LLM4SE and highlights the need for efficient and green LLM4SE\nsolutions. Subsequently, the paper presents a vision for a future where\nefficient and green LLM4SE revolutionizes the LLM-based software engineering\ntool landscape, benefiting various stakeholders, including industry, individual\npractitioners, and society. The paper then delineates a roadmap for future\nresearch, outlining specific research paths and potential solutions for the\nresearch community to pursue. While not intended to be a definitive guide, the\npaper aims to inspire further progress, with the ultimate goal of establishing\nefficient and green LLM4SE as a central element in the future of software\nengineering.\n","authors":["Jieke Shi","Zhou Yang","David Lo"],"pdf_url":"https://arxiv.org/pdf/2404.04566v2.pdf","comment":"Under Review in the Special Issue of ACM Transactions on Software\n  Engineering and Methodology (TOSEM): 2030 Software Engineering Roadmap"},{"id":"http://arxiv.org/abs/2409.19894v2","updated":"2024-10-01T04:35:05Z","published":"2024-09-30T02:53:03Z","title":"TRANSAGENT: An LLM-Based Multi-Agent System for Code Translation","summary":"  Code translation converts code from one programming language to another while\nmaintaining its original functionality, which is crucial for software\nmigration, system refactoring, and cross-platform development. Traditional\nrule-based methods rely on manually-written rules, which can be time-consuming\nand often result in less readable code. To overcome this, learning-based\nmethods have been developed, leveraging parallel data to train models for\nautomated code translation. More recently, the advance of Large Language Models\n(LLMs) further boosts learning-based code translation. Although promising,\nLLM-translated program still suffers from diverse quality issues (e.g., syntax\nerrors and semantic errors). In particular, it can be challenging for LLMs to\nself-debug these errors when simply provided with the corresponding error\nmessages.\n  In this work, we propose a novel LLM-based multi-agent system TRANSAGENT,\nwhich enhances LLM-based code translation by fixing the syntax errors and\nsemantic errors with the synergy between four LLM-based agents, including\nInitial Code Translator, Syntax Error Fixer, Code Aligner, and Semantic Error\nFixer. The main insight of TRANSAGENT is to first localize the error code block\nin the target program based on the execution alignment between the target and\nsource program, which can narrow down the fixing space and thus lower down the\nfixing difficulties. To evaluate TRANSAGENT, we first construct a new benchmark\nfrom recent programming tasks to mitigate the potential data leakage issue. On\nour benchmark, TRANSAGENT outperforms the latest LLM-based code translation\ntechnique UniTrans in both translation effectiveness and efficiency;\nadditionally, our evaluation on different LLMs show the generalization of\nTRANSAGENT and our ablation study shows the contribution of each agent.\n","authors":["Zhiqiang Yuan","Weitong Chen","Hanlin Wang","Kai Yu","Xin Peng","Yiling Lou"],"pdf_url":"https://arxiv.org/pdf/2409.19894v2.pdf","comment":null}],"Human-Computer Interaction":[{"id":"http://arxiv.org/abs/2410.01096v1","updated":"2024-10-01T21:58:28Z","published":"2024-10-01T21:58:28Z","title":"Mechanic Maker: Accessible Game Development Via Symbolic Learning\n  Program Synthesis","summary":"  Game development is a highly technical practice that traditionally requires\nprogramming skills. This serves as a barrier to entry for would-be developers\nor those hoping to use games as part of their creative expression. While there\nhave been prior game development tools focused on accessibility, they generally\nstill require programming, or have major limitations in terms of the kinds of\ngames they can make. In this paper we introduce Mechanic Maker, a tool for\ncreating a wide-range of game mechanics without programming. It instead relies\non a backend symbolic learning system to synthesize game mechanics from\nexamples. We conducted a user study to evaluate the benefits of the tool for\nparticipants with a variety of programming and game development experience. Our\nresults demonstrated that participants' ability to use the tool was unrelated\nto programming ability. We conclude that tools like ours could help democratize\ngame development, making the practice accessible regardless of programming\nskills.\n","authors":["Megan Sumner","Vardan Saini","Matthew Guzdial"],"pdf_url":"https://arxiv.org/pdf/2410.01096v1.pdf","comment":"11 pages, 8 figures, AAAI Conference on Artificial Intelligence and\n  Interactive Digital Entertainment"},{"id":"http://arxiv.org/abs/2410.01088v1","updated":"2024-10-01T21:33:10Z","published":"2024-10-01T21:33:10Z","title":"Exploring Empty Spaces: Human-in-the-Loop Data Augmentation","summary":"  Data augmentation is crucial to make machine learning models more robust and\nsafe. However, augmenting data can be challenging as it requires generating\ndiverse data points to rigorously evaluate model behavior on edge cases and\nmitigate potential harms. Creating high-quality augmentations that cover these\n\"unknown unknowns\" is a time- and creativity-intensive task. In this work, we\nintroduce Amplio, an interactive tool to help practitioners navigate \"unknown\nunknowns\" in unstructured text datasets and improve data diversity by\nsystematically identifying empty data spaces to explore. Amplio includes three\nhuman-in-the-loop data augmentation techniques: Augment With Concepts, Augment\nby Interpolation, and Augment with Large Language Model. In a user study with\n18 professional red teamers, we demonstrate the utility of our augmentation\nmethods in helping generate high-quality, diverse, and relevant model safety\nprompts. We find that Amplio enabled red teamers to augment data quickly and\ncreatively, highlighting the transformative potential of interactive\naugmentation workflows.\n","authors":["Catherine Yeh","Donghao Ren","Yannick Assogba","Dominik Moritz","Fred Hohman"],"pdf_url":"https://arxiv.org/pdf/2410.01088v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.01071v1","updated":"2024-10-01T21:01:52Z","published":"2024-10-01T21:01:52Z","title":"An Approach to Elicit Human-Understandable Robot Expressions to Support\n  Human-Robot Interaction","summary":"  Understanding the intentions of robots is essential for natural and seamless\nhuman-robot collaboration. Ensuring that robots have means for non-verbal\ncommunication is a basis for intuitive and implicit interaction. For this, we\ncontribute an approach to elicit and design human-understandable robot\nexpressions. We outline the approach in the context of non-humanoid robots. We\npaired human mimicking and enactment with research from gesture elicitation in\ntwo phases: first, to elicit expressions, and second, to ensure they are\nunderstandable. We present an example application through two studies (N=16 \\&\nN=260) of our approach to elicit expressions for a simple 6-DoF robotic arm. We\nshow that it enabled us to design robot expressions that signal curiosity and\ninterest in getting attention. Our main contribution is an approach to generate\nand validate understandable expressions for robots, enabling more natural\nhuman-robot interaction.\n","authors":["Jan Leusmann","Steeven Villa","Thomas Liang","Chao Wang","Albrecht Schmidt","Sven Mayer"],"pdf_url":"https://arxiv.org/pdf/2410.01071v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.01026v1","updated":"2024-10-01T19:34:46Z","published":"2024-10-01T19:34:46Z","title":"Understanding the Human-LLM Dynamic: A Literature Survey of LLM Use in\n  Programming Tasks","summary":"  Large Language Models (LLMs) are transforming programming practices, offering\nsignificant capabilities for code generation activities. While researchers have\nexplored the potential of LLMs in various domains, this paper focuses on their\nuse in programming tasks, drawing insights from user studies that assess the\nimpact of LLMs on programming tasks. We first examined the user interaction\nbehaviors with LLMs observed in these studies, from the types of requests made\nto task completion strategies. Additionally, our analysis reveals both benefits\nand weaknesses of LLMs showing mixed effects on the human and task. Lastly, we\nlooked into what factors from the human, LLM or the interaction of both, affect\nthe human's enhancement as well as the task performance. Our findings highlight\nthe variability in human-LLM interactions due to the non-deterministic nature\nof both parties (humans and LLMs), underscoring the need for a deeper\nunderstanding of these interaction patterns. We conclude by providing some\npractical suggestions for researchers as well as programmers.\n","authors":["Deborah Etsenake","Meiyappan Nagappan"],"pdf_url":"https://arxiv.org/pdf/2410.01026v1.pdf","comment":"16 pages, 8 tables, 2 figures"},{"id":"http://arxiv.org/abs/2410.01014v1","updated":"2024-10-01T19:11:44Z","published":"2024-10-01T19:11:44Z","title":"\"For Us By Us\": Intentionally Designing Technology for Lived Black\n  Experiences","summary":"  HCI research to date has only scratched the surface of the unique approaches\nracially minoritized communities take to building, designing, and using\ntechnology systems. While there has been an increase in understanding how\npeople across racial groups create community across different platforms, there\nis still a lack of studies that explicitly center on how Black technologists\ndesign with and for their own communities. In this paper, we present findings\nfrom a series of semi-structured interviews with Black technologists who have\nused, created, or curated resources to support lived Black experiences. From\ntheir experiences, we find a multifaceted approach to design as a means of\nsurvival, to stay connected, for cultural significance, and to bask in\ncelebratory joy. Further, we provide considerations that emphasize the need for\ncentering lived Black experiences in design and share approaches that can\nempower the broader research community to conduct further inquiries into design\nfocused on those in the margins.\n","authors":["Lisa Egede","Leslie Coney","Brittany Johnson","Christina N. Harrington","Denae Ford"],"pdf_url":"https://arxiv.org/pdf/2410.01014v1.pdf","comment":"15 pages, 2 tables"},{"id":"http://arxiv.org/abs/2410.02829v1","updated":"2024-10-01T18:40:43Z","published":"2024-10-01T18:40:43Z","title":"LLMs May Not Be Human-Level Players, But They Can Be Testers: Measuring\n  Game Difficulty with LLM Agents","summary":"  Recent advances in Large Language Models (LLMs) have demonstrated their\npotential as autonomous agents across various tasks. One emerging application\nis the use of LLMs in playing games. In this work, we explore a practical\nproblem for the gaming industry: Can LLMs be used to measure game difficulty?\nWe propose a general game-testing framework using LLM agents and test it on two\nwidely played strategy games: Wordle and Slay the Spire. Our results reveal an\ninteresting finding: although LLMs may not perform as well as the average human\nplayer, their performance, when guided by simple, generic prompting techniques,\nshows a statistically significant and strong correlation with difficulty\nindicated by human players. This suggests that LLMs could serve as effective\nagents for measuring game difficulty during the development process. Based on\nour experiments, we also outline general principles and guidelines for\nincorporating LLMs into the game testing process.\n","authors":["Chang Xiao","Brenda Z. Yang"],"pdf_url":"https://arxiv.org/pdf/2410.02829v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.06908v3","updated":"2024-10-01T18:35:10Z","published":"2023-12-12T00:39:24Z","title":"\"I Want It That Way\": Enabling Interactive Decision Support Using Large\n  Language Models and Constraint Programming","summary":"  A critical factor in the success of decision support systems is the accurate\nmodeling of user preferences. Psychology research has demonstrated that users\noften develop their preferences during the elicitation process, highlighting\nthe pivotal role of system-user interaction in developing personalized systems.\nThis paper introduces a novel approach, combining Large Language Models (LLMs)\nwith Constraint Programming to facilitate interactive decision support. We\nstudy this hybrid framework through the lens of meeting scheduling, a\ntime-consuming daily activity faced by a multitude of information workers. We\nconduct three studies to evaluate the novel framework, including a diary study\n(n=64) to characterize contextual scheduling preferences, a quantitative\nevaluation of the system's performance, and a user study (n=10) with a\nprototype system. Our work highlights the potential for a hybrid LLM and\noptimization approach for iterative preference elicitation and design\nconsiderations for building systems that support human-system collaborative\ndecision-making processes.\n","authors":["Connor Lawless","Jakob Schoeffer","Lindy Le","Kael Rowan","Shilad Sen","Cristina St. Hill","Jina Suh","Bahareh Sarrafzadeh"],"pdf_url":"https://arxiv.org/pdf/2312.06908v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.18659v4","updated":"2024-10-01T18:34:37Z","published":"2024-02-28T19:09:08Z","title":"Large Language Models and Games: A Survey and Roadmap","summary":"  Recent years have seen an explosive increase in research on large language\nmodels (LLMs), and accompanying public engagement on the topic. While starting\nas a niche area within natural language processing, LLMs have shown remarkable\npotential across a broad range of applications and domains, including games.\nThis paper surveys the current state of the art across the various applications\nof LLMs in and for games, and identifies the different roles LLMs can take\nwithin a game. Importantly, we discuss underexplored areas and promising\ndirections for future uses of LLMs in games and we reconcile the potential and\nlimitations of LLMs within the games domain. As the first comprehensive survey\nand roadmap at the intersection of LLMs and games, we are hopeful that this\npaper will serve as the basis for groundbreaking research and innovation in\nthis exciting new field.\n","authors":["Roberto Gallotta","Graham Todd","Marvin Zammit","Sam Earle","Antonios Liapis","Julian Togelius","Georgios N. Yannakakis"],"pdf_url":"https://arxiv.org/pdf/2402.18659v4.pdf","comment":"Accepted for publication at the IEEE Transactions on Games (19 pages,\n  6 figures)"},{"id":"http://arxiv.org/abs/2410.00978v1","updated":"2024-10-01T18:07:06Z","published":"2024-10-01T18:07:06Z","title":"Uncovering the Viral Nature of Toxicity in Competitive Online Video\n  Games","summary":"  Toxicity is a widespread phenomenon in competitive online video games. In\naddition to its direct undesirable effects, there is a concern that toxicity\ncan spread to others, amplifying the harm caused by a single player's\nmisbehavior. In this study, we estimate whether and to what extent a player's\ntoxic speech spreads, causing their teammates to behave similarly. To this end,\nwe analyze proprietary data from the free-to-play first-person action game Call\nof Duty: Warzone. We formulate and implement an instrumental variable\nidentification strategy that leverages the network of interactions among\nplayers across matches. Our analysis reveals that all else equal, all of a\nplayer's teammates engaging in toxic speech increases their probability of\nengaging in similar behavior by 26.1 to 30.3 times the average player's\nlikelihood of engaging in toxic speech. These findings confirm the viral nature\nof toxicity, especially toxic speech, in competitive online video games.\n","authors":["Jacob Morrier","Amine Mahmassani","R. Michael Alvarez"],"pdf_url":"https://arxiv.org/pdf/2410.00978v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.00906v1","updated":"2024-10-01T17:51:09Z","published":"2024-10-01T17:51:09Z","title":"Generative AI and Perceptual Harms: Who's Suspected of using LLMs?","summary":"  Large language models (LLMs) are increasingly integrated into a variety of\nwriting tasks. While these tools can help people by generating ideas or\nproducing higher quality work, like many other AI tools they may risk causing a\nvariety of harms, disproportionately burdening historically marginalized\ngroups. In this work, we introduce and evaluate perceptual harm, a term for the\nharm caused to users when others perceive or suspect them of using AI. We\nexamined perceptual harms in three online experiments, each of which entailed\nhuman participants evaluating the profiles for fictional freelance writers. We\nasked participants whether they suspected the freelancers of using AI, the\nquality of their writing, and whether they should be hired. We found some\nsupport for perceptual harms against for certain demographic groups, but that\nperceptions of AI use negatively impacted writing evaluations and hiring\noutcomes across the board.\n","authors":["Kowe Kadoma","Danaë Metaxa","Mor Naaman"],"pdf_url":"https://arxiv.org/pdf/2410.00906v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.00897v1","updated":"2024-10-01T17:35:18Z","published":"2024-10-01T17:35:18Z","title":"The Gradient of Health Data Privacy","summary":"  In the era of digital health and artificial intelligence, the management of\npatient data privacy has become increasingly complex, with significant\nimplications for global health equity and patient trust. This paper introduces\na novel \"privacy gradient\" approach to health data governance, offering a more\nnuanced and adaptive framework than traditional binary privacy models. Our\nmultidimensional concept considers factors such as data sensitivity,\nstakeholder relationships, purpose of use, and temporal aspects, allowing for\ncontext-sensitive privacy protections. Through policy analyses, ethical\nconsiderations, and case studies spanning adolescent health, integrated care,\nand genomic research, we demonstrate how this approach can address critical\nprivacy challenges in diverse healthcare settings worldwide. The privacy\ngradient model has the potential to enhance patient engagement, improve care\ncoordination, and accelerate medical research while safeguarding individual\nprivacy rights. We provide policy recommendations for implementing this\napproach, considering its impact on healthcare systems, research\ninfrastructures, and global health initiatives. This work aims to inform\npolicymakers, healthcare leaders, and digital health innovators, contributing\nto a more equitable, trustworthy, and effective global health data ecosystem in\nthe digital age.\n","authors":["Baihan Lin"],"pdf_url":"https://arxiv.org/pdf/2410.00897v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.00873v1","updated":"2024-10-01T17:09:01Z","published":"2024-10-01T17:09:01Z","title":"Aligning Human and LLM Judgments: Insights from EvalAssist on\n  Task-Specific Evaluations and AI-assisted Assessment Strategy Preferences","summary":"  Evaluation of large language model (LLM) outputs requires users to make\ncritical judgments about the best outputs across various configurations. This\nprocess is costly and takes time given the large amounts of data. LLMs are\nincreasingly used as evaluators to filter training data, evaluate model\nperformance or assist human evaluators with detailed assessments. To support\nthis process, effective front-end tools are critical for evaluation. Two common\napproaches for using LLMs as evaluators are direct assessment and pairwise\ncomparison. In our study with machine learning practitioners (n=15), each\ncompleting 6 tasks yielding 131 evaluations, we explore how task-related\nfactors and assessment strategies influence criteria refinement and user\nperceptions. Findings show that users performed more evaluations with direct\nassessment by making criteria task-specific, modifying judgments, and changing\nthe evaluator model. We conclude with recommendations for how systems can\nbetter support interactions in LLM-assisted evaluations.\n","authors":["Zahra Ashktorab","Michael Desmond","Qian Pan","James M. Johnson","Martin Santillan Cooper","Elizabeth M. Daly","Rahul Nair","Tejaswini Pedapati","Swapnaja Achintalwar","Werner Geyer"],"pdf_url":"https://arxiv.org/pdf/2410.00873v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.00866v1","updated":"2024-10-01T17:01:09Z","published":"2024-10-01T17:01:09Z","title":"\"I don't trust them\": Exploring Perceptions of Fact-checking Entities\n  for Flagging Online Misinformation","summary":"  The spread of misinformation through online social media platforms has had\nsubstantial societal consequences. As a result, platforms have introduced\nmeasures to alert users of news content that may be misleading or contain\ninaccuracies as a means to discourage them from sharing it. These interventions\nsometimes cite external sources, such as fact-checking organizations and news\noutlets, for providing assessments related to the accuracy of the content.\nHowever, it is unclear whether users trust the assessments provided by these\nentities and whether perceptions vary across different topics of news. We\nconducted an online study with 655 US participants to explore user perceptions\nof eight categories of fact-checking entities across two misinformation topics,\nas well as factors that may impact users' perceptions. We found that\nparticipants' opinions regarding the trustworthiness and bias of the entities\nvaried greatly, aligning largely with their political preference. However, just\nthe presence of a fact-checking label appeared to discourage participants from\nsharing the headlines studied. Our results hint at the need for further\nexploring fact-checking entities that may be perceived as neutral, as well as\nthe potential for incorporating multiple assessments in such labels.\n","authors":["Hana Habib","Sara Elsharawy","Rifat Rahman"],"pdf_url":"https://arxiv.org/pdf/2410.00866v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.19180v2","updated":"2024-10-01T15:52:07Z","published":"2024-09-27T23:29:47Z","title":"Esports Training, Periodization, and Tools -- a Scoping Review","summary":"  Electronic sports (esports) and research on this emerging field are\ninterdisciplinary in nature. By extension, it is essential to understand how to\nstandardize and structure training with the help of existing tools developed by\nyears of research in sports sciences and informatics. Our goal in this article\nwas to verify if the current body of research contains substantial evidence of\nthe training systems applied to training esports players. To verify the\nexisting sources, we have applied a framework of scoping review to address the\nsearch from multiple scientific databases with further local processing. We\nconclude that the current research on esports dealt mainly with describing and\nmodeling performance metrics spanned over multiple fragmented research areas\n(psychology, nutrition, informatics), and yet these building blocks were not\nassembled into an existing well-functioning theory of performance in esports by\nproviding exercise regimes, and ways of periodization for esports.\n","authors":["Andrzej Białecki","Bartłomiej Michalak","Jan Gajewski"],"pdf_url":"https://arxiv.org/pdf/2409.19180v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.00778v1","updated":"2024-10-01T15:19:13Z","published":"2024-10-01T15:19:13Z","title":"Google, How Should I Vote? How Users Formulate Search Queries to Find\n  Political Information on Search Engines","summary":"  Search engine results depend not only on the algorithms but also on how users\ninteract with them. However, factors affecting the selection of a search query\nremain understudied. Using a representative survey of Swiss citizens before a\nround of federal popular votes, this study examines how users formulate search\nqueries related to the retirement policies that were voted on in March 2024.\nContrary to existing research, we find no direct evidence of selective\nexposure, or users' tendency to search for pro-attitudinal information, which\nwe explain by the less polarizing search topics. However, we find that the\nsentiment of the query is partially aligned with the expected vote outcome. Our\nresults also suggest that undecided and non-voters are more likely to search\nfor nuanced information, such as consequences and interpretations of the\npolicies. The perceived importance and effect of the issue, political views,\nand sociodemographics also affect query formulation.\n","authors":["Victoria Vziatysheva","Mykola Makhortykh","Maryna Sydorova","Vihang Jumle"],"pdf_url":"https://arxiv.org/pdf/2410.00778v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.00693v1","updated":"2024-10-01T13:47:42Z","published":"2024-10-01T13:47:42Z","title":"Optimizing Photoplethysmography-Based Sleep Staging Models by Leveraging\n  Temporal Context for Wearable Devices Applications","summary":"  Accurate sleep stage classification is crucial for diagnosing sleep disorders\nand evaluating sleep quality. While polysomnography (PSG) remains the gold\nstandard, photoplethysmography (PPG) is more practical due to its affordability\nand widespread use in wearable devices. However, state-of-the-art sleep staging\nmethods often require prolonged continuous signal acquisition, making them\nimpractical for wearable devices due to high energy consumption. Shorter signal\nacquisitions are more feasible but less accurate. Our work proposes an adapted\nsleep staging model based on top-performing state-of-the-art methods and\nevaluates its performance with different PPG segment sizes. We concatenate\n30-second PPG segments over 15-minute intervals to leverage longer segment\ncontexts. This approach achieved an accuracy of 0.75, a Cohen's Kappa of 0.60,\nan F1-Weighted score of 0.74, and an F1-Macro score of 0.60. Although reducing\nsegment size decreased sensitivity for deep and REM stages, our strategy\noutperformed single 30-second window methods, particularly for these stages.\n","authors":["Joseph A. P. Quino","Diego A. C. Cardenas","Marcelo A. F. Toledo","Felipe M. Dias","Estela Ribeiro","Jose E. Krieger","Marco A. Gutierrez"],"pdf_url":"https://arxiv.org/pdf/2410.00693v1.pdf","comment":"11 pages, 5 figures, 1 table"}],"Programming Languages":[{"id":"http://arxiv.org/abs/2402.16982v3","updated":"2024-10-01T17:45:37Z","published":"2024-02-26T19:29:46Z","title":"Synthesizing Tight Privacy and Accuracy Bounds via Weighted Model\n  Counting","summary":"  Programmatically generating tight differential privacy (DP) bounds is a hard\nproblem. Two core challenges are (1) finding expressive, compact, and efficient\nencodings of the distributions of DP algorithms, and (2) state space explosion\nstemming from the multiple quantifiers and relational properties of the DP\ndefinition.\n  We address the first challenge by developing a method for tight privacy and\naccuracy bound synthesis using weighted model counting on binary decision\ndiagrams, a state-of-the-art technique from the artificial intelligence and\nautomated reasoning communities for exactly computing probability\ndistributions. We address the second challenge by developing a framework for\nleveraging inherent symmetries in DP algorithms. Our solution benefits from\nongoing research in probabilistic programming languages, allowing us to\nsuccinctly and expressively represent different DP algorithms with approachable\nlanguage syntax that can be used by non-experts.\n  We provide a detailed case study of our solution on the binary randomized\nresponse algorithm. We also evaluate an implementation of our solution using\nthe Dice probabilistic programming language for the randomized response and\ntruncated geometric above threshold algorithms. We compare to prior work on\nexact DP verification using Markov chain probabilistic model checking and the\ndecision procedure DiPC. Very few existing works consider mechanized analysis\nof accuracy guarantees for DP algorithms. We additionally provide a detailed\nanalysis using our technique for finding tight accuracy bounds for DP\nalgorithms.\n","authors":["Lisa Oakley","Steven Holtzen","Alina Oprea"],"pdf_url":"https://arxiv.org/pdf/2402.16982v3.pdf","comment":"In IEEE 37th Computer Security Foundations Symposium (CSF) 2024"},{"id":"http://arxiv.org/abs/2301.11301v4","updated":"2024-10-01T15:42:19Z","published":"2023-01-26T18:39:19Z","title":"A Complete Inference System for Skip-free Guarded Kleene Algebra with\n  Tests","summary":"  Guarded Kleene Algebra with Tests (GKAT) is a fragment of Kleene Algebra with\nTests (KAT) that was recently introduced to reason efficiently about imperative\nprograms. In contrast to KAT, GKAT does not have an algebraic axiomatization,\nbut relies on an analogue of Salomaa's axiomatization of Kleene Algebra. In\nthis paper, we present an algebraic axiomatization and prove two completeness\nresults for a large fragment of GKAT consisting of skip-free programs.\n","authors":["Tobias Kappé","Todd Schmid","Alexandra Silva"],"pdf_url":"https://arxiv.org/pdf/2301.11301v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.00540v1","updated":"2024-10-01T09:29:05Z","published":"2024-10-01T09:29:05Z","title":"Conditional Nested Pattern Matching in Interaction Net","summary":"  Interaction nets are a form of restricted graph rewrite system that can serve\nas a graphical or textual programming language. As such, benefits include\none-step confluence, ease of parallelism and explicit garbage collection.\nHowever, some of these restrictions burden the programmer, so they have been\nextended in several ways, notably to include data types and conditional rules.\nThis paper introduces a further extension to allow nested pattern matching and\nto do so in a way that preserves these benefits and fundamental properties of\ninteraction nets. We also show that by introducing a translation to non-nested\nmatching, this extension is conservative in rewriting. In addition, we propose\na new notation to express this pattern matching.\n","authors":["Shinya Sato"],"pdf_url":"https://arxiv.org/pdf/2410.00540v1.pdf","comment":"In Proceedings DCM 2023, arXiv:2409.19298"}],"Networking and Internet Architecture":[{"id":"http://arxiv.org/abs/2410.01070v1","updated":"2024-10-01T20:59:50Z","published":"2024-10-01T20:59:50Z","title":"Meta Learning Based Adaptive Cooperative Perception in Nonstationary\n  Vehicular Networks","summary":"  To accommodate high network dynamics in real-time cooperative perception\n(CP), reinforcement learning (RL) based adaptive CP schemes have been proposed,\nto allow adaptive switchings between CP and stand-alone perception modes among\nconnected and autonomous vehicles. The traditional offline-training\nonline-execution RL framework suffers from performance degradation under\nnonstationary network conditions. To achieve fast and efficient model\nadaptation, we formulate a set of Markov decision processes for adaptive CP\ndecisions in each stationary local vehicular network (LVN). A meta RL solution\nis proposed, which trains a meta RL model that captures the general features\namong LVNs, thus facilitating fast model adaptation for each LVN with the meta\nRL model as an initial point. Simulation results show the superiority of meta\nRL in terms of the convergence speed without reward degradation. The impact of\nthe customization level of meta models on the model adaptation performance has\nalso been evaluated.\n","authors":["Kaige Qu","Zixiong Qin","Weihua Zhuang"],"pdf_url":"https://arxiv.org/pdf/2410.01070v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.03747v1","updated":"2024-10-01T18:35:25Z","published":"2024-10-01T18:35:25Z","title":"Distributed AI Platform for the 6G RAN","summary":"  Cellular Radio Access Networks (RANs) are rapidly evolving towards 6G, driven\nby the need to reduce costs and introduce new revenue streams for operators and\nenterprises. In this context, AI emerges as a key enabler in solving complex\nRAN problems spanning both the management and application domains.\nUnfortunately, and despite the undeniable promise of AI, several practical\nchallenges still remain, hindering the widespread adoption of AI applications\nin the RAN space. This article attempts to shed light to these challenges and\nargues that existing approaches in addressing them are inadequate for realizing\nthe vision of a truly AI-native 6G network. Motivated by this lack of\nsolutions, it proposes a generic distributed AI platform architecture, tailored\nto the needs of an AI-native RAN and discusses its alignment with ongoing\nstandardization efforts.\n","authors":["Ganesh Ananthanarayanan","Xenofon Foukas","Bozidar Radunovic","Yongguang Zhang"],"pdf_url":"https://arxiv.org/pdf/2410.03747v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.09662v2","updated":"2024-10-01T15:52:15Z","published":"2024-05-15T19:04:30Z","title":"Large-Scale Security Analysis of Real-World Backend Deployments Speaking\n  IoT-Focused Protocols","summary":"  Internet-of-Things (IoT) devices, ranging from smart home assistants to\nhealth devices, are pervasive: Forecasts estimate their number to reach 29\nbillion by 2030. Understanding the security of their machine-to-machine\ncommunication is crucial. Prior work focused on identifying devices'\nvulnerabilities or proposed protocol-specific solutions. Instead, we\ninvestigate the security of backends speaking IoT protocols, that is, the\nbackbone of the IoT ecosystem.\n  We focus on three real-world protocols for our large-scale analysis: MQTT,\nCoAP, and XMPP. We gather a dataset of over 337,000 backends, augment it with\ngeographical and provider data, and perform non-invasive active measurements to\ninvestigate three major security threats: information leakage, weak\nauthentication, and denial of service. Our results provide quantitative\nevidence of a problematic immaturity in the IoT ecosystem. Among other issues,\nwe find that 9.44% backends expose information, 30.38% CoAP-speaking backends\nare vulnerable to denial of service attacks, and 99.84% of MQTT- and\nXMPP-speaking backends use insecure transport protocols (only 0.16% adopt TLS,\nof which 70.93% adopt a vulnerable version).\n","authors":["Carlotta Tagliaro","Martina Komsic","Andrea Continella","Kevin Borgolte","Martina Lindorfer"],"pdf_url":"https://arxiv.org/pdf/2405.09662v2.pdf","comment":"Appeared at the 27th International Symposium on Research in Attacks,\n  Intrusions and Defenses (RAID 2024)"},{"id":"http://arxiv.org/abs/2308.03547v2","updated":"2024-10-01T14:20:24Z","published":"2023-08-07T12:55:29Z","title":"Near-optimal pilot assignment in cell-free massive MIMO","summary":"  Cell-free massive MIMO systems are currently being considered as potential\nenablers of future (6G) technologies for wireless communications. By combining\ndistributed processing and massive MIMO, they are expected to deliver improved\nuser coverage and efficiency. A possible source of performance degradation in\nsuch systems is pilot contamination, which contributes to causing interference\nduring uplink training and affects channel estimation negatively. Contamination\noccurs when the same pilot sequence is assigned to more than one user. This is\nin general inevitable, as the number of mutually orthogonal pilot sequences\ncorresponds to only a fraction of the coherence interval. We introduce a new\nalgorithm for pilot assignment and analyze its performance both from a\ntheoretical perspective and in computational experiments. We show that it has\nan approximation ratio close to 1 for a plausibly large number of orthogonal\npilot sequences, as well as low computational complexity under massive\nparallelism. We also show that, on average, it outperforms other methods in\nterms of per-user SINR and throughput on the uplink.\n","authors":["Raphael M. Guedes","José F. de Rezende","Valmir C. Barbosa"],"pdf_url":"https://arxiv.org/pdf/2308.03547v2.pdf","comment":"This version updates metadata and expands content"},{"id":"http://arxiv.org/abs/2410.00583v1","updated":"2024-10-01T11:15:12Z","published":"2024-10-01T11:15:12Z","title":"A Mathematical Theory of Hyper-simplex Fractal Network for Blockchain:\n  Part I","summary":"  Blockchain technology holds promise for Web 3.0, but scalability remains a\ncritical challenge. Here, we present a mathematical theory for a novel\nblockchain network topology based on fractal N-dimensional simplexes. This\nHyper-simplex fractal network folds one-dimensional data blocks into geometric\nshapes, reflecting both underlying and overlaying network connectivities. Our\napproach offers near-infinite scalability, accommodating trillions of nodes\nwhile maintaining efficiency.\n  We derive the mathematical foundations for generating and describing these\nnetwork topologies, proving key properties such as node count, connectivity\npatterns, and fractal dimension. The resulting structure facilitates a\nhierarchical consensus mechanism and enables deterministic address mapping for\nrapid routing. This theoretical framework lays the groundwork for\nnext-generation blockchain architectures, potentially revolutionizing\nlarge-scale decentralized systems. The Part I work was conducted between March\nand September 2024.\n","authors":["Kaiwen Yang","Hao Xu","Yunqing Sun","Jiacheng Qian","Zihan Zhou","Xiaoshuai Zhang","Erwu Liu","Lei Zhang","Chih-Lin I"],"pdf_url":"https://arxiv.org/pdf/2410.00583v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.21181v3","updated":"2024-10-01T11:14:41Z","published":"2024-07-30T20:38:22Z","title":"Optimal Sampling under Cost for Remote Estimation of the Wiener Process\n  over a Channel with Delay","summary":"  In this paper, we address the optimal sampling of a Wiener process under\nsampling and transmission costs, with the samples being forwarded to a remote\nestimator over a channel with random IID delay. The goal of the estimator is to\nreconstruct an estimate of the real-time signal value from causally received\nsamples. Our study focuses on the optimal online strategy for both sampling and\ntransmission, aiming to minimize the mean square estimation error. We establish\nthat the optimal strategy involves threshold policies for both sampling and\ntransmission, and we derive the optimal thresholds. We utilize Lagrange\nrelaxation and backward induction as our methodology, revealing the problem of\nminimizing estimation error, under the assumption that sampling and\ntransmission times are independent of the observed Wiener process. Our\ncomparative analysis demonstrates that the estimation error achieved by the\noptimal joint sampling and transmission policy is significantly lower than that\nof age-optimal sampling, zero-wait sampling, periodic sampling, and policies\nthat optimize only the sampling times.\n","authors":["Orhan T. Yavaşcan","Süleyman Çıtır","Elif Uysal"],"pdf_url":"https://arxiv.org/pdf/2407.21181v3.pdf","comment":"In this version only sampling policy is defined on the other hand\n  solution is made for joint sampling and transmission policy, therefore\n  problem formulation and solution is not consistent"},{"id":"http://arxiv.org/abs/2402.12716v5","updated":"2024-10-01T04:22:34Z","published":"2024-02-20T04:56:48Z","title":"Off-Path TCP Hijacking in Wi-Fi Networks: A Packet-Size Side Channel\n  Attack","summary":"  In this paper, we unveil a fundamental side channel in Wi-Fi networks,\nspecifically the observable frame size, which can be exploited by attackers to\nconduct TCP hijacking attacks. Despite the various security mechanisms (e.g.,\nWEP and WPA2/WPA3) implemented to safeguard Wi-Fi networks, our study reveals\nthat an off path attacker can still extract sufficient information from the\nframe size side channel to hijack the victim's TCP connection. Our side channel\nattack is based on two significant findings: (i) response packets (e.g., ACK\nand RST) generated by TCP receivers vary in size, and (ii) the encrypted frames\ncontaining these response packets have consistent and distinguishable sizes. By\nobserving the size of the victim's encrypted frames, the attacker can detect\nand hijack the victim's TCP connections. We validate the effectiveness of this\nside channel attack through two case studies, i.e., SSH DoS and web traffic\nmanipulation. Precisely, our attack can terminate the victim's SSH session in\n19 seconds and inject malicious data into the victim's web traffic within 28\nseconds. Furthermore, we conduct extensive measurements to evaluate the impact\nof our attack on real-world Wi-Fi networks. We test 30 popular wireless routers\nfrom 9 well-known vendors, and none of these routers can protect victims from\nour attack. Besides, we implement our attack in 80 real-world Wi-Fi networks\nand successfully hijack the victim's TCP connections in 75 (93.75%) evaluated\nWi-Fi networks. We have responsibly disclosed the vulnerability to the Wi-Fi\nAlliance and proposed several mitigation strategies to address this issue.\n","authors":["Ziqiang Wang","Xuewei Feng","Qi Li","Kun Sun","Yuxiang Yang","Mengyuan Li","Ganqiu Du","Ke Xu","Jianping Wu"],"pdf_url":"https://arxiv.org/pdf/2402.12716v5.pdf","comment":null}],"Distributed, Parallel, and Cluster Computing":[{"id":"http://arxiv.org/abs/2408.12290v2","updated":"2024-10-01T23:19:11Z","published":"2024-08-22T10:59:48Z","title":"KS+: Predicting Workflow Task Memory Usage Over Time","summary":"  Scientific workflow management systems enable the reproducible execution of\ndata analysis pipelines on cluster infrastructures managed by resource managers\nsuch as Kubernetes, Slurm, or HTCondor. These resource managers require\nresource estimates for each workflow task to be executed on one of the cluster\nnodes. However, task resource consumption varies significantly between\ndifferent tasks and for the same task with different inputs. Furthermore,\nresource consumption also fluctuates during a task's execution. As a result,\nmanually configuring static memory allocations is error-prone, often leading\nusers to overestimate memory usage to avoid costly failures from\nunder-provisioning, which results in significant memory wastage. We propose\nKS+, a method that predicts a task's memory consumption over time depending on\nits inputs. For this, KS+ dynamically segments the task execution and predicts\nthe memory required for each segment. Our experimental evaluation shows an\naverage reduction in memory wastage of 38% compared to the best-performing\nstate-of-the-art baseline for two real-world workflows from the popular nf-core\nrepository.\n","authors":["Jonathan Bader","Ansgar Lößer","Lauritz Thamsen","Björn Scheuermann","Odej Kao"],"pdf_url":"https://arxiv.org/pdf/2408.12290v2.pdf","comment":"Paper accepted in 2024 IEEE ReWorDS, eScience"},{"id":"http://arxiv.org/abs/2105.00110v3","updated":"2024-10-01T19:29:16Z","published":"2021-04-30T22:29:10Z","title":"Triangle Centrality","summary":"  Triangle centrality is introduced for finding important vertices in a graph\nbased on the concentration of triangles surrounding each vertex. It has the\ndistinct feature of allowing a vertex to be central if it is in many triangles\nor none at all.\n  We show experimentally that triangle centrality is broadly applicable to many\ndifferent types of networks. Our empirical results demonstrate that 30% of the\ntime triangle centrality identified central vertices that differed with those\nfound by five well-known centrality measures, which suggests novelty without\nbeing overly specialized. It is also asymptotically faster to compute on sparse\ngraphs than all but the most trivial of these other measures.\n  We introduce optimal algorithms that compute triangle centrality in\n$O(m\\bar\\delta)$ time and $O(m+n)$ space, where $\\bar\\delta\\le O(\\sqrt{m})$ is\nthe $\\textit{average degeneracy}$ introduced by Burkhardt, Faber, and Harris\n(2020). In practical applications, $\\bar\\delta$ is much smaller than $\\sqrt{m}$\nso triangle centrality can be computed in nearly linear time. On a Concurrent\nRead Exclusive Write (CREW) Parallel Random Access Machine (PRAM), we give a\nnear work-optimal parallel algorithm that takes $O(\\log n)$ time using\n$O(m\\sqrt{m})$ CREW PRAM processors. In MapReduce, we show it takes four rounds\nusing $O(m\\sqrt{m})$ communication bits and is therefore optimal. We also\nderive a linear algebraic formulation of triangle centrality which can be\ncomputed in $O(m\\bar\\delta)$ time on sparse graphs.\n","authors":["Paul Burkhardt"],"pdf_url":"https://arxiv.org/pdf/2105.00110v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.19513v2","updated":"2024-10-01T18:19:34Z","published":"2024-05-29T20:51:38Z","title":"Decentralized Optimization in Time-Varying Networks with Arbitrary\n  Delays","summary":"  We consider a decentralized optimization problem for networks affected by\ncommunication delays. Examples of such networks include collaborative machine\nlearning, sensor networks, and multi-agent systems. To mimic communication\ndelays, we add virtual non-computing nodes to the network, resulting in\ndirected graphs. This motivates investigating decentralized optimization\nsolutions on directed graphs. Existing solutions assume nodes know their\nout-degrees, resulting in limited applicability. To overcome this limitation,\nwe introduce a novel gossip-based algorithm, called DT-GO, that does not need\nto know the out-degrees. The algorithm is applicable in general directed\nnetworks, for example networks with delays or limited acknowledgment\ncapabilities. We derive convergence rates for both convex and non-convex\nobjectives, showing that our algorithm achieves the same complexity order as\ncentralized Stochastic Gradient Descent. In other words, the effects of the\ngraph topology and delays are confined to higher-order terms. Additionally, we\nextend our analysis to accommodate time-varying network topologies. Numerical\nsimulations are provided to support our theoretical findings.\n","authors":["Tomas Ortega","Hamid Jafarkhani"],"pdf_url":"https://arxiv.org/pdf/2405.19513v2.pdf","comment":"arXiv admin note: text overlap with arXiv:2401.11344"},{"id":"http://arxiv.org/abs/2410.00825v1","updated":"2024-10-01T16:07:41Z","published":"2024-10-01T16:07:41Z","title":"Developing a BLAS library for the AMD AI Engine","summary":"  Spatial (dataflow) computer architectures can mitigate the control and\nperformance overhead of classical von Neumann architectures such as traditional\nCPUs. Driven by the popularity of Machine Learning (ML) workloads, spatial\ndevices are being marketed as ML inference accelerators. Despite providing a\nrich software ecosystem for ML practitioners, their adoption in other\nscientific domains is hindered by the steep learning curve and lack of reusable\nsoftware, which makes them inaccessible to non-experts. We present our ongoing\nproject AIEBLAS, an open-source, expandable implementation of Basic Linear\nAlgebra Routines (BLAS) for the AMD AI Engine. Numerical routines are designed\nto be easily reusable, customized, and composed in dataflow programs,\nleveraging the characteristics of the targeted device without requiring the\nuser to deeply understand the underlying hardware and programming model.\n","authors":["Tristan Laan","Tiziano De Matteis"],"pdf_url":"https://arxiv.org/pdf/2410.00825v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.00801v1","updated":"2024-10-01T15:46:27Z","published":"2024-10-01T15:46:27Z","title":"Understanding Data Movement in AMD Multi-GPU Systems with Infinity\n  Fabric","summary":"  Modern GPU systems are constantly evolving to meet the needs of\ncomputing-intensive applications in scientific and machine learning domains.\nHowever, there is typically a gap between the hardware capacity and the\nachievable application performance. This work aims to provide a better\nunderstanding of the Infinity Fabric interconnects on AMD GPUs and CPUs. We\npropose a test and evaluation methodology for characterizing the performance of\ndata movements on multi-GPU systems, stressing different communication options\non AMD MI250X GPUs, including point-to-point and collective communication, and\nmemory allocation strategies between GPUs, as well as the host CPU. In a\nsingle-node setup with four GPUs, we show that direct peer-to-peer memory\naccesses between GPUs and utilization of the RCCL library outperform MPI-based\nsolutions in terms of memory/communication latency and bandwidth. Our test and\nevaluation method serves as a base for validating memory and communication\nstrategies on a system and improving applications on AMD multi-GPU computing\nsystems.\n","authors":["Gabin Schieffer","Ruimin Shi","Stefano Markidis","Andreas Herten","Jennifer Faj","Ivy Peng"],"pdf_url":"https://arxiv.org/pdf/2410.00801v1.pdf","comment":"To be published in Workshop Proceedings of The International\n  Conference for High Performance Computing Networking, Storage, and Analysis\n  (SC-W '24) (2024)"},{"id":"http://arxiv.org/abs/2408.03829v2","updated":"2024-10-01T15:30:13Z","published":"2024-08-07T15:08:26Z","title":"PeerSwap: A Peer-Sampler with Randomness Guarantees","summary":"  The ability of a peer-to-peer (P2P) system to effectively host decentralized\napplications often relies on the availability of a peer-sampling service, which\nprovides each participant with a random sample of other peers. Despite the\npractical effectiveness of existing peer samplers, their ability to produce\nrandom samples within a reasonable time frame remains poorly understood from a\ntheoretical standpoint. This paper contributes to bridging this gap by\nintroducing PeerSwap, a peer-sampling protocol with provable randomness\nguarantees. We establish execution time bounds for PeerSwap, demonstrating its\nability to scale effectively with the network size. We prove that PeerSwap\nmaintains the fixed structure of the communication graph while allowing\nsequential peer position swaps within this graph. We do so by showing that\nPeerSwap is a specific instance of an interchange process, a renowned model for\nparticle movement analysis. Leveraging this mapping, we derive execution time\nbounds, expressed as a function of the network size N. Depending on the network\nstructure, this time can be as low as a polylogarithmic function of N,\nhighlighting the efficiency of PeerSwap. We implement PeerSwap and conduct\nnumerical evaluations using regular graphs with varying connectivity and\ncontaining up to 32768 (2^15) peers. Our evaluation demonstrates that PeerSwap\nquickly provides peers with uniform random samples of other peers.\n","authors":["Rachid Guerraoui","Anne-Marie Kermarrec","Anastasiia Kucherenko","Rafael Pinot","Martijn de Vos"],"pdf_url":"https://arxiv.org/pdf/2408.03829v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.00695v1","updated":"2024-10-01T13:50:12Z","published":"2024-10-01T13:50:12Z","title":"E-MPC: Edge-assisted Model Predictive Control","summary":"  Model predictive control (MPC) has become the de facto standard action space\nfor local planning and learning-based control in many continuous robotic\ncontrol tasks, including autonomous driving. MPC solves a long-horizon cost\noptimization as a series of short-horizon optimizations based on a global\nplanner-supplied reference path. The primary challenge in MPC, however, is that\nthe computational budget for re-planning has a hard limit, which frequently\ninhibits exact optimization. Modern edge networks provide low-latency\ncommunication and heterogeneous properties that can be especially beneficial in\nthis situation. We propose a novel framework for edge-assisted MPC (E-MPC) for\npath planning that exploits the heterogeneity of edge networks in three\nimportant ways: 1) varying computational capacity, 2) localized sensor\ninformation, and 3) localized observation histories. Theoretical analysis and\nextensive simulations are undertaken to demonstrate quantitatively the benefits\nof E-MPC in various scenarios, including maps, channel dynamics, and\navailability and density of edge nodes. The results confirm that E-MPC has the\npotential to reduce costs by a greater percentage than standard MPC does.\n","authors":["Yuan-Yao Lou","Jonathan Spencer","Kwang Taik Kim","Mung Chiang"],"pdf_url":"https://arxiv.org/pdf/2410.00695v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.00688v1","updated":"2024-10-01T13:43:44Z","published":"2024-10-01T13:43:44Z","title":"Supercomputer 3D Digital Twin for User Focused Real-Time Monitoring","summary":"  Real-time supercomputing performance analysis is a critical aspect of\nevaluating and optimizing computational systems in a dynamic user environment.\nThe operation of supercomputers produce vast quantities of analytic data from\nmultiple sources and of varying types so compiling this data in an efficient\nmatter is critical to the process. MIT Lincoln Laboratory Supercomputing Center\nhas been utilizing the Unity 3D game engine to create a Digital Twin of our\nsupercomputing systems for several years to perform system monitoring. Unity\noffers robust visualization capabilities making it ideal for creating a\nsophisticated representation of the computational processes. As we scale the\nsystems to include a diversity of resources such as accelerators and the\naddition of more users, we need to implement new analysis tools for the\nmonitoring system. The workloads in research continuously change, as does the\ncapability of Unity, and this allows us to adapt our monitoring tools to scale\nand incorporate features enabling efficient replay of system wide events, user\nisolation, and machine level granularity. Our system fully takes advantage of\nthe modern capabilities of the Unity Engine in a way that intuitively\nrepresents the real time workload performed on a supercomputer. It allows HPC\nsystem engineers to quickly diagnose usage related errors with its responsive\nuser interface which scales efficiently with large data sets.\n","authors":["William Bergeron","Matthew Hubbell","Daniel Mojica","Albert Reuther","William Arcand","David Bestor","Daniel Burrill"," Chansup"," Byun","Vijay Gadepally","Michael Houle","Hayden Jananthan","Michael Jones","Piotr Luszczek","Peter Michaleas","Lauren Milechin","Julie Mullen Andrew Prout","Antonio Rosa","Charles Yee","Jeremy Kepner"],"pdf_url":"https://arxiv.org/pdf/2410.00688v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.00644v1","updated":"2024-10-01T12:55:47Z","published":"2024-10-01T12:55:47Z","title":"PARSIR: a Package for Effective Parallel Discrete Event Simulation on\n  Multi-processor Machines","summary":"  In this article we present PARSIR (PARallel SImulation Runner), a package\nthat enables the effective exploitation of shared-memory multi-processor\nmachines for running discrete event simulation models. PARSIR is a\ncompile/run-time environment for discrete event simulation models developed\nwith the {\\tt C} programming language. The architecture of PARSIR has been\ndesigned in order to keep low the amount of CPU-cycles required for running\nmodels. This is achieved via the combination of a set of techniques like: 1)\ncausally consistent batch-processing of simulation events at an individual\nsimulation object for caching effectiveness; 2) high likelihood of disjoint\naccess parallelism; 3) the favoring of memory accesses on local NUMA\n(Non-Uniform-Memory-Access) nodes in the architecture, while still enabling\nwell balanced workload distribution via work-stealing from remote nodes; 4) the\nuse of RMW (Read-Modify-Write) machine instructions for fast access to\nsimulation engine data required by the worker threads for managing the\nconcurrent simulation objects and distributing the workload. Furthermore, any\narchitectural solution embedded in the PARSIR engine is fully transparent to\nthe application level code implementing the simulation model. We also provide\nexperimental results showing the effectiveness of PARSIR when running the\nreference PHOLD benchmark on a NUMA shared-memory multi-processor machine\nequipped with 40 CPUs.\n","authors":["Francesco Quaglia"],"pdf_url":"https://arxiv.org/pdf/2410.00644v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.00627v1","updated":"2024-10-01T12:18:54Z","published":"2024-10-01T12:18:54Z","title":"Parallel state estimation for systems with integrated measurements","summary":"  This paper presents parallel-in-time state estimation methods for systems\nwith Slow-Rate inTegrated Measurements (SRTM). Integrated measurements are\ncommon in various applications, and they appear in analysis of data resulting\nfrom processes that require material collection or integration over the\nsampling period. Current state estimation methods for SRTM are inherently\nsequential, preventing temporal parallelization in their standard form. This\npaper proposes parallel Bayesian filters and smoothers for linear Gaussian SRTM\nmodels. For that purpose, we develop a novel smoother for SRTM models and\ndevelop parallel-in-time filters and smoother for them using an associative\nscan-based parallel formulation. Empirical experiments ran on a GPU demonstrate\nthe superior time complexity of the proposed methods over traditional\nsequential approaches.\n","authors":["Fatemeh Yaghoobi","Simo Särkkä"],"pdf_url":"https://arxiv.org/pdf/2410.00627v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.15216v2","updated":"2024-10-01T11:20:53Z","published":"2024-09-23T17:00:35Z","title":"FLeNS: Federated Learning with Enhanced Nesterov-Newton Sketch","summary":"  Federated learning faces a critical challenge in balancing communication\nefficiency with rapid convergence, especially for second-order methods. While\nNewton-type algorithms achieve linear convergence in communication rounds,\ntransmitting full Hessian matrices is often impractical due to quadratic\ncomplexity. We introduce Federated Learning with Enhanced Nesterov-Newton\nSketch (FLeNS), a novel method that harnesses both the acceleration\ncapabilities of Nesterov's method and the dimensionality reduction benefits of\nHessian sketching. FLeNS approximates the centralized Newton's method without\nrelying on the exact Hessian, significantly reducing communication overhead. By\ncombining Nesterov's acceleration with adaptive Hessian sketching, FLeNS\npreserves crucial second-order information while preserving the rapid\nconvergence characteristics. Our theoretical analysis, grounded in statistical\nlearning, demonstrates that FLeNS achieves super-linear convergence rates in\ncommunication rounds - a notable advancement in federated optimization. We\nprovide rigorous convergence guarantees and characterize tradeoffs between\nacceleration, sketch size, and convergence speed. Extensive empirical\nevaluation validates our theoretical findings, showcasing FLeNS's\nstate-of-the-art performance with reduced communication requirements,\nparticularly in privacy-sensitive and edge-computing scenarios. The code is\navailable at https://github.com/sunnyinAI/FLeNS\n","authors":["Sunny Gupta","Mohit Jindal","Pankhi Kashyap","Pranav Jeevan","Amit Sethi"],"pdf_url":"https://arxiv.org/pdf/2409.15216v2.pdf","comment":"10 pages, 3 figures, 2 Tables"},{"id":"http://arxiv.org/abs/2410.00583v1","updated":"2024-10-01T11:15:12Z","published":"2024-10-01T11:15:12Z","title":"A Mathematical Theory of Hyper-simplex Fractal Network for Blockchain:\n  Part I","summary":"  Blockchain technology holds promise for Web 3.0, but scalability remains a\ncritical challenge. Here, we present a mathematical theory for a novel\nblockchain network topology based on fractal N-dimensional simplexes. This\nHyper-simplex fractal network folds one-dimensional data blocks into geometric\nshapes, reflecting both underlying and overlaying network connectivities. Our\napproach offers near-infinite scalability, accommodating trillions of nodes\nwhile maintaining efficiency.\n  We derive the mathematical foundations for generating and describing these\nnetwork topologies, proving key properties such as node count, connectivity\npatterns, and fractal dimension. The resulting structure facilitates a\nhierarchical consensus mechanism and enables deterministic address mapping for\nrapid routing. This theoretical framework lays the groundwork for\nnext-generation blockchain architectures, potentially revolutionizing\nlarge-scale decentralized systems. The Part I work was conducted between March\nand September 2024.\n","authors":["Kaiwen Yang","Hao Xu","Yunqing Sun","Jiacheng Qian","Zihan Zhou","Xiaoshuai Zhang","Erwu Liu","Lei Zhang","Chih-Lin I"],"pdf_url":"https://arxiv.org/pdf/2410.00583v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.12968v2","updated":"2024-10-01T11:01:37Z","published":"2024-04-19T15:54:15Z","title":"Scalable Data Assimilation with Message Passing","summary":"  Data assimilation is a core component of numerical weather prediction\nsystems. The large quantity of data processed during assimilation requires the\ncomputation to be distributed across increasingly many compute nodes, yet\nexisting approaches suffer from synchronisation overhead in this setting. In\nthis paper, we exploit the formulation of data assimilation as a Bayesian\ninference problem and apply a message-passing algorithm to solve the spatial\ninference problem. Since message passing is inherently based on local\ncomputations, this approach lends itself to parallel and distributed\ncomputation. In combination with a GPU-accelerated implementation, we can scale\nthe algorithm to very large grid sizes while retaining good accuracy and\ncompute and memory requirements.\n","authors":["Oscar Key","So Takao","Daniel Giles","Marc Peter Deisenroth"],"pdf_url":"https://arxiv.org/pdf/2404.12968v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.05495v2","updated":"2024-10-01T10:36:52Z","published":"2024-08-10T09:03:06Z","title":"Asynchronous Approximate Agreement with Quadratic Communication","summary":"  We consider an asynchronous network of $n$ message-sending parties, up to $t$\nof which are byzantine. We study approximate agreement, where the parties\nobtain approximately equal outputs in the convex hull of their inputs. In their\nseminal work, Abraham, Amit and Dolev [OPODIS '04] achieve this with the\noptimal resilience $t < \\frac{n}{3}$ with a protocol where each party reliably\nbroadcasts its input every iteration. This takes $\\Theta(n^2)$ messages per\nreliable broadcast, or $\\Theta(n^3)$ messages per iteration.\n  In this work, we present optimally resilient asynchronous approximate\nagreement protocols where we forgo reliable broadcast to require communication\nproportional to $n^2$ instead of $n^3$. We begin with a protocol for\n$\\omega$-dimensional barycentric agreement with $\\mathcal{O}(\\omega n^2)$ small\nmessages that does not use reliable broadcast. Then, we achieve edge agreement\nin a tree of diameter $D$ with $\\lceil \\log_2 D \\rceil$ iterations of a\nmultivalued graded consensus variant. This results in a\n$\\mathcal{O}(\\log\\frac{1}{\\varepsilon})$-round protocol for\n$\\varepsilon$-agreement in $[0, 1]$ with\n$\\mathcal{O}(n^2\\log\\frac{1}{\\varepsilon})$ messages and\n$\\mathcal{O}(n^2\\log\\frac{1}{\\varepsilon}\\log\\log\\frac{1}{\\varepsilon})$ bits\nof communication, improving over the state of the art which matches this\ncomplexity only when the inputs are all either $0$ or $1$. Finally, we extend\nour edge agreement protocol for edge agreement in $\\mathbb{Z}$ and thus\n$\\varepsilon$-agreement in $\\mathbb{R}$ with quadratic communication, in\n$\\mathcal{O}(\\log\\frac{M}{\\varepsilon})$ rounds where $M$ is the maximum honest\ninput magnitude.\n","authors":["Mose Mizrahi Erbes","Roger Wattenhofer"],"pdf_url":"https://arxiv.org/pdf/2408.05495v2.pdf","comment":"25 pages, 3 figures, preprint"},{"id":"http://arxiv.org/abs/2410.00531v1","updated":"2024-10-01T09:18:56Z","published":"2024-10-01T09:18:56Z","title":"TPI-LLM: Serving 70B-scale LLMs Efficiently on Low-resource Edge Devices","summary":"  Large model inference is shifting from cloud to edge due to concerns about\nthe privacy of user interaction data. However, edge devices often struggle with\nlimited computing power, memory, and bandwidth, requiring collaboration across\nmultiple devices to run and speed up LLM inference. Pipeline parallelism, the\nmainstream solution, is inefficient for single-user scenarios, while tensor\nparallelism struggles with frequent communications. In this paper, we argue\nthat tensor parallelism can be more effective than pipeline on low-resource\ndevices, and present a compute- and memory-efficient tensor parallel inference\nsystem, named TPI-LLM, to serve 70B-scale models. TPI-LLM keeps sensitive raw\ndata local in the users' devices and introduces a sliding window memory\nscheduler to dynamically manage layer weights during inference, with disk I/O\nlatency overlapped with the computation and communication. This allows larger\nmodels to run smoothly on memory-limited devices. We analyze the communication\nbottleneck and find that link latency, not bandwidth, emerges as the main\nissue, so a star-based allreduce algorithm is implemented. Through extensive\nexperiments on both emulated and real testbeds, TPI-LLM demonstrated over 80%\nless time-to-first-token and token latency compared to Accelerate, and over 90%\ncompared to Transformers and Galaxy, while cutting the peak memory footprint of\nLlama 2-70B by 90%, requiring only 3.1 GB of memory for 70B-scale models.\n","authors":["Zonghang Li","Wenjiao Feng","Mohsen Guizani","Hongfang Yu"],"pdf_url":"https://arxiv.org/pdf/2410.00531v1.pdf","comment":"This paper is currently under review. Find the code at\n  https://github.com/Lizonghang/TPI-LLM"},{"id":"http://arxiv.org/abs/2409.11765v2","updated":"2024-10-01T08:36:00Z","published":"2024-09-18T07:44:56Z","title":"Massively parallel CMA-ES with increasing population","summary":"  The Increasing Population Covariance Matrix Adaptation Evolution Strategy\n(IPOP-CMA-ES) algorithm is a reference stochastic optimizer dedicated to\nblackbox optimization, where no prior knowledge about the underlying problem\nstructure is available. This paper aims at accelerating IPOP-CMA-ES thanks to\nhigh performance computing and parallelism when solving large optimization\nproblems. We first show how BLAS and LAPACK routines can be introduced in\nlinear algebra operations, and we then propose two strategies for deploying\nIPOP-CMA-ES efficiently on large-scale parallel architectures with thousands of\nCPU cores. The first parallel strategy processes the multiple searches in the\nsame ordering as the sequential IPOP-CMA-ES, while the second one processes\nconcurrently these multiple searches. These strategies are implemented in\nMPI+OpenMP and compared on 6144 cores of the supercomputer Fugaku. We manage to\nobtain substantial speedups (up to several thousand) and even super-linear\nones, and we provide an in-depth analysis of our results to understand\nprecisely the superior performance of our second strategy.\n","authors":["David Redon","Pierre Fortin","Bilel Derbel","Miwako Tsuji","Mitsuhisa Sato"],"pdf_url":"https://arxiv.org/pdf/2409.11765v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.00455v1","updated":"2024-10-01T07:19:21Z","published":"2024-10-01T07:19:21Z","title":"Fine-Grained Vectorized Merge Sorting on RISC-V: From Register to Cache","summary":"  Merge sort as a divide-sort-merge paradigm has been widely applied in\ncomputer science fields. As modern reduced instruction set computing\narchitectures like the fifth generation (RISC-V) regard multiple registers as a\nvector register group for wide instruction parallelism, optimizing merge sort\nwith this vectorized property is becoming increasingly common. In this paper,\nwe overhaul the divide-sort-merge paradigm, from its register-level sort to the\ncache-aware merge, to develop a fine-grained RISC-V vectorized merge sort\n(RVMS). From the register-level view, the inline vectorized transpose\ninstruction is missed in RISC-V, so implementing it efficiently is non-trivial.\nBesides, the vectorized comparisons do not always work well in the merging\nnetworks. Both issues primarily stem from the expensive data shuffle\ninstruction. To bypass it, RVMS strides to take register data as the proxy of\ndata shuffle to accelerate the transpose operation, and meanwhile replaces\nvectorized comparisons with scalar cousin for more light real value swap. On\nthe other hand, as cache-aware merge makes larger data merge in the cache, most\nmerge schemes have two drawbacks: the in-cache merge usually has low cache\nutilization, while the out-of-cache merging network remains an ineffectively\nsymmetric structure. To this end, we propose the half-merge scheme to employ\nthe auxiliary space of in-place merge to halve the footprint of naive merge\nsort, and meanwhile copy one sequence to this space to avoid the former data\nexchange. Furthermore, an asymmetric merging network is developed to adapt to\ntwo different input sizes.\n","authors":["Jin Zhang","Jincheng Zhou","Xiang Zhang","Di Ma","Chunye Gong"],"pdf_url":"https://arxiv.org/pdf/2410.00455v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.04272v5","updated":"2024-10-01T05:20:59Z","published":"2024-07-05T05:55:18Z","title":"Accelerating Communication in Deep Learning Recommendation Model\n  Training with Dual-Level Adaptive Lossy Compression","summary":"  DLRM is a state-of-the-art recommendation system model that has gained\nwidespread adoption across various industry applications. The large size of\nDLRM models, however, necessitates the use of multiple devices/GPUs for\nefficient training. A significant bottleneck in this process is the\ntime-consuming all-to-all communication required to collect embedding data from\nall devices. To mitigate this, we introduce a method that employs error-bounded\nlossy compression to reduce the communication data size and accelerate DLRM\ntraining. We develop a novel error-bounded lossy compression algorithm,\ninformed by an in-depth analysis of embedding data features, to achieve high\ncompression ratios. Moreover, we introduce a dual-level adaptive strategy for\nerror-bound adjustment, spanning both table-wise and iteration-wise aspects, to\nbalance the compression benefits with the potential impacts on accuracy. We\nfurther optimize our compressor for PyTorch tensors on GPUs, minimizing\ncompression overhead. Evaluation shows that our method achieves a 1.38$\\times$\ntraining speedup with a minimal accuracy impact.\n","authors":["Hao Feng","Boyuan Zhang","Fanjiang Ye","Min Si","Ching-Hsiang Chu","Jiannan Tian","Chunxing Yin","Summer Deng","Yuchen Hao","Pavan Balaji","Tong Geng","Dingwen Tao"],"pdf_url":"https://arxiv.org/pdf/2407.04272v5.pdf","comment":"camera-ready version for SC '24"},{"id":"http://arxiv.org/abs/2312.05492v6","updated":"2024-10-01T05:16:31Z","published":"2023-12-09T07:37:38Z","title":"cuSZ-$i$: High-Ratio Scientific Lossy Compression on GPUs with Optimized\n  Multi-Level Interpolation","summary":"  Error-bounded lossy compression is a critical technique for significantly\nreducing scientific data volumes. Compared to CPU-based compressors, GPU-based\ncompressors exhibit substantially higher throughputs, fitting better for\ntoday's HPC applications. However, the critical limitations of existing\nGPU-based compressors are their low compression ratios and qualities, severely\nrestricting their applicability. To overcome these, we introduce a new\nGPU-based error-bounded scientific lossy compressor named cuSZ-$i$, with the\nfollowing contributions: (1) A novel GPU-optimized interpolation-based\nprediction method significantly improves the compression ratio and\ndecompression data quality. (2) The Huffman encoding module in cuSZ-$i$ is\noptimized for better efficiency. (3) cuSZ-$i$ is the first to integrate the\nNVIDIA Bitcomp-lossless as an additional compression-ratio-enhancing module.\nEvaluations show that cuSZ-$i$ significantly outperforms other latest GPU-based\nlossy compressors in compression ratio under the same error bound (hence, the\ndesired quality), showcasing a 476% advantage over the second-best. This leads\nto cuSZ-$i$'s optimized performance in several real-world use cases.\n","authors":["Jinyang Liu","Jiannan Tian","Shixun Wu","Sheng Di","Boyuan Zhang","Robert Underwood","Yafan Huang","Jiajun Huang","Kai Zhao","Guanpeng Li","Dingwen Tao","Zizhong Chen","Franck Cappello"],"pdf_url":"https://arxiv.org/pdf/2312.05492v6.pdf","comment":"camera-ready version for SC '24"},{"id":"http://arxiv.org/abs/2407.04267v5","updated":"2024-10-01T05:07:08Z","published":"2024-07-05T05:42:10Z","title":"A High-Quality Workflow for Multi-Resolution Scientific Data Reduction\n  and Visualization","summary":"  Multi-resolution methods such as Adaptive Mesh Refinement (AMR) can enhance\nstorage efficiency for HPC applications generating vast volumes of data.\nHowever, their applicability is limited and cannot be universally deployed\nacross all applications. Furthermore, integrating lossy compression with\nmulti-resolution techniques to further boost storage efficiency encounters\nsignificant barriers. To this end, we introduce an innovative workflow that\nfacilitates high-quality multi-resolution data compression for both uniform and\nAMR simulations. Initially, to extend the usability of multi-resolution\ntechniques, our workflow employs a compression-oriented Region of Interest\n(ROI) extraction method, transforming uniform data into a multi-resolution\nformat. Subsequently, to bridge the gap between multi-resolution techniques and\nlossy compressors, we optimize three distinct compressors, ensuring their\noptimal performance on multi-resolution data. Lastly, we incorporate an\nadvanced uncertainty visualization method into our workflow to understand the\npotential impacts of lossy compression. Experimental evaluation demonstrates\nthat our workflow achieves significant compression quality improvements.\n","authors":["Daoce Wang","Pascal Grosset","Jesus Pulido","Tushar M. Athawale","Jiannan Tian","Kai Zhao","Zarija Lukić","Axel Huebl","Zhe Wang","James Ahrens","Dingwen Tao"],"pdf_url":"https://arxiv.org/pdf/2407.04267v5.pdf","comment":"camera-ready version for SC '24"}]}}